{
  "Task-level Accuracy & Performance": [
    "completely correct response rate",
    "expert-rated accuracy",
    "human-graded accuracy",
    "top-3 diagnostic accuracy",
    "accuracy/success rate",
    "global assessment scores",
    "expert accuracy rating (4-point scale)",
    "correctness of first aid instructions",
    "nursing process scores",
    "SOLO taxonomy accuracy score",
    "macro-averaged F1 score",
    "macro-F1 score",
    "performance benchmark (unspecified)",
    "MPE",
    "RAGAs Context Recall",
    "F1 (implied)",
    "task-specific automatic metrics",
    "Likert scale ratings (accuracy, completeness, empathy)",
    "accuracy (Likert)",
    "surgeon accuracy ratings",
    "7-point Likert accuracy scale",
    "Top-5 accuracy",
    "unsure (likely segmentation metrics such as Dice score)",
    "reference location accuracy",
    "7-point Likert scale (accuracy, consistency, relevance)",
    "Likert scale for accuracy",
    "5-point Likert ratings for accuracy, completeness, safety",
    "percentage correct answers",
    "scores",
    "accuracy vs validated answers",
    "cumulative mean score",
    "unspecified (likely precision/recall/F1)",
    "reasonableness of medical advice (accuracy)",
    "response relevance",
    "custom scoring rubric (0\u20134 for descriptions, 0\u20132 for diagnoses)",
    "expert accuracy assessment",
    "5-point Likert accuracy rating",
    "weighted accuracy",
    "completeness and accuracy rubric",
    "output structure compliance rate",
    "qualitative accuracy assessment",
    "explanation accuracy/comprehensiveness",
    "macro precision",
    "compliance rate",
    "mean rank",
    "accuracy",
    "top-k accuracy",
    "categorical accuracy (correct/partially correct/incorrect/other)",
    "severity score",
    "ranking performance",
    "Visual Analogue Scale for Pain (VAS-P)",
    "exact match for quantitative metrics",
    "Likert-scale accuracy score",
    "rank position",
    "CVSA (concordance, validity, safety, accuracy)",
    "first choice accuracy",
    "pass\u2013fail threshold",
    "manual correctness classification (correct/hedging/incorrect)",
    "semiquantitative Likert-style ratings of accuracy and clinical utility",
    "percent correct diagnoses",
    "Likert-scale ratings of accuracy and completeness",
    "recommendation frequency",
    "Hits@1",
    "macro-averaged F1",
    "proportion of correct diagnoses in top 3",
    "expert correctness rating",
    "complete error rate",
    "5-point Likert scale (accuracy, completeness, helpfulness, specificity, overall quality)",
    "physician rating scores (0-10) for accuracy, comprehensiveness, credibility",
    "proportion of satisfactory responses",
    "average score",
    "expert qualitative assessment of factual accuracy",
    "accuracy (correct answer rate)",
    "root mean square error",
    "Artificial Intelligence Performance Instrument",
    "recommendation accuracy",
    "task-specific quantitative metrics (e.g., accuracy, mAP, IoU)",
    "extended accuracy",
    "subjective accuracy assessment",
    "Z scores compared to clinician norms",
    "percentile rank vs residents",
    "primary diagnosis accuracy",
    "percentage correctness",
    "accuracy (top-1)",
    "graded accuracy categories",
    "top-5 accuracy",
    "top-1 diagnostic accuracy",
    "reasoning accuracy",
    "number and types of drug-related problems identified",
    "accuracy on Diabetes Knowledge Questionnaire",
    "score difference percentage",
    "number and type of errors",
    "Likert accuracy rating (1-5)",
    "correct response rate",
    "exam score / percentage correct",
    "factual accuracy percentage",
    "accuracy of standardized nursing terminology",
    "number of clinically relevant pDDIs detected",
    "differential inclusion rate",
    "response accuracy",
    "misclassification count",
    "exam accuracy",
    "accuracy (right/wrong)",
    "medical accuracy rating",
    "expert rating (correct/comprehensive)",
    "accuracy vs reference standard",
    "MSE",
    "Likert scale ratings for medical accuracy (1\u20136) and completeness (1\u20133)",
    "MME benchmark perceptual score",
    "accuracy (unspecified)",
    "expert rating (0-2 accuracy/completeness scale)",
    "proportion correctly classified",
    "nutrient accuracy",
    "Likert scale (accuracy)",
    "mean absolute error",
    "percentage error",
    "Recall@K",
    "answer relevancy score",
    "exam percentage score",
    "unspecified performance metrics",
    "OSCE checklist scores",
    "Mean Reciprocal Rank",
    "Likert-style 0-5 scoring (accuracy, comprehensiveness, relevance, clarity)",
    "rank position of correct diagnosis",
    "ICD-10 coding accuracy",
    "expert-rated accuracy (correct/partially correct/incorrect)",
    "accuracy/comprehensiveness ratings",
    "exam pass threshold",
    "50%-responder rate",
    "inaccurate information rate",
    "proportion with hyperkalemia",
    "percent correct (accuracy)",
    "question accuracy score (Likert)",
    "Likert scales for accuracy and completeness",
    "regression performance",
    "step accuracy",
    "modified Turing test (source identification accuracy)",
    "accuracy shift",
    "4-point rating scale for clarity, accuracy, evidence-based content",
    "mean HEART score",
    "net score",
    "correct triage rate",
    "medication adherence rate",
    "misinterpretation rate",
    "exam score / accuracy",
    "accuracy score",
    "counts/proportions",
    "5-point Likert scale (accuracy, rationale, relevance, trustworthiness)",
    "accuracy (correct response rate)",
    "expert Likert-style ratings for accuracy, relevance, coherence, clarity, practical utility, ethical considerations, empathy, responsiveness",
    "inaccuracy rating",
    "Likert scale (accuracy, relevance, depth)",
    "accuracy (formal accuracy)",
    "Accuracy",
    "prediction error",
    "accuracy/performance score",
    "diagnosis ranking",
    "detection accuracy (unspecified)",
    "ranked accuracy",
    "weighted average score",
    "proportion correct (accuracy)",
    "passing rate",
    "accuracy rating (Likert scale)",
    "pass/fail relative to cutoff",
    "exam score percentage",
    "Generative AI Performance Score (G-PS)",
    "condition-specific accuracy",
    "expert accuracy review",
    "task-specific metrics (e.g., F1, accuracy, ROUGE)",
    "Likert scale ratings for accuracy, comprehensiveness, similarity",
    "physician accuracy rating scale",
    "QAMAI (accuracy, clarity, relevance, completeness, source quality, usefulness)",
    "diagnostic accuracy (point-based score)",
    "micro-F1",
    "percentile rank",
    "top-3 accuracy",
    "do-not-miss accuracy",
    "expert grading (correct/comprehensive vs. containing errors)",
    "Likert scale ratings (correctness, completeness, conciseness, potential harm)",
    "mean error",
    "6-point Likert scale for accuracy and completeness",
    "binary accuracy (correct diagnosis in top 3)",
    "ordering score",
    "checklist compliance percentage",
    "Likert scale ratings (accuracy, comprehensiveness, conciseness, satisfaction)",
    "accuracy grading",
    "hit rate",
    "F1 score",
    "4-point expert accuracy grading",
    "exam score/accuracy",
    "expert grading (correct / partially correct / incorrect)",
    "failure rate",
    "percentage of correct answers",
    "incorrect statement rate",
    "accuracy (correct categorization)",
    "composite proficiency score",
    "answer accuracy",
    "diagnostic accuracy (%)",
    "Likert scale (relevance, completeness, accuracy)",
    "standard classification metrics (e.g., F1, accuracy)",
    "clinician scoring (0\u201310 for accuracy, completeness, safety)",
    "aggregate weighted normalized score",
    "accuracy percentage on true-false questions",
    "differential diagnosis percentile ranking",
    "adherence rate",
    "Likert scale (professionalism and accuracy)",
    "expert grading (correct / incomplete / false)",
    "estimate error",
    "expert accuracy rating (accurate/partially accurate/inaccurate)",
    "three-point accuracy rating",
    "5-point Likert scale accuracy ratings",
    "Relative Comparative Score (RCS)",
    "missing answer recall",
    "Likert scale accuracy rating (1\u20135)",
    "accuracy categories",
    "expert accuracy rating (percentage correct)",
    "Likert scale ratings (accuracy, comprehensibility, correlation)",
    "qualitative assessment (accuracy, informativeness, accessibility)",
    "symptom retention",
    "expert pharmacist clinical accuracy rating",
    "diagnostic accuracy (correct / partial / incorrect)",
    "factual accuracy",
    "manual accuracy grading",
    "physician-rated accuracy",
    "inclusion of correct diagnosis",
    "attack success rate",
    "accuracy of cardiac arrest recognition",
    "comparison to passing threshold",
    "median percentage change in seizures",
    "Likert scale ratings (accuracy, comprehensiveness)",
    "percentage correct recommendations",
    "subjective ratings (accessibility, informativeness, accuracy)",
    "average score (0-2 scale)",
    "score percentage",
    "presence of incorrect information",
    "response relevance and accuracy scores",
    "4-point scale for accuracy, clarity, appropriateness",
    "Likert-scale accuracy (0\u20132)",
    "accuracy difference (%)",
    "unspecified quantitative performance comparison",
    "prescription accuracy",
    "expert rating (accuracy, completeness, readability)",
    "clinician accuracy score (0-10)",
    "4-point accuracy rating by experts",
    "expert correctness assessment",
    "5-level subjective accuracy scale",
    "4-tier accuracy rating",
    "Likert scale ratings (accuracy and comprehensiveness)",
    "expert judgment (accurate / inaccurate / unreliable)",
    "accuracy (implied)",
    "multi-dimensional Likert-style scoring (correctness, completeness, readability, helpfulness, safety, satisfaction)",
    "inclusion of correct diagnosis in differential",
    "Top-2 accuracy",
    "expert grading of accuracy, comprehensiveness, reproducibility",
    "subjective categorical grading (excellent/satisfactory/unsatisfactory)",
    "30-second sit-to-stand repetitions",
    "clinician accuracy rating (-1/0/1)",
    "count accuracy",
    "percent correct",
    "Likert scales for accuracy, completeness, comprehensibility",
    "expert-rated correctness/comprehensiveness categories",
    "mean percentage score",
    "6-point Likert scale ratings for accuracy and completeness",
    "subjective pass/fail assessment",
    "clinical validation success rate",
    "Global Quality Score",
    "Likert-scale accuracy (1\u20136)",
    "accuracy (case identification rate)",
    "four-level accuracy scale",
    "diagnostic reasoning score",
    "effectiveness",
    "percentage correct (accuracy)",
    "Likert scale scores (accuracy, relevance, clarity, utility, comprehensiveness)",
    "mean absolute error (MAE)",
    "expert 1\u20134 correctness scale",
    "subjective accuracy",
    "error analysis",
    "final diagnosis accuracy",
    "differential score",
    "correctness of emergency call advice",
    "thematic accuracy",
    "accuracy (presumed)",
    "accuracy/percentage correct",
    "modified Artificial Intelligence Performance Index (AIPI)",
    "percentage of key content included (accuracy)",
    "5-point Likert scale for accuracy",
    "identification of minor/major inaccuracies",
    "accuracy of surgeon identification",
    "Likert scale ratings of accuracy",
    "manual accuracy check",
    "Likert-scale ratings (accuracy, applicability, comprehensiveness, clarity)",
    "iterations required",
    "LLM pairwise win rate",
    "proportion correct diagnosis in top 3",
    "CUI F1-score",
    "first-rank accuracy",
    "accuracy (correct/partially correct/incorrect)",
    "correctness percentage",
    "misidentification percentage",
    "Likert scale ratings of accuracy and relevance",
    "management accuracy",
    "overall standardized score",
    "accuracy (correct/incorrect counts)",
    "human accuracy rating scale",
    "scientific correctness",
    "passing threshold",
    "Likert scale ratings (accuracy, comprehensiveness, readability, overall quality)",
    "three-point accuracy scale",
    "5-point accuracy/comprehensiveness scale",
    "4-point expert rating scale (accuracy, comprehensiveness, safety)",
    "percentage of partially correct CPT codes",
    "overall alignment rate",
    "accuracy (correct/incorrect as judged by pharmacists)",
    "reference accuracy score (0\u20132)",
    "exam grade (percentage)",
    "regression error (unspecified)",
    "Precision@10",
    "accuracy ratings",
    "4-point Likert scale for accuracy",
    "net positive inference rate (NPIR)",
    "decision accuracy",
    "proportion of prompts triggering referral",
    "union accuracy",
    "correctness scores",
    "effective rate",
    "Likert-scale ratings (1-5) on relevance, accuracy, clarity, completeness, evidence-based, consistency",
    "error score",
    "Likert scale for accuracy (1\u20136)",
    "text error rate",
    "Loss",
    "estimation error (mean \u00b1 SD)",
    "effectiveness rate",
    "correct match rate",
    "correct / partially correct / incorrect classification",
    "Likert scale ratings (accuracy, completeness)",
    "Likert scale (accuracy 1\u20136, completeness 1\u20133)",
    "accuracy rate",
    "Likert-scale ratings for accuracy",
    "3-point correctness scale",
    "3-tier accuracy grading",
    "mean accuracy score",
    "4-point human accuracy grading scale",
    "percent correct / pass threshold",
    "percent correct / accuracy",
    "hierarchical correctness scale",
    "top-1/top-3 diagnostic accuracy",
    "expert accuracy rating (good/borderline/poor)",
    "medical entity recognition",
    "accuracy rating (Likert)",
    "AISAS (accuracy, completeness, clarity, readability)",
    "5-point Likert scale for coherency, factuality, comprehensiveness, safety",
    "final SIRI-2 score",
    "translation accuracy",
    "response relevancy",
    "Likert-scale ratings (1\u20135) of accuracy, clarity, efficacy",
    "accuracy (correct/incorrect classification)",
    "Likert-style correctness score",
    "answer relevance",
    "error analysis of image feature descriptions",
    "Likert scale ratings (1\u20135) for accuracy, comprehensiveness, safety",
    "top-3 inclusion rate",
    "exact match ratio",
    "performance rating (moderate proficiency)",
    "AI/human identification accuracy",
    "number correct",
    "5-point Likert scale accuracy score",
    "global module scores",
    "5-point Likert ratings (accuracy, comprehensiveness, similarity)",
    "average error rate (AER)",
    "exam score/pass rate",
    "exact match rate",
    "0-100 quality score",
    "5-point Likert scale for completeness, misleadingness, accuracy, up-to-dateness, appropriateness",
    "percentage of correct CPT codes",
    "proportion above threshold",
    "percentage correct/incorrect classifications",
    "identification accuracy",
    "5-point Likert ratings (currency, relevance, accuracy, comprehensiveness, clarity, urgency)",
    "global quality score",
    "expert rating scale (4-point accuracy/thoroughness rubric)",
    "pass/fail threshold",
    "logic-adjusted accuracy",
    "accuracy/completeness ratings",
    "1\u20135 accuracy score",
    "Likert scale ratings for clarity and accuracy",
    "mean rank score",
    "differential diagnosis score (DDx Score)",
    "Likert scale accuracy ratings",
    "Journal of American Medical Association benchmark",
    "diagnostic accuracy (unspecified)",
    "subjective ratings (accuracy, relevance)",
    "accuracy score (1-5)",
    "three-tier clinical accuracy rating",
    "physician ratings for accuracy, comprehensiveness, understandability",
    "expert quality and accuracy ratings (Likert-style)",
    "AIPI score",
    "accuracy (correct / partially correct / incorrect)",
    "5-point Likert ratings (accuracy, comprehensiveness, overall quality)",
    "clinical error metrics",
    "dosage accuracy",
    "error count",
    "Likert scale ratings (accuracy, clarity, relevance)",
    "dosimetric metrics (target coverage, homogeneity, OAR sparing)",
    "exam score / number of correct answers",
    "expert grading (comprehensive/correct but inadequate/incorrect)",
    "ranking position of correct diagnosis",
    "Turing test pass rate",
    "expert binary correctness rating (accurate / inaccurate / unreliable)",
    "rubric score (0-10)",
    "accuracy of suggested tests",
    "SOLO taxonomy accuracy level",
    "accuracy score (1/0.5/0)",
    "INR compliance rate",
    "three-point Likert scale (0-2) for correctness",
    "response rate (non-answers)",
    "G-Eval",
    "5-point Likert ratings (relevance, accuracy, clarity, completeness)",
    "diagnostic accuracy",
    "Script Concordance Test score (%)",
    "human ratings of correctness",
    "electronic visual analog scale",
    "average magnitude of errors (AME)",
    "top-10 accuracy",
    "conversational reasoning performance",
    "accuracy / percent correct",
    "0\u201310 Likert scale ratings for correctness, completeness, safety",
    "accuracy classification (completely/partially correct/incorrect)",
    "percentage score",
    "accuracy/percent correct",
    "5-point Likert scales (accuracy, completeness, clarity, clinical relevance, naturalness)",
    "expert grading (accuracy, comprehensiveness)",
    "accuracy rating (correct/partially correct/incorrect/unanswered)",
    "accuracy grading (correct/incomplete/mixed/irrelevant)",
    "mean average precision (MAP)",
    "diagnostic accuracy (top-5 inclusion)",
    "categorical accuracy grading (comprehensive/correct but inadequate/etc.)",
    "expert-rated accuracy (percentage correct)",
    "pass threshold",
    "number of inaccuracies identified by experts",
    "accuracy/misinformation rating",
    "5-point Likert ratings for factual accuracy, relevance, completeness, coherence, fluency",
    "subjective global accuracy/relevance assessment",
    "accuracy (correct vs incorrect)",
    "detail score",
    "accuracy scores",
    "expert grading (4-point accuracy/completeness scale)",
    "QAMAI score",
    "over-triage rate",
    "triage urgency accuracy",
    "mean squared error",
    "proportion correct",
    "accuracy score (1\u20136)",
    "diagnostic accuracy (correct diagnosis in top 3)",
    "HPI content retrieval accuracy",
    "score with penalty",
    "accuracy (yes/no)",
    "terminology accuracy",
    "expert 4-point accuracy/completeness rating",
    "accuracy (%)",
    "passing score",
    "accuracy of observations",
    "expert Likert ratings (accuracy, conciseness, readability)",
    "expert Likert ratings (accuracy and completeness)",
    "accuracy (correct/incorrect/insufficient)",
    "pass threshold comparison",
    "accuracy (unsure)",
    "detection accuracy",
    "traffic light categorical rating (adequate / needs reformulation / incorrect)",
    "functional testing outcomes",
    "error counts",
    "number of correct diagnoses",
    "expert grading on 0\u20132 accuracy scale",
    "correct identification of specific risks (binary hit/miss)",
    "proportion of correct facts vs. consensus",
    "chart score",
    "pass rate",
    "success rate",
    "Key-Features Questions score",
    "SCALE",
    "rate of correct answers (accuracy)",
    "urgency classification accuracy",
    "Artificial Intelligence Performance Instrument (AIPI) treatment subscore",
    "percent correct event identification",
    "custom 6-point accuracy/safety scale (-2 to 3)",
    "accuracy rating (1\u20136)",
    "accuracy percentage",
    "accuracy of recommendations",
    "comparative risk ratings",
    "3-point Likert scale for accuracy, relevance, comprehensiveness",
    "qualitative assessment of precision",
    "4-point Likert scale for accuracy, quality, empathy",
    "4-point Likert scale ratings of accuracy, precision, clarity",
    "answer accuracy (%)",
    "error detection rate (accuracy)",
    "percentage accuracy",
    "overall exam score/pass-fail",
    "automatic accuracy metrics",
    "Likert scale ratings (correctness, relevance, completeness, linguistic accuracy, usefulness)",
    "QAMAI questionnaire (Accuracy, Clarity, Relevance, Completeness, Sources, Usefulness)",
    "misdiagnosis rate",
    "diagnostic reasoning score (%)",
    "F-score",
    "balanced accuracy",
    "expert rating of accuracy",
    "Correctness",
    "5-point Likert scale (accuracy, comprehensiveness, ease of understanding, human care, clinical case analysis ability)",
    "pass mark comparison",
    "6-point Likert accuracy scale",
    "expert rating scales (accuracy 6-point, completeness 3-point, appropriateness 3-point)",
    "correctness score",
    "5-point Likert scale accuracy rating",
    "4-point accuracy grading scale",
    "factual accuracy rate",
    "ASR performance metrics",
    "FORTE F1-score",
    "GPT-4 automated scoring",
    "Likert accuracy score",
    "F1-micro",
    "3-point Likert-like scale for correctness, completeness, adaptability",
    "pass/fail rate",
    "4-point accuracy/completeness scale",
    "correct answer rate",
    "expert-rated accuracy/adequacy",
    "5-point Likert scales (correctness, completeness, readability, helpfulness, safety)",
    "USMLE accuracy/performance",
    "proportion of correct diagnoses",
    "3-point Likert scale for accuracy and completeness",
    "tiered correctness classification",
    "proportion selecting metformin",
    "noninferiority vs human performance",
    "30-day point prevalence abstinence",
    "percentage correct",
    "Likert scale ratings (1-5) for relevance, accuracy, clarity, completeness",
    "accuracy score (1\u20134)",
    "DDxScore",
    "clinical accuracy",
    "triage accuracy",
    "four-point accuracy scale",
    "prevalence accuracy",
    "expert grading of scientific correctness",
    "MAE",
    "expert accuracy rating",
    "expert accuracy scores",
    "accuracy (number of correct answers)",
    "percentile ranking",
    "mean accuracy",
    "accuracy assessment",
    "unspecified performance metrics (e.g., accuracy)",
    "percentage of sentences incorrectly translated",
    "accuracy (number of correct protocols)",
    "clinician-rated accuracy",
    "5-point Likert scale (accuracy, completeness, harmfulness, helpfulness, intelligibleness)",
    "comparative accuracy rating (Arabic vs English)",
    "top-1 diagnosis match rate",
    "final score",
    "error classification",
    "top-1 accuracy",
    "Journal of the American Medical Association benchmark",
    "3-point Likert scale accuracy ratings",
    "expert-graded accuracy",
    "correctness scoring",
    "subjective Likert-scale ratings (accuracy, completeness, grammar, potential harm, comfort)",
    "error categorization (misleading/incorrect)",
    "correctness",
    "accuracy (normalized score)",
    "accuracy (percent correct AO codes)",
    "clinician Likert ratings for conciseness, completeness, correctness, clinical utility",
    "medical error rate",
    "custom content accuracy questions",
    "exam pass rate/score",
    "expert rating (accuracy and rationality)",
    "passing score threshold",
    "Top-5 Accuracy",
    "expert accuracy ratings",
    "qualitative assessment of correctness and comprehensiveness",
    "median rank of correct diagnosis",
    "accuracy (percentage match)",
    "accuracy proportion",
    "Likert-scale ratings for accuracy/appropriateness",
    "number of medical errors",
    "comparative superiority judgement",
    "accuracy (percent correct)",
    "percentage correct/accuracy",
    "graded accuracy (A-D)",
    "classification metrics (unspecified)",
    "LLM-as-judge semantic correctness",
    "response rate",
    "Likert scale ratings (clinical accuracy, grammatical accuracy, stylistic quality)",
    "5-point Likert scale (accuracy, safety, comprehensiveness)",
    "Likert scale ratings (accuracy, usefulness)",
    "expert rubric scores (0\u20135) for conciseness, completeness, correctness",
    "3-point accuracy/sufficiency rating scale",
    "coding accuracy",
    "presence of correct diagnosis anywhere in list",
    "normalized diagnostic accuracy (%)",
    "root mean squared error",
    "diagnostic accuracy rate",
    "JAMA benchmark score",
    "Likert scale ratings for accuracy, completeness, conciseness",
    "weighted scoring (out of 50)",
    "number of INR values within target range",
    "expert grading scale (4-point correctness/comprehensiveness)",
    "error rate",
    "dosage correctness",
    "accuracy (number of correct triage classifications)",
    "accuracy categorization",
    "expert rating (0-4) of accuracy, clarity, and conciseness",
    "5-point accuracy scale",
    "lenient accuracy",
    "Likert scale ratings (correctness, comprehensibility, relevance, empathy)",
    "pertinence percentage",
    "content accuracy",
    "modality identification accuracy",
    "error rates",
    "accuracy rating (1\u20134)",
    "pass rate probability",
    "recognition accuracy",
    "percentage correctness/comprehension",
    "expert ratings (accuracy, currency, completeness)",
    "Likert-scale ratings (readability, completeness, curation, correctness, usefulness, patient safety)",
    "observation scores",
    "error type distribution",
    "macro F1",
    "Likert scale ratings for accuracy and completeness",
    "pass/fail rating",
    "5-point Likert scale (accuracy, clarity, detail, adequacy)",
    "regional accuracy rate (RAR)",
    "manual accuracy rating",
    "5-point Likert scale on factual consistency, comprehensiveness, coherence, medical harmfulness",
    "surgeon grading of accuracy",
    "diagnosis accuracy",
    "classification accuracy",
    "medical knowledge accuracy",
    "R-squared",
    "accuracy rate (correct / partially correct / incorrect / non-answer)",
    "1-10 Likert scale for accuracy/completeness",
    "expert 4-level accuracy scale",
    "accuracy (percentage of questions answered correctly)",
    "rank position distribution",
    "accuracy rating (6-point scale)",
    "percentage caloric deviation",
    "0\u20134 expert accuracy rating scale",
    "error correction rate",
    "Likert scale accuracy rating",
    "JAMA Benchmark",
    "expert-rated accuracy categories",
    "accuracy categorization (accurate/partial/inaccurate)",
    "subjective researcher assessment of accuracy",
    "exam score (percentage correct)",
    "examiner pass likelihood rating",
    "correct diagnosis rate (top-10, top-5, top-1)",
    "Likert scale accuracy",
    "3-point Likert accuracy score",
    "5-point expert accuracy rating",
    "test score / accuracy",
    "scaled score",
    "accuracy (percentage score)",
    "percentage difference from target energy and protein levels",
    "accuracy rating",
    "success rate (% satisfactory actions)",
    "MAPE",
    "0-2 scoring system",
    "accuracy (specific metric not stated)",
    "accuracy (error categorization)",
    "Macro-F1",
    "RadGraph F1",
    "4-point expert accuracy scale",
    "accuracy (proportion of correct responses)",
    "accuracy (% correct)",
    "Recall@k",
    "aggregate performance score",
    "percentage correctness categories",
    "percent accuracy",
    "exam score (% correct)",
    "correctness rate",
    "1-to-5 accuracy scale",
    "custom answer scoring system (-1 to 2)",
    "numeric score",
    "number of correct answers",
    "error detection rate",
    "5-point Likert scale for accuracy and completeness",
    "diagnostic accuracy (details unspecified)",
    "error analysis of feature descriptions",
    "medical accuracy",
    "4-point Likert-style accuracy/clarity scale",
    "diagnostic ranking",
    "Strict Accuracy",
    "medical proficiency",
    "JAMA benchmarks",
    "expert accuracy scoring",
    "BI-RADS classification accuracy",
    "4-point Likert accuracy scale",
    "5-point Likert scale for correctness",
    "proportion meeting all criteria",
    "percentage of correct evaluations",
    "1\u20134 correctness score",
    "rubric score (out of 50)",
    "accuracy checklist",
    "accuracy (7.90% improvement)",
    "triage accuracy categories (agree/unsafe/too cautious)",
    "Likert scale ratings for relevance, accuracy, novelty",
    "3-point Likert ratings for accuracy",
    "expert Likert rating (correct/partially correct/incorrect)",
    "5-point Likert scale accuracy",
    "Likert-scale ratings (accuracy)",
    "subjective ratings of accuracy, usefulness, clarity",
    "Likert-scale ratings of accuracy, comprehensiveness, validity",
    "4-point accuracy scoring rubric",
    "six quality metrics (e.g., accuracy, clarity, objectivity, etc.)",
    "overall score (1\u20135)",
    "six-point Likert scale (accuracy)",
    "pass-fail threshold",
    "accuracy (presence in top-3)",
    "7-point Likert ratings for correctness, reliability, safety, usability",
    "diagnostic accuracy (final diagnosis in top 10)",
    "subjective 5-level accuracy rating",
    "overall accuracy",
    "instruction adherence",
    "comparison to random guessing",
    "binary correctness grading",
    "top-10 diagnostic inclusion accuracy",
    "expert grading of accuracy/comprehensiveness",
    "Likert scale ratings (accuracy, relevance, empathy, completeness, practicality)",
    "first-pass diagnostic accuracy",
    "correlation with ground truth",
    "top-N accuracy",
    "accuracy (proportion correct)",
    "expert scoring of comprehensiveness and accuracy",
    "location accuracy",
    "presence of gross inaccuracies",
    "Top-1 accuracy",
    "refusal rate",
    "Likert-scale ratings for relevance, accuracy, completeness, understandability",
    "3-point accuracy scale",
    "expert adjudication of medical accuracy",
    "5-point Likert accuracy score",
    "exact triage accuracy",
    "percentage error in nutrient values",
    "ease-of-question percentages",
    "side effect rate",
    "5-point Likert correctness scale",
    "Likert-scale ratings (accuracy, clarity, completeness, relevance)",
    "accuracy (percentage correct)",
    "accuracy in identifying inappropriate medications/interactions",
    "accuracy (likely)",
    "expert ratings of logical errors",
    "Top-5 diagnostic accuracy",
    "presence of inaccurate statements",
    "accuracy (survey-based rating)",
    "unspecified task-specific quantitative metrics",
    "overall percentage score/pass rate",
    "0\u201310 correctness scale rated by pharmacists",
    "pass/fail threshold comparison",
    "accuracy rating (1-5)",
    "normalized mean square error",
    "custom grading scale (4-level accuracy categories)",
    "expert grading for correctness and comprehensiveness",
    "7-point Likert scale for correctness",
    "categorical accuracy ratings",
    "expert scoring of accuracy, correctness, completeness, safety",
    "7-point Likert scale for accuracy, completeness, satisfaction",
    "various task-specific metrics",
    "reference accuracy",
    "pass rate (\u226560%)",
    "macro average",
    "4-point Response Accuracy Score (Likert-style)",
    "accuracy vs German Drug Directory",
    "F1 Score",
    "4-point accuracy rating",
    "mean score",
    "ABA SOE topic scores",
    "intent recognition accuracy",
    "grade A\u2013E classification",
    "radiologist accuracy ratings",
    "diagnostic accuracy (success rate)",
    "residual error",
    "accuracy (correct/incorrect/misleading classification)",
    "predictive accuracy (regression/correlation with future PHQ-9)",
    "prediction accuracy",
    "pass/fail relative to historical pass mark",
    "percentage correct identification",
    "overall accuracy (%)",
    "overall benchmark score",
    "percent correct answers",
    "exam pass rate",
    "translation error count",
    "Likert Scale (accuracy/completeness)",
    "referral adherence",
    "inclusion of correct diagnosis in top-10 list",
    "multiple-choice accuracy rate",
    "human expert rating of accuracy",
    "binary accuracy",
    "Top-10 accuracy",
    "Likert scale accuracy score",
    "Artificial Intelligence Performance Instrument (AIPI)",
    "overall score",
    "accuracy scale (1-5)",
    "Likert-scale expert accuracy rating",
    "manual accuracy checking",
    "correct / partially correct / incorrect rating",
    "pass/fail",
    "rate of non-numerical outputs",
    "4-point accuracy scale",
    "RMSLE",
    "human ratings of accuracy (entirely correct/mostly correct)",
    "manual accuracy",
    "macro-F1",
    "Mika et al. scoring system",
    "6-point accuracy scale",
    "0\u201310 rating scales (accuracy, comprehensiveness, reliability)",
    "accuracy scoring",
    "accuracy Likert scale",
    "functional tests",
    "accuracy ratings by reviewers",
    "micro F1",
    "technical skill ratings",
    "total score (TS)",
    "exam pass/fail",
    "quality of reasoning",
    "diagnostic accuracy (inclusion of correct diagnosis)",
    "medical accuracy score",
    "mean scores",
    "expert grading (accuracy and clinical relevance)",
    "summarization score",
    "Likert-scale accuracy scores",
    "Likert scale ratings (correctness, relevance, completeness, linguistic accuracy)",
    "Likert-scale ratings for accuracy, informativeness, accessibility"
  ],
  "Safety & Harm Assessment": [
    "patient safety",
    "under-triage rate",
    "error counts (content, trust-breaking, post-therapy misconduct)",
    "expert ratings: severity of harm",
    "critical failure count",
    "risk of patient harm",
    "percentage of life-threatening recommendations",
    "proportion of responses deemed safe",
    "safety issue rate",
    "danger score",
    "harm severity",
    "potential medical harm rating",
    "harmful response rate",
    "human ratings of safety and usability",
    "critical error count",
    "theoretical harm assessment",
    "identification of pitfalls",
    "risk of harm assessment",
    "dangerous information presence",
    "risk management",
    "toxicity assessment",
    "occurrences of warning INR values",
    "frequency of clinically significant category changes",
    "percentage of harmful safety issues",
    "harmfulness assessment",
    "Likert-scale ratings for potential harm",
    "safety assessment",
    "safety/no-harm assessment",
    "recommendation to call emergency services",
    "safety",
    "safety metrics (incorrect information, likelihood of harm, extent of harm, missing content)",
    "critical failure rate",
    "safety (no harm)",
    "harmfulness rating",
    "recommendation to consult professional",
    "potential for harm",
    "safety (under/over triage)",
    "three-tier clinical safety assessment",
    "likelihood/extent of harm",
    "incidence of harmful recommendations",
    "likelihood of harm (subjective)",
    "near-miss event rate",
    "undertriage rate",
    "safety score (1\u20133)",
    "rate of risky/unrealistic information",
    "number of medication errors",
    "number of disinformation blogs generated",
    "categorization of error severity (minor/major/critical)",
    "potential harmful errors score",
    "direction of prognosis (optimistic vs pessimistic)",
    "human clinical safety assessment",
    "Hartwig scale",
    "health risk assessment",
    "Likert scale for misinformation",
    "hazard assessment",
    "potential risk",
    "unnecessary biopsy rate",
    "safety classification",
    "safety ratings",
    "presence of disclaimer",
    "rubric scores for safety, accuracy, relevance",
    "5-point Likert for misinformation",
    "rate of unnecessary or harmful medications",
    "threat rating (none/mild/moderate/high)",
    "harmlessness",
    "recommendation to seek medical review",
    "overconclusiveness",
    "medical harmfulness",
    "safety rating",
    "toxicity",
    "potential harm rate",
    "possibility of harm (%)",
    "safety grading",
    "harm potential",
    "risk of harm"
  ],
  "Clinical Appropriateness & Guideline Concordance": [
    "agreement with meta-analyses",
    "expert rating scale (1\u20134 accuracy/appropriateness)",
    "NCCN concordance",
    "appropriateness rate",
    "manual grading for appropriateness (RA/RI/unreliable)",
    "accuracy versus guideline",
    "binary criteria (coherence, scientific correctness, appropriateness)",
    "expert rating (1-4 scale)",
    "guideline agreement percentage",
    "Ottawa Clinic Assessment Tool",
    "expert quality score (0-10)",
    "qualitative expert assessment",
    "qualitative expert relevance rating",
    "surgeon appropriateness rating (appropriate/inappropriate/unreliable)",
    "JAMA Benchmark Criteria Score",
    "rate of appropriate suggestions",
    "guideline-concordance (unsure)",
    "4-point Likert scale for appropriateness and accuracy",
    "rating scale (1\u20135) vs EAU guidelines",
    "concordance with experts",
    "percentage adherence to guidelines",
    "clinical utility rating",
    "proportion evidence-based",
    "guideline conformity",
    "guideline adherence categories",
    "expert appropriateness assessment",
    "Alignment Compliance Index (ACI)",
    "subjective expert assessment (plausibility, usefulness)",
    "antibiotic appropriateness (expert rated)",
    "source appropriateness",
    "necessity of prescriptions",
    "agreement with expert consensus (inclusion of optimal and poor choices)",
    "adequacy grading (optimal/satisfactory/harmful)",
    "expert domain-specific ratings",
    "clinical recommendation score",
    "presence of physician recommendation",
    "justification appropriateness",
    "concordance with multidisciplinary tumor board",
    "guideline consistency percentage",
    "expert ratings: alignment with medical consensus",
    "5-point Likert ratings (safety, guideline adherence, adequacy, completeness, overall quality)",
    "agreement with guideline recommendations",
    "appropriateness of preclinical measures",
    "concordance with expert consensus",
    "subjective content appropriateness",
    "over/under-recommendation rates",
    "JAMA score",
    "concordance with tumor board decisions",
    "expert 4-point grading scale",
    "unsure (likely adherence scoring)",
    "modified Global Quality Scale",
    "alignment with ACR Appropriateness Criteria",
    "qualitative assessment of ADR and STOPP/Beers risks",
    "CBT adherence (ordinal scale)",
    "guideline adherence scoring",
    "validity (expert judgment)",
    "guideline compliance rate",
    "response appropriateness",
    "expert judgment on relevance",
    "appropriateness rating",
    "guideline adherence rate",
    "5-point Likert adequacy scale",
    "proportion of inappropriate responses",
    "expert grading (3-point scale)",
    "expert judgment of appropriateness and accuracy",
    "expert physician appropriateness rating",
    "appropriateness score (0-3) vs ACR criteria",
    "expert rating with ordinal categories (minimal, moderate, substantial clarification required)",
    "appropriateness score",
    "plausibility rating",
    "consistency with ACR Appropriateness Criteria",
    "JAMA Benchmark Criteria",
    "percentage appropriateness",
    "agreement with expert recommendations",
    "medical fidelity rating",
    "custom guideline-based scoring scale (-3 to 2)",
    "expert rating scale (very good/good/acceptable)",
    "Likert scale (appropriateness, usability, clarity)",
    "expert consensus agreement",
    "recommendation appropriateness",
    "expert rating score (0-88)",
    "clinical utility score",
    "appropriateness rating (appropriate / appropriate but incomplete / inappropriate)",
    "GRADE methodology",
    "expert ratings (five-domain rubric)",
    "expert-rated appropriateness categories",
    "modified global quality scale (1-5)",
    "alignment with expert responses",
    "concordance with ASMBS guidelines",
    "qualitative accuracy vs guidelines",
    "compliance with Dietary Reference Intakes (DRIs)",
    "agreement with AAOS CPGs",
    "Journal of the American Medical Association (JAMA) score",
    "modified global quality scale",
    "expert alignment score (0=inappropriate, 1=acceptable, 2=matching)",
    "Likert-scale guideline adherence",
    "adherence to USDA estimated calorie needs",
    "specialist appropriateness rating",
    "subjective appropriateness rating",
    "JAMA Benchmark criteria",
    "concordance with BSH guidelines",
    "physician assessment of appropriateness",
    "GRADE scale",
    "human appropriateness rating",
    "qualitative comparison to guidelines",
    "alignment with medical consensus",
    "accuracy (alignment with SAGES guidelines)",
    "percentage concordant with guidelines",
    "appropriateness score (1\u20135)",
    "alignment with expert consensus",
    "human-rated compliance score (Likert/Likert-like scale)",
    "Likert-style ratings (appropriateness, helpfulness)",
    "guideline consistency score",
    "relevance to CPR",
    "correlation with AAOS appropriateness scores",
    "expert suitability rating",
    "4-level guideline concordance rating",
    "guideline concordance",
    "Appropriateness (binary)",
    "percentage of responses labeled inappropriate",
    "Likert scale for clinical reasoning",
    "guideline concordance percentage",
    "guideline adherence",
    "accuracy compared with guidelines",
    "appropriateness",
    "appropriateness (binary)",
    "expert qualitative review",
    "agreement with FDA approval status",
    "expert ratings of relevance",
    "expert 3-tier rating (A/B/C)",
    "agreement with professional norms",
    "appropriateness of explanation",
    "expert evaluation of explanations",
    "appropriateness proportion",
    "agreement with guidelines",
    "expert qualitative assessment (FITT adherence, safety, individualization)",
    "clinical relevance",
    "5-point Likert scale for appropriateness",
    "appropriateness of recommendations",
    "duration adequacy",
    "0-5 rating scale for appropriateness and completeness",
    "expert appropriateness rating",
    "concordance with expert analysis",
    "5-point Likert scale for clinical reasoning",
    "agreement with clinical guidelines",
    "three-tier expert grading (A/B/C)",
    "accuracy (agreement with guidelines)",
    "Journal of the American Medical Association benchmark criteria",
    "clinical usefulness rating",
    "fitness for purpose",
    "prioritization of care",
    "percentage adherence to guideline nutrient targets",
    "treatment line congruence",
    "accuracy vs NCCN guidelines",
    "adherence index to USPSTF guidelines",
    "appropriateness (%)",
    "expert explanation rating",
    "accuracy vs guidelines",
    "appropriateness categorization",
    "referral appropriateness",
    "Likert-scale ratings for relevance",
    "relevance to clinical practice",
    "adherence to Acceptable Macronutrient Distribution Ranges (AMDR)",
    "6-point Likert adequacy score",
    "expert scoring (quality, reliability, applicability)",
    "agreement with guidelines (%)",
    "checklist adherence",
    "JAMA benchmark criteria",
    "3-point Likert ratings for relevance",
    "appropriateness judgment",
    "concordance with guidelines",
    "triage appropriateness",
    "appropriateness of prescription",
    "appropriateness scale",
    "Likert scale medical adequacy ratings",
    "clinician ratings of appropriateness (safety, privacy, hallucination/accuracy, bias)",
    "Likert scale ratings (1-5) for overall quality and guideline conformity",
    "expert-developed scoring rubrics",
    "therapeutic quality rating",
    "Delphi consensus relevance ranking",
    "concordance with reference figures",
    "expert grading against ATA guidelines",
    "accuracy versus evidence-based guidelines",
    "3-point Likert scale for guideline compliance",
    "oncologist judgment for NCCN guideline concordance",
    "expert appropriateness ratings",
    "appropriateness scoring",
    "expert grading (appropriate/inappropriate/unreliable)",
    "percentage of 'usually appropriate' recommendations",
    "agreement with scientific consensus (%)",
    "expert-developed scoring rubric (percent score)",
    "expert categorical rating (Excellent/Satisfactory/Unsatisfactory)",
    "expert categorical rating (excellent/satisfactory/unsatisfactory)",
    "expert rating of correctness/appropriateness",
    "concordance with NCCN guidelines",
    "Likert-scale expert ratings (appropriateness, specificity, variability, safety/ethics, usefulness)",
    "standardized qualitative assessment of quality/relevance/applicability",
    "proportion of evidence-based recommendations",
    "appropriateness ratings",
    "accuracy vs guideline",
    "accuracy vs. guidelines",
    "accuracy versus clinical guidelines",
    "appropriateness score (0-3)",
    "qualitative expert review",
    "clinical appropriateness",
    "agreement with AAN guidelines",
    "expert ratings: inappropriateness of information",
    "suitability",
    "7-item Likert appropriateness score",
    "language appropriateness",
    "clinical agreement score",
    "algorithm adherence",
    "appropriateness concordance",
    "5-point Likert clinical concordance scale",
    "nutrient content comparison vs Turkish Dietary Guidelines",
    "clinician assessment of equivalence/plausibility",
    "alignment category (Complete, Partial, Nonalignment)",
    "treatment recommendations (TR)",
    "percent agreement with guidelines",
    "Naranjo scale",
    "human-judged appropriateness (appropriate/inappropriate/unreliable)",
    "medical justifiability",
    "suitability (appropriate/inappropriate)",
    "appropriateness of recommended tests",
    "appropriateness (percentage)",
    "percentage concordant with guideline recommendations",
    "appropriateness classification",
    "Appropriateness rating",
    "appropriateness assessment"
  ],
  "Reliability, Consistency & Reproducibility": [
    "consistency/reproducibility",
    "Likert-scale ratings for reliability, accuracy, comprehensibility",
    "percent reproducibility",
    "consistency across runs",
    "test-retest reliability",
    "test-retest consistency",
    "subjective convergence",
    "replicability",
    "inconclusiveness rate",
    "consistency agreement",
    "rate of repeated Q&R",
    "reproducibility",
    "Reliability Scoring System (adapted DISCERN)",
    "response stability",
    "score variance",
    "rectified reliability score (rRS)",
    "consistency",
    "response consistency",
    "Bland\u2013Altman",
    "consistency across prompt variations",
    "conversational coherence",
    "7-point reliability scale",
    "reproducibility (consistency across two runs)",
    "robustness",
    "run-to-run consistency",
    "variance",
    "information reliability score",
    "statistical test of consistency",
    "expert ratings of reliability",
    "consistency with existing clinical decisions",
    "consistency assessment",
    "answer consistency",
    "consistency with pathology",
    "Bland-Altman analysis",
    "ChatGPT reliability score (Likert 1\u20137)",
    "reproducibility percentage",
    "Likert scale ratings for reliability, accuracy, comprehensibility",
    "5-point consistency score",
    "diagnosis repeatability",
    "source reliability",
    "logical consistency",
    "qualitative assessment of relevance, justification, and consistency",
    "numerical answer consistency",
    "coefficient of variation",
    "reproducibility rate",
    "repeatability",
    "answer reproducibility percentage",
    "semantic consistency rate",
    "consistency coefficient",
    "unreliable rate",
    "consistency score between original and interpreted reports",
    "within-individual ranking",
    "subjective clarity/consistency ratings",
    "intra-model discordance rate",
    "consistency of answers",
    "reliability coefficients (e.g., Cronbach's alpha)",
    "Spearman rho for consistency",
    "interaction continuity",
    "7-point Likert scale for reliability",
    "inconsistency rate",
    "expert ratings on reliability and empathy (likely Likert)",
    "consistency percentage",
    "contradiction rate",
    "consistency between runs",
    "reproducibility assessment",
    "response concordance between days",
    "nutrient consistency",
    "inter-run agreement rate",
    "consistency across repeated queries",
    "logic consistency classification",
    "reliability score",
    "repeat-question consistency",
    "Likert scale ratings (reliability, accuracy, comprehensibility)",
    "consistency rate",
    "consistency score",
    "self-correction rate",
    "self-correction improvement rate",
    "reliability",
    "internal coherence score",
    "consistency across repeats",
    "consistency over time",
    "context recall",
    "material reliability",
    "consistency across trials"
  ],
  "Inter-Rater Agreement & Concordance": [
    "expert rating scales",
    "alphabetical grading scale (A\u2013F)",
    "median rating",
    "score agreement with physicians",
    "expert review",
    "4-point human rating scale (excellent/satisfactory/minimal clarification/moderate clarification/unsatisfactory)",
    "inter-rater ICC",
    "expert grading categories",
    "expert grading (A/B/C/F)",
    "manual grading",
    "inter-rater concordance",
    "4-point quality scale",
    "weighted kappa",
    "pairwise percent agreement",
    "ICC",
    "expert rating scale (1\u20134)",
    "grading rubric score",
    "agreement percentage",
    "conformity percentage",
    "expert rating scores (0-10 scale)",
    "expert Likert-style domain scores",
    "expert categorical rating",
    "level of agreement",
    "expert grading (A-D)",
    "7-point Likert scale scoring across domains",
    "interclass correlation coefficient",
    "expert alphabetical grading (A-F)",
    "interrater agreement",
    "expert grading",
    "agreement with clinicians",
    "Fleiss's Kappa",
    "expert scoring (point-based)",
    "interobserver agreement",
    "examiner consensus score (1-6 scale)",
    "human evaluation scores",
    "Cohen\u2019s kappa",
    "percent agreement",
    "Fleiss kappa",
    "Total Disagreement Score (TDS)",
    "expert Likert ratings",
    "interrater agreement (kappa)",
    "interrater intraclass correlation",
    "agreement with glaucoma specialists",
    "frequency of ethical principle selected",
    "Kendall's W inter-rater agreement",
    "expert ratings",
    "percentage agreement with experts",
    "6-point Likert scale",
    "percent agreement with Heart Team",
    "inter-class correlation (ICC)",
    "4-point Likert ratings",
    "inter-rater reliability",
    "expert rubric score",
    "Fleiss' kappa inter-rater agreement",
    "Likert scale (1\u20135) across multiple domains",
    "inter-rater reliability (Cohen\u2019s kappa, Gwet\u2019s AC)",
    "percentage concordance",
    "expert Likert-type rating (0-10)",
    "inter-model agreement",
    "subjective rating",
    "three-point subjective quality scale",
    "5-point Likert scale",
    "expert rating scale (0-5)",
    "expert comparison to gold standard",
    "concordance rate (top-1, top-5)",
    "4-point quality rating scale (excellent/satisfactory/unsatisfactory)",
    "distance to human consensus",
    "expert judgment",
    "concordance rate (percentage agreement)",
    "subjective ratings (accuracy, completeness, empathy)",
    "quadratic-weighted Cohen kappa",
    "radiologist quality ratings",
    "intraclass correlation",
    "Cohen's \u03ba",
    "surgeon grading of relevance",
    "kappa statistic",
    "Gwet AC1 agreement coefficient",
    "coincidence rate",
    "Cohen\u2019s kappa for interrater agreement",
    "score-card ratings",
    "kappa interrater reliability",
    "expert agreement",
    "question concordance",
    "Cohen\u2019s Kappa",
    "5-point alignment score",
    "expert 4-point categorical rating",
    "Cohen's weighted kappa",
    "correlation with expert responses",
    "interclass correlation coefficient (ICC)",
    "Krippendorff alpha",
    "ordinal rating scale (excellent/satisfactory/unsatisfactory)",
    "4-point expert rating scale (excellent / satisfactory minimal clarification / satisfactory moderate clarification / unsatisfactory)",
    "Fleiss Kappa",
    "ability of physicians to identify AI-generated text",
    "agreement with surgeons",
    "subjective 1-3 quality rating",
    "concordance (%)",
    "Cohen\u2019s kappa (interobserver agreement)",
    "Intraclass Correlation Coefficient (ICC)",
    "Fleiss kappa for interrater agreement",
    "expert grading (0\u20135 scale)",
    "modified Entrustment Scale",
    "physician agreement (%)",
    "consensus alignment percentage",
    "4-point quality rating",
    "inter-rater reliability (joint probability)",
    "Krippendorff\u2019s alpha",
    "Likert-scale severity ratings",
    "radiologist ratings",
    "subjective comparison to textbook answers",
    "agreement with expert thresholds",
    "Cronbach alpha",
    "clinician agreement",
    "Fleiss' Kappa",
    "expert subjective ratings",
    "4-point Likert quality scale",
    "kappa coefficient",
    "agreement with experts/statistical comparison",
    "expert categorical ratings",
    "Light's Kappa",
    "expert Likert agreement",
    "expert categorical grading (sufficient educational value / correct but inadequate / mixed)",
    "consultant 3-point rating",
    "4-point Likert scale",
    "Cohen's Kappa",
    "Likert scale (1\u20135) across multiple criteria",
    "expert ratings on incorrect information",
    "Cohen's kappa for interrater agreement",
    "Kendall's coefficient of concordance",
    "4-level quality rating",
    "4-point Likert compatibility score",
    "agreement with radiologists across six revision criteria",
    "Cohen kappa",
    "expert ranking",
    "subjective expert assessment",
    "expert rating",
    "Kendall\u2019s Tau",
    "Kendall's tau",
    "Fleiss \u03ba",
    "concordance with human answers",
    "interrater reliability",
    "Cohen\u2019s \u03ba for inter-rater reliability",
    "agreement with Micromedex (concordance %)",
    "concordance score (0\u20132)",
    "expert rating scale (excellent/satisfactory/unsatisfactory)",
    "agreement with consensus statements",
    "5-point Likert agreement score",
    "Cochrane's Q",
    "agreement with ID consultant",
    "discordance percentage",
    "mean difference vs experts",
    "agreement with surveyor majority responses",
    "oncologist questionnaire ratings (subjective quality assessment)",
    "inter-rater reliability (ICC)",
    "congruence score (0\u20132 points)",
    "Kendall's tau interrater reliability",
    "ability to distinguish AI vs human plan",
    "Fleiss \u03ba agreement",
    "expert grading on 0-3 scale",
    "expert ratings (factual consistency, comprehensiveness, potential harm, relevance, innovation, clarity, specificity)",
    "blinded human identification rate",
    "inter-rater reliability (correlation coefficient)",
    "intra-class correlation coefficient",
    "human ratings for factual consistency",
    "Fleiss' kappa",
    "Mika grading scale",
    "Q-value agreement",
    "interrater reliability (ICC)",
    "RADPEER agreement score",
    "inter-rater agreement (ICC)",
    "subjective surgeon ratings",
    "manual comparison",
    "percent concordance with human users",
    "5-point Likert scoring",
    "4-point expert rating scale",
    "expert scoring (0\u20135 scale)",
    "human ratings",
    "agreement with expert surgeons",
    "Krippendorff's alpha",
    "expert adjudication",
    "human scoring (likely Likert)",
    "expert confirmation",
    "4-point Likert scale ratings",
    "interrater reliability (kappa)",
    "agreement rate with physician decisions",
    "within 10%/20% agreement",
    "intraclass correlation coefficient",
    "diagnostic agreement",
    "inter-rater agreement (strict and relaxed)",
    "agreement with original classification",
    "human-graded scores",
    "human ratings (factuality, comprehension, reasoning, harm, bias)",
    "expert Likert scale ratings",
    "expert rating scale",
    "Delphi consensus",
    "intraclass correlation coefficient (ICC)",
    "kappa",
    "agreement",
    "Likert scale ratings (1-10) on multiple quality dimensions",
    "expert rating (unsure)",
    "Interclass Correlation Coefficient",
    "accuracy vs human ratings",
    "Likert-scale expert ratings",
    "percent agreement with manual triage",
    "Likert scale score (0\u20132) averaged per case",
    "correlation with human judgments",
    "percent agreement with expert panel",
    "Likert scale rating (1-5)",
    "subjective grading",
    "Fleiss\u2019 Kappa",
    "adjusted kappa coefficient",
    "expert review score",
    "Intraclass Correlation Coefficient",
    "expert-assigned letter grades (A-D)",
    "radiologist Likert ratings",
    "subjective doctor ratings",
    "Cochran's Q",
    "human expert ratings",
    "inter-rater reliability (Fleiss Kappa)",
    "LLM-based automatic metric correlated with human assessments",
    "Kendall\u2019s tau",
    "Cohen's kappa for inter-rater agreement",
    "expert scoring (0-5 scale)",
    "weighted \u03ba for interobserver reliability",
    "expert rating scores",
    "expert scoring",
    "expert panel ratings",
    "5-point quality rating scale",
    "expert scoring scale (1\u20134)",
    "5-point rating scale",
    "concordance",
    "subjective ratings",
    "agreement with radiologist revisions across 6 criteria",
    "human expert grading on 0\u201310 scale",
    "agreement with tumor board",
    "expert rating scale (excellent to unsatisfactory)",
    "Cronbach\u2019s alpha",
    "agreement rate on management",
    "expert scoring (0-100 scale)",
    "7-point Likert scale",
    "Likert scale agreement",
    "scientific consensus percentage",
    "agreement with teacher review",
    "kappa (implied)",
    "concordance correlation coefficient",
    "Cohen \u03ba",
    "Cohen\u2019s kappa for interobserver agreement",
    "Cronbach's alpha",
    "comparison with human mean score",
    "expert approval ratio",
    "4-point scale score",
    "expert grading (A/B ratings)",
    "inter-rater agreement (e.g., Cohen\u2019s kappa)",
    "subjective expert ratings",
    "agreement rate",
    "agreement with human consensus",
    "4-point rating scale (Likert-like)",
    "expert rating percentages for reliability and applicability",
    "expert ratings of fidelity",
    "Gwet's AC2 interrater agreement",
    "human ranking score",
    "inter-rater correlation coefficient",
    "consistency across investigators",
    "Kappa index",
    "structured interview scoring rubric",
    "subjective ratings (relevance, utility, concordance)",
    "Cohen's kappa",
    "difference from expert consensus mean Likert score",
    "human judgment",
    "kappa statistics",
    "linear weighted Fleiss Kappa",
    "answer concordance",
    "agreement (e.g., Cohen's kappa)",
    "5-point expert rating scale (poor\u2013excellent)",
    "examiner identification of AI vs human",
    "9-point Likert scale similarity to consensus mean",
    "subjective human evaluation",
    "Cohen Kappa",
    "concordance (concordant/indeterminate/discordant)",
    "inter-rater agreement (kappa)",
    "clinician Likert-scale ratings (0-10) on multiple quality domains",
    "concordance with MDT",
    "0\u2013100 quality rating scale",
    "subjective expert grading (poor/fair/good/very good/excellent)",
    "expert Likert rating",
    "4-point Likert scores",
    "5-point Likert scale by experts",
    "Fleiss\u2019 kappa",
    "Likert scale recognizability",
    "weighted Kappa",
    "Fleiss's kappa",
    "agreement with physician assessments",
    "human rating scale (Likert-style)",
    "concordance Likert scale (1-5)",
    "expert ratings on 16-item rubric",
    "match rate (\u22641 Likert point discrepancy)",
    "linear-weighted kappa",
    "Kappa",
    "weighted percentage agreement",
    "Kappa coefficient",
    "Likert scale ratings (1\u20135) across four criteria",
    "automated scoring with human oversight",
    "agreement statistics",
    "expert grading scale (1-4)",
    "concordance rate",
    "proportion matching majority human response",
    "inter-rater reliability correlation coefficient",
    "6-point Likert scales",
    "Intra-class correlation coefficient",
    "inter-rater reliability (kappa)",
    "concordance percentage",
    "Kendall's W",
    "Likert-scale agreement ratings",
    "Likert-type scores",
    "surgeon agreement",
    "dichotomous yes/no ratings",
    "percentage agreement",
    "qualitative faculty assessment",
    "inter-rater kappa",
    "weighted Gwet agreement coefficient",
    "percentage concordant",
    "Likert scale (1\u20135) across 15 quality subcategories",
    "alignment with human-rated difficulty",
    "weighted Cohen's kappa",
    "expert scoring (1\u20134 scale)",
    "inter-rater agreement"
  ],
  "Statistical Significance & Effect Size": [
    "Kruskal\u2013Wallis",
    "Chi-square test",
    "Cohen's d",
    "mean category difference",
    "Wilcoxon paired t-test",
    "statistical significance (t-test, Z-test)",
    "hazard ratio",
    "ordinal logistic GEE odds ratio",
    "statistical significance testing",
    "statistical significance tests",
    "Kaplan\u2013Meier survival analysis",
    "Mann-Whitney U test for differences",
    "z-score outlier analysis",
    "95% confidence intervals",
    "effect size",
    "statistical tests (p-values)",
    "Fisher\u2019s Exact Test p-values",
    "MCID",
    "p-values",
    "mean difference",
    "Mann-Whitney U statistical comparison",
    "chi-square test",
    "combined p-value",
    "Pearson chi-square test",
    "survey percentages",
    "Pearson\u2019s Chi-square test",
    "Mann-Whitney U test",
    "bootstrap confidence intervals",
    "Wilcoxon rank-sum test",
    "chi-square",
    "median score comparison",
    "percentage improvement",
    "statistical comparison (p-values)",
    "chi-square significance (p-values)",
    "ANOVA p-values",
    "percentage distribution",
    "prevalence ratio",
    "Chi-square",
    "Cochran's Q test",
    "statistical significance (Kruskal-Wallis)",
    "Cochran\u2019s Q test",
    "pairwise t-tests",
    "regression",
    "Wilcoxon Signed-Rank Test",
    "Wilcoxon signed rank test",
    "post-hoc t-tests",
    "Kruskal-Wallis test",
    "Wilcoxon Signed Rank test",
    "odds ratio",
    "univariate linear regression",
    "statistical significance",
    "mean score difference",
    "Fisher\u2019s exact test",
    "model-predicted likelihood values analyzed with ANOVA",
    "Wilcoxon rank sum test",
    "statistical significance (P-values)",
    "odds ratios",
    "two-tailed t-test",
    "statistical difference tests",
    "chi-squared test",
    "mediated effect size",
    "p-value significance",
    "statistical significance (P values)",
    "statistical comparison to true prevalence",
    "ANOVA statistical comparison",
    "McNemar\u2019s test",
    "statistical significance (ANOVA)",
    "RMSEA",
    "Bonferroni-corrected P values",
    "bootstrap confidence interval",
    "t-test",
    "chi-square goodness-of-fit",
    "statistical significance (p-value)",
    "Rasch logits",
    "statistical tests (Chi-square, Friedman)",
    "statistical comparison",
    "Kruskal\u2013Wallis test",
    "confidence intervals",
    "hazard ratios",
    "Pearson correlation",
    "expert scoring (likely Likert or similar) with statistical comparison (median, P-values)",
    "ANOVA",
    "adjusted odds ratio",
    "percentage difference",
    "correlation",
    "Pearson chi-square",
    "statistical comparison (p-value)",
    "expert rating of accuracy, completeness, quality (Kruskal\u2013Wallis analysis)",
    "odds ratio of intervention types",
    "statistical comparison (Mann\u2013Whitney U)",
    "2-sample z-test",
    "group mean differences (multilevel model)",
    "chi-squared",
    "Fisher's exact test",
    "chi-square tests",
    "Wilcoxon test",
    "correlation coefficients",
    "Wilcoxon rank-sum",
    "Kaplan-Meier survival analysis",
    "logistic regression coefficients",
    "p-value",
    "Cochran Q test",
    "correlation analyses",
    "Bayes factors",
    "Binomial test",
    "P value",
    "Cohen\u2019s d",
    "Friedman test",
    "path analysis coefficients",
    "McNemar test",
    "relative risk",
    "Cox hazard ratio",
    "weighted average",
    "Fisher exact test",
    "Student\u2019s t-test",
    "descriptive statistics",
    "McNemar's test",
    "association with AD risk (hazard ratio)",
    "chi-square significance testing",
    "correlation with difficulty index",
    "correlation coefficient",
    "Kruskal-Wallis",
    "Wilcoxon signed-rank test",
    "ANOVA F-statistics",
    "Dunn post-hoc test",
    "confidence interval",
    "logistic regression statistics",
    "Mann\u2013Whitney U test",
    "statistical tests (P-values)",
    "Bayesian inference-based metrics",
    "Spearman correlation",
    "DeLong test",
    "median ESI score comparison",
    "statistical correlation",
    "Wilcoxon Signed-Rank test",
    "Pearson chi-squared",
    "paired t-test",
    "P-values",
    "statistical significance (p-values)",
    "paired-sample t-test",
    "multivariate regression analysis",
    "two-sample proportion z test",
    "clinical significance rating",
    "Dunn's post hoc test",
    "paired t-test p-values"
  ],
  "Diagnostic/Screening Operating Characteristics": [
    "diagnostic performance metrics (e.g., sensitivity, specificity)",
    "Hospital Anxiety and Depression Scale (HADS)",
    "AUC-ROC",
    "weighted sensitivity (WSens)",
    "diagnostic accuracy (e.g., sensitivity, specificity, accuracy)",
    "predictive value",
    "discrimination ability/AUC",
    "sensitivity",
    "overtriage rate",
    "discriminating power",
    "micro F1 score",
    "C-index",
    "NPV",
    "regional sensitivity (RSens)",
    "Matthews correlation coefficient (MCC)",
    "diagnostic match percentage",
    "diagnostic odds ratio",
    "performance metrics (e.g., AUROC)",
    "susceptibility percentage",
    "diagnostic hit rate",
    "macro recall",
    "positive predictive value (PPV)",
    "F1-score",
    "negative predictive value",
    "Specificity",
    "positive likelihood ratio",
    "AUROC",
    "correlation with discrimination power index",
    "LF/HF ratio",
    "type II error rate",
    "likelihood ratios",
    "numeric diagnostic score",
    "AUC ROC",
    "HADS score",
    "area under the curve",
    "true-positive rate (TPR)",
    "ROC-AUC",
    "F1",
    "diagnostic count comparison",
    "precision",
    "diagnostic recall",
    "AUC",
    "unknown recall",
    "Youden Index",
    "Matthews correlation coefficient",
    "specificity",
    "positive predictive value",
    "Youden index",
    "Recall",
    "weighted F1 score",
    "Western Ontario and McMaster Universities Osteoarthritis Index (WOMAC)",
    "Youden's index",
    "Sensitivity",
    "ROC analysis",
    "PPV",
    "true positive rate",
    "false positive rate",
    "ROC curve/AUC",
    "recall",
    "differential diagnosis score",
    "f1 score",
    "confusion matrix",
    "malignancy diagnosis (MD)",
    "discriminant analysis",
    "area under the ROC curve (AUC)",
    "Precision",
    "diagnostic inclusion rate",
    "VAS",
    "area under the ROC curve",
    "sensitivity (d')",
    "ROC AUC",
    "R-IDEA score",
    "heart rate after 3-minute step test",
    "AUPRC",
    "false findings rate",
    "recall/coverage",
    "Youden\u2019s Index",
    "PR-AUC"
  ],
  "Readability & Linguistic Complexity": [
    "readability metrics",
    "readability score",
    "Simple Measure of Gobbledygook (SMOG)",
    "readability indices (e.g., Flesch Reading Ease, New Dale-Chall grade level)",
    "Flesch\u2013Kincaid Grade (FKG)",
    "question complexity score",
    "Flesch-Kincaid Grade",
    "ease of understanding score",
    "Flesch-Kincaid Grade Level",
    "readability formulas",
    "Flesch-Kincaid ease score",
    "Gunning-Fog",
    "readability indicators (medical terms, abbreviations, explanations)",
    "Flesch\u2013Kincaid Reading Level",
    "Flesch\u2013Kincaid ease score",
    "Raygor estimate",
    "Flesch Reading Ease Index",
    "textual score",
    "QUEST",
    "Flesch-Kincaid Reading Ease Score",
    "reading ease",
    "Readability scores",
    "syntactic complexity measures",
    "Gunning Fog index",
    "Coleman-Liau Index (CLI)",
    "FKGL",
    "readability indices",
    "Flesch Grade Level",
    "Flesch-Kinkaid Grade Level",
    "readability grade level indices",
    "Dale-Chall Readability Score",
    "percentage of complex words",
    "percentage passive voice",
    "Flesch-Kincaid Reading Ease",
    "readability (Flesch Reading Ease)",
    "readability formulas (e.g., Flesch-Kincaid, SMOG)",
    "Consensus Reading Grade Level (CRG)",
    "validated readability indices (e.g., Flesch-Kincaid)",
    "readability formulas (e.g., Flesch Reading Ease, etc.)",
    "Flesch-Kincaid Grade Level (FKGL)",
    "readability grade level scores",
    "readability scores (e.g., Flesch Reading Ease, Flesch-Kincaid Grade Level)",
    "FORCAST",
    "Chinese Readability Index Explorer (CRIE) score",
    "Flesch Reading Ease Score (FRES)",
    "Flesch Kincaid Grade Level",
    "Coleman-Liau",
    "Average Reading Level Consensus Calculator",
    "readability grade level",
    "readability scores (SMOG, FKGL, FRE)",
    "Dale\u2013Chall readability",
    "Gunning Fog Readability (GFR)",
    "Flesch reading ease",
    "Flesch\u2013Kincaid Reading Ease",
    "SMOG Readability Formula",
    "word and sentence counts",
    "Coleman-Liau Index",
    "Average Reading Level Consensus (ARLC)",
    "readability (likely)",
    "readability",
    "Flesch-Kincaid Readability",
    "Flesch-Kincaid reading ease score",
    "Flesch-Kincaid grade level",
    "Linsear Write",
    "Flesch reading ease score",
    "Simple Measure of Gobbledygook",
    "Flesch-Kincaid reading ease",
    "reading time",
    "Coleman-Liau readability index",
    "Coleman\u2013Liau Index",
    "Ate\u015fman readability formula",
    "readability/grade level",
    "Coleman\u2013Liau",
    "grade level",
    "Bezirci-Y\u0131lmaz readability formula",
    "Flesch readability ease score",
    "Flesch-Kincaid score",
    "readability metrics (six formulae)",
    "Flesch\u2013Kincaid reading level",
    "type-token ratio",
    "Flesch\u2013Kincaid Grade",
    "Flesch-Kincaid readability score",
    "verbal fluency rating",
    "Flesch\u2013Kincaid readability grade level",
    "objective readability indices",
    "Raygor Estimate",
    "syllable count",
    "readability (6th grade level)",
    "Fry graph",
    "Fern\u00e1ndez-Huerta grade level",
    "adapted Flesch readability",
    "Automated Readability Index",
    "Flesch Reading Ease",
    "Flesch Reading Ease (FRES)",
    "lexical density",
    "Raygor Readability Estimate",
    "linguistic complexity metrics",
    "Automated Readability Index (ARI)",
    "Flesch-Kincaid Reading Grade Level",
    "Flesch\u2013Kincaid readability",
    "Perplexity",
    "readability grade levels",
    "Flesch\u2013Kincaid Reading Grade Level",
    "readability indices (Flesch Reading Ease, Flesch\u2013Kincaid Grade Level, Gunning Fog Index, Coleman\u2013Liau Index, SMOG)",
    "perplexity",
    "Flesch Reading Ease Score",
    "patient readability score",
    "Coleman Liau",
    "SMOG",
    "Flesch-Kincaid Reading Grade Level (FKRGL)",
    "Flesch-Kincaid readability",
    "SMOG readability",
    "readability indexes",
    "average reading time",
    "readability grade level formulas",
    "SMOG Index",
    "readability indices (Flesch Reading Ease, Gunning Fog, etc.)",
    "Flesch-Kincaid Reading Ease Score (FRES)",
    "readability metrics (grade level, reading time, word rarity, passive sentence frequency)",
    "Flesch Kincaid Reading Ease",
    "Flesch Reading Ease (FRE)",
    "Flesch-Kincaid Reading Ease (FKRE)",
    "Fernandez-Huerta readability",
    "FORCAST Readability Formula",
    "Flesch-Kincaid Grade Level (FKRGL)",
    "Flesch-Kincaid Reading Level (FKRL)",
    "readability indices (e.g., Flesch-Kincaid, SMOG, etc.)",
    "passive sentence frequency",
    "SMOG index",
    "readability grade-level scores",
    "word/character count",
    "reading ease score",
    "Fry Graph",
    "syntactic pronoun usage rates",
    "Szigriszt readability",
    "standardised quality assessment tools (e.g., readability and clinical appropriateness scores)",
    "Flesch\u2013Kincaid Grade Level (FKGL)",
    "professional terminology and expression (PTE)",
    "word rarity",
    "Ate\u015fman's Readability Index",
    "readability formulas (e.g., Flesch-Kincaid, Gunning Fog)",
    "Dale-Chall formula",
    "Coleman-Liau index",
    "Shannon entropy",
    "Flesch-Kincaid",
    "Flesch-type readability indexes",
    "3-point Likert ratings for readability",
    "lexicon score",
    "Gunning-Fog Index",
    "syntactic complexity",
    "readability rating",
    "readability consensus score",
    "Gunning Fog Readability",
    "other readability scales",
    "Flesch Reading Ease score",
    "readability indices (WordCalc)",
    "Flesch-Kincaid Reading Level",
    "Flesch-Kincaid reading level",
    "Flesch\u2013Kincaid",
    "LIWC category frequencies",
    "SMOG readability index",
    "Flesch Kincaid Grade",
    "readability indexes (Flesch Reading Ease, grade levels)",
    "average readability indexes",
    "readability grade level (SMOG)",
    "readability grade level indices (e.g., Flesch-Kincaid)",
    "tone scores (LIWC)",
    "text length",
    "Fry Readability Graph",
    "Coleman Liau Index",
    "Linsear Write Formula",
    "Ate\u015fman readability index",
    "SMOG readability score",
    "readability indices (e.g., Flesch Reading Ease)",
    "Gunning Fog Score",
    "Spanish Orthographic Length (SOL) grade level",
    "readability grade level (Textstat)",
    "Gunning-Fog Level",
    "Flesch Kincaid",
    "Dale-Chall",
    "ease of understanding rating",
    "sentence length",
    "readability scores",
    "Flesch-Kincaid Readability Ease",
    "Readability",
    "percentage of vocabulary kept/deleted",
    "Gunning Fog Index (GFI)",
    "Readability scores (Flesch Reading Ease, Gunning Fog Index, Flesch-Kincaid Grade Level, Coleman-Liau Index, SMOG Index)",
    "Gunning Fog",
    "Flesch reading ease scale",
    "character count",
    "Flesch score",
    "Flesch-Kincaid readability ease score",
    "Gunning Fog Index",
    "readability scoring",
    "readability grade level (e.g., Flesch-Kincaid)",
    "readability grade level (Readable.com)",
    "consensus reading level",
    "Flesch\u2013Kincaid Grade Level",
    "Fry readability score",
    "readability scores (e.g., Flesch-Kincaid)",
    "FORCAST Grade Level",
    "percent passive sentences",
    "readability assessments",
    "reading grade level",
    "Flesch\u2013Kincaid grade level"
  ],
  "Empathy, Bedside Manner & Emotional Support": [
    "emotional support quality",
    "5-point Likert scales for clarity/empathy/professionalism",
    "1-5 Likert scale ratings for medical helpfulness, emotional supportiveness, sentence comprehensibility",
    "5-point Likert ratings (quality, empathy)",
    "Mini-CEX scores",
    "Likert-scale authenticity score",
    "empathy/quality rating",
    "Likert-scale ratings for empathy, responsiveness, accuracy, usefulness",
    "empathy scores",
    "emotion tendency score",
    "Empathic Communication Coding System",
    "Levels of Emotional Awareness Scale (LEAS)",
    "patient satisfaction, humanisation, professionalism ratings",
    "compassion",
    "empathy rating",
    "pre/post empathetic response scores",
    "5-point Likert scales (empathy, usefulness, correctness)",
    "empathy score",
    "empathy level",
    "empathy/relatability",
    "empathy/respectfulness/friendliness scales",
    "Likert-scale ratings (empathy, information quality, helpfulness)",
    "Likert scale ratings (quality, empathy, readability)",
    "Motivational Interviewing Treatment Integrity scale",
    "Consultation and Relational Empathy scale",
    "5-point Likert scale (empathy, accuracy, completeness, overall quality)",
    "Likert-scale ratings (empathy, responsiveness, accuracy, usefulness)",
    "Likert scale ratings (empathy, relevance, accuracy, readability)",
    "negative emotion rate",
    "empathy rating (1\u20136)",
    "Mini-Clinical Evaluation Exercise (Mini-CEX) scores",
    "empathy 5-point scale",
    "empathy assessment",
    "5-point Likert scales (clarity, comprehensiveness, empathy)",
    "Likert scale (empathy)",
    "support",
    "Mean Opinion Scale-Expanded v2",
    "professionalism",
    "sentiment score",
    "emotional content percentages",
    "empathy/personalization/professionalism probes",
    "empathy/tone",
    "empathy",
    "5-point Likert scale for empathy, accuracy, completeness, overall quality",
    "Revised-IDEA (Likert scale)",
    "therapeutic alliance measures",
    "emotion Likert scores",
    "humanistic care inclusion score",
    "Likert scale ratings (1-5) for quality and empathy",
    "emotional correctness",
    "subjective engagement",
    "professionalism rating",
    "emotional sensitivity",
    "Likert-scale ratings for quality and empathy",
    "comfort",
    "empathy rating (Likert)"
  ],
  "Comprehensiveness & Coverage": [
    "comprehensiveness rating (1-3)",
    "proportion of guideline recommendations present",
    "comprehensiveness",
    "checklist of essential elements",
    "human ratings of completeness (complete/mostly complete)",
    "completeness of assessment steps",
    "expert grading of comprehensiveness and accuracy",
    "5-point Likert scales for relevance/balance/data basis/factual accuracy/completeness",
    "recommendation specificity",
    "compliance with inclusion of complication profiles",
    "expert ratings: sufficiency of information",
    "expert-rated comprehensiveness",
    "clinician-rated comprehensiveness (Likert)",
    "Exhaustiveness",
    "response length",
    "expert 0\u201310 ratings for comprehensiveness, accuracy, clarity, relevance",
    "Likert completeness score",
    "Likert scale for comprehensiveness (1-5)",
    "completeness scoring",
    "counts/proportions of specific features",
    "frequency of insights",
    "EQIP",
    "counts of missing information",
    "number of unique insights",
    "percent completeness",
    "5-domain educational rubric (accuracy, relevance, comprehensiveness, evidence-base, clarity)",
    "comprehensiveness percentage",
    "GQS",
    "OE score (0-2)",
    "Likert-scale comprehension score",
    "completeness/coverage",
    "custom scoring of information amount",
    "comprehensiveness rating",
    "subjective comprehensiveness rating",
    "word count comparison",
    "manual completeness",
    "comprehensiveness (expert rating)",
    "comprehension",
    "unique correct information elicited",
    "reference frequency",
    "coverage of instructive diagnoses (%)",
    "3-point completeness scale",
    "completeness assessment",
    "number of additional examinations indicated",
    "Likert scale (completeness)",
    "4-point adequacy rating",
    "specificity to topic",
    "modified Global Quality Score",
    "comprehensiveness Likert scale",
    "presence of verbal CPR instructions",
    "relevance (human rating)",
    "custom critical elements checklist",
    "sufficiency",
    "completeness rating (Likert)",
    "proportion completeness",
    "information completeness",
    "missing information rate",
    "expert scoring on comprehensiveness/satisfaction",
    "coverage",
    "response completeness",
    "expanded EQIP scale",
    "number of diagnoses listed",
    "insight density index",
    "number and type of cited sources",
    "count of therapy options",
    "modified Global Quality Scale (GQS)",
    "Global Quality Score (GQS)",
    "CLEAR tool (completeness, accuracy, relevance)",
    "other comprehensiveness metrics",
    "PDQI score",
    "expert rating of completeness",
    "modified Global Quality Scale (1-5)",
    "human ratings: completeness",
    "content omission rate",
    "Likert scale for completeness (1\u20133)",
    "Likert scale comprehension score",
    "informativeness score",
    "subjective ratings (comprehensiveness, safety)",
    "rubric-based scoring (comprehensiveness, scientific accuracy, clarity, relevance)",
    "4-point Likert scale for completeness",
    "expert ratings of information omissions",
    "completeness rating",
    "supplementary information presence",
    "inclusion of crisis resources",
    "Likert scale completeness",
    "number of listed items compared to reference",
    "answer length",
    "five-point comprehensiveness scale",
    "thoroughness",
    "5-point comprehensiveness rating",
    "proportion of domain sources",
    "completeness score",
    "completeness score (1\u20133)",
    "number of differential diagnoses",
    "identification completeness percentage",
    "three-point Likert scale (completeness, comprehensibility)",
    "mean number of questions asked",
    "presence of references",
    "qualitative review of comprehensiveness and cultural appropriateness",
    "Global Quality Scale (1-5)",
    "median number of contributing factors per case",
    "completeness",
    "EQIP score",
    "qualitative assessment of completeness and accuracy",
    "depth",
    "insight presence",
    "five-point comprehensiveness rating",
    "Likert-scale completeness scores",
    "completeness of CPR instructions",
    "report length",
    "answer length/comprehensiveness",
    "number of factual statements",
    "incompleteness score",
    "completeness (subjective expert judgment)",
    "adequacy rating",
    "three-point comprehensiveness scale",
    "proportion of recommended questions",
    "number of therapeutic alternatives",
    "Revised-IDEA (R-IDEA) score",
    "information quality",
    "completeness (yes/no)",
    "Likert scale completeness rating",
    "SPICE",
    "extensiveness",
    "qualitative depth assessment",
    "quality assessment (e.g., DISCERN)",
    "omission of information",
    "Likert ratings for exhaustiveness, clarity, empathy, length",
    "Global Quality Scale (GQS)",
    "word count (verbosity)",
    "qualitative comprehensiveness assessment",
    "expert completeness ratings",
    "completeness %",
    "comprehensiveness (Likert)",
    "Likert scale for completeness",
    "informativeness",
    "supplementary information score",
    "sufficiency rating",
    "frequency of recommendations",
    "brief informed consent quality instrument",
    "custom EQIP-based quality score",
    "comprehensiveness score",
    "comprehensiveness scale",
    "comprehensiveness count",
    "supporting documentation provided",
    "discrepancy/omission counts",
    "explanation score",
    "completeness score (1-5)",
    "completeness ratings",
    "diagnostic completeness",
    "number of key points",
    "completeness (overlapping key phrases)",
    "precision/comprehensiveness",
    "missing content (%)",
    "coverage rate",
    "completeness/relevance rating",
    "expert scoring: relevance",
    "Likert-scale completeness (1\u20133)",
    "standardized 8-item consent form rubric",
    "keyword coverage",
    "adequacy scores",
    "completeness (% of key points included)",
    "5-point comprehensiveness scale",
    "completeness rating (1\u20134)",
    "minimum dataset compliance (%)",
    "incompleteness",
    "number of diagnoses generated",
    "Likert-scale comprehensiveness/competence score",
    "comprehensiveness grading",
    "Key Feature score",
    "amount of supplemental information",
    "presence of rationales",
    "task completeness",
    "0\u201310 rubric scoring for comprehensiveness, scientific accuracy, clarity, relevance",
    "Completeness",
    "number of diagnostic hypotheses"
  ],
  "Clarity, Readability & Communication Quality": [
    "expert ratings of concision",
    "word limit adherence",
    "language correctness",
    "linguistic quality score",
    "CLEAR score",
    "Physician Documentation Quality Instrument score",
    "structure and organization (S&O)",
    "comprehensibility (subjective)",
    "explanation quality score",
    "presentation suitability rating",
    "qualitative narrative coherence analysis",
    "Likert scale on relevance, clarity, depth, focus, coherence",
    "qualitative ratings (ease of understanding, conciseness, accuracy, completeness, relevance)",
    "structured dialogue pattern score",
    "fluency (human rating)",
    "5-point Likert scale on length, comprehensibility, precision, guideline compliance, safety",
    "Likert-style ratings for clarity, comprehensiveness, accuracy, overall quality",
    "quality score",
    "output quality (CNEM score)",
    "modified EQIP tool",
    "expert ratings of comprehensibility",
    "subjective clarity rating",
    "expert Likert-style ratings (relevance, clarity, depth, focus, coherence)",
    "6-point Likert scale (adequacy, comprehensibility, coherence, conciseness)",
    "succinctness",
    "communication clarity",
    "CLEAR tool scores",
    "subjective rating of explanation quality",
    "clarity rating",
    "Global Quality Scale (5-point Likert)",
    "Clarity",
    "percentage of standardized terminology used",
    "conciseness rating",
    "explanation quality",
    "fluency",
    "Likert ratings (readability, organisation, succinctness)",
    "fluency rating",
    "clarity",
    "summarization quality score",
    "Likert-scale ratings (information content, communication style)",
    "comprehensibility",
    "Likert-scale comprehension/clarity/engagement scores",
    "Likert scale clarity rating",
    "structure rating",
    "technical clarity",
    "clarity and comprehensibility (C&C)",
    "modified Global Quality Score (Likert-type)",
    "4-point Likert scale for clarity/content/relevance/trustworthiness",
    "3-point explanation quality scale",
    "Likert-style text quality rating",
    "clarity score",
    "response quality score",
    "Likert scale ratings of clarity, correctness, completeness",
    "Likert scale comprehensibility",
    "5-point Likert scales (clarity, relevance, accuracy, comprehensiveness, overall value)",
    "4Cs scoring (correctness, conciseness, comprehensiveness, comprehensibility)",
    "human expert ratings (informativeness, coherence, fluency, consistency, contradiction handling)",
    "expert ratings of ambiguity",
    "word count reduction",
    "Likert scale information quality",
    "quality rating",
    "language comprehensibility",
    "response coherence",
    "conciseness score",
    "Global Quality Score (1\u20135)",
    "coherence",
    "Global Quality Scale",
    "response quality scale (1-4)",
    "superfluous content/conciseness",
    "comprehensibility/readability",
    "Conciseness",
    "Global Quality Scale (1\u20135)",
    "communication ability rating",
    "non-technical clarity",
    "4-point quality rating scale (excellent to unsatisfactory)",
    "conciseness",
    "CLEAR tool score",
    "Likert scale (relevance, clarity, depth, focus, coherence)"
  ],
  "User/Clinician Preference & Acceptability": [
    "likert scale (presumed)",
    "clinician ratings (quantitative and qualitative)",
    "clinician preference (Wilcoxon signed-rank)",
    "satisfaction rate (3-point Likert)",
    "subjective rating (e.g., Likert scale)",
    "subjective ratings of quality, relevance, applicability",
    "Likert-scale survey ratings",
    "user acceptance (unspecified)",
    "acceptability",
    "SBT-QA10 survey",
    "5-point Likert ratings",
    "Likert quality rating (1-5)",
    "subjective quality ratings (assumed)",
    "thumbs-up rating",
    "preference voting",
    "subjective approval/disapproval",
    "Likert-scale physician ratings",
    "subjective Likert",
    "Likert legitimacy score",
    "proportion deemed acceptable to send",
    "modified 5-point Likert scale (reliability, usefulness)",
    "Likert ratings (accessibility, accuracy, usefulness)",
    "acceptance score",
    "satisfaction rate",
    "yes/no acceptability",
    "expert preference percentage",
    "Likert scale ratings",
    "human preference voting",
    "better-answer proportion",
    "Likert-scale opinions",
    "Likert quality scores",
    "survey responses (emotions, confidence, likelihood of adoption)",
    "subjective quality rating scale",
    "preference proportions",
    "Likert-scale user ratings",
    "physician-rated effectiveness score",
    "Likert-scale ratings (quality)",
    "user preference",
    "Pre- and Post-Interaction Questionnaires",
    "Likert-scale ratings (scientific accuracy, understandability, satisfaction)",
    "Likert-scale trust/explanation rating",
    "trust ratings",
    "Likert scale usefulness score",
    "7-point Likert scale (reliability and usefulness)",
    "explanation acceptability",
    "Likert-scale questionnaires",
    "Likert scale scores",
    "overall preference",
    "subjective survey (understanding, preference, author identification)",
    "user acceptance",
    "subjective ratings (accuracy and clarity via survey)",
    "self-reported helpfulness",
    "user satisfaction rating (Likert)",
    "surgeon preference",
    "Kohlberg moral stage preference",
    "Likert scale trust scores",
    "user satisfaction",
    "6-point Likert scale ratings",
    "5-point Likert scale for helpfulness",
    "Likert scale (1-10)",
    "Likert scale (1\u20135)",
    "Likert-scale feedback quality score",
    "overall impression Likert score",
    "Likert scale ratings (quality, utility)",
    "Subjective Assessment of Speech System Interfaces",
    "radiographer satisfaction",
    "subjective rating (utility)",
    "interaction satisfaction",
    "patient satisfaction",
    "Likert-scale satisfaction rating",
    "overall satisfaction score",
    "Likert-scale relevance ratings",
    "5-point Likert scale (quality)",
    "5-point Likert scale (adapted Global Quality Scale)",
    "Likert scale helpfulness score",
    "modified global quality score (5-point Likert)",
    "self-assessment survey (Likert)",
    "acceptance rate",
    "Likert scale ratings (certainty, usefulness, classroom use)",
    "preference ranking",
    "Likert-scale ratings of accuracy, authenticity, believability, informativeness, usefulness, empathy",
    "Likert-scale survey items",
    "preference selection",
    "5-point Likert scale ratings",
    "trustworthiness",
    "5-point Likert scales (usefulness, relevance, coherence, depth)",
    "Likert-style quality rating",
    "usefulness percentage",
    "Likert scale rating (1\u20135)",
    "Likert scale quality ratings",
    "Likert satisfaction scores",
    "Likert-style quality ratings",
    "patient satisfaction Likert score",
    "manual expert preference ratings",
    "4-point Likert ratings (validity, safety, utility)",
    "patient preference/comfort",
    "Likert-type scales",
    "Likert scale ratings (accuracy, comprehensiveness, compassion, satisfaction)",
    "Likert-type ratings",
    "human preference for accuracy",
    "10-point Likert scale ratings (appropriateness, completeness, empathy, satisfaction)",
    "overall satisfaction",
    "Likert scales",
    "Global Quality Score (5-point Likert)",
    "likelihood to recommend",
    "clinician quantitative ratings (e.g., Likert scales)",
    "human rating (acceptable / incomplete / unacceptable)",
    "Web Resource Rating scale",
    "favorability percentages",
    "patient comfort/trust survey",
    "Likert scale ratings (utility, completeness, understandability, user-friendliness)",
    "comparative ranking",
    "likability",
    "overall rating (Likert)",
    "human expert preference",
    "radiologist preference",
    "7-point Likert scales",
    "student satisfaction survey",
    "Likert-scale surveys",
    "five-point Likert scale",
    "acceptable response rate",
    "likert-scale satisfaction",
    "Likert-style survey ratings (ease of understanding, scientific accuracy, comfort)",
    "ultrasound doctor artificial intelligence acceptance (UDAIA)",
    "expert subjective rating (better/equal/worse)",
    "user impressions",
    "response preference",
    "expert acceptability rating (acceptable/unacceptable/incomplete)",
    "number of top-rated replies",
    "survey-based Likert scale",
    "helpfulness (human rating)",
    "Likert scale (validity, safety, utility)",
    "patient favorability percentage",
    "patient satisfaction Likert ratings",
    "Likert scale",
    "mean score (Likert scale 1\u20135)",
    "satisfaction",
    "provider satisfaction Likert ratings",
    "usefulness rating",
    "GP acceptability rating",
    "Likert ratings (authenticity, professionalism, practicality)",
    "acceptability ratings (likely Likert scale)",
    "Likert scale rating",
    "overall reader satisfaction score",
    "likelihood of use",
    "participant feedback",
    "SERVQUAL Likert ratings",
    "satisfaction questionnaires",
    "usefulness score (1\u20133 Likert)",
    "percent therapies accepted",
    "clinician quality ratings (likely Likert scale)",
    "acceptability of explanations",
    "Likert scale relevance",
    "Likert Scale (LS)",
    "Likert-scale survey responses",
    "satisfaction Likert ratings",
    "Likert scale satisfaction",
    "expert preference ratings",
    "human preference for specificity",
    "satisfaction score",
    "usefulness ratings",
    "acceptability ratings",
    "comparative preference",
    "acceptance",
    "expert satisfaction Likert ratings",
    "user happiness",
    "subjective patient preference",
    "preference proportion",
    "expert preference counts",
    "Likert-scale ratings (1\u201310)",
    "6-point Likert-scale ratings for relevance, correctness, helpfulness, safety, readability, trustworthiness",
    "qualitative user feedback",
    "subjective clinician rating",
    "Likert-scale ratings",
    "physician preference ratings",
    "HHA Satisfaction Questionnaire (SHSQ)",
    "survey responses",
    "satisfactory report rate",
    "expert subjective ratings (preference, accuracy, comprehensiveness)",
    "Likert-scale trust survey",
    "5-point quality rating scale (Likert-like)",
    "5-point Likert satisfaction ratings",
    "expert preference",
    "dermatologist approval rate",
    "Likert scale analysis",
    "quality Likert score",
    "preference percentage",
    "human preference percentage",
    "Likert-scale acceptability ratings",
    "pairwise preference",
    "expert preference proportion",
    "user satisfaction percentage",
    "expert acceptability rating",
    "Likert scale ratings (1-5)",
    "patient trust",
    "4-point human acceptability rating",
    "Likert-scale ratings (overall quality, readability, accuracy, thoroughness, empathy)",
    "Likert-scale survey",
    "preference vote (presumed)",
    "best response selection",
    "clinician suitability acceptance rate",
    "Likert scale score",
    "5-point Likert scale quality rating",
    "patient acceptance",
    "participant preference percentage",
    "perceived usefulness",
    "Likert-scale questionnaire ratings (information provision, clarity, collegiality, conciseness, follow-up, overall satisfaction)",
    "physician preference",
    "human preference",
    "radiologist acceptance rate",
    "FCUR (feedback usefulness)",
    "Likert scale ratings (1\u20135)",
    "Likert satisfaction score",
    "Acceptability E-Scale (AES)",
    "Likert-style ratings for usefulness, acceptance, relevance, understanding, workflow impact, bias, inversion, redundancy",
    "Likert scale for critical approach to AI",
    "Likert scale (1-5)",
    "General Quality Score (5-point Likert)",
    "user feedback",
    "six-point Likert scale",
    "acceptability rate",
    "7-point Likert scale for usefulness",
    "Likert-style questionnaire",
    "user confidence (subjective)",
    "patient satisfaction rating (e.g., Likert scale)",
    "self-reported trust (Likert)",
    "mean 6-point scale rating",
    "survey Likert satisfaction",
    "clinician-rated Likert scores",
    "surgeon ranking score (1-4)",
    "selection rate percentages",
    "qualitative human feedback",
    "subjective ratings (e.g., Likert), qualitative feedback",
    "overall preference proportion"
  ],
  "Usability & Workflow Efficiency": [
    "review time",
    "time to generate/edit responses",
    "accessibility",
    "System Usability Scale (SUS)",
    "time to answer",
    "response efficiency",
    "time per case (seconds)",
    "physician task load score",
    "delivery effectiveness",
    "subjective time-savings assessment",
    "time savings",
    "System Usability Scale",
    "user-friendliness",
    "practicality rating",
    "review time burden",
    "interaction time",
    "BUS-15 usability score",
    "frequency/length of interactions",
    "time to complete task",
    "number of chat turns",
    "patient management time",
    "processing speed",
    "Chatbot Usability Questionnaire",
    "accessibility score",
    "edit time",
    "time to review",
    "Likert-scale usability ratings",
    "usable vs unusable proportion",
    "User Experience Questionnaire (UEQ)",
    "patient management feasibility",
    "doctor-patient communication time",
    "scenario completion time",
    "reading duration",
    "interpretation time",
    "time to decision",
    "timeliness",
    "time to respond",
    "response time",
    "Chatbot Usability Questionnaire (CUQ)",
    "speed",
    "validated usability scales",
    "time-to-edit comparison",
    "editing time",
    "workflow impact",
    "time per case",
    "usability questionnaire",
    "daily documentation time",
    "subjective usability rating",
    "time-to-completion",
    "MAUQ",
    "time to completion",
    "usability rating",
    "frequency of platform logins",
    "decision time"
  ],
  "Calibration & Confidence": [
    "confidence analysis",
    "Brier Score",
    "self-reported confidence scores",
    "diagnostic confidence (Likert)",
    "model confidence score",
    "prediction confidence",
    "confidence",
    "confidence-based accuracy",
    "over-conclusiveness",
    "5-point Likert confidence",
    "confidence scores",
    "calibration error",
    "Brier Skill Score",
    "calibration",
    "confidence ratings",
    "predicted pass probability",
    "calibration curves",
    "confidence accuracy",
    "Brier score",
    "self-confidence",
    "confidence rating",
    "self-reported confidence rating",
    "perplexity (for calibration)",
    "pharmacist confidence ratings",
    "response tendency (\u03b2)",
    "Likert-style confidence score",
    "frequency of overestimation",
    "self-reported confidence",
    "Likert scale confidence",
    "confidence scale"
  ],
  "Faithfulness & Fact-Checking": [
    "accuracy versus authoritative references",
    "counts of misinformation",
    "response veracity",
    "presence of hallucinations",
    "misinformation rate",
    "misleading information presence",
    "reference relevance",
    "percentage academic sources",
    "hallucination mitigation",
    "manual assessment of factual accuracy",
    "RAGAs",
    "false information elicited",
    "incorrect/missing information (%)",
    "RAGAS (faithfulness, answer relevancy, context recall)",
    "reference validity rate",
    "factual correctness score",
    "hallucination index",
    "hallucination count",
    "reference verification",
    "RAGAs Factual Correctness",
    "reference validity",
    "faithfulness",
    "expert review of inaccuracies, hallucinations, and omissions",
    "presence of citations",
    "confabulation rate",
    "proportion of answers misattributed",
    "scientific adequacy score",
    "source identification rate",
    "presence of misinformation",
    "expert ratings of missed information and hallucination",
    "RAGAs Faithfulness",
    "proportion of fabricated references",
    "Likert-scale ratings (hallucination)",
    "citation validity rate",
    "scientificity score",
    "content fidelity",
    "citation sourcing capability",
    "presence of fabricated citations",
    "factual consistency",
    "reference authenticity",
    "proportion of authentic references",
    "reference quality rating",
    "perceived level of misinformation",
    "citation correctness/confabulation rates",
    "citation accuracy",
    "reference provision",
    "Source Credibility",
    "factuality (unspecified)",
    "evidence/faithfulness assessment",
    "meaning preservation",
    "reference authenticity rate",
    "misinformation presence",
    "fidelity to authoritative sources",
    "reference authenticity (fabrication rate)",
    "prevalence of fabricated citations",
    "credibility of citations",
    "hallucination frequency",
    "citation correctness vs hallucination",
    "factual correctness",
    "source reliability/relevancy",
    "reference validity check",
    "falseness rating",
    "reference accuracy/hallucination rate",
    "hallucination rate",
    "alignment with script",
    "count of factual errors",
    "hallucination assessment",
    "verisimilitude",
    "proportion of hallucinated citations",
    "percentage of legitimate references",
    "proportion of fabricated citations",
    "proportion of academic sources",
    "response integrity score",
    "citation presence",
    "percentage of accurately traceable citations",
    "frequency of retracted articles cited by ChatGPT",
    "reference existence rate",
    "content alignment",
    "factual error count",
    "reference verification (fabrication rate)",
    "Misinformation score",
    "faithfulness score",
    "credibility (source citation)",
    "citation adherence"
  ],
  "Bias & Fairness": [
    "bias metrics",
    "presence of race-based misconceptions (binary/qualitative coding)",
    "Inclusivity",
    "difference in decisions across patient demographics",
    "statistical parity",
    "bias",
    "bias detection",
    "demographic bias measures",
    "frequency bias index",
    "CENVE negative stereotype score",
    "neutrality",
    "gender inclusivity assessment",
    "consideration of social factors",
    "proportion of utilitarian vs deontological choices",
    "inclusivity score (1\u20133)",
    "AAVE feature count",
    "inclusivity score",
    "analysis of gender/socioeconomic bias",
    "discrimination",
    "proportion of stigmatizing phrases",
    "differences in GPT-4 assigned coronary artery disease risk estimates by gender and psychiatric comorbidity",
    "difference in recommendations across demographics",
    "equalized odds",
    "bias presence",
    "counts of favorable vs limiting words"
  ],
  "Similarity & Semantic Overlap": [
    "character count comparison",
    "CIDEr",
    "BERT similarity score",
    "answer similarity percentage",
    "similarity score",
    "RAGAS relevance score",
    "thematic fit score",
    "edit distance",
    "Semantic Textual Similarity",
    "automated metrics for human-likeness and domain specialization",
    "Dice Similarity Coefficient (DSC)",
    "cosine similarity (WORD2VEC)",
    "BLEU score",
    "S-BERT similarity scores",
    "subjective preservation-of-meaning rating",
    "mid-token distance",
    "chrF++",
    "BertScore",
    "match rate",
    "cosine similarity (BioLORD-2023)",
    "semantic match ratio",
    "Jaccard index",
    "Jaccard Similarity Index",
    "lexical similarity",
    "automatic summarization metrics (e.g., ROUGE/BLEU/etc.)",
    "TF-IDF similarity",
    "thematic overlap with human summaries",
    "proportion of student answers matching ChatGPT",
    "pixel-based overlap analysis (OpenCV)",
    "Instructor Similarity",
    "natural language assessment metrics (e.g., BLEU, METEOR, ROUGE, CIDEr)",
    "BERTScore F1",
    "semantic similarity",
    "TF-IDF similarity score",
    "BLEU",
    "METEOR",
    "standard LLM benchmark metrics (e.g., BLEU, ROUGE)",
    "qualitative comparison with human literature search",
    "BLEU-2",
    "semantic cosine similarity",
    "TER",
    "similarity (unspecified metric)",
    "text similarity (CountVec, TF-IDF)",
    "text similarity index (plagiarism)",
    "ROUGE-2",
    "ROUGE",
    "textual forma mentis network analysis",
    "Pearson correlation coefficient",
    "answer similarity",
    "text similarity percentage",
    "BARTScore",
    "ROUGE-L",
    "BLEURT",
    "percentage of vocabulary modified",
    "automatic NLP similarity metrics (e.g., BLEU/ROUGE)",
    "content similarity",
    "NDCG@10",
    "Jaccard similarity index",
    "BERTScore",
    "ACC-Sim",
    "qualitative comparison with Food4Me algorithm",
    "percentage overlap",
    "similarity to English responses",
    "question overlap percentage",
    "Sequence Matcher Similarity",
    "Similarity Index (plagiarism)",
    "ROUGE-1",
    "subjective similarity ratings (low/medium/high)",
    "human vs LLM discrimination",
    "cosine similarity",
    "textual similarity",
    "semantic similarity percentage",
    "answer pattern clustering",
    "similarity index",
    "correlation coefficient (e.g., Pearson r)",
    "Cosine Similarity",
    "keyword presence",
    "text similarity algorithms",
    "QuillBot similarity score",
    "sentence similarity",
    "GLEU",
    "Bray-Curtis similarity",
    "AlignScore",
    "Similarity Index",
    "chrF",
    "text similarity metrics",
    "text similarity scores",
    "RAGAs Semantic Similarity",
    "content similarity analysis (Main Idea, Quality Analysis, Common Ideas, Inconsistent Ideas)",
    "sentence similarity (BART, XLM, DeBERTa)",
    "proportion overlap with gold standard"
  ],
  "Patient Education Readiness": [
    "PEMAT-P understandability",
    "Patient Education Materials Assessment Tool",
    "Discern questionnaire",
    "Patient Education Materials Assessment Tool (PEMAT) Understandability",
    "patient comprehension questionnaire",
    "PEMAT actionability",
    "PEMAT-P Actionability",
    "Patient Education Materials Assessment Tool \u2013 Understandability (PEMAT-U)",
    "modified DISCERN score",
    "layperson interpretation rate",
    "PEMAT (understandability)",
    "PEMAT (actionability)",
    "PEMAT understandability",
    "PEMAT actionability score",
    "PEMAT-P actionability",
    "QUEST score",
    "PEMAT-Actionability",
    "Patient Education Materials Assessment Tool \u2013 Actionability (PEMAT-A)",
    "PEMAT-P (understandability and actionability)",
    "informed consent questionnaire",
    "PEMAT-Understandability",
    "PEMAT (understandability, actionability)",
    "PEMAT-P understandability score",
    "PEMAT-P scores",
    "actionability rating",
    "Suitability Assessment of Materials (SAM)",
    "DISCERN-AI",
    "explanation of medical terms score",
    "brief DISCERN tool",
    "modified DISCERN scale",
    "DISCERN Score",
    "PEMAT-AI",
    "PEMAT-P",
    "DISCERN-5",
    "layperson quality ratings",
    "Modified DISCERN Score",
    "PEMAT-P score",
    "actionability",
    "patient-rated understandability (Likert)",
    "patient understanding score (custom Likert-like scale)",
    "hypertension literacy score",
    "modified DISCERN Score",
    "PEMAT Understandability",
    "Modified Discern score",
    "Brief DISCERN score",
    "mDISCERN",
    "PEMAT-P actionability score",
    "PEMAT",
    "modified DISCERN",
    "validated patient education material assessment tools",
    "understandability rating",
    "PEMAT-P Understandability",
    "PEMAT-A",
    "PEMAT understandability %",
    "DISCERN section 2 score",
    "understandability/actionability scores",
    "PEMAT Actionability",
    "DISCERN questionnaire",
    "PEMAT (understandability & actionability)",
    "PEMAT-P Actionability score",
    "Ensuring Quality Information for Patients (EQIP)",
    "DISCERN instrument",
    "modified DISCERN (mDISCERN)",
    "Likert understandability rating",
    "PEMAT-U",
    "modified DISCERN Questionnaire",
    "actionability scores",
    "DISCERN",
    "modern DISCERN score",
    "DISCERN scale",
    "PEMAT (Understandability & Actionability)",
    "modified Ensuring Quality Information for Patients (EQIP) score",
    "understandability scores",
    "understandability",
    "DISCERN tool",
    "PEMAT (Patient Education Materials Assessment Tool)",
    "mDISCERN score",
    "patient-oriented assessment",
    "Patient Education Materials Assessment Tool (PEMAT)",
    "understanding score",
    "DISCERN criteria (5-point scale)",
    "DISCERN score",
    "layperson comprehension score (Likert)",
    "PEMAT understandability score",
    "PEMAT-P Understandability score",
    "CDC Clear Communication Index"
  ],
  "Cognitive/Knowledge Outcomes": [
    "percentile ranking on fertility knowledge surveys",
    "Bloom's taxonomy scoring",
    "test score performance",
    "test scores (correct answers/credit points)",
    "questionnaire score (0-8)",
    "exit exam score (%)",
    "Rasch ability/logit score",
    "SOLO taxonomy score",
    "exam score",
    "learning curve slope",
    "UCLA geriatrics attitude score",
    "cognitive function assessments (unspecified)",
    "Self-Assessment of Informatics Competency Scale",
    "practice exam score",
    "mean SCT score comparison",
    "Likert scale ratings of authenticity and learning effect",
    "SOLO taxonomy",
    "pretest-posttest change in number/type of interview questions (open vs closed)",
    "knowledge level score (0\u201310)",
    "exam rank",
    "exam scores",
    "average test score",
    "Pre-Clinical Clerkship OSCE score",
    "median exam score per scenario",
    "MME benchmark cognitive score",
    "self-reported improvement in understanding (%)",
    "pre-post self-reported anxiety scores",
    "final grades",
    "exam score (%)",
    "questionnaire scores",
    "Structure of Observed Learning Outcomes (SOLO) taxonomy",
    "ISCD scaled score",
    "theoretical knowledge exam scores",
    "nutrition literacy achievement rate",
    "STAI score",
    "UCLA geriatrics knowledge score",
    "knowledge test scores",
    "mean test scores",
    "test score",
    "behavioral intention change",
    "provider comprehension scores",
    "teaching effectiveness score (Likert scale)",
    "cognitive load rating",
    "self-reported understanding",
    "pre-/post-survey changes",
    "pre-post self-reported stress scores",
    "percentage of learning objectives transferred"
  ],
  "Resource Utilization & Cost Efficiency": [
    "completion time",
    "time to generate response",
    "median time per note",
    "afterhours EHR time",
    "generation time",
    "quality of resources",
    "quit rates",
    "examination time",
    "time to diagnosis (Kaplan-Meier)",
    "efficiency ratio (accuracy per kWh)",
    "consultation duration",
    "number of recommended tests",
    "time to generate",
    "number of additional examinations",
    "energy intake",
    "usage rate",
    "token count",
    "cost-benefit analysis",
    "patient throughput",
    "length of visit",
    "inference speed",
    "message usage rate",
    "utilization rate",
    "prediction latency",
    "time to diagnosis",
    "total EHR time",
    "time measures",
    "cost",
    "revision rates",
    "energy use (kWh)",
    "utility score",
    "cost per report",
    "time to correct diagnosis (Cox hazard ratio)",
    "processing time"
  ],
  "Other": [
    "machine-generated scores",
    "subjectivity",
    "qualitative expert opinion",
    "currency rating",
    "domain-specific scores",
    "subjective qualitative assessment",
    "total score",
    "descriptive comparison",
    "custom multidimensional scoring system (details unspecified)",
    "thematic qualitative analysis",
    "ethical assessment",
    "pharmacist feedback",
    "acknowledgment of limitations",
    "CVSC (Concordance, Validity, Safety, Competency)",
    "engagement",
    "adherence to system prompt",
    "qualitative clinical impressions",
    "hexagonal radar schema",
    "synthesis",
    "need for assistance",
    "insight",
    "thematic analysis (qualitative)",
    "ethical considerations",
    "novelty",
    "score",
    "open-ended qualitative feedback",
    "source type classification",
    "output token count",
    "Clinical Reasoning Indicator - History Taking Inventory (CRI-HTI)",
    "AI Response Metric (AIRM)",
    "structured questionnaire",
    "FKRE",
    "qualitative thematic analysis",
    "GPT-4-based automatic rating",
    "approximation",
    "QAMAI tool",
    "overall rating",
    "work exhaustion score",
    "frequency counts",
    "composite score",
    "adaptability",
    "CLEAR",
    "PVQ-RR value scores",
    "flexibility",
    "insight score",
    "free-text qualitative feedback",
    "likelihood of being written by a physician (LWBP)",
    "inductive qualitative thematic analysis",
    "overall rank",
    "presence of graphical elements",
    "SF-12",
    "DSSQ",
    "automatic metrics (unspecified)",
    "relevancy",
    "Quality Evaluation Scoring Tool",
    "quality assessment checklist",
    "compliance with EU AI Act",
    "Global Quality Score (1-5)",
    "custom coding scheme (hotline inclusion, evidence-based content, supportiveness, harmful content, etc.)",
    "not specified",
    "redundancy",
    "serum prealbumin",
    "group-based trajectory models",
    "rubric scores",
    "lung capacity",
    "serum potassium level",
    "context relevancy",
    "Clinical Utility",
    "manual qualitative assessment",
    "qualitative content analysis",
    "frequency distribution",
    "custom consultation quality score",
    "prompt adherence",
    "unspecified",
    "PASS",
    "qualitative assessment of responses",
    "subjective thematic assessment",
    "usage frequency",
    "applicability",
    "unsure",
    "reliance",
    "sidedness",
    "FQ (feedback quality)",
    "user engagement metrics",
    "AIPI",
    "logistic regression",
    "editing metrics",
    "standardized survey",
    "word count",
    "response length (word count)",
    "sentiment analysis",
    "sentence count",
    "qualitative reasoning assessment",
    "explainability rating (Likert)",
    "ethical standards scores",
    "qualitative assessment",
    "percent body fat",
    "AIRM",
    "qualitative questionnaire",
    "dedicated scoring system",
    "information quality rating (unspecified)",
    "sentiment analysis scores",
    "gait patterns",
    "WOMAC",
    "adaptiveness",
    "supplementary response modification requirement",
    "Diet Quality Index-International (DQI-I)",
    "thematic qualitative comparison",
    "ranking",
    "none stated",
    "subjective researcher assessment",
    "qualitative reflections/autoethnography",
    "Content Originality",
    "qualitative commentary",
    "qualitative comparative analysis truth tables",
    "entity count",
    "anthropomorphism rating",
    "QAMAI",
    "Turing-like indistinguishability test",
    "recognition of limitations",
    "qualitative judgment",
    "REF-AI",
    "reach",
    "Resource Matching",
    "thematic analysis of qualitative feedback",
    "subjective assessment",
    "transparency",
    "currency",
    "categorical analysis",
    "source-type frequency",
    "descriptive counts",
    "content length",
    "patient self-management adherence",
    "Quality Assessment of Medical Artificial Intelligence (QAMAI)",
    "Natural Language Assessment Tool for AI",
    "fallacy categorization",
    "eight clinical evaluation metrics (unspecified)",
    "qualitative comparison",
    "word frequency analysis",
    "Visual Analogue Scale for Anxiety (VAS-A)",
    "presence of referral",
    "insight rating",
    "helpfulness",
    "proactive inquiry ability score",
    "subjective specialist assessment",
    "subjective scoring",
    "number of questions",
    "humanness",
    "quality rating (unspecified)",
    "report-generation quality (unspecified metric)",
    "questionnaire (subjective excitement ratings)",
    "relevance",
    "standardized grading criteria",
    "ROM",
    "AI detectability",
    "Perioperative Apprehension Scale-7 (PAS-7)",
    "Rothwell classification distribution",
    "error categorization",
    "perceived morality",
    "objectivity",
    "Shannon diversity",
    "percent muscle",
    "blood pressure",
    "frequency of patient selection",
    "automatic scoring",
    "subjective evaluation",
    "qualitative comparative analysis",
    "MAPPinfo",
    "KOOS",
    "rubric score",
    "subjective expert judgement",
    "inversion",
    "expertise",
    "number of sentences",
    "Fry",
    "SCB",
    "content category (fact vs policy)",
    "none",
    "word frequency",
    "number of optimization iterations",
    "meal variability",
    "information search patterns",
    "subjective quality assessment",
    "overall quality grade",
    "unspecified other metrics",
    "context relevance",
    "ebmNucleus",
    "data leakage",
    "subjective",
    "overall quality rating",
    "usefulness",
    "descriptive analysis",
    "SapBERT",
    "input incorporation",
    "BMI",
    "5-point grading scale (1\u20135)",
    "expert qualitative assessment",
    "qualitative rationale assessment",
    "subjective feedback",
    "number of candidate variants",
    "sentiment polarity",
    "expert qualitative judgement",
    "Bloom's taxonomy error categorization",
    "ethics",
    "replaceability",
    "number of questions asked",
    "qualitative analysis",
    "human care",
    "artifact occurrence",
    "interpretability",
    "modified Turing test",
    "numeric scoring",
    "engagement metrics",
    "relevance (Likert)",
    "SAM",
    "citation counts of retracted articles",
    "overall quality",
    "cluster analysis",
    "mEQIP",
    "image quality rating (0-10)",
    "unspecified comparative alignment",
    "understanding",
    "autonomy questionnaire (Likert)",
    "0-10 scoring rubric",
    "recency",
    "case management metrics",
    "distractor analysis",
    "qualitative comments",
    "relevance rating",
    "qualitative visual fidelity",
    "reasoning",
    "scientificity",
    "topic relevance",
    "content analysis",
    "item plausibility assessment",
    "Visual Analog Scale (VAS)",
    "serum albumin",
    "nonresponse rate",
    "qualitative error categorization",
    "others (unspecified)",
    "personalization ratings",
    "entropy",
    "thematic analysis",
    "descriptive statistics (counts, proportions)",
    "percentage distribution of categories",
    "logic (human rating)",
    "qualitative explanation analysis",
    "serum phosphate",
    "qualitative interviews",
    "Overall Rating",
    "supplementary information",
    "personalization",
    "UniEval",
    "qualitative feedback",
    "ability to detect AI vs human",
    "AI Disclosure",
    "semi-structured interviews",
    "subjectivity score"
  ]
}