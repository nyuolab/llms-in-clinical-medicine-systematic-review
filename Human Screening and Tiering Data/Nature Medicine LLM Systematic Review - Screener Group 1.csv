Title,Abstract,Include?,Screener Name,Comments,,Include,177,Exclude,321,# Remaining,0,% Done,100.00%
Impact of Multimodal Prompt Elements on Diagnostic Performance of GPT-4(V) in Challenging Brain MRI Cases,"Background Recent studies have explored the application of multimodal large language models (LLMs) in radiological differential diagnosis. Yet, how different multimodal input combinations affect diagnostic performance is not well understood. Purpose To evaluate the impact of varying multimodal input elements on the accuracy of GPT-4(V)based brain MRI differential diagnosis. Methods Thirty brain MRI cases with a challenging yet verified diagnosis were selected. Seven prompt groups with variations of four input elements (image, image annotation, medical history, image description) were defined. For each MRI case and prompt group, three identical queries were performed using an LLM-based search engine (© PerplexityAI, powered by GPT-4(V)). Accuracy of LLM-generated differential diagnoses was rated using a binary and a numeric scoring system and analyzed using a chi-square test and a Kruskal-Wallis test. Results were corrected for false discovery rate employing the Benjamini-Hochberg procedure. Regression analyses were performed to determine the contribution of each individual input element to diagnostic performance. Results The prompt group containing an annotated image, medical history, and image description as input exhibited the highest diagnostic accuracy (67.8% correct responses). Significant differences were observed between prompt groups, especially between groups that contained the image description among their inputs, and those that did not. Regression analyses confirmed a large positive effect of the image description on diagnostic accuracy (p << 0.001), as well as a moderate positive effect of the medical history (p < 0.001). The presence of unannotated or annotated images had only minor or insignificant effects on diagnostic accuracy. Conclusion The textual description of radiological image findings was identified as the strongest contributor to performance of GPT-4(V) in brain MRI differential diagnosis, followed by the medical history. The unannotated or annotated image alone yielded very low diagnostic performance. These findings offer guidance on the effective utilization of multimodal LLMs in clinical practice.",Yes,Sully,,,,,,,,,,
Evaluating the utility of ChatGPT to convert clinic letters into patient friendly language,"Communication with patients in language they understand leads to greater comprehension of treatment and diagnoses but can be time consuming for clinicians. Here we sought to investigate the utility of ChatGPT to translate clinic letters into language patients understood, without loss of clinical information. Twenty-three letters from a range of specialities were translated, resulting in no loss of clinical information. Subjective analysis from patient representatives revealed significantly increased understanding of treatment and diagnoses, increased satisfaction, and a significant decrease in the requirement to seek medical assistance in understanding their content when compared to original letters written to clinicians. Overall, we conclude that ChatGPT can be used to translate clinic letters into patient friendly language, and that these letters are preferred by patients.",Yes,Sully,,,,,,,,,,
Quality assurance and validity of AI-generated single best answer questions,"BACKGROUND: Recent advancements in generative artificial intelligence (AI) have opened new avenues in educational methodologies, particularly in medical education. This study seeks to assess whether generative AI might be useful in addressing the depletion of assessment question banks, a challenge intensified during the Covid-era due to the prevalence of open-book examinations, and to augment the pool of formative assessment opportunities available to students. While many recent publications have sought to ascertain whether AI can achieve a passing standard in existing examinations, this study investigates the potential for AI to generate the exam itself. This research utilized a commercially available AI large language model (LLM), OpenAI GPT-4, to generate 220 single best answer (SBA) questions, adhering to Medical Schools Council Assessment Alliance guidelines the and a selection of Learning Outcomes (LOs) of the Scottish Graduate-Entry Medicine (ScotGEM) program. All questions were assessed by an expert panel for accuracy and quality. A total of 50 AI-generated and 50 human-authored questions were used to create two 50-item formative SBA examinations for Year 1 and Year 2 ScotGEM students. Each exam, delivered via the Speedwell eSystem, comprised 25 AI-generated and 25 human-authored questions presented in random order. Students completed the online, closed-book exams on personal devices under exam conditions that reflected summative examinations. The performance of both AI-generated and human-authored questions was evaluated, focusing on facility and discrimination index as key metrics. The screening process revealed that 69% of AI-generated SBAs were fit for inclusion in the examinations with little or no modifications required. Modifications, when necessary, were predominantly due to reasons such as the inclusion of ""all of the above"" options, usage of American English spellings, and non-alphabetized answer choices. 31% of questions were rejected for inclusion in the examinations, due to factual inaccuracies and non-alignment with students' learning. When included in an examination, post hoc statistical analysis indicated no significant difference in performance between the AI- and human- authored questions in terms of facility and discrimination index. DISCUSSION AND CONCLUSION: The outcomes of this study suggest that AI LLMs can generate SBA questions that are in line with best-practice guidelines and specific LOs. However, a robust quality assurance process is necessary to ensure that erroneous questions are identified and rejected. The insights gained from this research provide a foundation for further investigation into refining AI prompts, aiming for a more reliable generation of curriculum-aligned questions. LLMs show significant potential in supplementing traditional methods of question generation in medical education. This approach offers a viable solution to rapidly replenish and diversify assessment resources in medical curricula, marking a step forward in the intersection of AI and education.",No,Sully,"This is a question generation test, not a question answering test if that makes sense",,,,,,,,,
MISTIC: a novel approach for metastasis classification in Italian electronic health records using transformers,"BACKGROUND: Analysis of Electronic Health Records (EHRs) is crucial in 
real-world evidence (RWE), especially in oncology, as it provides valuable 
insights into the complex nature of the disease. The implementation of advanced 
techniques for automated extraction of structured information from textual data 
potentially enables access to expert knowledge in highly specialized contexts. 
In this paper, we introduce MISTIC, a Natural Language Processing (NLP) approach 
to classify the presence or absence of metastasis in Italian EHRs, in the breast 
cancer domain.
METHODS: Our approach consists of a transformer-based framework designed for 
few-shot learning, requiring a small labelled dataset and minimal computational 
resources for training. The pipeline includes text segmentation to improve model 
processing and topic analysis to filter informative content, ensuring relevant 
input data for classification.
RESULTS: MISTIC was evaluated across multiple data sources, and compared to 
several benchmark methodologies, ranging from a pattern-matching system, 
composed of regex and semantic rules, to BERT-based models implemented in a 
zero-shot learning setup and Large Language Models (LLMs). The results 
demonstrate the generalization of our approach, achieving an F-Score above 87% 
on all the sources, and outperforming the other experiments, with an overall 
F-Score of 91.2%.
CONCLUSIONS: MISTIC achieves high performance in the Italian metastasis 
classification task, outperforming rule-based systems, zero-shot BERT models, 
and LLMs. Its few-shot learning setup offers a computationally efficient 
alternative to large-scale models, while its segmentation and topic analysis 
steps enhance explainability by explicitly linking predictions to key textual 
elements. Furthermore, MISTIC demonstrates strong generalization across 
different data sources, reinforcing its potential as a scalable and transparent 
solution for clinical text classification. By extracting high-quality metastatic 
information from diverse textual data, MISTIC supports medical researchers in 
analyzing unstructured and highly informative content across a wide range of 
medical reports. In doing so, it enhances data accessibility and 
interpretability, addressing a critical gap in health informatics and clinical 
practice.

© 2025. The Author(s).",No,Sully,This study aims to extract data from EHR,,,,,,,,,
Gardenia Iridoid Glucosides Protect Against α-Naphthalene Isothiocya-Nate-Induced Cholestatic Rats Through Activation of the FXR-SHP Signaling Pathway,"Introduction: Cholestasis is a common liver disorder that currently has limited treatment options. Gardenia Iridoid Glucosides (GIG) have been found to possess various physiological activities, such as cholagogic, hypoglycemic, antibacterial, and anti-inflammatory effects. The objective of this study was to investigate the effects of GIG on bile acid enterohepatic circulation and explore the underlying mechanism in cholestatic rats. Methods: In order to identify key pathways associated with cholestasis, we conducted Gene Ontology (GO) Enrichment and Kyoto Encyclopedia of Genes and Genomes (KEGG) analyses. In vivo experiments were then performed on alpha-naphthylisothiocyanate (ANIT)-treated rats to assess the impact of GIG. We measured bile flow and various biomarkers including total bilirubin (TB), total bile acids (TBA), total cholesterol (TC), malondialdehyde (MDA), glutamic-pyruvic transaminase (GPT), glutamic oxaloacetic transaminase (GOT), and total superoxide dismutase (T-SOD) in the serum. We also examined the expression levels of bile salt export pump (BSEP), ATP-binding cassette subfamily B member 4 (ABCB4), far-nesoid X receptor (FXR), small heterodimer partner (SHP), cholesterol 7α-hydroxylase (CYP7A1), and sodium taurocholate cotransporting polypeptide (NTCP) in liver tissue. In vitro experiments were conducted on primary hepatocytes to further investigate the mechanism of action of GIG on the expression of SHP, CYP7A1, NTCP, and FXR. Results: Our in vivo experiments demonstrated that GIG significantly increased bile flow and reduced the levels of TB, TBA, TC, MDA, GPT, and GOT, while increasing T-SOD levels in ANIT-treated rats. Additionally, GIG ameliorated liver tissue damage induced by ANIT, upregulated the expression of BSEP and ABCB4, and modulated the protein expression of FXR, SHP, CYP7A1, and NTCP in model rats. In vitro experiments further revealed that GIG inhibited the expression of SHP, CYP7A1, and NTCP by suppressing the expression of FXR. Conclusion: This study provides new insights into the therapeutic potential of GIG for the treatment of cholestasis. GIG demonstrated beneficial effects on bile acid enterohepatic circulation and liver biomarkers in cholestatic rats. The modulation of FXR and its downstream targets may contribute to the mechanism of action of GIG. These findings highlight the potential of GIG as a therapeutic intervention for cholangitis. © 2023 Xu et al.",No,Sully,Irrelevant,,,,,,,,,
Application of generative language models to orthopaedic practice,"Objective To explore whether large language models (LLMs) Generated Pre-trained Transformer (GPT)-3 and ChatGPT can write clinical letters and predict management plans for common orthopaedic scenarios. Design Fifteen scenarios were generated and ChatGPT and GPT-3 prompted to write clinical letters and separately generate management plans for identical scenarios with plans removed. Main outcome measures Letters were assessed for readability using the Readable Tool. Accuracy of letters and management plans were assessed by three independent orthopaedic surgery clinicians. Results Both models generated complete letters for all scenarios after single prompting. Readability was compared using Flesch-Kincade Grade Level (ChatGPT: 8.77 (SD 0.918); GPT-3: 8.47 (SD 0.982)), Flesch Readability Ease (ChatGPT: 58.2 (SD 4.00); GPT-3: 59.3 (SD 6.98)), Simple Measure of Gobbledygook (SMOG) Index (ChatGPT: 11.6 (SD 0.755); GPT-3: 11.4 (SD 1.01)), and reach (ChatGPT: 81.2%; GPT-3: 80.3%). ChatGPT produced more accurate letters (8.7/10 (SD 0.60) vs 7.3/10 (SD 1.41), p=0.024) and management plans (7.9/10 (SD 0.63) vs 6.8/10 (SD 1.06), p<0.001) than GPT-3. However, both LLMs sometimes omitted key information or added additional guidance which was at worst inaccurate. Conclusions This study shows that LLMs are effective for generation of clinical letters. With little prompting, they are readable and mostly accurate. However, they are not consistent, and include inappropriate omissions or insertions. Furthermore, management plans produced by LLMs are generic but often accurate. In the future, a healthcare specific language model trained on accurate and secure data could provide an excellent tool for increasing the efficiency of clinicians through summarisation of large volumes of data into a single clinical letter.  © Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.",Yes,Sully,,,,,,,,,,
Are ChatGPT’s knowledge and interpretation ability comparable to those of medical students in Korea for taking a parasitology examination?: a descriptive study,"This study aimed to compare the knowledge and interpretation ability of ChatGPT, a language model of artificial general intelligence, with those of medical students in Korea by administering a parasitology examination to both ChatGPT and medical students. The examination consisted of 79 items and was administered to ChatGPT on January 1, 2023. The examination results were analyzed in terms of ChatGPT’s overall performance score, its correct answer rate by the items’ knowledge level, and the acceptability of its explanations of the items. ChatGPT’s performance was lower than that of the medical students, and ChatGPT’s correct answer rate was not related to the items’ knowledge level. However, there was a relationship between acceptable explanations and correct answers. In conclusion, ChatGPT’s knowledge and interpretation ability for this parasitology examination were not yet comparable to those of medical students in Korea. 2023 Korea Health Personnel Licensing Examination Institute.",Yes,Sully,,,,,,,,,,
Benchmarking Human–AI collaboration for common evidence appraisal tools,"Background and Objective: It is unknown whether large language models (LLMs) may facilitate time- and resource-intensive text-related processes in evidence appraisal. The objective was to quantify the agreement of LLMs with human consensus in appraisal of scientific reporting (Preferred Reporting Items for Systematic reviews and Meta-Analyses [PRISMA]) and methodological rigor (A MeaSurement Tool to Assess systematic Reviews [AMSTAR]) of systematic reviews and design of clinical trials (PRagmatic Explanatory Continuum Indicator Summary 2 [PRECIS-2]) and to identify areas where collaboration between humans and artificial intelligence (AI) would outperform the traditional consensus process of human raters in efficiency. Study Design and Setting: Five LLMs (Claude-3-Opus, Claude-2, GPT-4, GPT-3.5, Mixtral-8x22B) assessed 112 systematic reviews applying the PRISMA and AMSTAR criteria and 56 randomized controlled trials applying PRECIS-2. We quantified the agreement between human consensus and (1) individual human raters; (2) individual LLMs; (3) combined LLMs approach; (4) human–AI collaboration. Ratings were marked as deferred (undecided) in case of inconsistency between combined LLMs or between the human rater and the LLM. Results: Individual human rater accuracy was 89% for PRISMA and AMSTAR, and 75% for PRECIS-2. Individual LLM accuracy was ranging from 63% (GPT-3.5) to 70% (Claude-3-Opus) for PRISMA, 53% (GPT-3.5) to 74% (Claude-3-Opus) for AMSTAR, and 38% (GPT-4) to 55% (GPT-3.5) for PRECIS-2. Combined LLM ratings led to accuracies of 75%–88% for PRISMA (4%–74% deferred), 74%–89% for AMSTAR (6%–84% deferred), and 64%–79% for PRECIS-2 (29%–88% deferred). Human–AI collaboration resulted in the best accuracies from 89% to 96% for PRISMA (25/35% deferred), 91%–95% for AMSTAR (27/30% deferred), and 80%–86% for PRECIS-2 (76/71% deferred). Conclusion: Current LLMs alone appraised evidence worse than humans. Human–AI collaboration may reduce workload for the second human rater for the assessment of reporting (PRISMA) and methodological rigor (AMSTAR) but not for complex tasks such as PRECIS-2. © 2024 The Authors",No,Sully,,,,,,,,,,
Identifying and Extracting Rare Diseases and Their Phenotypes with Large Language Models,"Purpose: Phenotyping is critical for informing rare disease diagnosis and treatment, but disease phenotypes are often embedded in unstructured text. While natural language processing (NLP) can automate extraction, a major bottleneck is developing annotated corpora. Recently, prompt learning with large language models (LLMs) has been shown to lead to generalizable results without any (zero-shot) or few annotated samples (few-shot), but none have explored this for rare diseases. Our work is the first to study prompt learning for identifying and extracting rare disease phenotypes in the zero- and few-shot settings. Methods: We compared the performance of prompt learning with ChatGPT and fine-tuning with BioClinicalBERT. We engineered novel prompts for ChatGPT to identify and extract rare diseases and their phenotypes (e.g., diseases, symptoms, and signs), established a benchmark for evaluating its performance, and conducted an in-depth error analysis. Results: Overall, fine-tuning BioClinicalBERT resulted in higher performance (F1 of 0.689) than ChatGPT (F1 of 0.472 and 0.610 in the zero- and few-shot settings, respectively). However, ChatGPT achieved higher accuracy for rare diseases and signs in the one-shot setting (F1 of 0.778 and 0.725). Conversational, sentence-based prompts generally achieved higher accuracy than structured lists. Conclusion: Prompt learning using ChatGPT has the potential to match or outperform fine-tuning BioClinicalBERT at extracting rare diseases and signs with just one annotated sample. Given its accessibility, ChatGPT could be leveraged to extract these entities without relying on a large, annotated corpus. While LLMs can support rare disease phenotyping, researchers should critically evaluate model outputs to ensure phenotyping accuracy. © The Author(s) 2024.",No,Sully,This is a data extraction task,,,,,,,,,
The accuracy of large language models in labelling neurosurgical ‘case-control studies’ and risk of bias assessment: protocol for a study of interrater agreement with human reviewers,"Introduction: Accurate identification of study designs and risk of bias (RoB) assessment is crucial for evidence synthesis in research. However, mislabelling of case-control studies (CCS) is prevalent, leading to a downgraded quality of evidence. Large Language Models (LLMs), a form of artificial intelligence, have shown impressive performance in various medical tasks. Still, their utility and application in categorising study designs and assessing RoB needs to be further explored. This study will evaluate the performance of four publicly available LLMs (ChatGPT-3.5, ChatGPT-4, Claude 3 Sonnet, Claude 3 Opus) in accurately identifying CCS designs from the neurosurgical literature. Secondly, we will assess the human-LLM interrater agreement for RoB assessment of true CCS. Methods: We identified thirty-four top-ranking neurosurgical-focused journals and searched them on PubMed/MEDLINE for manuscripts reported as CCS in the title/abstract. Human reviewers will independently assess study designs and RoB using the Newcastle-Ottawa Scale. The methods sections/full-text articles will be provided to LLMs to determine study designs and assess RoB. Cohen's kappa will be used to evaluate human-human, human-LLM and LLM-LLM interrater agreement. Logistic regression will be used to assess study characteristics affecting performance. A p-value < 0.05 at a 95% confidence interval will be considered statistically significant. Conclusion If the human-LLM agreement is high, LLMs could become valuable teaching and quality assurance tools for critical appraisal in neurosurgery and other medical fields. This study will contribute to validating LLMs for specialised scientific tasks in evidence synthesis. This could lead to reduced review costs, faster completion, standardisation, and minimal errors in evidence synthesis.",No,Sully,"Once again, data extraction",,,,,,,,,
An LLM-Based Visualization and Analysis Aid for a Secondary Use Clinical Data Platform,"This work introduces a novel approach to facilitate clinical research on secondary clinical data by integrating an LLM-based chatbot within a specialized platform called data hotel. The platform is designed to empower clinical researchers within our institution by enabling the generation of research hypotheses from secondary use patient data sources. Our focus in this work is on the deployment and functionality of the LLM-based chatbot within the data hotel ecosystem. The aim is to aid medical experts in visualizing and analyzing data sourced from the platform but also to enable the seamless storage of the generated code, enhancing the efficiency and reproducibility of the research process. This integration represents a significant advancement in leveraging LLM capabilities to enhance the utility and accessibility of clinical research platforms. © 2024 The Authors.",No,Sully,Data analysis again,,,,,,,,,
Putting ChatGPT’s Medical Advice to the (Turing) Test,"Importance: Chatbots could play a role in answering patient questions, but patients’ ability to distinguish between provider and chatbot responses, and patients’ trust in chatbots’ functions are not well established. Objective: To assess the feasibility of using ChatGPT or a similar AI-based chatbot for patient-provider communication. Design: Survey in January 2023 Setting: Survey Participants: A US representative sample of 430 study participants aged 18 and above was recruited on Prolific, a crowdsourcing platform for academic studies. 426 participants filled out the full survey. After removing participants who spent less than 3 minutes on the survey, 392 respondents remained. 53.2% of respondents analyzed were women; their average age was 47.1. Exposure(s): Ten representative non-administrative patient-provider interactions were extracted from the EHR. Patients’ questions were placed in ChatGPT with a request for the chatbot to respond using approximately the same word count as the human provider’s response. In the survey, each patient’s question was followed by a provider- or ChatGPT-generated response. Participants were informed that five responses were provider-generated and five were chatbot-generated. Participants were asked, and incentivized financially, to correctly identify the response source. Participants were also asked about their trust in chatbots’ functions in patient-provider communication, using a Likert scale of 1-5. Main Outcome(s) and Measure(s): Main outcome: Proportion of responses correctly classified as provider- vs chatbot-generated. Secondary outcomes: Average and standard deviation of responses to trust questions. Results: The correct classification of responses ranged between 49.0% to 85.7% for different questions. On average, chatbot responses were correctly identified 65.5% of the time, and provider responses were correctly distinguished 65.1% of the time. On average, responses toward patients’ trust in chatbots’ functions were weakly positive (mean Likert score: 3.4), with lower trust as the health-related complexity of the task in questions increased. Conclusions and Relevance: ChatGPT responses to patient questions were weakly distinguishable from provider responses. Laypeople appear to trust the use of chatbots to answer lower risk health questions. It is important to continue studying patient-chatbot interaction as chatbots move from administrative to more clinical roles in healthcare.",Yes,Sully,This is a silly study but fits the inclusion criteria,,,,,,,,,
Effects of Large Language Model–Based Offerings on the Well-Being of Students: Qualitative Study,"Background: In recent years, the adoption of large language model (LLM) applications, such as ChatGPT, has seen a significant surge, particularly among students. These artificial intelligence–driven tools offer unprecedented access to information and conversational assistance, which is reshaping the way students engage with academic content and manage the learning process. Despite the growing prevalence of LLMs and reliance on these technologies, there remains a notable gap in qualitative in-depth research examining the emotional and psychological effects of LLMs on users’ mental well-being. Objective: In order to address these emerging and critical issues, this study explores the role of LLM-based offerings, such as ChatGPT, in students’ lives, namely, how postgraduate students use such offerings and how they make students feel, and examines the impact on students’ well-being. Methods: To address the aims of this study, we employed an exploratory approach, using in-depth, semistructured, qualitative, face-to-face interviews with 23 users (13 female and 10 male users; mean age 23 years, SD 1.55 years) of ChatGPT-4o, who were also university students at the time (inclusion criteria). Interviewees were invited to reflect upon how they use ChatGPT, how it makes them feel, and how it may influence their lives. Results: The current findings from the exploratory qualitative interviews showed that users appreciate the functional support (8/23, 35%), escapism (8/23, 35%), and fantasy fulfillment (7/23, 30%) they receive from LLM-based offerings, such as ChatGPT, but at the same time, such usage is seen as a “double-edged sword,” with respondents indicating anxiety (8/23, 35%), dependence (11/23, 48%), concerns about deskilling (12/23, 52%), and angst or pessimism about the future (11/23, 48%). Conclusions: This study employed exploratory in-depth interviews to examine how the usage of LLM-based offerings, such as ChatGPT, makes users feel and assess the effects of using LLM-based offerings on mental well-being. The findings of this study show that students used ChatGPT to make their lives easier and felt a sense of cognitive escapism and even fantasy fulfillment, but this came at the cost of feeling anxious and pessimistic about the future. © 2024 JMIR Publications Inc.. All rights reserved.",No,Sully,,,,,,,,,,
Pros and Cons of Using Artificial Intelligence Chatbots for Musculoskeletal Rehabilitation Management,2023. doi:10.2519/jospt.2023.12000.,No,Sully,Op-ed,,,,,,,,,
Toward Improved Radiologic Diagnostics: Investigating the Utility and Limitations of GPT-3.5 Turbo and GPT-4 with Quiz Cases,"BACKGROUND AND PURPOSE: The rise of large language models such as generative pretrained transformers (GPTs) has sparked considerable interest in radiology, especially in interpreting radiologic reports and image findings. While existing research has focused on GPTs estimating diagnoses from radiologic descriptions, exploring alternative diagnostic information sources is also crucial. This study introduces the use of GPTs (GPT-3.5 Turbo and GPT-4) for information retrieval and summarization, searching relevant case reports via PubMed, and investigates their potential to aid diagnosis. MATERIALS AND METHODS: From October 2021 to December 2023, we selected 115 cases from the “Case of the Week” series on the American Journal of Neuroradiology website. Their Description and Legend sections were presented to the GPTs for the 2 tasks. For the Direct Diagnosis task, the models provided 3 differential diagnoses that were considered correct if they matched the diagnosis in the diagnosis section. For the Case Report Search task, the models generated 2 keywords per case, creating PubMed search queries to extract up to 3 relevant reports. A response was considered correct if reports containing the disease name stated in the diagnosis section were extracted. The McNemar test was used to evaluate whether adding a Case Report Search to Direct Diagnosis improved overall accuracy. RESULTS: In the Direct Diagnosis task, GPT-3.5 Turbo achieved a correct response rate of 26% (30/115 cases), whereas GPT-4 achieved 41% (47/115). For the Case Report Search task, GPT-3.5 Turbo scored 10% (11/115), and GPT-4 scored 7% (8/115). Correct responses totaled 32% (37/115) with 3 overlapping cases for GPT-3.5 Turbo, whereas GPT-4 had 43% (50/115) of correct responses with 5 overlapping cases. Adding Case Report Search improved GPT-3.5 Turbo's performance (P ¼ .023) but not that of GPT-4 (P ¼ .248). CONCLUSIONS: The effectiveness of adding Case Report Search to GPT-3.5 Turbo was particularly pronounced, suggesting its potential as an alternative diagnostic approach to GPTs, particularly in scenarios where direct diagnoses from GPTs are not obtainable. Nevertheless, the overall performance of GPT models in both direct diagnosis and case report retrieval tasks remains not optimal, and users should be aware of their limitations. © 2024 American Society of Neuroradiology. All rights reserved.",Yes,Sully,,,,,,,,,,
Dispensing Climate Change Information in Mother Tongue Using a GPT-4 Based a ChatBot: A Case with Mauritian Creole,"As the effects of climate change become more pronounced, residents of low lying coastal areas are experiencing these effects with often devastating results. Being able to dispense information about climate change to the residents of these areas in languages which they understand is important. Mauritius is an island nation in the Indian Ocean and has been in the path of multiple cyclones of increasing strength due to climate change. This paper looks at the possibility of using OpenAI's GPT-4 API connected to a mobile chat app such as Whatsapp in order to dispense information about climate change and adjacent topics such as the built environment in the mother tongue of the residents of Mauritius-namely Mauritian Creole. A chatbot was created using GPT-4 which was configured to be an expert in climate change and associated architectural issues and which communicated textually in Mauritian Creole. This paper reports on the language evaluation of this chatbot. © 2024 IEEE.",No,Sully,,,,,,,,,,
Automated Harmonization and Large-Scale Integration of Heterogeneous Biomedical Sample Metadata Using Large Language Models,"The exponential growth of biomedical data has created an urgent need for efficient integration and analysis of heterogeneous sample metadata across studies. However, current methods for harmonizing and standardizing these metadata are largely manual, time-consuming, and prone to inconsistencies. Here, we present a novel computational framework that leverages large language models (LLMs) to automate the harmonization and large-scale integration of diverse biomedical sample metadata. Our approach combines semantic clustering techniques with LLM-driven natural language processing to extract, interpret, and standardize metadata from various sources, including research papers, supplementary tables, and text data from public databases. We demonstrate the efficacy of our framework by applying it to thousands of human gut microbiome papers, successfully extracting and integrating metadata from over 400,000 samples. Our method achieved a 50% recovery rate of manually curated metadata, significantly outperforming traditional rule-based methods. Furthermore, our framework enabled the creation of a unified, searchable database of standardized metadata, facilitating cross-study analyses and revealing previously obscured patterns in microbiome composition across diverse populations and conditions. The scalability and adaptability of our approach suggest its potential applicability to a wide range of biomedical fields, potentially accelerating meta-analyses and fostering new insights from existing data. This work represents a significant advancement in biomedical data integration, offering a powerful tool for researchers to unlock the full potential of accumulated scientific knowledge.",No,Sully,,,,,,,,,,
How will artificial intelligence transform cardiovascular computed tomography? A conversation with an AI model,"Artificial intelligence (AI) has the potential to transform healthcare, but its clinical use also has important challenges and limitations. Recently natural language processing and generative pre-training transformer (GPT) models have gained particular interest due to their ability to simulate human conversation. We aimed to explore output of the ChatGPT model (OpenAI, https://openai.com/blog/chatgpt) regarding current debates in cardiovascular CT. Prompts included debate questions from the Society of Cardiovascular Computed Tomography 2023 programme as well as questions about high risk plaque (HRP), quantitative plaque analysis, and how AI will transform cardiovascular CT. The AI model rapidly provided plausible responses including both pro and con sides of the argument. Advantages of AI for cardiovascular CT that were described by the AI model included improving image quality, speed of reporting, accuracy, and consistency. The AI model also acknowledged the importance for continued involvement of clinicians in patient care. © 2023 Society of Cardiovascular Computed Tomography",No,Sully,Why did anyone even do this study,,,,,,,,,
Patient2Trial: From patient to participant in clinical trials using large language models,"Purpose: Large language models (LLMs) exhibit promising language understanding and generation capabilities and have been adopted for various clinical use cases. Investigating the feasibility of leveraging LLMs in building a clinical trial retrieval system for patients is crucial as it can greatly enhance the patient enrollment process by prioritizing the most suitable trials pertaining to a patient. In this work, we develop an LLM-assisted system focused on a patient-initiated approach, allowing patients with specific conditions to directly find eligible trials by completing disorder-specific questionnaires. Methods: We obtained clinical trial eligibility criteria (from ClinicalTrials.gov) and simulated patient questionnaires (or topics) from the Text REtrieval Conference (TREC) 2023 Clinical Trials Track conducted by the National Institute of Standards and Technology (NIST), in which we also participated. These topics cover eight disorders across diverse domains, namely glaucoma, anxiety, chronic obstructive pulmonary disease, breast cancer, Covid-19, rheumatoid arthritis, sickle cell anemia, and type 2 diabetes. A Generative Pre-trained Transformer model (GPT-4) was employed for system development. We conducted both quantitative and qualitative evaluation using 37 patient topics. Results: The system achieved an overall Precision@10 (proportion of relevant trials) of 0.7351 and NDCG@10 (considers ranking order of relevant trials) of 0.8109, indicating its effectiveness in retrieving ranked lists of suitable trials for patients. Notably, for eight out of 37 patient topics, all the top 10 retrieved trials were relevant. The system scored the highest on breast cancer (NDCG@10 = 0.9347, Precision@10 = 0.84) and the lowest on type 2 diabetes (NDCG@10 = 0.61, Precision@10 = 0.475). One probable reason could be that the information in breast cancer topics is relatively straightforward to match. Qualitative error analysis classified errors into four categories (e.g., difficulty in correctly matching inclusion criteria) and further highlighted strengths (e.g., ability to make clinical inference). Conclusion: We demonstrated the feasibility of integrating LLMs in identifying and ranking suitable trials for patients across multiple disorders. Further work is required to assess the system's generalizability on other disorders and patient information sources. This system has the potential to expedite the patient-trial matching process by suggesting a ranked list of applicable trials to patients and clinicians. © 2025",No,Sully,This is a cool LLM application but not really a super clinical one,,,,,,,,,
Crafting medical MCQs with generative AI: A how-to guide on leveraging ChatGPT,"2024.

Crafting medical MCQs with generative AI: A how-to guide on leveraging ChatGPT.

Stadler M(1), Horrer A(1), Fischer MR(1).

Author information:
(1)LMU University Hospital, LMU Munich, Institute for Medical Education, Munich, 
Germany.

As medical educators grapple with the consistent demand for high-quality 
assessments, the integration of artificial intelligence presents a novel 
solution. This how-to article delves into the mechanics of employing ChatGPT for 
generating Multiple Choice Questions (MCQs) within the medical curriculum. 
Focusing on the intricacies of prompt engineering, we elucidate the steps and 
considerations imperative for achieving targeted, high-fidelity results. The 
article presents varying outcomes based on different prompt structures, 
highlighting the AI's adaptability in producing questions of distinct 
complexities. While emphasizing the transformative potential of ChatGPT, we also 
spotlight challenges, including the AI's occasional ""hallucination"", 
underscoring the importance of rigorous review. This guide aims to furnish 
educators with the know-how to integrate AI into their assessment creation 
process, heralding a new era in medical education tools.

Copyright © 2024 Stadler et al.",No,Sully,Tests a med-ed use case,,,,,,,,,
ESR paper on structured reporting in radiology—update 2023,"Structured reporting in radiology continues to hold substantial potential to improve the quality of service provided to patients and referring physicians. Despite many physicians’ preference for structured reports and various efforts by radiological societies and some vendors, structured reporting has still not been widely adopted in clinical routine. While in many countries national radiological societies have launched initiatives to further promote structured reporting, cross-institutional applications of report templates and incentives for usage of structured reporting are lacking. Various legislative measures have been taken in the USA and the European Union to promote interoperable data formats such as Fast Healthcare Interoperability Resources (FHIR) in the context of the EU Health Data Space (EHDS) which will certainly be relevant for the future of structured reporting. Lastly, recent advances in artificial intelligence and large language models may provide innovative and efficient approaches to integrate structured reporting more seamlessly into the radiologists’ workflow. The ESR will remain committed to advancing structured reporting as a key component towards more value-based radiology. Practical solutions for structured reporting need to be provided by vendors. Policy makers should incentivize the usage of structured radiological reporting, especially in cross-institutional setting. Critical relevance statement Over the past years, the benefits of structured reporting in radiology have been widely discussed and agreed upon; however, implementation in clinical routine is lacking due—policy makers should incentivize the usage of structured radiological reporting, especially in cross-institutional setting. Key points 1. Various national societies have established initiatives for structured reporting in radiology. 2. Almost no monetary or structural incentives exist that favor structured reporting. 3. A consensus on technical standards for structured reporting is still missing. 4. The application of large language models may help structuring radiological reports. 5. Policy makers should incentivize the usage of structured radiological reporting. Graphical Abstract: [Figure not available: see fulltext.]. © 2023, The Author(s).",No,Sully,This talks about using LLMs to structure already-written reports,,,,,,,,,
Research Letter: Characterizing spin in psychiatric clinical research literature using large language models,"Importance: Spin is a common form of biased reporting that misrepresents study results in publications as more positive than an objective assessment would indicate, but its prevalence in psychiatric journals is unknown. Objective: To apply a large language model to characterize the extent to which original reports of pharmacologic and non-pharmacologic interventions in psychiatric journals reflect spin. Design: We identified abstracts from studies published between 2013 and 2023 in 3 high-impact psychiatric journals describing randomized trials or meta-analyses of interventions. Main Outcome and Measure: Presence or absence of spin estimated by a large language model (GPT4-turbo, turbo-2024-04-09), validated using gold standard abstracts with and without spin. Results: Among a total of 663 abstracts, 296 (44.6%) exhibited possible or probable spin – 230/529 (43.5%) randomized trials, 66/134 (49.3%) meta-analyses; 148/310 (47.7%) for medication, 107/238 (45.0%) for psychotherapy, and 41/115 (35.7%) for other interventions. In a multivariable logistic regression model, reports of randomized trials, and non-pharmacologic/non-psychotherapy interventions, were less likely to exhibit spin, as were more recent publications Conclusions and Relevance: A substantial subset of psychiatric intervention abstracts in high-impact journals may contain results presented in a potentially misleading way, with the potential to impact clinical practice. The success in automating spin detection via large language models may facilitate identification and revision to minimize spin in future publications.",No,Sully,This is kinda cool but is an analysis of studies,,,,,,,,,
An Opportunity to Standardize and Enhance Intelligent Virtual Assistant-Delivered Layperson Cardiopulmonary Resuscitation Instructions,"Importance: Intelligent virtual assistants (IVAs) are ubiquitous and hold the potential to provide bystander cardiopulmonary resuscitation (CPR) instructions during an emergency. Objective: To evaluate the quality of CPR instructions provided by IVAs. Design: We evaluated the appropriateness of responses of four IVAs (Amazon Alexa, Apple Siri, Google Assistant, and Microsoft Cortana) to eight CPR-related questions. We also evaluated text-based responses provided by OpenAI ChatGPT, a recently developed artificial intelligence large language model. Results: Out of 32 responses provided by IVAs, only 19 (59%) were related to CPR, 9 (28%) suggested calling emergency services, and 4 (12%) provided verbal CPR instructions. All responses provided by ChatGPT were related to CPR and suggested calling emergency services. Among responses related to CPR, the answers provided varied significantly in the utility of information provided. Conclusions and Relevance: These results highlight the need for the technology industry to partner with the medical community to improve and standardize bystander CPR instruction provided by IVAs.",No,Sully,,,,,,,,,,
"Adoption of ChatGPT in Higher Education-Application of IDT Model, Testing and Validation","ChatGPT refers to a latest AI tool which is natural language processing (NLP) based, an interactive Chatbot, which can do conversation with identified and notable users for various purposes like content creation, writing, auditing and providing answers to day-to-day questions. ChatGPT is been used by many users belong to different professions, ages, genders etc. As of now, but most of the users of ChatGPT are found to be students' category, who are using ChatGPT for their academic learning purpose. With this background, an attempt has been made to understand the factors influencing adoption of ChatGPT by the higher education students. For this purpose, a research survey has been designed and the Innovation Diffusion Theory (IDT) was applied to know the factors affecting Innovation Adoption (i.e. Adoption of ChatGPT). The primary data was collected from higher education students in the city of Visakhapatnam, India. The statistical tools CFA and SEM were applied to achieve the research aim of factors influencing higher education students to adopt ChatGPT. The results show that two factors/ constructs i.e. Trialability (T) and Observability (O) are found to be significant and three factors Relative Advantage (A), Compatibility (C) and Complexity (C) are not found to be significant.  © 2023 IEEE.",No,Sully,,,,,,,,,,
The efficacy of artificial intelligence in urology: a detailed analysis of kidney stone-related queries,"Purpose: The study aimed to assess the efficacy of OpenAI's advanced AI model, ChatGPT, in diagnosing urological conditions, focusing on kidney stones. Materials and methods: A set of 90 structured questions, compliant with EAU Guidelines 2023, was curated by seasoned urologists for this investigation. We evaluated ChatGPT's performance based on the accuracy and completeness of its responses to two types of questions [binary (true/false) and descriptive (multiple-choice)], stratified into difficulty levels: easy, moderate, and complex. Furthermore, we analyzed the model's learning and adaptability capacity by reassessing the initially incorrect responses after a 2 week interval. Results: The model demonstrated commendable accuracy, correctly answering 80% of binary questions (n:45) and 93.3% of descriptive questions (n:45). The model's performance showed no significant variation across different question difficulty levels, with p-values of 0.548 for accuracy and 0.417 for completeness, respectively. Upon reassessment of initially 12 incorrect responses (9 binary to 3 descriptive) after two weeks, ChatGPT's accuracy showed substantial improvement. The mean accuracy score significantly increased from 1.58 ± 0.51 to 2.83 ± 0.93 (p = 0.004), underlining the model's ability to learn and adapt over time. Conclusion: These findings highlight the potential of ChatGPT in urological diagnostics, but also underscore areas requiring enhancement, especially in the completeness of responses to complex queries. The study endorses AI's incorporation into healthcare, while advocating for prudence and professional supervision in its application. © The Author(s) 2024.",Yes,Sully,Uses ChatGPT to answer questions about kidney stones,,,,,,,,,
AI-driven evidence synthesis: data extraction of randomized controlled trials with large language models,"The advancement of large language models (LLMs) presents promising opportunities to enhance evidence synthesis efficiency, particularly in data extraction processes, yet existing prompts for data extraction remain limited, focusing primarily on commonly used items without accommodating diverse extraction needs. This research letter developed structured prompts for LLMs and evaluated their feasibility in extracting data from randomized controlled trials (RCTs). Using Claude (Claude-2) as the platform, we designed comprehensive structured prompts comprising 58 items across six Cochrane Handbook domains and tested them on 10 randomly selected RCTs from published Cochrane reviews. The results demonstrated high accuracy with an overall correct rate of 94.77% (95% CI: 93.66% to 95.73%), with domain-specific performance ranging from 77.97% to 100%. The extraction process proved efficient, requiring only 88 seconds per RCT. These findings substantiate the feasibility and potential value of LLMs in evidence synthesis when guided by structured prompts, marking a significant advancement in systematic review methodology. Copyright © 2025 The Author(s). Published by Wolters Kluwer Health, Inc.",No,Sully,Clinical-adjacent data extraction task,,,,,,,,,
Generating Uniformly Cross-Reactive Ebolavirus spp. Anti-nucleoprotein Nanobodies to Facilitate Forward Capable Detection Strategies,"It is often challenging for a single monoclonal antibody to cross-react equally with all species of a particular viral genus that are separated by time and geographies to ensure broad long-term global immunodiagnostic use. Here, we set out to isolate nanobodies or single-domain antibodies (sdAbs) with uniform cross-reactivity to the genus Ebolavirus by immunizing a llama with recombinant nucleoprotein (NP) representing the 5 cultivated species to assemble a phage display repertoire for mining. Screening sdAbs for reactivity against the C-terminal domain of NP guided the isolation of clones that could perform as both captor and tracer for polyvalent antigen in sandwich assays. Two promising sdAbs had equivalent reactivities across all 5 species and greatly enhanced the equilibrium concentration at 50% (EC50) for recombinant NP when compared with a differentially cross-reactive nonimmune sdAb isolated previously. Uniform reactivity and enhanced sensitivity were relayed to live virus titrations, resulting in lower limits of detection of 2-5 pfu for the best sdAbs, representing 10-, 20-, and 100-fold improvements for Zaire, Sudan/Reston, and Taï Forest viruses, respectively. Fusions of the sdAbs with ascorbate peroxidase (APEX2) and mNeonGreen generated one-step immunoreagents useful for colorimetric and fluorescent visualization of cellular NP. Both sdAbs were also able to recognize recombinant NPs from the recently discovered Bombali virus, a putative sixth Ebolavirus species unknown at the start of these experiments, validating the forward capabilities of the sdAbs. The simplicity and modularity of these sdAbs should enable advances in antigen-based diagnostic technologies to be retuned toward filoviral detection relatively easily, thereby proactively safeguarding human health. © 2022 American Chemical Society",No,Sully,Cool but unrelated,,,,,,,,,
ChatGPT-o1 and the Pitfalls of Familiar Reasoning in Medical Ethics,"Large language models (LLMs) like ChatGPT often exhibit Type 1 thinking—fast, intuitive reasoning that relies on familiar patterns—which can be dangerously simplistic in complex medical or ethical scenarios requiring more deliberate analysis. In our recent explorations, we observed that LLMs frequently default to well-known answers, failing to recognize nuances or twists in presented situations. For instance, when faced with modified versions of the classic ""Surgeon's Dilemma"" or medical ethics cases where typical dilemmas were resolved, LLMs still reverted to standard responses, overlooking critical details. Even models designed for enhanced analytical reasoning, such as ChatGPT-o1, did not consistently overcome these limitations. This suggests that despite advancements toward fostering Type 2 thinking, LLMs remain heavily influenced by familiar patterns ingrained during training. As LLMs are increasingly integrated into clinical practice, it is crucial to acknowledge and address these shortcomings to ensure reliable and contextually appropriate AI assistance in medical decision-making.",Yes,Sully,"This is a tough call, but they actually do try to evaluate clinical judgement, specifically from an ethics standpoint here",,,,,,,,,
SF-GPT: A training-free method to enhance capabilities for knowledge graph construction in LLMs,"Knowledge graphs (KGs) are constructed by extracting knowledge triples from text and fusing knowledge, enhancing information retrieval efficiency. Current methods for knowledge triple extraction include ”Pretrain and Fine-tuning” and Large Language Models (LLMs). The former shifts effort from manual extraction to dataset annotation and suffers from performance degradation with different test and training set distributions. LLMs-based methods face errors and incompleteness in extraction. We introduce SF-GPT, a training-free method to address these issues. Firstly, we propose the Entity Extraction Filter (EEF) module to filter triple generation results, addressing evaluation and cleansing challenges. Secondly, we introduce a training-free Entity Alignment Module based on Entity Alias Generation (EAG), tackling semantic richness and interpretability issues in LLM-based knowledge fusion. Finally, our Self-Fusion Subgraph strategy uses multi-response self-fusion and a common entity list to filter triple results, reducing noise from LLMs’ multi-responses. In experiments, SF-GPT showed a 55.5% increase in recall and a 32.6% increase in F1 score on the BDNC dataset compared to the UniRel model trained on the NYT dataset and achieved a 5% improvement in F1 score compared to GPT-4+EEF baseline on the WebNLG dataset in the case of a fusion round of three. SF-GPT offers a promising way to extract knowledge from unstructured information.",No,Sully,,,,,,,,,,
Research Domain Criteria in NIMH Grants Characterized Using Large Language Models,"Importance: Over the past decade, the leadership of the National Institute of Mental Health (NIMH) has emphasized the importance of a transdiagnostic approach to psychiatric investigation using Research Domain Criteria (RDoC) mapping more closely to neurobiology. Objective: To investigate whether research support from the NIMH for individual RDoC domains and for transdiagnostic investigation has changed over time and has had differential impact in terms of publication, citations, or patent filings. Design, Setting, and Participants: In this longitudinal cohort study, all R01, R21, and R03 studies funded by the NIMH between January 2003 and December 2023 were identified via the National Institutes of Health RePORTER database. Their abstracts were characterized in terms of RDoC domains (negative valence, positive valence, cognition, social, arousal, and sensorimotor) using a large language model. Main Outcomes and Measures: Primary outcomes were publications, citation impact estimated at 5 years from the index year of funding, and patents, examined using regression models adjusted for other grant characteristics. Results: Among 8897 R01, R03, and R21 projects, reflecting $17.7 billion of investment, abstracts of 3141 (35.3%) reflected negative valence; 1344 (15.1%), positive valence; 2781 (31.3%), cognition; 1607 (18.1%), social; 343 (3.9%), arousal; and 571 (6.4%), sensorimotor domains. A total of 1793 (20.2%) incorporated a transdiagnostic perspective. Positive and social domains were associated with fewer publications (difference, -1.13 [95% CI, -2.11 to -0.15] and -2.23 [95% CI, -3.15 to -1.30], respectively) and lesser citation impact (difference, -0.47 [95% CI, -0.75 to -0.18] and -1.19 [95% CI, -1.46 to -0.91], respectively) at 5 years. Social (adjusted odds ratio [AOR], 0.11; 95% CI, 0.04-0.23) and cognitive (AOR, 0.66; 95% CI, 0.48-0.89) domains and transdiagnostic proposals (AOR, 0.37; 95% CI, 0.21-0.60) were associated with lower likelihood of patent filing. Conclusions and Relevance: In this study of NIMH funding, grants reflecting different RDoC domains differed substantially in their scientific impact in terms of publications, citations, and patent generation. The findings suggest that large language models represent a promising approach to characterizing research proposals at scale, which may be useful in guiding resource allocation to maximize scientific return on investment.",No,Sully,,,,,,,,,,
Evaluating the Diagnostic and Treatment Recommendation Capabilities of GPT-4 Vision in Dermatology,"Background: The integration of artificial intelligence (AI) in dermatology presents a promising frontier for enhancing diagnostic accuracy and treatment planning. However, general purpose AI models require rigorous evaluation before being applied to real-world medical cases. Objective: This project specifically evaluates GPT-4V's performance in accurately diagnosing and generating treatment plans for common dermatological conditions, comparing its assessment of textual versus image data and its performance with multimodal inputs. Beyond the immediate scope, this study contributes to the broader trajectory of integrating AI in healthcare, highlighting the limitations of these technologies, as well as their potential to enhance efficiency, and education within medical training and practice. Methods: A dataset of 102 images representing nine common dermatological conditions was compiled from open-access websites. Fifty-four images were ultimately selected by two board-certified dermatologists as being representative and typical of the common conditions. Additionally, nine clinical scenarios corresponding to these conditions were developed. GPT-4V's diagnostic capabilities were assessed in three setups: Image Prompt (image-based), Scenario Prompt (text-based), and Image and Scenario Prompt (combining both modalities). The model's performance was evaluated based on diagnostic accuracy, differential diagnosis, and treatment recommendations. Results: In the Image Prompt setup, GPT-4V correctly identified the primary diagnosis for 29 of 54 images. The Scenario Prompt setup showed a higher accuracy rate of 89% in identifying the primary diagnosis. The multimodal Image and Scenario Prompt setup also achieved an 89% accuracy rate. However, a notable bias towards textual data over visual data was observed. Treatment recommendations were evaluated by the same two dermatologists, using a modified Entrustment Scale, showing competent but not expert-level performance. Conclusion: GPT-4V demonstrates promising capabilities in dermatological diagnosis and treatment recommendations, particularly in text-based scenarios. However, its performance in image-based diagnosis and integration of multimodal data highlights areas for improvement. The study underscores the potential of AI in augmenting dermatological practice, emphasizing the need for further development, and fine-tuning of such models to ensure their efficacy and reliability in clinical settings.",Yes,Sully,,,,,,,,,,
Effects of Different Prompts on the Quality of GPT-4 Responses to Dementia Care Questions,"Evidence suggests that different prompts lead large language models (LLMs) to generate responses with varying quality. Yet, little is known about prompts' effects on response quality in health care domains. In this exploratory study, we address this gap, focusing on a specific healthcare domain: dementia caregiving. We first developed an innovative prompt template with three components: (1) system prompts (SPs) featuring 4 different roles; (2) an initialization prompt; and (3) task prompts (TPs) specifying different levels of details, totaling 12 prompt combinations. Next, we selected 3 social media posts containing complicated, real-world questions about dementia caregivers' challenges in 3 areas: memory loss and confusion, aggression, and driving. We then entered these posts into G PT-4, with our 12 prompts, to generate 12 responses per post, totaling 36 responses. We compared the word count of the 36 responses to explore potential differences in response length. Two experienced dementia care clinicians on our team assessed the response quality using a rating scale with 5 quality indicators: factual, interpretation, application, synthesis, and comprehensiveness (scoring range: 0-5; higher scores indicate higher quality). Both clinicians rated the responses from 3 to 5, with 75% agreement. Consensus was reached through discussion. Overall, 44% of responses (16/36) were rated as 5; another 44% (16/36), as 4; the remaining 4 (11 %), as 3. We found no interaction effect of system and task prompts or main effect of system prompts on response length. Task prompts had a statistically significant effect on response length: F(2,24) = 82.784, p <.001. Post hoc analysis showed that the significant difference in responses was due to TP3, which led to significantly longer responses. There was no interaction or main effect of system and task prompts on response quality. Our clinicians' qualitative feedback provided further insight: (1) system prompts with the different professional roles (neuropsychologist and social worker) did not lead to noticeable differences in response content (that is, there were no neuropsychology- and social work-versions of GPT-4 responses); and (2) TP3, while producing longer responses statistically, might not necessarily have produced higher quality responses clinically: at times the details contained in the lengthy responses seem unnecessary from a clinical perspective. We discuss study limitations and future research directions. © 2024 IEEE.",Yes,Sully,,,,,,,,,,
Does Google’s Bard Chatbot perform better than ChatGPT on the European hand surgery exam?,"Purpose: According to a previous research, the chatbot ChatGPT® V3.5 was unable to pass the first part of the European Board of Hand Surgery (EBHS) diploma examination. This study aimed to investigate whether Google's chatbot Bard® would have superior performance compared to ChatGPT on the EBHS diploma examination. Methods: Chatbots were asked to answer 18 EBHS multiple choice questions (MCQs) published in the Journal of Hand Surgery (European Volume) in five trials (A1 to A5). After A3, chatbots received correct answers, and after A4, incorrect answers. Consequently, their ability to modify their response was measured and compared. Results: Bard® scored 3/18 (A1), 1/18 (A2), 4/18 (A3) and 2/18 (A4 and A5). The average percentage of correct answers was 61.1% for A1, 62.2% for A2, 64.4% for A3, 65.6% for A4, 63.3% for A5 and 63.3% for all trials combined. Agreement was moderate from A1 to A5 (kappa = 0.62 (IC95% = [0.51; 0.73])) as well as from A1 to A3 (kappa = 0.60 (IC95% = [0.47; 0.74])). The formulation of Bard® responses was homogeneous, but its learning capacity is still developing. Conclusions: The main hypothesis of our study was not proved since Bard did not score significantly higher than ChatGPT when answering the MCQs of the EBHS diploma exam. In conclusion, neither ChatGPT® nor Bard®, in their current versions, can pass the first part of the EBHS diploma exam. © 2023, The Author(s) under exclusive licence to SICOT aisbl.",Yes,Sully,Why does anyone need this study,,,,,,,,,
The Artificial Intelligence Shoulder Arthroplasty Score: development and validation of a tool for large language model responses to common patient questions regarding total shoulder arthroplasty,"Background and Hypothesis: While research into artificial intelligence, specifically large language model (LLM), ability to respond to patient questions regarding specific orthopedic pathologies continues to grow, no tool presently exists to systematically and comprehensively evaluate the quality of LLM responses. The present study seeks to develop and validate the Artificial Intelligence Shoulder Arthroplasty Score (AISAS) to create a comprehensive, standardized, and reproducible system for evaluating artificial intelligence responses to patient questions regarding their orthopedic pathology. Methods: The novel scoring tool, AISAS, was developed to include four equally weighted components related to accuracy, completeness, clarity, and readability. Fifteen common patient questions on glenohumeral arthritis were asked one by one to three of the most used LLMs: ChatGPT (version 3.5), Claude (version 3.5) Sonnet, and Gemini. Ten shoulder and elbow fellowship trained orthopedic surgeons used the proposed framework to evaluate each of the 45 responses. Inter-rater reliability was calculated via Cohen's kappa and rater-score correlation was calculated via Cronbach's alpha. Results: AISAS use for Claude and ChatGPT produced moderate agreement (k = 0.55 and 0.43) while Gemini produced substantial reliability among raters ((k = 0.66). Cronbach's alpha scores demonstrated excellent correlation of Gemini ratings (⍺ = 0.91) and acceptable correlation of the Claude and ChatGPT ratings (⍺ = 0.79 and 0.75). Discussion and Conclusion: AISAS use enables systematic assessment of the overall quality of an LLM response, as well as the individual components of a response that may vary in quality to enable easy comparisons for LLM responses. Furthermore, it offers a tool to trend the progress of LLMs in ability to respond to patient questions. Establishing such a framework to guide areas of improvement for LLMs will serve to optimize LLMs as a patient tool, identify areas for improvement, and allow physicians to better direct patients on how to utilize these tools for optimal use. Conclusion: The AISAS is a comprehensive and reproducible tool for evaluating LLM responses, with high levels of inter-rater reliability. AISAS use can help to evaluate responses to patient questions to guide growth and improvement of LLMs for use in the orthopedic setting. © 2025 American Shoulder and Elbow Surgeons",Yes,Sully,,,,,,,,,,
Identification of ChatGPT-Generated Abstracts Within Shoulder and Elbow Surgery Poses a Challenge for Reviewers,"Purpose: To evaluate the extent to which experienced reviewers can accurately discern between artificial intelligence (AI)–generated and original research abstracts published in the field of shoulder and elbow surgery and compare this with the performance of an AI detection tool. Methods: Twenty-five shoulder- and elbow-related articles published in high-impact journals in 2023 were randomly selected. ChatGPT was prompted with only the abstract title to create an AI-generated version of each abstract. The resulting 50 abstracts were randomly distributed to and evaluated by 8 blinded peer reviewers with at least 5 years of experience. Reviewers were tasked with distinguishing between original and AI-generated text. A Likert scale assessed reviewer confidence for each interpretation, and the primary reason guiding assessment of generated text was collected. AI output detector (0%-100%) and plagiarism (0%-100%) scores were evaluated using GPTZero. Results: Reviewers correctly identified 62% of AI-generated abstracts and misclassified 38% of original abstracts as being AI generated. GPTZero reported a significantly higher probability of AI output among generated abstracts (median, 56%; interquartile range [IQR], 51%-77%) compared with original abstracts (median, 10%; IQR, 4%-37%; P < .01). Generated abstracts scored significantly lower on the plagiarism detector (median, 7%; IQR, 5%-14%) relative to original abstracts (median, 82%; IQR, 72%-92%; P < .01). Correct identification of AI-generated abstracts was predominately attributed to the presence of unrealistic data/values. The primary reason for misidentifying original abstracts as AI was attributed to writing style. Conclusions: Experienced reviewers faced difficulties in distinguishing between human and AI-generated research content within shoulder and elbow surgery. The presence of unrealistic data facilitated correct identification of AI abstracts, whereas misidentification of original abstracts was often ascribed to writing style. Clinical Relevance: With rapidly increasing AI advancements, it is paramount that ethical standards of scientific reporting are upheld. It is therefore helpful to understand the ability of reviewers to identify AI-generated content. © 2024 The Author(s)",No,Sully,Kinda neat but not relevant,,,,,,,,,
Faster and better than a physician?: Assessing diagnostic proficiency of ChatGPT in misdiagnosed individuals with neuromyelitis optica spectrum disorder,"Background: Neuromyelitis optica spectrum disorder (NMOSD) is a commonly misdiagnosed condition. Driven by cost-consciousness and technological fluency, distinct generations may gravitate towards healthcare alternatives, including artificial intelligence (AI) models, such as ChatGPT (Generative Pre-trained Transformer). Our objective was to evaluate the speed and accuracy of ChatGPT-3.5 (GPT-3.5) in the diagnosis of people with NMOSD (PwNMOSD) initially misdiagnosed. Methods: Misdiagnosed PwNMOSD were retrospectively identified with clinical symptoms and time line of medically related events processed through GPT-3.5. For each subject, seven digital derivatives representing different races, ethnicities, and sexes were created and processed identically to evaluate the impact of these variables on accuracy. Scoresheets were used to track diagnostic success and time to diagnosis. Diagnostic speed of GPT-3.5 was evaluated against physicians using a Cox proportional hazards model, clustered by subject. Logistical regression was used to estimate the diagnostic accuracy of GPT-3.5 compared with the estimated accuracy of physicians. Results: Clinical time lines for 68 individuals (59 female, 42 Black/African American, 13 White, 11 Hispanic, 2 Asian; mean age at first symptoms 34.4 years (y) (standard deviation = 15.5y)) were analyzed and 476 digital simulations created, yielding 544 conversations for analysis. The instantaneous probability of correct diagnosis was 70.65% less for physicians relative to GPT-3.5 within 240 days of symptom onset (p < 0.0001). The estimated probability of correct diagnosis for GPT-3.5 was 80.88% [95% CI = (76.35%, 99.81%)]. Conclusion: GPT-3.5 may be of value in recognizing NMOSD. However, the manner in which medical information is conveyed, combined with the potential for inaccuracies may result in unnecessary psychological stress. © 2024 Elsevier B.V.",Yes,Sully,,,,,,,,,,
MDE and LLM Synergy for Network Experimentation: Case Analysis of Wireless System Performance in Beaulieu-Xie Fading and κ-µ Co-Channel Interference Environment with Diversity Combining,"Channel modeling is a first step towards the successful projecting of any wireless communication system. Hence, in this paper, we analyze the performance at the output of a multi-branch selection combining (SC) diversity receiver in a wireless environment that has been distracted by fading and co-channel interference (CCI), whereby the fading is modelled by newer Beaulieu-Xie (BX) distribution, and the CCI is modelled by the κ-µ distribution. The BX distribution provides the ability to include in consideration any number of line-of-sight (LOS) useful signal components and non-LOS (NLOS) useful signal components. This distribution contains characteristics of some other fading models thanks to its flexible fading parameters, which also applies to the κ-µ distribution. We derived here the expressions for the probability density function (PDF) and cumulative distribution function (CDF) for the output signal-to-co-channel interference ratio (SIR). After that, other performances are obtained, namely: outage probability (Pout), channel capacity (CC), moment-generating function (MGF), average bit error probability (ABEP), level crossing rate (LCR), and average fade duration (AFD). Numerical results are presented in several graphs versus the SIR for different values of fading and CCI parameters, as well as the number of input branches in the SC receiver. Then, the impact of parameters on all performance is checked. From our numerical results, it is possible to directly obtain the performance for all derived and displayed quantities for cases of previously known distributions of fading and CCI by inserting the appropriate parameter values. In the second part of the paper, a workflow for automated network experimentation relying on the synergy of Large Language Models (LLMs) and model-driven engineering (MDE) is presented, while the previously derived expressions are used for evaluation. Due to the aforementioned, the biggest value of the obtained results is the applicability to the cases of a large number of other distributions for fading and CCI by replacing the corresponding parameters in the formulas for the respective performances.",No,Sully,,,,,,,,,,
Evaluation of ChatGPT as a diagnostic tool for medical learners and clinicians,"Background ChatGPT is a large language model (LLM) trained on over 400 billion words from books, articles, and websites. Its extensive training draws from a large database of information, making it valuable as a diagnostic aid. Moreover, its capacity to comprehend and generate human language allows medical trainees to interact with it, enhancing its appeal as an educational resource. This study aims to investigate ChatGPT’s diagnostic accuracy and utility in medical education. Methods 150 Medscape case challenges (September 2021 to January 2023) were inputted into ChatGPT. The primary outcome was the number (%) of cases for which the answer given was correct. Secondary outcomes included diagnostic accuracy, cognitive load, and quality of medical information. A qualitative content analysis was also conducted to assess its responses. Results ChatGPT answered 49% (74/150) cases correctly. It had an overall accuracy of 74%, a precision of 48.67%, sensitivity of 48.67%, specificity of 82.89%, and an AUC of 0.66. Most answers were considered low cognitive load 51% (77/150) and most answers were complete and relevant 52% (78/150). Discussion ChatGPT in its current form is not accurate as a diagnostic tool. ChatGPT does not necessarily give factual correctness, despite the vast amount of information it was trained on. Based on our qualitative analysis, ChatGPT struggles with the interpretation of laboratory values, imaging results, and may overlook key information relevant to the diagnosis. However, it still offers utility as an educational tool. ChatGPT was generally correct in ruling out a specific differential diagnosis and providing reasonable next diagnostic steps. Additionally, answers were easy to understand, showcasing a potential benefit in simplifying complex concepts for medical learners. Our results should guide future research into harnessing ChatGPT’s potential educational benefits, such as simplifying medical concepts and offering guidance on differential diagnoses and next steps.",Yes,Sully,"Was initially going to say no to this since it's med-ed, but they actually do try to evaluate how clinically ready it is for diagnostics",,,,,,,,,
How accurately can ChatGPT 3.5 answer frequently asked questions by patients on glenohumeral osteoarthritis?; [Wie genau kann ChatGPT 3.5 häufig gestellte Fragen von Patienten zur glenohumeralen Osteoarthritis beantworten?],"Background: Conversational artificial intelligence (AI) systems like ChatGPT have emerged as valuable assets in providing accessible information across various domains, including the healthcare system. The use of ChatGPT may contribute to better patient education and better general healthcare knowledge. However, there is a paucity of data on the reliability of responses generated by ChatGPT in the context of specific medical diagnoses. Methods: We identified 12 frequently asked questions by patients about glenohumeral osteoarthritis. These questions were formulated in both English and German, using common and medical terms for the condition, thus creating four groups for evaluation. The questions were then presented to ChatGPT 3.5. The generated responses were evaluated for accuracy by four independent orthopedic and trauma surgery consultants using a Likert scale (0 = fully inaccurate to 4 = fully accurate). Results: Although there were two questions in two groups, all questions across all versions were answered with good accuracy by ChatGPT 3.5. The highest score on the Likert scale was 3.9 for the group where questions were posed in English using the medical term “glenohumeral osteoarthritis.” The lowest score of 3.2 was for the group where questions were posed in English using the common term “shoulder arthrosis.” On average, questions in English received a score of 3.5 on the Likert scale, slightly higher than those in German, which received a score of 3.4. Conclusion: ChatGPT 3.5 can already provide accurate responses to patients’ frequently asked questions on glenohumeral osteoarthritis. ChatGPT can therefore be a valuable tool for patient communication and education in the field of orthopedics. Further studies, however, have to be performed in order to fully understand the mechanisms and impact of ChatGPT in the field. © The Author(s) 2024.",Yes,Sully,,,,,,,,,,
Does Prompt Engineering Help Turkish Named Entity Recognition?,"The extraction of entity mentions in a text (named entity recognition) has been traditionally formulated as a sequence labeling problem. In recent years, this approach has evolved from recognizing entities to answering formulated questions related to entity types. The questions, constructed as prompts, are used to elicit desired entity mentions and their types from large language models. In this work, we investigated prompt engineering in Turkish named entity recognition and studied two prompting strategies to guide pretrained language models toward correctly identifying mentions. In particular, we examined the impact of zero-shot and few-shot prompting on the recognition of Turkish named entities by conducting experiments on two large language models. Our evaluations using different prompt templates revealed promising results and demonstrated that carefully constructed prompts can achieve high accuracy on entity recognition, even in languages with complex morphology. © 2024 IEEE.",No,Sully,,,,,,,,,,
"Self-reported mental health symptoms, quality of life and coping strategies in French health sciences students during the early stage of the COVID-19 pandemic: An online survey; [Santé mentale, qualité de vie et stratégies de coping des étudiants en santé français au début de la pandémie COVID-19 : une enquête en ligne]","Introduction: Health sciences students usually report high rates of mental health problems. The COVID-19 pandemic context may have serious psychological impacts in this at-risk population. We aimed to assess the self-reported mental health status, health-related quality of life and coping strategies of health sciences students during the early stage of the pandemic. Method: An online 128-item questionnaire sent to 17,673 health sciences students from the Claude Bernard University Lyon 1 in April 2020 assessed: a) sociodemographic characteristics, b) conditions of lockdown, c) depressive (Beck Depression Inventory- Short Form, BDI-SF), anxiety (State-Trait Anxiety Inventory-A, STAI-A) and traumatic symptoms (Impact of Event Scale -Revised, IES-R), d) health-related quality of life (SF12) and e) coping strategies (Brief Coping Orientation to Problems Experienced, Brief COPE). Results: The participation rate was 9.9% (n = 1,765). A total of 19.5% of participants reported an IES-R > 33, 11.6% depressive symptoms, 58.1% anxiety symptoms, and 4.4% suicidal ideation. Their mental health-related quality of life was significantly poorer than for physical health. Female gender, COVID-like symptoms, social isolation due to the lockdown, pandemic-related financial restraint and exams-related stress were significantly associated with poorer self-reported mental health conditions. Volunteering in the healthcare system was significantly associated with lower mental health scores. Coping strategies were mostly oriented toward avoidance and positive appraisal. Conclusion: French health sciences students exhibited high levels of self-reported mental health problems and a poor mental health-related quality of life during the early stage of the COVID-19 pandemic. Specific risk factors related to the pandemic partly explain the observed prevalence. © 2021 L'Encéphale, Paris",No,Sully,,,,,,,,,,
Assessing the performance of ChatGPT-4 and ChatGPT-4o in lung cancer diagnoses,,Yes,Sully,,,,,,,,,,
Assessing ChatGPT's Mastery of Bloom's Taxonomy Using Psychosomatic Medicine Exam Questions: Mixed-Methods Study,"Background: Large language models such as GPT-4 (Generative Pre-trained Transformer 4) are being increasingly used in medicine and medical education. However, these models are prone to “hallucinations” (ie, outputs that seem convincing while being factually incorrect). It is currently unknown how these errors by large language models relate to the different cognitive levels defined in Bloom's taxonomy. Objective: This study aims to explore how GPT-4 performs in terms of Bloom's taxonomy using psychosomatic medicine exam questions. Methods: We used a large data set of psychosomatic medicine multiple-choice questions (N=307) with real-world results derived from medical school exams. GPT-4 answered the multiple-choice questions using 2 distinct prompt versions: detailed and short. The answers were analyzed using a quantitative approach and a qualitative approach. Focusing on incorrectly answered questions, we categorized reasoning errors according to the hierarchical framework of Bloom's taxonomy. Results: GPT-4's performance in answering exam questions yielded a high success rate: 93% (284/307) for the detailed prompt and 91% (278/307) for the short prompt. Questions answered correctly by GPT-4 had a statistically significant higher difficulty than questions answered incorrectly (P = .002 for the detailed prompt and P < .001 for the short prompt). Independent of the prompt, GPT-4's lowest exam performance was 78.9% (15/19), thereby always surpassing the “pass” threshold. Our qualitative analysis of incorrect answers, based on Bloom's taxonomy, showed that errors were primarily in the “remember” (29/68) and “understand” (23/68) cognitive levels; specific issues arose in recalling details, understanding conceptual relationships, and adhering to standardized guidelines. Conclusions: GPT-4 demonstrated a remarkable success rate when confronted with psychosomatic medicine multiple-choice exam questions, aligning with previous findings. When evaluated through Bloom's taxonomy, our data revealed that GPT-4 occasionally ignored specific facts (remember), provided illogical reasoning (understand), or failed to apply concepts to a new situation (apply). These errors, which were confidently presented, could be attributed to inherent model biases and the tendency to generate outputs that maximize likelihood. © 2024 Journal of Medical Internet Research. All rights reserved.",Yes,Sully,,,,,,,,,,
ChatGPT and Corporations of Mega-journals Jeopardize the Norms That Underpin Academic Publishing,"2980. Arch Iran Med. 2024 Feb 1;27(2):110-112. doi: 10.34172/aim.2024.17.

ChatGPT and Corporations of Mega-journals Jeopardize the Norms That Underpin 
Academic Publishing.

Rahimi F(1), Talebi Bezmin Abadi A(2).

Author information:
(1)Research School of Biology, The Australian National University, Ngunnawal and 
Ngambri Country, Canberra, Australia.
(2)Department of Bacteriology, Faculty of Medical Sciences, Tarbiat Modares 
University, Tehran, Iran.

Those who participate in and contribute to academic publishing are affected by 
its evolution. Funding bodies, academic institutions, researchers and 
peer-reviewers, junior scholars, freelance language editors, language-editing 
services, and journal editors are to enforce and uphold the ethical norms on 
which academic publishing is founded. Deviating from such norms will challenge 
and threaten the scholarly reputation, academic careers, and institutional 
standing; reduce the publishers' true impacts; squander public funding; and 
erode the public trust to the academic enterprise. Rigorous review is paramount 
because peer-review norms guarantee that scientific findings are scrutinized 
before being publicized. Volunteer peer-reviewers and guest journal editors 
devote an immense amount of unremunerated time to reviewing papers, voluntarily 
serving the scientific community, and benefiting the publishers. Some 
mega-journals are motivated to mass-produce publications and attract the funded 
projects instead of maintaining the scientific rigor. The rapid development of 
mega-journals may diminish some traditional journals by outcompeting their 
impacts. Artificial intelligence (AI) tools/algorithms such as ChatGPT may be 
misused to contribute to the mass-production of publications which may have not 
been rigorously revised or peer-reviewed. Maintaining norms that guarantee 
scientific rigor and academic integrity enable the academic community to 
overcome the new challenges such as mega-journals and AI tools.

© 2024 The Author(s). This is an open-access article distributed under the terms 
of the Creative Commons Attribution License 
(https://creativecommons.org/licenses/by/4.0), which permits unrestricted use, 
distribution, and reproduction in any medium, provided the original work is 
properly cited.",No,Sully,,,,,,,,,,
"Comparison of the problem-solving performance of ChatGPT-3.5, ChatGPT-4, Bing Chat, and Bard for the Korean emergency medicine board examination question bank","Large language models (LLMs) have been deployed in diverse fields, and the potential for their application in medicine has been explored through numerous studies. This study aimed to evaluate and compare the performance of ChatGPT-3.5, ChatGPT-4, Bing Chat, and Bard for the Emergency Medicine Board Examination question bank in the Korean language. Of the 2353 questions in the question bank, 150 questions were randomly selected, and 27 containing figures were excluded. Questions that required abilities such as analysis, creative thinking, evaluation, and synthesis were classified as higher-order questions, and those that required only recall, memory, and factual information in response were classified as lower-order questions. The answers and explanations obtained by inputting the 123 questions into the LLMs were analyzed and compared. ChatGPT-4 (75.6%) and Bing Chat (70.7%) showed higher correct response rates than ChatGPT-3.5 (56.9%) and Bard (51.2%). ChatGPT-4 showed the highest correct response rate for the higher-order questions at 76.5%, and Bard and Bing Chat showed the highest rate for the lower-order questions at 71.4%. The appropriateness of the explanation for the answer was significantly higher for ChatGPT-4 and Bing Chat than for ChatGPT-3.5 and Bard (75.6%, 68.3%, 52.8%, and 50.4%, respectively). ChatGPT-4 and Bing Chat outperformed ChatGPT-3.5 and Bard in answering a random selection of Emergency Medicine Board Examination questions in the Korean language. © 2024 Lippincott Williams and Wilkins. All rights reserved.",Yes,Sully,,,,,,,,,,
DracoGPT: Extracting Visualization Design Preferences from Large Language Models,"Trained on vast corpora, Large Language Models (LLMs) have the potential to encode visualization design knowledge and best practices. However, if they fail to do so, they might provide unreliable visualization recommendations. What visualization design preferences, then, have LLMs learned? We contribute DracoGPT, a method for extracting, modeling, and assessing visualization design preferences from LLMs. To assess varied tasks, we develop two pipelines-DracoGPT-Rank and DracoGPT-Recommend-to model LLMs prompted to either rank or recommend visual encoding specifications. We use Draco as a shared knowledge base in which to represent LLM design preferences and compare them to best practices from empirical research. We demonstrate that DracoGPT can accurately model the preferences expressed by LLMs, enabling analysis in terms of Draco design constraints. Across a suite of backing LLMs, we find that DracoGPT-Rank and DracoGPT-Recommend moderately agree with each other, but both substantially diverge from guidelines drawn from human subjects experiments. Future work can build on our approach to expand Draco's knowledge base to model a richer set of preferences and to provide a robust and cost-effective stand-in for LLMs.",No,Sully,,,,,,,,,,
Evaluating the Efficacy of ChatGPT in Navigating the Spanish Medical Residency Entrance Examination (MIR): Promising Horizons for AI in Clinical Medicine,"The rapid progress in artificial intelligence, machine learning, and natural language processing has led to increasingly sophisticated large language models (LLMs) for use in healthcare. This study assesses the performance of two LLMs, the GPT-3.5 and GPT-4 models, in passing the MIR medical examination for access to medical specialist training in Spain. Our objectives included gauging the model’s overall performance, analyzing discrepancies across different medical specialties, discerning between theoretical and practical questions, estimating error proportions, and assessing the hypothetical severity of errors committed by a physician. Material and methods: We studied the 2022 Spanish MIR examination results after excluding those questions requiring image evaluations or having acknowledged errors. The remaining 182 questions were presented to the LLM GPT-4 and GPT-3.5 in Spanish and English. Logistic regression models analyzed the relationships between question length, sequence, and performance. We also analyzed the 23 questions with images, using GPT-4’s new image analysis capability. Results: GPT-4 outperformed GPT-3.5, scoring 86.81% in Spanish (p < 0.001). English translations had a slightly enhanced performance. GPT-4 scored 26.1% of the questions with images in English. The results were worse when the questions were in Spanish, 13.0%, although the differences were not statistically significant (p = 0.250). Among medical specialties, GPT-4 achieved a 100% correct response rate in several areas, and the Pharmacology, Critical Care, and Infectious Diseases specialties showed lower performance. The error analysis revealed that while a 13.2% error rate existed, the gravest categories, such as “error requiring intervention to sustain life” and “error resulting in death”, had a 0% rate. Conclusions: GPT-4 performs robustly on the Spanish MIR examination, with varying capabilities to discriminate knowledge across specialties. While the model’s high success rate is commendable, understanding the error severity is critical, especially when considering AI’s potential role in real-world medical practice and its implications for patient safety. © 2023 by the authors.",Yes,Sully,,,,,,,,,,
Performance of ChatGPT on Solving Orthopedic Board-Style Questions: A Comparative Analysis of ChatGPT 3.5 and ChatGPT 4,"Background: The application of artificial intelligence and large language models in the medical field requires an evaluation of their accuracy in providing medical information. This study aimed to assess the performance of Chat Generative Pre-trained Trans-former (ChatGPT) models 3.5 and 4 in solving orthopedic board-style questions. Methods: A total of 160 text-only questions from the Orthopedic Surgery Department at Seoul National University Hospital, con-forming to the format of the Korean Orthopedic Association board certification examinations, were input into the ChatGPT 3.5 and ChatGPT 4 programs. The questions were divided into 11 subcategories. The accuracy rates of the initial answers provided by Chat GPT 3.5 and ChatGPT 4 were analyzed. In addition, inconsistency rates of answers were evaluated by regenerating the responses. Results: ChatGPT 3.5 answered 37.5% of the questions correctly, while ChatGPT 4 showed an accuracy rate of 60.0% (p < 0.001). ChatGPT 4 demonstrated superior performance across most subcategories, except for the tumor-related questions. The rates of inconsistency in answers were 47.5% for ChatGPT 3.5 and 9.4% for ChatGPT 4. Conclusions: ChatGPT 4 showed the ability to pass orthopedic board-style examinations, outperforming ChatGPT 3.5 in accuracy rate. However, inconsistencies in response generation and instances of incorrect answers with misleading explanations require caution when applying ChatGPT in clinical settings or for educational purposes. © 2024 by The Korean Orthopaedic Association.",Yes,Sully,,,,,,,,,,
"Rapid, Sensitive, and Selective Quantification of Bacillus cereus Spores Using xMAP Technology","Bacillus cereus is a spore-forming ubiquitous bacterium notable as a food poisoning agent. Detection of B. cereus spores using selective media is laborious and non-specific. Herein, the quantitative detection of B. cereus spores was investigated with commercial antibodies and published aptamer sequences. Several detection reagents were screened for affinity to Bacillus collagen-like protein A (BclA), an abundant exosporium glycoprotein. Sensitivity and selectivity toward B. cereus spores were tested using immunoassays and multi-analyte profiling (xMAP). A recombinant antibody developed in llama against BclA protein showed B. cereus spore selectivity and sensitivity between 102 and 105 spores/mL using xMAP. DNA aptamer sequences demonstrated sensitivity from 103 to 107 spores/mL and no cross-reaction to B. megaterium and B. subtilis. Selectivity for B. cereus spores was also demonstrated in a mixture of several diverse microorganisms and within a food sample with no compromise of sensitivity. As proof of concept for multiplexed measurement of human pathogens, B. cereus and three other microorganisms, E. coli, P. aeruginosa, and S. cerevisiae, were simultaneously detected using xMAP. These data support the development of a rapid, sensitive, and selective system for quantitation of B. cereus spores and multiplexed monitoring of human pathogens in complex matrices. © 2022 by the authors.",No,Sully,,,,,,,,,,
"Regarding ""Practice patterns surrounding the use of tibial interventions for claudication in the Medicare population: ChatGPT writes a Letter to the Editor""","3068. J Vasc Surg. 2023 Jul;78(1):262. doi: 10.1016/j.jvs.2023.03.033.

Regarding ""Practice patterns surrounding the use of tibial interventions for 
claudication in the Medicare population: ChatGPT writes a Letter to the Editor"".

Samson RH(1).

Author information:
(1)The Mote Vascular Foundation, Inc, Sarasota, FL.

Comment on
    J Vasc Surg. 2023 Feb;77(2):454-462.e1. doi: 10.1016/j.jvs.2022.08.033.",No,Sully,WHAT IS THIS,,,,,,,,,
"Comparing the performance of ChatGPT-3.5-Turbo, ChatGPT-4, and Google Bard with Iranian students in pre-internship comprehensive exams","This study aims to measure the performance of different AI-language models in three sets of pre-internship medical exams and to compare their performance with Iranian medical students. Three sets of Persian pre-internship exams were used, along with their English translation (six sets in total). In late September 2023, we sent requests to ChatGPT-3.5-Turbo-0613, GPT-4-0613, and Google Bard in both Persian and English languages (excluding questions with any visual content) with each query in a new session and reviewed their responses. GPT models produced responses at varying levels of randomness. In both Persian and English tests, GPT-4 ranked first and obtained the highest score in all exams and different levels of randomness. While Google Bard scored below average on the Persian exams (still in an acceptable range), ChatGPT-3.5 failed all exams. There was a significant difference between the Large Language Models (LLMs) in Persian exams. While GPT-4 yielded the best scores on the English exams, the distinction between all LLMs and students was not statistically significant. The GPT-4 model outperformed students and other LLMs in medical exams, highlighting its potential application in the medical field. However, more research is needed to fully understand and address the limitations of using these models.",Yes,Sully,why did anyone do this,,,,,,,,,
Generative artificial intelligence responses to patient messages in the electronic health record: early lessons learned,"Background: Electronic health record (EHR)-based patient messages can contribute to burnout. Messages with a negative tone are particularly challenging to address. In this perspective, we describe our initial evaluation of large language model (LLM)-generated responses to negative EHR patient messages and contend that using LLMs to generate initial drafts may be feasible, although refinement will be needed. Methods: A retrospective sample (n = 50) of negative patient messages was extracted from a health system EHR, de-identified, and inputted into an LLM (ChatGPT). Qualitative analyses were conducted to compare LLM responses to actual care team responses. Results: Some LLM-generated draft responses varied from human responses in relational connection, informational content, and recommendations for next steps. Occasionally, the LLM draft responses could have potentially escalated emotionally charged conversations. Conclusion: Further work is needed to optimize the use of LLMs for responding to negative patient messages in the EHR. Lay Summary Doctors and other clinicians are receiving a growing number of messages from patients through electronic health records systems. This workload is contributing to clinician burnout. Some messages can be very negative or emotionally charged. These messages often require a lot of time or effort to respond to. In this article, we discuss results from a preliminary evaluation we conducted using large language models (like ChatGPT). We analyzed whether these models could help provide starting drafts to respond to patient messages, with a focus on negative messages, since these can be particularly difficult. We found that ChatGPT provided reasonable starting drafts in many cases, but that there were also issues in the drafts that would require further editing. These issues included sometimes not drafting the text from the perspective of a clinician, using overly broad or generic language, inappropriate escalation (eg, instructing the patient to file complaints to the medical board), and inconsistent recommendations for in-person follow-up visits. Based on this evaluation, we highlight not only the promise and possibilities of this technology but also considerations and challenges that need to be addressed for optimizing its future use. # The Author(s) 2024.",Yes,Sully,,,,,,,,,,
"Still a Long Way to Go, the Potential of ChatGPT in Personalized Dietary Prescription, From a Perspective of a Clinical Dietitian","Objective: Prominent large language models, such as OpenAI's Chat Generative Pre-trained Transformer (ChatGPT), have shown promising implementation in the field of nutrition. Special care should be taken when using ChatGPT to prescribe protein-restricted diets for kidney-impaired patients. The objective of the current study is to simulate a chronic kidney disease (CKD) patient and evaluate the capabilities of ChatGPT in the context of dietary prescription, with a focus on protein contents of the diet. Methods: We simulated a scenario involving a CKD patient and replicated a clinical counseling session that covered general dietary principles, dietary assessment, energy and protein recommendation, dietary prescription, and diet customization based on dietary culture. To confirm the results derived from our qualitative observations, 10 colleagues were recruited and provided with identical dietary prescription prompts to run the process again. The actual energy and protein levels of the given meal plans were recorded and the difference from the targets were compared. Results: ChatGPT provides general principles overall aligning with best practices. The recommendations for energy and protein requirements of CKD patients were tailored and satisfactory. It failed to prescribe a reliable diet based on the target energy and protein requirements. For the quantitative analysis, the prescribed energy levels were generally lower than the targets, ranging from −28.9% to −17.0%, and protein contents were tremendously higher than the targets, ranging from 59.3% to 157%. Conclusion: ChatGPT is competent in offering generic dietary advice, giving satisfactory nutrients recommendations and adapting cuisines to different cultures but failed to prescribe nutritionally accurate dietary plans for CKD patients. At present, patients with strict protein and other particular nutrient restrictions are not recommended to rely on the dietary plans prescribed by ChatGPT to avoid potential health risks. © 2025 National Kidney Foundation, Inc.",Yes,Sully,,,,,,,,,,
An Explainable Artificial Intelligence Text Classifier for Suicidality Prediction in Youth Crisis Text Line Users: Development and Validation Study,"Background: Suicide represents a critical public health concern, and machine learning (ML) models offer the potential for identifying at-risk individuals. Recent studies using benchmark datasets and real-world social media data have demonstrated the capability of pretrained large language models in predicting suicidal ideation and behaviors (SIB) in speech and text. Objective: This study aimed to (1) develop and implement ML methods for predicting SIBs in a real-world crisis helpline dataset, using transformer-based pretrained models as a foundation; (2) evaluate, cross-validate, and benchmark the model against traditional text classification approaches; and (3) train an explainable model to highlight relevant risk-associated features. Methods: We analyzed chat protocols from adolescents and young adults (aged 14-25 years) seeking assistance from a German crisis helpline. An ML model was developed using a transformer-based language model architecture with pretrained weights and long short-term memory layers. The model predicted suicidal ideation (SI) and advanced suicidal engagement (ASE), as indicated by composite Columbia-Suicide Severity Rating Scale scores. We compared model performance against a classical word-vector-based ML model. We subsequently computed discrimination, calibration, clinical utility, and explainability information using a Shapley Additive Explanations value-based post hoc estimation model. Results: The dataset comprised 1348 help-seeking encounters (1011 for training and 337 for testing). The transformer-based classifier achieved a macroaveraged area under the curve (AUC) receiver operating characteristic (ROC) of 0.89 (95% CI 0.81-0.91) and an overall accuracy of 0.79 (95% CI 0.73-0.99). This performance surpassed the word-vector-based baseline model (AUC-ROC=0.77, 95% CI 0.64-0.90; accuracy=0.61, 95% CI 0.61-0.80). The transformer model demonstrated excellent prediction for nonsuicidal sessions (AUC-ROC=0.96, 95% CI 0.96-0.99) and good prediction for SI and ASE, with AUC-ROCs of 0.85 (95% CI 0.97-0.86) and 0.87 (95% CI 0.81-0.88), respectively. The Brier Skill Score indicated a 44% improvement in classification performance over the baseline model. The Shapley Additive Explanations model identified language features predictive of SIBs, including self-reference, negation, expressions of low self-esteem, and absolutist language. Conclusions: Neural networks using large language model–based transfer learning can accurately identify SI and ASE. The post hoc explainer model revealed language features associated with SI and ASE. Such models may potentially support clinical decision-making in suicide prevention services. Future research should explore multimodal input features and temporal aspects of suicide risk. ©Julia Thomas, Antonia Lucht, Jacob Segler, Richard Wundrack, Marcel Miché, Roselind Lieb, Lars Kuchinke, Gunther Meinlschmidt.",No,Sully,This is not an LLM,,,,,,,,,
Adapting to the Impact of Artificial Intelligence in Scientific Writing: Balancing Benefits and Drawbacks while Developing Policies and Regulations,"This article examines the advantages and disadvantages of large language models (LLMs) and artificial intelligence (AI) in research and education and proposes the urgent need for an international statement to guide their responsible use. LLMs and AI demonstrate remarkable natural language processing, data analysis, and decision-making capabilities, offering potential benefits such as improved efficiency and transformative solutions. However, concerns regarding ethical considerations, bias, fake publications, and malicious use also arise. The objectives of this paper are to critically evaluate the utility of LLMs and AI in research and education, call for discussions between stakeholders, and discuss the need for an international statement. We identify advantages such as data processing, task automation, and personalized experiences, alongside disadvantages such as bias reinforcement, interpretability challenges, inaccurate reporting, and plagiarism. Stakeholders from academia, industry, government, and civil society must engage in open discussions to address the ethical, legal, and societal implications. The proposed international statement should emphasize transparency, accountability, ongoing research, and risk mitigation. Monitoring, evaluation, user education, and awareness are essential components. By fostering discussions and establishing guidelines, we can ensure the responsible and ethical development and use of LLMs and AI, maximizing benefits while minimizing risks. Copyright:  © 2023 Journal of Nature and Science of Medicine.",No,Sully,,,,,,,,,,
Can ChatGPT write radiology reports?,"These case examples exemplify the utility of ChatGPT in augmenting the radiology report drafting process, thereby contributing to the efficiency of report generation. © The Author(s) 2024.",Yes,Sully,,,,,,,,,,
Comment to: ChatGPT: immutable insertion in health research and researchers' lives,"2404. Einstein (Sao Paulo). 2024 Sep 20;22:eCE1115. doi: 
10.31744/einstein_journal/2024CE1115. eCollection 2024.

Comment to: ChatGPT: immutable insertion in health research and researchers' 
lives.

Daungsupawong H(1), Wiwanitkit V(2).

Author information:
(1)Private Academic Consultant, Phonhong, Lao People's Democratic Republic.
(2)University Centre for Research & Development Department of Pharmaceutical 
Sciences, Chandigarh University, Mohali, Punjab, India.",No,Sully,,,,,,,,,,
Research and Application of GPT-Based Large Language Models in Business and Economics: A Systematic Literature Review in Progress,"Represented by ChatGPT and GPT-4, Large Language Models (LLM) based on the Generative Pre-trained Transformer (GPT) have revolutionized the capability of Artificial Intelligence (AI) in natural language processing. In the fields of business and economics, large amounts of research and applications of GPT-based LLMs have been developed and published to automate tasks that mandate advanced human-machine interaction. Nevertheless, there has not been a systematic literature review on GPT-based LLMs in business and economics. To fill this gap, we present our in-progress literature review in this paper focusing on these two related fields. This paper analyzed 30 published research articles and delineated the trends in research, application, prompt engineering and ethical considerations. Our goal is to provide a research framework as well as an application guideline for the fast-growing audience of GPT and LLMs in business and economics. Results of the literature review indicate that many studies are: (1) engaged in creating new applications of GPT-LLM; (2) empirical-qualitative research based on evidenced-oriented data sources; (3) applying diverse methods of prompt engineering; (4) concerned about ethical challenges of GPT-based LLMs. © 2023 IEEE.",No,Sully,,,,,,,,,,
Utilizing Artificial Intelligence Application for Diagnosis of Oral Lesions and Assisting Young Oral Histopathologist in Deriving Diagnosis from Provided Features – A Pilot study,"Background: AI in healthcare services is advancing every day, with a focus on uprising cognitive capabilities. Higher cognitive functions in AI entail performing intricate processes like decision-making, problem-solving, perception, and reasoning. This advanced cognition surpasses basic data handling, encompassing skills to grasp ideas, understand and apply information contextually, and derive novel insights from previous experiences and acquired knowledge. ChatGPT, a natural language processing model, exemplifies this evolution by engaging in conversations with humans, furnishing responses to inquiries. Objective: We aimed to understand the capability of ChatGPT in solving doubts pertaining to symptoms and histological features related to subject of oral pathology. The study's objective is to evaluate ChatGPT's effectiveness in answering questions pertaining to diagnoses. Methods: This cross-sectional study was done using an AI-based ChatGPT application that provides free service for research and learning purposes. The current version of ChatGPT3.5 was used to obtain responses for a total of 25 queries. These randomly asked questions were based on basic queries from patient aspect and early oral histopathologists. These responses were obtained and stored for further processing. The responses were evaluated by five experienced pathologists on a four point liekart scale .The score were further subjected for deducing kappa values for reliability. Result & Statistical Analysis: A total of 25 queries were solved by the program in the shortest possible time for an answer. The sensitivity and specificity of the methods and the responses were represented using frequency and percentages. Both the responses were analysed and were statistically significant based on the measurement of kappa values. Conclusion: The proficiency of ChatGPT in handling intricate reasoning queries within pathology demonstrated a noteworthy level of relational accuracy. Consequently, its text output created coherent links between elements, producing meaningful responses. This suggests that scholars or students can rely on this program to address reasoning-based inquiries. Nevertheless, considering the continual advancements in the program's development, further research is essential to determine its accuracy levels in future versions.",Yes,Sully,,,,,,,,,,
Parental Perception on Usage of AI Chatbot to Understand Paediatric Otorhinolaryngology Condition: A Survey,"Artificial intelligence (AI) chatbots such as ChatGPT have the potential to assist parents and caregivers in understanding their child’s general health condition. Despite the potential benefits research on parents perceptions of using AI chatbots is still limited. This study explored parents’ and caregivers’ perceptions of AI chatbots to understand their child’s Otorhinolaryngology (ORL) condition. A cross-sectional survey was conducted among parents or caregivers of children with ORL conditions attending Paediatric ORL clinic over one month. The survey explored the familiarity with AI chatbots, perception, openness, and factors influencing their usage to understand their child’s ORL condition. 38 responses were obtained. Awareness of AI chatbots among parents/ caregivers was considered average, with only 52.63% (n = 20) having heard about the technology. A smaller subset used AI chatbots, i.e., ChatGPT (70.00%, n = 14), with 21.43% (n = 3) used ChatGPT specifically for pediatric health-related information. 68.42% preferred the explanation provided by doctors compared to the AI chatbot (n = 26), although the majority agreed that the AI chatbot might help them to understand health information better than traditional resources like web search engines, with 60.53% (n = 23). Most participants (60.53% n = 23) expressed interest in using AI chatbots. High openness was shown when using an AI chatbot to obtain general information about the condition (76.32%, n = 29) and symptom identification (71.05%, n = 7). The participants expressed their interest in adopting ChatGPT for health-related use, such as ease of understanding (68.42%, n = 26), accurate information (65.79%, n = 25), and easing communication with doctors (60.53%, n = 23). We found a high preference for medical consultation with doctors compared to AI chatbots (73.68%, n = 28). Familiarity with AI chatbots and their potential role in healthcare is still scarce in the community. Future research should continue exploring the potential of ChatGPT as a health AI chatbot and increase its accuracy in delivering health-related information. © Association of Otolaryngologists of India 2025.",Yes,Sully,,,,,,,,,,
Leveraging AI for improved reproducibility of mathematical disease models: insights from a retinitis pigmentosa case study,"Mathematical modeling of disease and drug action is becoming an indispensable component of drug development, underscored by recent examples of models predicting trial results. To be able to rely on such approaches, decision-makers need to be able to verify those results independently with in silico confirmatory studies. Artificial Intelligence (AI) offers a valuable avenue for improving the reproducibility of complex models, enabling their swift and software-agnostic deployment. This paper highlights AI’s impact through a case study on an Ordinary Differential Equation (ODE) model of Retinitis Pigmentosa (RP). We use a version of Chat GPT 4, a sophisticated large language model (LLM) developed by OpenAI, as customized by Mathpix company with additional capabilities. This setup facilitated the extraction of equations from the PDF and converted into a human-readable, text-based definition language called Antimony, which is part of the Python package tellurium. Subsequently, the model was converted into Systems Biology Markup Language (SBML) using tellurium and uploaded onto the jinkō platform for simulation. The RP model was efficiently and accurately implemented using AI techniques. Furthermore, we were able to reproduce the model behavior presented in the literature. Our findings advocate for the broader application of AI in mathematical model re-implementations to ensure reliability and reproducibility of the results.",No,Sully,,,,,,,,,,
A paradigm shift?—On the ethics of medical large language models,"After a wave of breakthroughs in image-based medical diagnostics and risk prediction models, machine learning (ML) has turned into a normal science. However, prominent researchers are claiming that another paradigm shift in medical ML is imminent—due to most recent staggering successes of large language models—from single-purpose applications toward generalist models, driven by natural language. This article investigates the implications of this paradigm shift for the ethical debate. Focusing on issues like trust, transparency, threats of patient autonomy, responsibility issues in the collaboration of clinicians and ML models, fairness, and privacy, it will be argued that the main problems will be continuous with the current debate. However, due to functioning of large language models, the complexity of all these problems increases. In addition, the article discusses some profound challenges for the clinical evaluation of large language models and threats to the reproducibility and replicability of studies about large language models in medicine due to corporate interests. © 2024 The Authors. Bioethics published by John Wiley & Sons Ltd.",No,Sully,,,,,,,,,,
"Physician vs. AI-generated messages in urology: evaluation of accuracy, completeness, and preference by patients and physicians","3991. World J Urol. 2024 Dec 27;43(1):48. doi: 10.1007/s00345-024-05399-y.

Physician vs. AI-generated messages in urology: evaluation of accuracy, 
completeness, and preference by patients and physicians.

Robinson EJ(1), Qiu C(2), Sands S(3), Khan M(4), Vora S(5), Oshima K(6), Nguyen 
K(7), DiFronzo LA(8), Rhew D(9), Feng MI(10).

Author information:
(1)Department of Urology, Los Angeles Medical Center, Kaiser Permanente, Los 
Angeles, CA, USA.
(2)Department of Anesthesiology, Baldwin Park Medical Center, Kaiser Permanente, 
Baldwin Park, CA, USA.
(3)Kaiser Permanente, Pleasanton, CA, USA.
(4)Microsoft Health & Life Sciences, Irvine, CA, USA.
(5)Microsoft Health & Life Sciences, Dallas, TX, USA.
(6)Kaiser Permanente, Oakland, CA, USA.
(7)Department of Family Medicine, Kaiser Permanente, Pasadena, CA, USA.
(8)Kaiser Permanente, Pasadena, CA, USA.
(9)Microsoft Health & Life Sciences, Redmond, WA, USA.
(10)Department of Urology, Baldwin Park Medical Center, Kaiser Permanente, 1011 
Baldwin Park Blvd., Baldwin Park, CA, 91706, USA. mark.i.feng@kp.org.

Comment in
    World J Urol. 2025 Jan 22;43(1):83. doi: 10.1007/s00345-025-05448-0.
    World J Urol. 2025 Jan 27;43(1):88. doi: 10.1007/s00345-025-05449-z.
    World J Urol. 2025 Feb 14;43(1):122. doi: 10.1007/s00345-025-05508-5.

PURPOSE: To evaluate the accuracy, comprehensiveness, empathetic tone, and 
patient preference for AI and urologist responses to patient messages concerning 
common BPH questions across phases of care.
METHODS: Cross-sectional study evaluating responses to 20 BPH-related questions 
generated by 2 AI chatbots and 4 urologists in a simulated clinical messaging 
environment without direct patient interaction. Accuracy, completeness, and 
empathetic tone of responses assessed by experts using Likert scales, and 
preferences and perceptions of authorship (chatbot vs. human) rated by 
non-medical evaluators.
RESULTS: Five non-medical volunteers independently evaluated, ranked, and 
inferred the source for 120 responses (n = 600 total). For volunteer 
evaluations, the mean (SD) score of chatbots, 3.0 (1.4) (moderately empathetic) 
was significantly higher than urologists, 2.1 (1.1) (slightly empathetic) 
(p < 0.001); mean (SD) and preference ranking for chatbots, 2.6 (1.6), was 
significantly higher than urologist ranking, 3.9 (1.6) (p < 0.001). Two subject 
matter experts (SMEs) independently evaluated 120 responses each (answers to 20 
questions from 4 urologist and 2 chatbots, n = 240 total). For SME evaluations, 
mean (SD) accuracy score for chatbots was 4.5 (1.1) (nearly all correct) and not 
significantly different than urologists, 4.6 (1.2). The mean (SD) completeness 
score for chatbots was 2.4 (0.8) (comprehensive), significantly higher than 
urologists, 1.6 (0.6) (adequate) (p < 0.001).
CONCLUSION: Answers to patient BPH messages generated by chatbots were evaluated 
by experts as equally accurate and more complete than urologist answers. 
Non-medical volunteers preferred chatbot-generated messages and considered them 
more empathetic compared to answers generated by urologists.

© 2024. The Author(s).",Yes,Sully,,,,,,,,,,
A PET/MRI study on the effect of obesity and NAFLD on hepatic [18F]FDG uptake,"Purpose: The potential limitations of hepatic [18F]FDG-PET imaging for individuals with obesity and excessive liver fat (NAFLD) are being investigated. In this study, we aim to determine the reliability of standardized uptake values (SUVs) focusing on adjustment for liver fat content (LFC) derived from DIXON images and the effects of whole-body normalizations. Methods: Lean and with obesity volunteers who underwent [18F]FDG-PET/MRI were reviewed retrospectively. DIXON fat images were used to determine LFC and for adjustment of SUVmean. The hepatic SUVs (mean, fat adjusted mean and max) were normalized to body weight, lean body mass and body surface area. Blood samples were analysed for glucose, serological liver enzymes and lipoproteins for further correlation of [18F]FDG uptake. Results: Out of 11 volunteers with obesity (M:8, F:3, BMI:30–39 kg/m2), 9 confirmed the presence of NAFLD (>5.6 % fat). 22 age-matched lean volunteers (M:10, F:11, BMI:19–26 kg/m2) were used as control group. Both SUVmean, before and after adjustment to LFC, did not provide any difference between lean and with obesity groups under BW, LBM and BSA. SUVmax BW showed a difference between groups (p = 0.05). SUVs were independent of levels of GPT, GOT, gGT, insulin, HOMA-IR, triglycerides, cholesterol and LDL. Volunteers with low HDL were clustered with an increased hepatic [18F]FDG uptake. Conclusion: Our method for adjustment of hepatic [18F]FDG-PET with DIXON fat images allows to achieve accurate results for individuals with NAFLD and obesity. For homogenic results, raw SUVmean should be combined with adjustment for liver fat, appropriate normalization and consideration of HDL levels. © 2024 The Authors",No,Sully,,,,,,,,,,
"Assessing the reliability of ChatGPT: a content analysis of self-generated and self-answered questions on clear aligners, TADs and digital imaging","INTRODUCTION: Artificial Intelligence (AI) is a tool that is already part of our 
reality, and this is an opportunity to understand how it can be useful in 
interacting with patients and providing valuable information about orthodontics.
OBJECTIVE: This study evaluated the accuracy of ChatGPT in providing accurate 
and quality information to answer questions on Clear aligners, Temporary 
anchorage devices and Digital imaging in orthodontics.
METHODS: forty-five questions and answers were generated by the ChatGPT 4.0, and 
analyzed separately by five orthodontists. The evaluators independently rated 
the quality of information provided on a Likert scale, in which higher scores 
indicated greater quality of information (1 = very poor; 2 = poor; 3 = 
acceptable; 4 = good; 5 = very good). The Kruskal-Wallis H test (p< 0.05) and 
post-hoc pairwise comparisons with the Bonferroni correction were performed.
RESULTS: From the 225 evaluations of the five different evaluators, 11 (4.9%) 
were considered as very poor, 4 (1.8%) as poor, and 15 (6.7%) as acceptable. The 
majority were considered as good [34 (15,1%)] and very good [161 (71.6%)]. 
Regarding evaluators' scores, a slight agreement was perceived, with Fleiss's 
Kappa equal to 0.004.
CONCLUSIONS: ChatGPT has proven effective in providing quality answers related 
to clear aligners, temporary anchorage devices, and digital imaging within the 
context of interest of orthodontics.

INTRODUÇÃO: A Inteligência Artificial (IA) é uma ferramenta que já faz parte de 
nossa realidade, e esta é uma oportunidade de entendermos como ela pode ser útil 
na interação com os pacientes e no fornecimento de informações valiosas sobre 
Ortodontia.
OBJETIVO: O objetivo deste estudo foi avaliar a precisão do ChatGPT em responder 
a perguntas sobre Alinhadores transparentes, Dispositivos de ancoragem 
temporária, e Imagens digitais em Ortodontia.
MÉTODOS: 45 perguntas e respostas foram geradas pelo ChatGPT 4.0 e analisadas 
separadamente por cinco ortodontistas que, de forma independente, avaliaram a 
qualidade das informações fornecidas, usando uma escala de Likert, na qual 
pontuações mais altas indicavam uma maior qualidade das informações (1 = muito 
ruim; 2 = ruim; 3 = aceitável; 4 = bom; 5 = muito bom). Aplicou-se o teste H de 
Kruskal-Wallis (p < 0,05) e comparações pareadas post-hoc com correção de 
Bonferroni.
RESULTADOS: Das 225 avaliações dos cinco avaliadores diferentes, 11 (4,9%) foram 
consideradas como muito ruins, 4 (1,8%) como ruins, e 15 (6,7%) como aceitáveis. 
A maioria foi considerada boa [34 (15,1%)] ou muito boa [161 (71,6%)]. Com 
relação às pontuações dos avaliadores, percebeu-se uma leve concordância, com o 
Kappa de Fleiss igual a 0,004.
CONCLUSÕES: O ChatGPT mostrou eficácia em fornecer respostas de qualidade para 
questões relacionadas a Alinhadores transparentes, Dispositivos de ancoragem 
temporária e Imagens digitais.",Yes,Sully,,,,,,,,,,
Can ChatGPT help researchers understand how the human brain handles language?,"2575. Proc Natl Acad Sci U S A. 2024 Jun 18;121(25):e2410196121. doi: 
10.1073/pnas.2410196121. Epub 2024 Jun 14.

Can ChatGPT help researchers understand how the human brain handles language?

Waldrop MM.",No,Sully,,,,,,,,,,
Quantitative Evaluation of Large Language Models to Streamline Radiology Report Impressions: A Multimodal Retrospective Analysis,"Background: The complex medical terminology of radiology reports may cause confusion or anxiety for patients, especially given increased access to electronic health records. Large language models (LLMs) can potentially simplify radiology report readability. Purpose: To compare the performance of four publicly available LLMs (ChatGPT-3.5 and ChatGPT-4, Bard [now known as Gemini], and Bing) in producing simplified radiology report impressions. Materials and Methods: In this retrospective comparative analysis of the four LLMs (accessed July 23 to July 26, 2023), the Medical Information Mart for Intensive Care (MIMIC)-IV database was used to gather 750 anonymized radiology report impressions covering a range of imaging modalities (MRI, CT, US, radiography, mammography) and anatomic regions. Three distinct prompts were employed to assess the LLMs' ability to simplify report impressions. The first prompt (prompt 1) was “Simplify this radiology report.” The second prompt (prompt 2) was “I am a patient. Simplify this radiology report.” The last prompt (prompt 3) was “Simplify this radiology report at the 7th grade level.” Each prompt was followed by the radiology report impression and was queried once. The primary outcome was simplification as assessed by readability score. Readability was assessed using the average of four established readability indexes. The nonparametric Wilcoxon signed-rank test was applied to compare reading grade levels across LLM output. Results: All four LLMs simplified radiology report impressions across all prompts tested (P < .001). Within prompts, differences were found between LLMs. Providing the context of being a patient or requesting simplification at the seventh-grade level reduced the reading grade level of output for all models and prompts (except prompt 1 to prompt 2 for ChatGPT-4) (P < .001). Conclusion: Although the success of each LLM varied depending on the specific prompt wording, all four models simplified radiology report impressions across all modalities and prompts tested. © RSNA, 2024.",Yes,Sully,,,,,,,,,,
The PDC30 Chatbot—Development of a Psychoeducational Resource on Dementia Caregiving Among Family Caregivers: Mixed Methods Acceptability Study,"Background: Providing ongoing support to the increasing number of caregivers as their needs change in the long-term course of dementia is a severe challenge to any health care system. Conversational artificial intelligence (AI) operating 24/7 may help to tackle this problem. Objective: This study describes the development of a generative AI chatbot—the PDC30 Chatbot—and evaluates its acceptability in a mixed methods study. Methods: The PDC30 Chatbot was developed using the GPT-4o large language model, with a personality agent to constrain its behavior to provide advice on dementia caregiving based on the Positive Dementia Caregiving in 30 Days Guidebook—a laypeople’s resource based on a validated training manual for dementia caregivers. The PDC30 Chatbot’s responses to 21 common questions were compared with those of ChatGPT and another chatbot (called Chatbot-B) as standards of reference. Chatbot-B was constructed using PDC30 Chatbot’s architecture but replaced the latter’s knowledge base with a collection of authoritative sources, including the World Health Organization’s iSupport, By Us For Us Guides, and 185 web pages or manuals by Alzheimer’s Association, National Institute on Aging, and UK Alzheimer’s Society. In the next phase, to assess the acceptability of the PDC30 Chatbot, 21 family caregivers used the PDC30 Chatbot for two weeks and provided ratings and comments on its acceptability. Results: Among the three chatbots, ChatGPT’s responses tended to be repetitive and not specific enough. PDC30 Chatbot and Chatbot-B, by virtue of their design, produced highly context-sensitive advice, with the former performing slightly better when the questions conveyed significant psychological distress on the part of the caregiver. In the acceptability study, caregivers found the PDC30 Chatbot highly user-friendly, and its responses quite helpful and easy to understand. They were rather satisfied with it and would strongly recommend it to other caregivers. During the 2-week trial period, the majority used the chatbot more than once per day. Thematic analysis of their written feedback revealed three major themes: helpfulness, accessibility, and improved attitude toward AI. Conclusions: The PDC30 Chatbot provides quality responses to caregiver questions, which are well-received by caregivers. Conversational AI is a viable approach to improve the support of caregivers. ©Sheung-Tak Cheng, Peter H F Ng.",Yes,Sully,,,,,,,,,,
Use of Natural Language Processing to Infer Sites of Metastatic Disease From Radiology Reports at Scale,"PURPOSE To evaluate natural language processing (NLP) methods to infer metastatic sites from radiology reports. METHODS A set of 4,522 computed tomography (CT) reports of 550 patients with 14 types of cancer was used to fine-tune four clinical large language models (LLMs) for multilabel classification of metastatic sites. We also developed an NLP information extraction (IE) system (on the basis of named entity recognition, assertion status detection, and relation extraction) for comparison. Model performances were measured by F1 scores on test and three external validation sets. The best model was used to facilitate analysis of metastatic frequencies in a cohort study of 6,555 patients with 53,838 CT reports. RESULTS The RadBERT, BioBERT, GatorTron-base, and GatorTron-medium LLMs achieved F1 scores of 0.84, 0.87, 0.89, and 0.91, respectively, on the test set. The IE system performed best, achieving an F1 score of 0.93. F1 scores of the IE system by individual cancer type ranged from 0.89 to 0.96. The IE system attained F1 scores of 0.89, 0.83, and 0.81, respectively, on external validation sets including additional cancer types, positron emission tomography-CT,and magnetic resonance imaging scans, respectively. In our cohort study, we found that for colorectal cancer, liver-only metastases were higher in de novo stage IV versus recurrent patients (29.7% v 12.2%; P <.001). Conversely, lung-only metastases were more frequent in recurrent versus de novo stage IV patients (17.2% v 7.3%; P <.001). CONCLUSION We developed an IE system that accurately infers metastatic sites in multiple primary cancers from radiology reports. It has explainable methods and performs better than some clinical LLMs. The inferred metastatic phenotypes could enhance cancer research databases and clinical trial matching, and identify potential patients for oligometastatic interventions.  © 2024 American Society of Clinical Oncology.",No,Sully,Data extraction task,,,,,,,,,
Diagnosis of malignancy in oropharyngeal confocal laser endomicroscopy using GPT 4.0 with vision,"2347. Eur Arch Otorhinolaryngol. 2024 Apr;281(4):2115-2122. doi: 
10.1007/s00405-024-08476-5. Epub 2024 Feb 8.

Diagnosis of malignancy in oropharyngeal confocal laser endomicroscopy using GPT 
4.0 with vision.

Sievert M(1), Aubreville M(2), Mueller SK(1), Eckstein M(3), Breininger K(4), 
Iro H(1), Goncalves M(5).

Author information:
(1)Department of Otorhinolaryngology, Head and Neck Surgery, Friedrich Alexander 
University of Erlangen-Nuremberg, Erlangen University Hospital, Erlangen, 
Germany.
(2)Technische Hochschule Ingolstadt, Ingolstadt, Germany.
(3)Institute of Pathology, Friedrich-Alexander-Universität Erlangen-Nürnberg, 
University Hospital, Erlangen, Germany.
(4)Department of Artificial Intelligence in Biomedical Engineering, 
Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany.
(5)Department of Otorhinolaryngology, Plastic and Aesthetic Operations, 
University Hospital Würzburg, Joseph-Schneider-Straße 11, 97080, Würzburg, 
Germany. Goncalves_M@ukw.de.

PURPOSE: Confocal Laser Endomicroscopy (CLE) is an imaging tool, that has 
demonstrated potential for intraoperative, real-time, non-invasive, 
microscopical assessment of surgical margins of oropharyngeal squamous cell 
carcinoma (OPSCC). However, interpreting CLE images remains challenging. This 
study investigates the application of OpenAI's Generative Pretrained Transformer 
(GPT) 4.0 with Vision capabilities for automated classification of CLE images in 
OPSCC.
METHODS: CLE Images of histological confirmed SCC or healthy mucosa from a 
database of 12 809 CLE images from 5 patients with OPSCC were retrieved and 
anonymized. Using a training data set of 16 images, a validation set of 139 
images, comprising SCC (83 images, 59.7%) and healthy normal mucosa (56 images, 
40.3%) was classified using the application programming interface (API) of 
GPT4.0. The same set of images was also classified by CLE experts (two surgeons 
and one pathologist), who were blinded to the histology. Diagnostic metrics, the 
reliability of GPT and inter-rater reliability were assessed.
RESULTS: Overall accuracy of the GPT model was 71.2%, the intra-rater agreement 
was κ = 0.837, indicating an almost perfect agreement across the three runs of 
GPT-generated results. Human experts achieved an accuracy of 88.5% with a 
substantial level of agreement (κ = 0.773).
CONCLUSIONS: Though limited to a specific clinical framework, patient and image 
set, this study sheds light on some previously unexplored diagnostic 
capabilities of large language models using few-shot prompting. It suggests the 
model`s ability to extrapolate information and classify CLE images with minimal 
example data. Whether future versions of the model can achieve clinically 
relevant diagnostic accuracy, especially in uncurated data sets, remains to be 
investigated.

© 2024. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
part of Springer Nature.",Yes,Sully,,,,,,,,,,
Comparison of Large Language Models in Answering Immuno-Oncology Questions: A Cross-Sectional Study,"Background: The capability of large language models (LLMs) to understand and generate human-readable text has prompted the investigation of their potential as educational and management tools for patients with cancer and healthcare providers. Materials and Methods: We conducted a cross-sectional study aimed at evaluating the ability of ChatGPT-4, ChatGPT-3.5, and Google Bard to answer questions related to 4 domains of immuno-oncology (Mechanisms, Indications, Toxicities, and Prognosis). We generated 60 open-ended questions (15 for each section). Questions were manually submitted to LLMs, and responses were collected on June 30, 2023. Two reviewers evaluated the answers independently. Results: ChatGPT-4 and ChatGPT-3.5 answered all questions, whereas Google Bard answered only 53.3% (P < .0001). The number of questions with reproducible answers was higher for ChatGPT-4 (95%) and ChatGPT3.5 (88.3%) than for Google Bard (50%) (P < .0001). In terms of accuracy, the number of answers deemed fully correct were 75.4%, 58.5%, and 43.8% for ChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (P = .03). Furthermore, the number of responses deemed highly relevant was 71.9%, 77.4%, and 43.8% for ChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (P = .04). Regarding readability, the number of highly readable was higher for ChatGPT-4 and ChatGPT-3.5 (98.1%) and (100%) compared to Google Bard (87.5%) (P = .02). Conclusion: ChatGPT-4 and ChatGPT-3.5 are potentially powerful tools in immuno-oncology, whereas Google Bard demonstrated relatively poorer performance. However, the risk of inaccuracy or incompleteness in the responses was evident in all 3 LLMs, highlighting the importance of expert-driven verification of the outputs returned by these technologies. © 2024 Oxford University Press. All rights reserved.",Yes,Sully,,,,,,,,,,
Artificial Intelligence Can Generate Fraudulent but Authentic-Looking Scientific Medical Articles: Pandora's Box Has Been Opened,"Background: Artificial intelligence (AI) has advanced substantially in recent years, transforming many industries and improving the way people live and work. In scientific research, AI can enhance the quality and efficiency of data analysis and publication. However, AI has also opened up the possibility of generating high-quality fraudulent papers that are difficult to detect, raising important questions about the integrity of scientific research and the trustworthiness of published papers. Objective: The aim of this study was to investigate the capabilities of current AI language models in generating high-quality fraudulent medical articles. We hypothesized that modern AI models can create highly convincing fraudulent papers that can easily deceive readers and even experienced researchers. Methods: This proof-of-concept study used ChatGPT (Chat Generative Pre-trained Transformer) powered by the GPT-3 (Generative Pre-trained Transformer 3) language model to generate a fraudulent scientific article related to neurosurgery. GPT-3 is a large language model developed by OpenAI that uses deep learning algorithms to generate human-like text in response to prompts given by users. The model was trained on a massive corpus of text from the internet and is capable of generating high-quality text in a variety of languages and on various topics. The authors posed questions and prompts to the model and refined them iteratively as the model generated the responses. The goal was to create a completely fabricated article including the abstract, introduction, material and methods, discussion, references, charts, etc. Once the article was generated, it was reviewed for accuracy and coherence by experts in the fields of neurosurgery, psychiatry, and statistics and compared to existing similar articles. Results: The study found that the AI language model can create a highly convincing fraudulent article that resembled a genuine scientific paper in terms of word usage, sentence structure, and overall composition. The AI-generated article included standard sections such as introduction, material and methods, results, and discussion, as well a data sheet. It consisted of 1992 words and 17 citations, and the whole process of article creation took approximately 1 hour without any special training of the human user. However, there were some concerns and specific mistakes identified in the generated article, specifically in the references. Conclusions: The study demonstrates the potential of current AI language models to generate completely fabricated scientific articles. Although the papers look sophisticated and seemingly flawless, expert readers may identify semantic inaccuracies and errors upon closer inspection. We highlight the need for increased vigilance and better detection methods to combat the potential misuse of AI in scientific research. At the same time, it is important to recognize the potential benefits of using AI language models in genuine scientific writing and research, such as manuscript preparation and language editing. © Martin Májovský, Martin Černý, Matěj Kasal, Martin Komarc, David Netuka. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 31.05.2023. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must be included.",No,Sully,,,,,,,,,,
LLM-FMS: A fine-grained dataset for functional movement screen action quality assessment,"The Functional Movement Screen (FMS) is a critical tool for assessing an individual’s basic motor abilities, aiming to prevent sports injuries. However, current automated FMS evaluation is based on deep learning methods, and the evaluation of actions is limited to rank scoring, which lacks fine-grained feedback suggestions and has poor interpretability. This limitation prevents the effective application of automated FMS evaluation for injury prevention and rehabilitation. We develop a fine-grained, hierarchical FMS dataset, LLM-FMS, derived from FMS videos and enriched with detailed, hierarchical action annotations. This dataset comprises 1812 action keyframe images from 45 subjects, encompassing 15 action representations of seven FMS actions. Each action includes a score, scoring criteria, and weight data for body parts. To our extensive knowledge, LLM-FMS is the first fine-grained fitness action dataset for action evaluation task. Additionally, a novel framework for action quality assessment based on large language models (LLMs) is proposed, designed to enhance the interpretability of FMS evaluations. Our method integrates expert rules, utilizes RTMPose to extract key skeletal-level action features from key frames, and inputs prompts into the LLM, enabling it to infer scores and provide detailed rationales. Experimental results demonstrate that our approach significantly outperforms existing methods while offering superior interpretability. Experimental results demonstrate that our approach outperforms existing methods in terms of accuracy and interpretability, with a substantial increase in the clarity and detail of the rationales provided. These findings highlight the potential of our framework for fine-grained action quality assessment with the aid of LLMs.",No,Sully,,,,,,,,,,
A comparative study of large language model-based zero-shot inference and task-specific supervised classification of breast cancer pathology reports,"Objective: Although supervised machine learning is popular for information extraction from clinical notes, creating large annotated datasets requires extensive domain expertise and is time-consuming. Meanwhile, large language models (LLMs) have demonstrated promising transfer learning capability. In this study, we explored whether recent LLMs could reduce the need for large-scale data annotations. Materials and Methods: We curated a dataset of 769 breast cancer pathology reports, manually labeled with 12 categories, to compare zero-shot classification capability of the following LLMs: GPT-4, GPT-3.5, Starling, and ClinicalCamel, with task-specific supervised classification performance of 3 models: random forests, long short-term memory networks with attention (LSTM-Att), and the UCSF-BERT model. Results: Across all 12 tasks, the GPT-4 model performed either significantly better than or as well as the best supervised model, LSTM-Att (average macro F1-score of 0.86 vs 0.75), with advantage on tasks with high label imbalance. Other LLMs demonstrated poor performance. Frequent GPT-4 error categories included incorrect inferences from multiple samples and from history, and complex task design, and several LSTM-Att errors were related to poor generalization to the test set. Discussion: On tasks where large annotated datasets cannot be easily collected, LLMs can reduce the burden of data labeling. However, if the use of LLMs is prohibitive, the use of simpler models with large annotated datasets can provide comparable results. Conclusions: GPT-4 demonstrated the potential to speed up the execution of clinical NLP studies by reducing the need for large annotated datasets. This may increase the utilization of NLP-based variables and outcomes in clinical studies.  © 2024 The Author(s).",Yes,Sully,,,,,,,,,,
Effective In-Context Learning for Named Entity Recognition,"Named entity recognition aims to identify meaningful words or phrases from text. Traditional NER methods depend heavily on training datasets to learn entity features, which often leads to poor performance in recognizing low-resource entities. Large language models offer a promising solution in low-resource scenarios, but they struggle with entity boundary recognition and often suffer from hallucination issues due to their reliance on general-purpose corpora. In this paper, we propose a novel approach that enhances LLMs' performance in NER by integrating a boundary regularity extraction algorithm and an explanatory path extraction method. The boundary regularity algorithm leverages ChatGPT's summarization capabilities to articulate entity boundaries in natural language, improving boundary detection accuracy. The explanatory path method constructs logical reasoning steps from text to entity recognition, guiding LLMs to generate more accurate predictions and mitigating hallucination problems. Extensive experiments on three public datasets demonstrate that our method outperforms current mainstream LLMs in accurately recognizing entities from unstructured text. These findings validate the effectiveness of our approach and its potential to address key challenges in NER. © 2024 IEEE.",No,Sully,,,,,,,,,,
Accuracy of Large Language Model-based Automatic Calculation of Ovarian-Adnexal Reporting and Data System MRI Scores from Pelvic MRI Reports,"Background Ovarian-Adnexal Reporting and Data System (O-RADS) for MRI helps 
assign malignancy risk, but radiologist adoption is inconsistent. Automatic 
assignment of O-RADS scores from reports could increase adoption and accuracy. 
Purpose To evaluate the accuracy of large language models (LLMs), after 
strategic optimization, for automatically calculating O-RADS scores from 
reports. Materials and Methods This retrospective single-center study from a 
large quaternary care cancer center included consecutive gadolinium 
chelate-enhanced pelvic MRI reports with at least one assigned O-RADS score from 
July 2021 to October 2023. Reports from January 2018 to October 2019 (before 
O-RADS MRI implementation) were randomly selected for additional testing. 
Reference standard O-RADS scores were determined by radiologists interpreting 
reports. After prompt optimization using a subset of reports, two LLM-based 
strategies were evaluated: few-shot learning with GPT-4 (version 0613; OpenAI) 
prompted with O-RADS rules (""LLM only"") and a hybrid strategy leveraging GPT-4 
to classify features fed into a deterministic formula (""hybrid""). Accuracy of 
each model and originally reported scores were calculated and compared using the 
McNemar test. Results A total of 284 reports from 284 female patients (mean age, 
53.2 years ± 16.3 [SD]) with 372 adnexal lesions were included: 10 reports in 
the training set (16 lesions), 134 reports in the internal test set 1 (173 
lesions; 158 O-RADS assigned), and 140 reports in internal test set 2 (183 
lesions). For assigning O-RADS MRI scores, the hybrid model accuracy (97%; 168 
of 173) outperformed LLM-only model (90%; 155 of 173; P = .006). For lesions 
with an originally reported O-RADS score, hybrid model accuracy exceeded that of 
reporting radiologists (97% [153 of 158] vs 88% [139 of 158]; P = .004). Hybrid 
model also outperformed LLM-only model for 183 lesions from before O-RADS 
implementation (95% [173 of 183] vs 87% [159 of 183], respectively; P = .01). 
Conclusion A hybrid LLM-based application, combining LLM feature classification 
with deterministic elements, accurately assigned O-RADS MRI scores from report 
descriptions, exceeding both an LLM-only strategy and the original reporting 
radiologist. © RSNA, 2025 Supplemental material is available for this article.",Yes,Sully,,,,,,,,,,
Assessment of Large Language Models (LLMs) in decision-making support for gynecologic oncology,"Objective: This study investigated the ability of Large Language Models (LLMs) to provide accurate and consistent answers by focusing on their performance in complex gynecologic cancer cases. Background: LLMs are advancing rapidly and require a thorough evaluation to ensure that they can be safely and effectively used in clinical decision-making. Such evaluations are essential for confirming LLM reliability and accuracy in supporting medical professionals in casework. Study design: We assessed three prominent LLMs—ChatGPT-4 (CG-4), Gemini Advanced (GemAdv), and Copilot—evaluating their accuracy, consistency, and overall performance. Fifteen clinical vignettes of varying difficulty and five open-ended questions based on real patient cases were used. The responses were coded, randomized, and evaluated blindly by six expert gynecologic oncologists using a 5-point Likert scale for relevance, clarity, depth, focus, and coherence. Results: GemAdv demonstrated superior accuracy (81.87 %) compared to both CG-4 (61.60 %) and Copilot (70.67 %) across all difficulty levels. GemAdv consistently provided correct answers more frequently (>60 % every day during the testing period). Although CG-4 showed a slight advantage in adhering to the National Comprehensive Cancer Network (NCCN) treatment guidelines, GemAdv excelled in the depth and focus of the answers provided, which are crucial aspects of clinical decision-making. Conclusion: LLMs, especially GemAdv, show potential in supporting clinical practice by providing accurate, consistent, and relevant information for gynecologic cancer. However, further refinement is needed for more complex scenarios. This study highlights the promise of LLMs in gynecologic oncology, emphasizing the need for ongoing development and rigorous evaluation to maximize their clinical utility and reliability.",Yes,Sully,,,,,,,,,,
Performance Evaluation of Multimodal Large Language Models (LLaVA and GPT-4-based ChatGPT) in Medical Image Classification Tasks,"Large language models (LLMs) have gained significant attention due to their prospective applications in medicine. Utilizing multimodal LLMs can potentially assist clinicians in medical image classification tasks. It is important to evaluate the performance of LLMs in medical image processing to potentially improve the medical system. We evaluated two multimodal LLMs (LLaVA and GPT-4-based ChatGPT) against the classic VGG in tumor classification across brain MRI, breast ultrasound, and kidney CT datasets. Despite LLMs facing significant hallucination issue in medical imaging, prompt engineering markedly enhanced their performance. In comparison to the baseline method, GPT-4-based ChatGPT with prompt engineering achieves 98%, 112%, and 69% of the baseline's performance in terms of accuracy (or 99%, 107%, and 62 % in terms of F1-score) in those three datasets, respectively. However, privacy, bias, accountability, and transparency concerns necessitate caution. Our study underscore LLMs' potential in medical imaging but emphasize the need for thorough performance and safety evaluations for their practical application. © 2024 IEEE.",Yes,Sully,,,,,,,,,,
Extraction and classification of structured data from unstructured hepatobiliary pathology reports using large language models: A feasibility study compared with rules-based natural language processing,"Aims Structured reporting in pathology is not universally adopted and extracting elements essential to research often requires expensive and time-intensive manual curation. The accuracy and feasibility of using large language models (LLMs) to extract essential pathology elements, for cancer research is examined here. Methods Retrospective study of patients who underwent pathology sampling for suspected hepatocellular carcinoma and underwent Ytrrium-90 embolisation. Five pathology report elements of interest were included for evaluation. LLMs (Generative Pre-trained Transformer (GPT) 3.5 turbo and GPT-4) were used to extract elements of interest. For comparison, a rules-based, regular expressions (REGEX) approach was devised for extraction. Accuracy for each approach was calculated. Results 88 pathology reports were identified. LLMs and REGEX were both able to extract research elements with high accuracy (average 84.1%-94.8%). Conclusions LLMs have significant potential to simplify the extraction of research elements from pathology reporting, and therefore, accelerate the pace of cancer research.  © Author(s) (or their employer(s)) 2025.",No,Sully,,,,,,,,,,
How Well Do Artificial Intelligence Chatbots Respond to the Top Search Queries About Urological Malignancies?,"10.

How Well Do Artificial Intelligence Chatbots Respond to the Top Search Queries 
About Urological Malignancies?

Musheyev D(1), Pan A(1), Loeb S(2), Kabarriti AE(3).

Author information:
(1)Department of Urology, State University of New York Downstate Health Sciences 
University, New York, NY, USA.
(2)Department of Urology, New York University and Manhattan Veterans Affairs, 
New York, NY, USA; Department of Population Health, New York University, New 
York, NY, USA.
(3)Department of Urology, State University of New York Downstate Health Sciences 
University, New York, NY, USA. Electronic address: abdo.kabarriti@downstate.edu.

Comment in
    Transl Androl Urol. 2024 May 31;13(5):879-883. doi: 10.21037/tau-23-635.
    Transl Androl Urol. 2024 Jun 30;13(6):1067-1070. doi: 10.21037/tau-23-629.

Artificial intelligence (AI) chatbots are becoming a popular source of 
information but there are limited data on the quality of information on 
urological malignancies that they provide. Our objective was to characterize the 
quality of information and detect misinformation about prostate, bladder, 
kidney, and testicular cancers from four AI chatbots: ChatGPT, Perplexity, Chat 
Sonic, and Microsoft Bing AI. We used the top five search queries related to 
prostate, bladder, kidney, and testicular cancers according to Google Trends 
from January 2021 to January 2023 and input them into the AI chatbots. Responses 
were evaluated for quality, understandability, actionability, misinformation, 
and readability using published instruments. AI chatbot responses had moderate 
to high information quality (median DISCERN score 4 out of 5, range 2-5) and 
lacked misinformation. Understandability was moderate (median Patient Education 
Material Assessment Tool for Printable Materials [PEMAT-P] understandability 
66.7%, range 44.4-90.9%) and actionability was moderate to poor (median PEMAT-P 
actionability 40%, range 0-40%The responses were written at a fairly difficult 
reading level. AI chatbots produce information that is generally accurate and of 
moderate to high quality in response to the top urological malignancy-related 
search queries, but the responses lack clear, actionable instructions and exceed 
the reading level recommended for consumer health information. PATIENT SUMMARY: 
Artificial intelligence chatbots produce information that is generally accurate 
and of moderately high quality in response to popular Google searches about 
urological cancers. However, their responses are fairly difficult to read, are 
moderately hard to understand, and lack clear instructions for users to act on.

Copyright © 2023 European Association of Urology. Published by Elsevier B.V. All 
rights reserved.",Yes,Sully,,,,,,,,,,
ChatGPT compared with Google Search and healthcare institution as sources of postoperative patient instructions after gynecological surgery,"3032. BJOG. 2024 Jul;131(8):1154-1156. doi: 10.1111/1471-0528.17746. Epub 2024 Jan 4.

ChatGPT compared with Google Search and healthcare institution as sources of 
postoperative patient instructions after gynecological surgery.

Meyer R(1)(2), Hamilton KM(1), Truong MD(1), Wright KN(1), Siedhoff MT(1), 
Brezinov Y(3), Levin G(3).

Author information:
(1)Division of Minimally Invasive Gynecologic Surgery, Department of Obstetrics 
and Gynecology, Cedars Sinai Medical Center, Los Angeles, California, USA.
(2)The Dr. Pinchas Bornstein Talpiot Medical Leadership Programme, Sheba Medical 
Center, Ramat-Gan, Israel.
(3)Lady Davis Institute for Cancer Research, Jewish General Hospital, McGill 
University, Montreal, Quebec, Canada.",Yes,Sully,,,,,,,,,,
TPepRet: a deep learning model for characterizing T-cell receptors-antigen binding patterns,"3801. Bioinformatics. 2024 Dec 26;41(1):btaf022. doi: 10.1093/bioinformatics/btaf022.

TPepRet: a deep learning model for characterizing T-cell receptors-antigen 
binding patterns.

Wang M(1), Fan W(2), Wu T(1), Li M(1).

Author information:
(1)School of Computer Science and Engineering, Central South University, 
Changsha 410083, China.
(2)Nuffield Department of Women's and Reproductive Health, University of Oxford, 
Oxford OX39DU, United Kingdom.

MOTIVATION: T-cell receptors (TCRs) elicit and mediate the adaptive immune 
response by recognizing antigenic peptides, a process pivotal for cancer 
immunotherapy, vaccine design, and autoimmune disease management. Understanding 
the intricate binding patterns between TCRs and peptides is critical for 
advancing these clinical applications. While several computational tools have 
been developed, they neglect the directional semantics inherent in sequence 
data, which are essential for accurately characterizing TCR-peptide 
interactions.
RESULTS: To address this gap, we develop TPepRet, an innovative model that 
integrates subsequence mining with semantic integration capabilities. TPepRet 
combines the strengths of the Bidirectional Gated Recurrent Unit (BiGRU) network 
for capturing bidirectional sequence dependencies with the Large Language Model 
framework to analyze subsequences and global sequences comprehensively, which 
enables TPepRet to accurately decipher the semantic binding relationship between 
TCRs and peptides. We have evaluated TPepRet to a range of challenging 
scenarios, including performance benchmarking against other tools using diverse 
datasets, analysis of peptide binding preferences, characterization of T cells 
clonal expansion, identification of true binder in complex environments, 
assessment of key binding sites through alanine scanning, validation against 
expression rates from large-scale datasets, and ability to screen SARS-CoV-2 
TCRs. The comprehensive results suggest that TPepRet outperforms existing tools. 
We believe TPepRet will become an effective tool for understanding TCR-peptide 
binding in clinical treatment.
AVAILABILITY AND IMPLEMENTATION: The source code can be obtained from 
https://github.com/CSUBioGroup/TPepRet.git.

© The Author(s) 2025. Published by Oxford University Press.",No,Sully,,,,,,,,,,
"Ameliorating Racial Disparities in HIV Prevention via a Nurse-Led, AI-Enhanced Program for Pre-Exposure Prophylaxis Utilization Among Black Cisgender Women: Protocol for a Mixed Methods Study","Background: HIV pre-exposure prophylaxis (PrEP) is a critical biomedical strategy to prevent HIV transmission among cisgender women. Despite its proven effectiveness, Black cisgender women remain significantly underrepresented throughout the PrEP care continuum, facing barriers such as limited access to care, medical mistrust, and intersectional racial or HIV stigma. Addressing these disparities is vital to improving HIV prevention outcomes within this community. On the other hand, nurse practitioners (NPs) play a pivotal role in PrEP utilization but are underrepresented due to a lack of awareness, a lack of human resources, and insufficient support. Equipped with the rapid evolution of artificial intelligence (AI) and advanced large language models, chatbots effectively facilitate health care communication and linkage to care in various domains, including HIV prevention and PrEP care. Objective: Our study harnesses NPs’ holistic care capabilities and the power of AI through natural language processing algorithms, providing targeted, patient-centered facilitation for PrEP care. Our overarching goal is to create a nurse-led, stakeholder-inclusive, and AI-powered program to facilitate PrEP utilization among Black cisgender women, ultimately enhancing HIV prevention efforts in this vulnerable group in 3 phases. This project aims to mitigate health disparities and advance innovative, technology-based solutions. Methods: The study uses a mixed methods design involving semistructured interviews with key stakeholders, including 50 PrEP-eligible Black women, 10 NPs, and a community advisory board representing various socioeconomic backgrounds. The AI-powered chatbot is developed using HumanX technology and SmartBot360’s Health Insurance Portability and Accountability Act–compliant framework to ensure data privacy and security. The study spans 18 months and consists of 3 phases: exploration, development, and evaluation. Results: As of May 2024, the institutional review board protocol for phase 1 has been approved. We plan to start recruitment for Black cisgender women and NPs in September 2024, with the aim to collect information to understand their preferences regarding chatbot development. While institutional review board approval for phases 2 and 3 is still in progress, we have made significant strides in networking for participant recruitment. We plan to conduct data collection soon, and further updates on the recruitment and data collection progress will be provided as the study advances. Conclusions: The AI-powered chatbot offers a novel approach to improving PrEP care utilization among Black cisgender women, with opportunities to reduce barriers to care and facilitate a stigma-free environment. However, challenges remain regarding health equity and the digital divide, emphasizing the need for culturally competent design and robust data privacy protocols. The implications of this study extend beyond PrEP care, presenting a scalable model that can address broader health disparities. © 2024 JMIR Publications Inc.. All rights reserved.",No,Sully,,,,,,,,,,
ChatGPT-estimated occupational complexity predicts cognitive outcomes and cortical thickness above and beyond socioeconomic status among older adults,"Many aging cohort studies have collected data on participants’ job titles, yet these job titles were seldom analyzed within the cognitive aging context despite their relevance to neurocognition, due to difficulties in analyzing these job titles quantitatively. While it is possible to rate these jobs’ occupational complexity (OC) using job classification systems, this can be somewhat labor-intensive and prone to human errors. To this end, we demonstrate a novel and simple method to extract OC ratings from job titles using ChatGPT. Then, we showcased the utility of these ratings in predicting cognitive and structural brain outcomes, especially compared to other socioeconomic status (SES) indicators. Community-dwelling older adults (N = 238, agemean = 70) completed cognitive assessments and underwent MRI scans. Regression models were fitted to predict 14 different cognitive outcomes, vertex-wise cortical thickness (CT), and subcortical gray matter volumes, using OC scores and/or SES predictors (e.g., education, housing type, and income levels), controlling for demographical covariates. OC scores outperformed SES indicators in predicting clusters of CT increases and most cognitive outcomes, including diagnoses of mild cognitive impairment. Furthermore, OC scores significantly predicted clusters of CT increases and various cognitive outcomes, even after controlling for SES. Meta-analytic decoding suggests these clusters of CT increases occurred in regions typically associated with sensorimotor and memory processing. These results highlight the significant and unique contribution of ChatGPT-derived OC scores in predicting cognitive and brain aging outcomes. These scores are easy to derive and can be helpful in fine-tuning predictions of cognitive and brain aging outcomes. © The Author(s), under exclusive licence to American Aging Association 2025.",No,Sully,Okay this is not really applying an LLM in a clinical context but wtf this one is kinda cool ,,,,,,,,,
Traditional Chinese Medicine Prescription Recommendation Model Based on Large Language Models and Graph Neural Networks,"Background: Traditional Chinese medicine (TCM) has a millennia-long history, offering unique treatments and insights into global health. Given the intricate symptoms and shifting syndrome patterns, prescribing can be tough for young doctors. TCM prescription recommendations can help these doctors address their experience gap. In recent years, with advancements in technologies such as artificial intelligence and big data, intelligent recommendations for TCM prescriptions have become feasible, holding significant implications for enhancing treatment efficacy and optimizing patient experience. Objective: This study aims to establish a novel TCM prescription recommendation model by integrating large language models with Graph Neural Network (GNN) to enhance the accuracy of prescription suggestions. Method: Based on the co-occurrence of symptoms and herbal medicines, we constructed symptom graphs, symptom-herb graphs, and herb-herb graphs. Using Graph Convolutional Network (GCN), we acquired embeddings for both symptoms and herbs. The symptom embeddings are then integrated with insights from large language model embeddings, while auxiliary information from an external knowledge graph is incorporated into the herb embeddings. A final list of herb recommendations was generated by interacting with the embeddings of symptoms and herbs. Results: The proposed algorithm achieved 22.1%, 17.2%, and 13% on the evaluation metrics P@5, P@10, and P@20, respectively. Concurrently, scores for R@5, R@10, and R@20 were 14%, 24%, and 32.5%, respectively. The P@5 metric surpassed the KDHR by 4.7%, and the R@20 metric exceeded the KDHR by 6%. Overall, the performance of our model outperformed other baseline models across various evaluation criteria. Conclusion: The TCM prescription recommendation model, infused with information from a large language model, can effectively enhance the outcomes of TCM prescription recommendations. The study may offer valuable insights for auxiliary clinical research and treatment in TCM.  © 2023 IEEE.",Yes,Sully,,,,,,,,,,
Evaluation of Large Language Models for Unit Test Generation,"In recent years, Artificial Intelligence (AI) has significantly transformed various industries, especially software development, through automation and enhanced decision-making processes. Traditional software testing, often manual and error-prone, cannot keep up with rapid development cycles and complex systems, leading to extended development times, higher costs, and undetected bugs. This study develops an AI-based platform using OpenAI models to generate and execute unit tests across multiple programming languages. By leveraging Large Language Models (LLMs) like GPT, we automate unit test creation, demonstrating proficiency in understanding and generating natural language to interpret code. Our web-based system architecture ensures efficient test generation and execution, significantly reducing manual effort and mitigating human error, thus revolutionizing software testing. Furthermore, we introduce unique evaluation metrics such as ""Is Executable"" and ""Assertion Count"" to assess the performance and effectiveness of the generated unit tests, providing a comprehensive measure of the models' capabilities. © 2024 IEEE.",No,Sully,,,,,,,,,,
The correlation between triiodothyronine and the severity of liver fibrosis,"Background: The severity of liver fibrosis is an important predictor of death in patients with non-alcoholic fatty liver disease (NAFLD) and type 2 diabetes mellitus (T2DM). However, there is still no definite conclusion on the relationship between triiodothyronine (T3) and the severity of liver fibrosis. Thus, the aim of this study was to analyze the correlation between T3 level and the severity of liver fibrosis. Methods: We performed a cross-sectional study of 2072 T2DM patients with normal thyroid function from January 2017 to January 2020. NAFLD fibrosis score (NFS), Fibrosis index based on the 4 factors (FIB-4) and BARD score (BARD) were used to assess the severity of fibrosis in T2DM patients, and linear regression analyses were used to determine the factors independently associated with liver fibrosis. Further experiments were performed to assess the impact of low T3 on fibrosis progression in mice model and explore possible mechanisms. Results: Free triiodothyronine (fT3) levels had significantly inverse correlations with NFS and FIB-4, and BARD in T2DM patients (P < 0.05). In multiple linear regression analyses, decreased fT3 level was an independent risk factor for the severity of liver fibrosis of T2DM patients (P < 0.01). Findings from in-vivo experiment using mice model proved that hypothyroidism mice had more severe of liver fibrosis than those mice with normal thyroid function. We also found that T3 could inhibit the profibrotic TREM2+CD9+ macrophage, which had been identified an important player in the progression of liver fibrosis. Conclusion: The findings from this study proved an inverse correlation between T3 level and the severity of liver fibrosis, and lower fT3 level within the normal range was an independent risk factor for severe liver fibrosis. © 2022, The Author(s).",No,Sully,,,,,,,,,,
Exposing Vulnerabilities in Clinical LLMs Through Data Poisoning Attacks: Case Study in Breast Cancer,"Training Large Language Models (LLMs) with billions of parameters on a dataset and publishing the model for public access is the standard practice currently. Despite their transformative impact on natural language processing, public LLMs present notable vulnerabilities given the source of training data is often web-based or crowdsourced, and hence can be manipulated by perpetrators. We delve into the vulnerabilities of clinical LLMs, particularly BioGPT which is trained on publicly available biomedical literature and clinical notes from MIMIC-III, in the realm of data poisoning attacks. Exploring susceptibility to data poisoning-based attacks on de-identified breast cancer clinical notes, our approach is the first one to assess the extent of such attacks and our findings reveal successful manipulation of LLM outputs. Through this work, we emphasize on the urgency of comprehending these vulnerabilities in LLMs, and encourage the mindful and responsible usage of LLMs in the clinical domain.",No,Sully,,,,,,,,,,
Assessing Completeness of Clinical Histories Accompanying Imaging Orders Using Adapted Open-Source and Closed-Source Large Language Models,"Background: Incomplete clinical histories are a well-known problem in radiology. Previous dedicated quality improvement efforts focusing on reproducible assessments of the completeness of free-text clinical histories have relied on tedious manual analysis. Purpose: To adapt and evaluate open-source and closed-source large language models (LLMs) for their ability to automatically extract clinical history elements within imaging orders and to use the best-performing adapted open-source model to assess the completeness of a large sample of clinical histories as a benchmark for clinical practice. Materials and Methods: This retrospective single-site study used previously extracted information accompanying CT, MRI, US, and radiography orders from August 2020 to May 2022 at an adult and pediatric emergency department of a 613-bed tertiary academic medical center. Two open-source (Llama 2–7B [Meta], Mistral-7B [Mistral AI]) and one closed-source (GPT-4 Turbo [OpenAI]) LLMs were adapted using prompt engineering, in-context learning, and fine-tuning (open-source only) to extract the elements “past medical history,” “what,” “when,” “where,” and “clinical concern” from clinical histories. Model performance, interreader agreement using Cohen κ (none to slight, 0.01–0.20; fair, 0.21–0.40; moderate, 0.41–0.60; substantial, 0.61–0.80; almost perfect, 0.81–1.00), and semantic similarity between the models and the adjudicated manual annotations of two board-certified radiologists with 16 and 3 years of postfellowship experience, respectively, were assessed using accuracy, Cohen κ, and BERTScore, an LLM metric that quantifies how well two pieces of text convey the same meaning; 95% CIs were also calculated. The best-performing open-source model was then used to assess completeness on a large dataset of unannotated clinical histories. Results: A total of 50 186 clinical histories were included (794 training, 150 validation, 300 initial testing, 48 942 real-world application). Of the two open-source models, Mistral-7B outperformed Llama 2–7B in assessing completeness and was further fine-tuned. Both Mistral-7B and GPT-4 Turbo showed substantial overall agreement with radiologists (mean κ, 0.73 [95% CI: 0.67, 0.78] to 0.77 [95% CI: 0.71, 0.82]) and adjudicated annotations (mean BERTScore, 0.96 [95% CI: 0.96, 0.97] for both models; P = .38). Mistral-7B also rivaled GPT-4 Turbo in performance (weighted overall mean accuracy, 91% [95% CI: 89, 93] vs 92% [95% CI: 90, 94]; P = .31) despite being a smaller model. Using Mistral-7B, 26.2% (12 803 of 48 942) of unannotated clinical histories were found to contain all five elements. Conclusion: An easily deployable fine-tuned open-source LLM (Mistral-7B), rivaling GPT-4 Turbo in performance, could effectively extract clinical history elements with substantial agreement with radiologists and produce a benchmark for completeness of a large sample of clinical histories. The model and code will be fully open-sourced. © RSNA, 2025.",No,Sully,,,,,,,,,,
ChatGPT and mycosis– a new weapon in the knowledge battlefield,"As current trend for physician tools, ChatGPT can sift through massive amounts of information and solve problems through easy-to-understand conversations, ultimately improving efficiency. Mycosis is currently facing great challenges, including high fungal burdens, high mortality, limited choice of antifungal drugs and increasing drug resistance. To address these challenges, We asked ChatGPT for fungal infection scenario-based questions and assessed its appropriateness, consistency, and potential pitfalls. We concluded ChatGPT can provide compelling responses to most prompts, including diagnosis, recommendations for examination, treatment and rational drug use. Moreover, we summarized exciting future applications in mycosis, such as clinical work, scientific research, education and healthcare. However, the largest barriers to implementation are deficits in indiviudal advice, timely literature updates, consistency, accuracy and data safety. To fully embrace the opportunity, we need to address these barriers and manage the risks. We expect that ChatGPT will become a new weapon in in the battlefield of mycosis. © 2023, The Author(s).",Yes,Sully,,,,,,,,,,
Simulate Scientific Reasoning with Multiple Large Language Models: An Application to Alzheimer’s Disease Combinatorial Therapy,"Motivation This study aims to develop an AI-driven framework that leverages large language models (LLMs) to simulate scientific reasoning and peer review to predict efficacious combinatorial therapy when data-driven prediction is infeasible. Results Our proposed framework achieved a significantly higher accuracy (0.74) than traditional knowledge-based prediction (0.52). An ablation study highlighted the importance of high quality few-shot examples, external knowledge integration, self-consistency, and review within the framework. The external validation with private experimental data yielded an accuracy of 0.82, further confirming the framework's ability to generate high-quality hypotheses in biological inference tasks. Our framework offers an automated knowledge-driven hypothesis generation approach when data-driven prediction is not a viable option. Availability and implementation Our source code and data are available at https://github.com/QidiXu96/Coated-LLM",No,Sully,,,,,,,,,,
AI Chatbots as Sources of STD Information: A Study on Reliability and Readability,"Background: Artificial intelligence (AI) chatbots are increasingly used for medical inquiries, including sensitive topics like sexually transmitted diseases (STDs). However, concerns remain regarding the reliability and readability of the information they provide. This study aimed to assess the reliability and readability of AI chatbots in providing information on STDs. The key objectives were to determine (1) the reliability of STD-related information provided by AI chatbots, and (2) whether the readability of this information meets the recommended standarts for patient education materials. Methods: Eleven relevant STD-related search queries were identified using Google Trends and entered into four AI chatbots: ChatGPT, Gemini, Perplexity, and Copilot. The reliability of the responses was evaluated using established tools, including DISCERN, EQIP, JAMA, and GQS. Readability was assessed using six widely recognized metrics, such as the Flesch-Kincaid Grade Level and the Gunning Fog Index. The performance of chatbots was statistically compared in terms of reliability and readability. Results: The analysis revealed significant differences in reliability across the AI chatbots. Perplexity and Copilot consistently outperformed ChatGPT and Gemini in DISCERN and EQIP scores, suggesting that these two chatbots provided more reliable information. However, results showed that none of the chatbots achieved the 6th-grade readability standard. All the chatbots generated information that was too complex for the general public, especially for individuals with lower health literacy levels. Conclusion: While Perplexity and Copilot showed better reliability in providing STD-related information, none of the chatbots met the recommended readability benchmarks. These findings highlight the need for future improvements in both the accuracy and accessibility of AI-generated health information, ensuring it can be easily understood by a broader audience. © The Author(s) 2025.",Yes,Sully,,,,,,,,,,
Does one size fit all? Developing an evaluation strategy to assess large language models for patient safety event report analysis,"Objective: Collecting and analyzing patient safety event (PSE) reports is a key component to the improvement of patient safety yet report analysis has been challenging. Large language models (LLMs) may support analysis; however, PSE reports tend to be a hybrid of clinical and general language. Materials and Methods: We propose a data-driven evaluation strategy to assess LLM fit for report analysis. We identify target tokens and sentences from PSE reports and use perplexity to evaluate four LLMs comprehension of the target sentence. Results: LLMs had statistically significantly different perplexity measures in six of seven event categories. Clinical models perform better with clinical narratives, often reported by nurses and physicians. General models perform better with colloquial language and communication themes. Discussion and Conclusion: For LLMs to support PSE report analysis there must be a good fit between the language model and the nature of the text in reports. A single LLM approach may not be the most useful strategy. © The Author(s) 2024.",No,Sully,,,,,,,,,,
The Disease of the Canine Eye - From Image to Diagnosis Using AI,"This research examines the application of computer vision (CV) and large language models (LLM) in diagnosing eye diseases in dogs. The study utilizes a U-Net framework, incorporating convolutional neural networks (CNNs) such as ResNet, Inception, VGG, and EfficientNet, to enhance the segmentation of eye disease areas. Along the base U-Net model, four U-Net-based models were developed and evaluated on a dataset specifically generated for this purpose, classifying eye diseases into four categories. The performance of the enhanced U-Net architectures was found to be superior to that of the standard U-Net, with the U-Net modified with ResNet34 achieving the best segmentation accuracy, as measured by a Jaccard index of 66.6% on a custom test set. The segmented images were then diagnosed using various LLMs, including ChatGPT, Mistral, Gemini (Bard), Claude, and Llama-2, which were assessed using 15 different symptom sets. The study demonstrates that combining advanced image segmentation techniques with LLMs can improve diagnostic accuracy in veterinary medicine. The approach leverages the segmentation capabilities of U-Net for precise localization and the diagnostic ability of LLMs to interpret symptoms, facilitating enhanced diagnostic tools. This method could be applicable to other medical diagnostic areas requiring similar dual capabilities. © 2024 University of West Bohemia. All rights reserved.",No,Sully,,,,,,,,,,
Correlates of Medical and Allied Health Students’ Engagement with Generative AI in Nigeria,"Introduction: The extent of artificial intelligence (AI) engagement and factors influencing its use among medical and allied health students in low-resource settings are not well documented. We assessed the knowledge and correlates of ChatGPT use among medical, dental, and allied health students in Nigeria. Methods: We used a cross-sectional mixed-methods study design and self-administered structured questionnaires, followed by in-depth interviews with a sub-sample (n = 20) of students. We employed logistic regression models to generate adjusted odds ratios, and thematic analysis to identify key factors. Results: Of the 420 respondents, 77.4% (n = 325) demonstrated moderate to good knowledge of ChatGPT. Most respondents (61.9%, n = 260) reported prior ChatGPT use in medical education, motivated mainly by ease of use (75.0%) and efficiency (72.1%). Major concerns included risk of dependency (65.0%), inaccuracy (49.7%), doubts about reliability (49.3%), and ethical issues (41.7%). ChatGPT use was more likely among male students (adjusted odds ratio (aOR) = 1.62, 95% confidence interval (95%CI) 1.13–3.72), older cohorts (≥ 25 years) (aOR = 1.74, 95%CI 1.16–4.50), final-year students (aOR = 2.46, 95%CI 1.12–5.67), those with good knowledge (aOR = 3.27, 95%CI 1.59–7.36), and those with positive attitudes (aOR = 4.29, 95%CI 1.92–8.56). Qualitative themes reinforced concerns about errors, ethics, and infrastructure limitations. Conclusion: We found moderate knowledge and engagement with ChatGPT among medical and allied health students in Nigeria. Engagement was influenced by gender, age, year of study, knowledge, and attitude. Targeted education and guidelines for responsible AI use will be important in shaping the future of medical and health professional education in similar settings. © The Author(s) under exclusive licence to International Association of Medical Science Educators 2024.",No,Sully,,,,,,,,,,
Identification of differentially expressed mRNAs as novel predictive biomarkers for gastric cancer diagnosis and prognosis,"BACKGROUND Gastric cancer (GC) has a high mortality rate worldwide. Despite significant progress in GC diagnosis and treatment, the prognosis for affected patients still remains unfavorable. AIM To identify important candidate genes related to the development of GC and iden -tify potential pathogenic mechanisms through comprehensive bioinformatics analysis. METHODS The Gene Expression Omnibus database was used to obtain the GSE183136 dataset, which includes a total of 135 GC samples. The limma package in R software was employed to identify differentially expressed genes (DEGs). Thereafter, enrichment analyses of Gene Ontology (GO) terms and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathways were performed for the gene modules using the clusterProfile package in R software. The protein-protein interaction (PPI) networks of target genes were constructed using STRING and visualized by Cytoscape software. The common hub genes that emerged in the cohort of DEGs that was retrieved from the GEPIA database were then screened using a Venn Diagram. The expression levels of these overlapping genes in stomach adenocarcinoma samples and non-tumor samples and their association with prognosis in GC patients were also obtained from the GEPIA database and Kaplan-Meier curves. Moreover, real-time quantitative polymerase chain reaction (RT-qPCR) and western blotting were performed to determine the mRNA and protein levels of glutamic-pyruvic transaminase (GPT) in GC and normal immortalized cell lines. In addition, cell viability, cell cycle distribution, migration and invasion were evaluated by cell counting kit-8, flow cytometry and transwell assays. Furthermore, we also conducted a retrospective analysis on 70 GC patients diagnosed and surgically treated in Wenzhou Central Hospital, Dingli Clinical College of Wenzhou Medical University, The Second Affiliated Hospital of Shanghai University between January 2017 to December 2020. The tumor and adjacent normal samples were collected from the patients to determine the potential association between the expression level of GPT and the clinical as well as pathological features of GC patients. RESULTS We selected 19214 genes from the GSE183136 dataset, among which there were 250 downregulated genes and 401 upregulated genes in the tumor samples of stage III-IV in comparison to those in tumor samples of stage I-II with a P-value < 0.05. In addition, GO and KEGG results revealed that the various upregulated DEGs were mainly enriched in plasma membrane and neuroactive ligand-receptor interaction, whereas the downregulated DEGs were primarily enriched in cytosol and pancreatic secretion, vascular smooth muscle contraction and biosynthesis of the different cofactors. Furthermore, PPI networks were constructed based on the various upregulated and downregulated genes, and there were a total 15 upregulated and 10 downregulated hub genes. After a comprehensive analysis, several hub genes, including runt-related transcription factor 2 (RUNX2), salmonella pathogenicity island 1 (SPI1), lysyl oxidase (LOX), fibrillin 1 (FBN1) and GPT, displayed prognostic values. Interestingly, it was observed that GPT was downregulated in GC cells and its upregulation could suppress the malignant phenotypes of GC cells. Furthermore, the expression level of GPT was found to be associated with age, lymph node metastasis, pathological staging and distant metastasis (P < 0.05). CONCLUSION RUNX2, SPI1, LOX, FBN1 and GPT were identified key hub genes in GC by bioinformatics analysis. GPT was significantly associated with the prognosis of GC, and its upregulation can effectively inhibit the proliferative, migrative and invasive capabilities of GC cells. © The Author(s) 2024. Published by Baishideng Publishing Group Inc. All rights reserved.",No,Sully,,,,,,,,,,
ChatGPT’s Performance on Iran’s Medical Licensing Exams,"Background: A 175 billion parameter transformer architecture is used by OpenAI’s ChatGPT language model to perform tasks requiring natural language processing. This study aims to evaluate the knowledge and interpretive abilities of ChatGPT on three types of Iranian medical license exams: basic sciences, pre-internship, and pre-residency. Methods: This comparative study involved administering three different levels of Iran’s medical license exams, which included basic sciences, pre-internship, and pre-residency, to ChatGPT 3.5. Two versions of each exam were used, corresponding to the ChatGPT 3.5’s internet access time: one during the access time and one after. These exams were inputted to ChatGPT in Persian and English. The accuracy and concordance of each question were extracted by two blinded adjudicators. Results: A total of 2210 questions, including 667 basic sciences, 763 pre-internship, and 780 pre-residency questions, were presented to ChatGPT in both English and Persian languages. Across all tests, the overall accuracy was found to be 48.5%, with an overall concordance of 91%. Notably, English questions exhibited higher accuracy and concordance rates, with 61.4% accuracy and 94.5% concordance, compared to 35.7% accuracy and 88.7% concordance for Persian questions. Conclusion: Our findings demonstrate that ChatGPT performs above the required passing scores on basic sciences and pre-internship exams. Moreover, ChatGPT could obtain the minimal score needed to apply for residency positions in Iran; however, it was lower than the applicants’ mean scores. Significantly, the model showcases its ability to provide reasoning and contextual information in the majority of responses. These results provide compelling evidence for the potential use of ChatGPT in medical education. © (2025), (Iran University of Medical Sciences). All rights reserved.",Yes,Sully,,,,,,,,,,
"Assessing ChatGPT’s Potential in HIV Prevention Communication: A Comprehensive Evaluation of Accuracy, Completeness, and Inclusivity","With the advancement of artificial intelligence(AI), platforms like ChatGPT have gained traction in different fields, including Medicine. This study aims to evaluate the potential of ChatGPT in addressing questions related to HIV prevention and to assess its accuracy, completeness, and inclusivity. A team consisting of 15 physicians, six members from HIV communities, and three experts in gender and queer studies designed an assessment of ChatGPT. Queries were categorized into five thematic groups: general HIV information, behaviors increasing HIV acquisition risk, HIV and pregnancy, HIV testing, and the prophylaxis use. A team of medical doctors was in charge of developing questions to be submitted to ChatGPT. The other members critically assessed the generated responses regarding level of expertise, accuracy, completeness, and inclusivity. The median accuracy score was 5.5 out of 6, with 88.4% of responses achieving a score ≥ 5. Completeness had a median of 3 out of 3, while the median for inclusivity was 2 out of 3. Some thematic groups, like behaviors associated with HIV transmission and prophylaxis, exhibited higher accuracy, indicating variable performance across different topics. Issues of inclusivity were identified, notably the use of outdated terms and a lack of representation for some communities. ChatGPT demonstrates significant potential in providing accurate information on HIV-related topics. However, while responses were often scientifically accurate, they sometimes lacked the socio-political context and inclusivity essential for effective health communication. This underlines the importance of aligning AI-driven platforms with contemporary health communication strategies and ensuring the balance of accuracy and inclusivity. © The Author(s) 2024.",No,Sully,,,,,,,,,,
Evaluating LLMs for Diagnosis Summarization,"During a patient's hospitalization, extensive information is documented in clinical notes. The efficient summarization of this information is vital for keeping healthcare professionals abreast of the patient's status. This paper proposes a methodology to assess the efficacy of six large language models (LLMs) in automating the task of diagnosis summarization, particularly in discharge summaries. Our approach involves defining an automatic metric based on LLMs, highly correlated with human assessments. We evaluate the performance of the six models using the F1-Score and compare the results with those of healthcare specialists. The experiments reveal that there is room for improvement in the medical knowledge and diagnostic capabilities of LLMs. The source code and data for these experiments are available on the project's GitHub page. © 2024 IEEE.",Yes,Sully,,,,,,,,,,
A large language model-based clinical decision support system for syncope recognition in the emergency department: A framework for clinical workflow integration,"Differentiation of syncope from transient loss of consciousness can be challenging in the emergency department (ED). Natural Language Processing (NLP) enables the analysis of free text in the electronic medical records (EMR). The present paper aimed to develop a large language models (LLM) for syncope recognition in the ED and proposed a framework for model integration within the clinical workflow. Two models, based on both the Italian and Multilingual Bidirectional Encoder Representations from Transformers (BERT) language model, were developed using consecutive EMRs. The “triage” model was only based on notes contained in the “triage” section of the EMR. The “anamnesis” model added data contained in the “medical history” section. Interpretation and calibration plots were generated. The Italian and Multi BERT models were developed and tested on both 15,098 and 15,222 EMRs, respectively. The triage model had an AUC of 0·95 for the Italian BERT and 0·94 for the Multi BERT. The anamnesis model had an AUC of 0·98 for the Italian BERT and 0·97 for Multi BERT. The LLM identified syncope when not explicitly mentioned in the EMR and also recognized common prodromal symptoms preceding syncope. Both models identified syncope patients in the ED with a high discriminative capability from nurses and doctors’ notes, thus potentially acting as a tool helping physicians to differentiate syncope from others transient loss of consciousness. © 2024",Yes,Pranav,,,,,,,,,,
Chat Generative Pretraining Transformer Answers Patient-focused Questions in Cervical Spine Surgery,"BACKGROUND: Artificial intelligence and its utilization to improve patient 
experience across medicine is seeing remarkable growth. One such usage is 
patient education. For the first time on a large scale, patients can ask 
targeted questions and receive similarly targeted answers. Although patients may 
use these resources to assist in decision-making, there still exists little data 
regarding their accuracy, especially within orthopedic surgery and more 
specifically spine surgery.
METHODS: We compiled 9 frequently asked questions cervical spine surgeons 
receive in the clinic to test ChatGPT's version 3.5 ability to answer a nuanced 
topic. Responses were reviewed by 2 independent reviewers on a Likert Scale for 
the accuracy of information presented (0-5 points), appropriateness in giving a 
specific answer (0-3 points), and readability for a layperson (0-2 points). 
Readability was assessed through the Flesh-Kincaid grade level analysis for the 
original prompt and for a second prompt asking for rephrasing at the sixth-grade 
reading level.
RESULTS: On average, ChatGPT's responses scored a 7.1/10. Accuracy was rated on 
average a 4.1/5. Appropriateness was 1.8/3. Readability was a 1.2/2. Readability 
was determined to be at the 13.5 grade level originally and at the 11.2 grade 
level after prompting.
CONCLUSIONS: ChatGPT has the capacity to be a powerful means for patients to 
gain important and specific information regarding their pathologies and surgical 
options. These responses are limited in their accuracy, and we, in addition, 
noted readability is not optimal for the average patient. Despite these 
limitations in ChatGPT's capability to answer these nuanced questions, the 
technology is impressive, and surgeons should be aware patients will likely 
increasingly rely on it.

Copyright © 2024 Wolters Kluwer Health, Inc. All rights reserved.",Yes,Pranav,,,,,,,,,,
ChatGPT and Clinical Questions on the Practical Guideline of Blepharoptosis: Reply,"In a recent Letter to the Editor authored by Daungsupawong et al. in Aesthetic Plastic Surgery, titled “ChatGPT and Clinical Questions on the Practical Guideline of Blepharoptosis: Correspondence,” the authors emphasized important points regarding the input language differences between input and output references. However, advanced versions, such as GPT-4, have shown marginal differences between English and Chinese inputs, possibly because of the use of larger training data. To address this issue, non-English-language-oriented large language models (LLMs) have been developed. The ability of LLMs to refer to existing references varies, with newer models, such as GPT-4, showing higher reference rates than GPT-3.5. Future research should focus on addressing the current limitations and enhancing the effectiveness of emerging LLMs in providing accurate and informative answers to medical questions across multiple languages. Level of Evidence V This journal requires that authors assign a level of evidence to each article. For a full description of these Evidence-Based Medicine ratings, please refer to the Table of Contents or the online Instructions to Authors www.springer.com/00266. © Springer Science+Business Media, LLC, part of Springer Nature and International Society of Aesthetic Plastic Surgery 2024.",No,Sully,,,,,,,,,,
Research Design Protocol: Assessing the Impact of Using ChatGPT in Radiology Reporting in an Emergency Setting in Egypt,"This research design protocol outlines a study conducted in Egypt as an example of a developing country with limited resources. The objective is to assess the impact of using ChatGPT, a language model, in radiology reporting in the context of an emergency setting where reporting is traditionally done manually. The study aims to evaluate the effectiveness of ChatGPT in helping format structured reports, drawing impressions from the reports, and improving the efficiency of communication between radiologists and treating clinicians. A standardized survey will be utilized to compare the differences between the older subjective reporting format and ChatGPT-assisted reports.",No,Sully,,,,,,,,,,
Prevalence of Words and Phrases Associated with Large Language Model-Generated Text in the Nursing Literature,"All disciplines, including nursing, may be experiencing significant changes with the advent of free, publicly available generative artificial intelligence tools. Recent research has shown the difficulty in distinguishing artificial intelligence-generated text from content that is written by humans, thereby increasing the probability for unverified information shared in scholarly works. The purpose of this study was to determine the extent of generative artificial intelligence usage in published nursing articles. The Dimensions database was used to collect articles with at least one appearance of words and phrases associated with generative artificial intelligence. These articles were then searched for words or phrases known to be disproportionately associated with large language model-based generative artificial intelligence. Several nouns, verbs, adverbs, and phrases had remarkable increases in appearance starting in 2023, suggesting use of generative artificial intelligence. Nurses, authors, reviewers, and editors will likely encounter generative artificial intelligence in their work. Although these sophisticated and emerging tools are promising, we must continue to work toward developing ways to verify accuracy of their content, develop policies that insist on transparent use, and safeguard consumers of the evidence they generate.  © Lippincott Williams & Wilkins.",No,Pranav,,,,,,,,,,
Detecting implicit biases of large language models with Bayesian hypothesis testing,"1054. Sci Rep. 2025 Apr 11;15(1):12415. doi: 10.1038/s41598-025-95825-x.

Detecting implicit biases of large language models with Bayesian hypothesis 
testing.

Si S(1), Jiang X(2)(3), Su Q(4)(5), Carin L(6).

Author information:
(1)School of Economics and Finance, Shanghai International Studies University, 
Shanghai, 201620, China.
(2)Institute of Language Sciences, Shanghai International Studies University, 
Shanghai, 201620, China. xiaoming.jiang@shisu.edu.cn.
(3)Key Laboratory of Language Sciences and Multilingual Intelligence 
Applications, Shanghai International Studies University, 201620, Shanghai, 
China. xiaoming.jiang@shisu.edu.cn.
(4)School of Computer Science and Engineering, Sun Yat-sen University, 
Guangzhou, 510006, China.
(5)Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, 
510006, China.
(6)Department of Electronic and Computer Engineering, Duke University, Durham, 
NC, 27705, USA.

Despite the remarkable performance of large language models (LLMs), such as 
generative pre-trained Transformers (GPTs), across various tasks, they often 
perpetuate social biases and stereotypes embedded in their training data. In 
this paper, we introduce a novel framework that reformulates bias detection in 
LLMs as a hypothesis testing problem, where the null hypothesis [Formula: see 
text] represents the absence of implicit bias. Our framework leverages 
binary-choice questions to measure social bias in both open-source and 
proprietary LLMs accessible via APIs. We demonstrate the flexibility of our 
approach by integrating classical statistical methods, such as the exact 
binomial test, with Bayesian inference using Bayes factors for bias detection 
and quantification. Extensive experiments are conducted on prominent models, 
including ChatGPT (GPT-3.5-Turbo), DeepSeek-V3, and Llama-3.1-70B, utilizing 
publicly available datasets such as BBQ, CrowS-Pairs (in both English and 
French), and Winogender. While the exact Binomial test fails to distinguish 
between no evidence of bias and evidence of no bias, our results underscore the 
advantages of Bayes factors, particularly their capacity to quantify evidence 
for both competing hypotheses and their robustness to small sample size. 
Additionally, our experiments reveal that the bias behavior of LLMs is largely 
consistent across the English and French versions of the CrowS-Pairs dataset, 
with subtle differences likely arising from variations in social norms across 
linguistic and cultural contexts.

© 2025. The Author(s).",No,Pranav,,,,,,,,,,
"The effectiveness of gabapentin and gabapentin/montelukast combination compared with dextromethorphan in the improvement of COVID-19- related cough: A randomized, controlled clinical trial","Introduction: Cough is one of the most common presenting symptoms of COVID-19, which can persist for weeks or months. Objective: The goal of this study was to evaluate the effectiveness of gabapentin (GBT) alone and in combination with montelukast (MTL) for improving cough. Methods: In this open-label randomized controlled clinical trial, eligible cases were patients hospitalized with moderate to severe COVID-19 who had cough with a Breathlessness, Cough, and Sputum Scale (BCSS) score of at least 2 based on its cough subscale. The participants were randomly assigned to three groups including two experimental groups and one control group. The first and second experimental groups received GBT and GBT/MTL, respectively, whereas the control group received dextromethorphan (DXM). Treatment duration was 5 days in all groups. Before and after the interventions, the severity of cough was evaluated using BCSS scale and Visual Analog Scale (VAS). Results: A total of 180 patients were included; GPT, GPT/MTL, and DXM consisted of 76, 51, and 53 patients, respectively. There was no significant difference between the three groups in terms of age, gender, and comorbidities (P > 0.05). Regarding BCSS and VAS scores, there was significant reduction from the baseline values in all groups (P < 0.0001), with the change rate being significantly higher in DXM group. The amount of reduction of BCSS in the GPT/MTL group was significantly more than the GPT group, whereas there was no significant difference between the two groups regarding VAS score. Although the duration of hospitalization differed between the groups with the GPT/MTL group having the shortest duration, the difference was statistically significant only between the GPT and GPT/MTL groups (P < 0.0001). Conclusion: GPT, both alone and in combination with MTL, improves cough frequency and severity in hospitalized patients with COVID-19, with the combination being more efficacious. This regimen may be useful in patients who cannot tolerate opioids. © 2022 The Authors. The Clinical Respiratory Journal published by John Wiley & Sons Ltd.",No,Pranav,,,,,,,,,,
Anti-tau single domain antibodies clear pathological tau and attenuate its toxicity and related functional defects,"3494. Cell Death Dis. 2024 Jul 30;15(7):543. doi: 10.1038/s41419-024-06927-9.

Anti-tau single domain antibodies clear pathological tau and attenuate its 
toxicity and related functional defects.

Nair S(1)(2), Jiang Y(1), Marchal IS(1)(2), Chernobelsky E(1)(2), Huang 
HW(1)(2), Suh S(2), Pan R(3), Kong XP(3), Ryoo HD(4), Sigurdsson EM(5)(6).

Author information:
(1)Department of Neuroscience and Physiology, Neuroscience Institute, New York 
University Grossman School of Medicine, New York, NY, USA.
(2)Department of Cell Biology, New York University Grossman School of Medicine, 
New York, NY, USA.
(3)Department of Biochemistry and Molecular Pharmacology, New York University 
Grossman School of Medicine, New York, NY, USA.
(4)Department of Cell Biology, New York University Grossman School of Medicine, 
New York, NY, USA. hyungdon.ryoo@nyulangone.org.
(5)Department of Neuroscience and Physiology, Neuroscience Institute, New York 
University Grossman School of Medicine, New York, NY, USA. 
einar.sigurdsson@nyulangone.org.
(6)Department of Psychiatry, New York University Grossman School of Medicine, 
New York, NY, USA. einar.sigurdsson@nyulangone.org.

Tauopathies are a group of neurodegenerative diseases characterized by the 
presence of tau inclusions. We have developed over fifty anti-tau single-domain 
antibodies (sdAbs) derived from phage display libraries of a llama immunized 
with recombinant and pathological tau immunogens. We examined the therapeutic 
potential of four of these sdAbs in a Drosophila tauopathy model following their 
transgenic expression either in all neurons or neuronal subtypes. Three of these 
sdAbs showed therapeutic potential in various assays, effectively clearing 
pathological tau and attenuating or preventing tau-induced phenotypes that 
typically manifest as defects in neuronal axonal transport, neurodegeneration, 
functional impairments, and shortened lifespan. Of these three, one sdAb was 
superior in every assay, which may at least in part be attributed to its 
tau-binding epitope. These findings support its development as a gene therapy 
for tauopathies.

© 2024. The Author(s).",No,Pranav,,,,,,,,,,
Large Language Models and Healthcare Alliance: Potential and Challenges of Two Representative Use Cases,"3587. Ann Biomed Eng. 2024 Aug;52(8):1928-1931. doi: 10.1007/s10439-024-03454-8. Epub 
2024 Feb 3.

Large Language Models and Healthcare Alliance: Potential and Challenges of Two 
Representative Use Cases.

García-Méndez S(#)(1), de Arriba-Pérez F(#)(2).

Author information:
(1)Information Technologies Group, atlanTTic, University of Vigo, Vigo, Spain.
(2)Information Technologies Group, atlanTTic, University of Vigo, Vigo, Spain. 
farriba@gti.uvigo.es.
(#)Contributed equally

Large language models (LLMS) emerge as the most promising Natural Language 
Processing approach for clinical practice acceleration (i.e., diagnosis, 
prevention and treatment procedures). Similarly, intelligent conversational 
systems that leverage LLMS have disruptively become the future of therapy in the 
era of ChatGPT. Accordingly, this research addresses the application of LLMS in 
healthcare, paying particular attention to two relevant use cases: cognitive 
decline and depression, more specifically, postpartum depression. In the end, 
the most promising opportunities they represent (e.g., clinical tasks 
augmentation, personalized healthcare, etc.) and related concerns (e.g., data 
privacy and quality, fairness, etc.) are discussed to contribute to the global 
debate on their integration in the sanitary system.

© 2024. The Author(s) under exclusive licence to Biomedical Engineering Society.",No,Pranav,Letter to the editor,,,,,,,,,
Analysis of responses from artificial intelligence programs to medication-related questions derived from critical care guidelines,"DISCLAIMER: In an effort to expedite the publication of articles, AJHP is posting manuscripts online as soon as possible after acceptance. Accepted manuscripts have been peer-reviewed and copyedited, but are posted online before technical formatting and author proofing. These manuscripts are not the final version of record and will be replaced with the final article (formatted per AJHP style and proofed by the authors) at a later time. PURPOSE: To evaluate the recommendations given by 4 publicly available artificial intelligence (AI) programs in comparison to recommendations in current clinical practice guidelines (CPGs) focused on critically ill adults. METHODS: This study evaluated 4 publicly available large language models (LLMs): ChatGPT 4.0, Microsoft Copilot Google Gemini Version 1.5, and Meta AI. Each AI chatbot was prompted with medication-related questions related to 6 CPGs published by the Society of Critical Care Medicine (SCCM) and also asked to provide references to support its recommendations. Responses were categorized as correct, partially correct, not correct, or ""other"" (eg, the LLM answered a question not asked). RESULTS: In total, 43 responses were recorded for each AI program, with a significant difference (P = 0.007) in response types by AI program. Microsoft Copilot had the highest proportion of correct recommendations, followed by Meta AI, ChatGPT 4.0, and Google Gemini. All 4 LLMs gave some incorrect recommendations, with Gemini having the most incorrect responses, followed closely by ChatGPT. Copilot had the most responses in the ""other"" category (n = 5, 11.63%). On average, ChatGPT provided the greatest number of references per question (n = 4.54), followed by Google Gemini (n = 3.43), Meta AI (n = 3.06), and Microsoft Copilot (n = 2.04). CONCLUSION: Although they showed potential for future utility to pharmacists with further development and refinement, the evaluated AI programs did not consistently give accurate medication-related recommendations for the purpose of answering clinical questions such as those pertaining to critical care CPGs.",Yes,Pranav,,,,,,,,,,
Applications of Artificial Intelligence in Neurosurgical Education: A Scoping Review,"Background: Artificial intelligence (AI) has revolutionized medical education due to its capacity to optimize instruction, assess competencies, and tailor learning. Given the interdisciplinary nature and transformative potential of AI, its integration into neurosurgical education merits thorough examination. Objective: To evaluate systematically the applications of AI in neurosurgical education. Methods: A scoping review was conducted in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews (PRISMA-ScR) guidelines. Original observational and experimental studies published in peer-reviewed journals that investigated the use of AI in neurosurgical education were included. The search was carried out in Scopus up to May 2024, and studies not written in English or Spanish were excluded. The selection process and data extraction were performed independently by two reviewers. A narrative synthesis approach was employed. Results: Twenty-three studies were selected, identifying four main areas. In board examination performance, advanced models like ChatGPT-4 outperformed previous versions and residents in answering neurosurgical exam questions, achieving higher accuracy in complex theoretical and image-based inquiries. In simulation training and tutoring, neural networks analyzed surgical simulation data, classifying participants by expertise levels and providing individualized, metric-based feedback that improved technical skills and identified distinct learning patterns among trainees. In performance evaluation, machine learning techniques assessed surgical skills during simulations with high accuracy, identifying key behavioral metrics associated with expertise. Other innovative applications included AI for neuroanatomical segmentation in imaging studies, analysis of surgical instrument utilization patterns through computer vision, and generation of academic content. These studies highlighted AI’s multifaceted roles and ethical considerations, such as overreliance risks and the need for robust databases and realistic simulations. Conclusions: AI has enhanced neurosurgical education by improving knowledge assessment, simulation training, and performance evaluation. Despite its transformative potential, ethical and technical challenges persist. The continuous development of AI models and their responsible implementation are recommended to further optimize neurosurgical training and ensure safe integration into educational curricula.",No,Pranav,Review,,,,,,,,,
Evaluation of a context-aware chatbot using retrieval-augmented generation for answering clinical questions on medication-related osteonecrosis of the jaw,"The potential of large language models (LLMs) in medical applications is significant, and Retrieval-augmented generation (RAG) can address the weaknesses of these models in terms of data transparency and scientific accuracy by incorporating current scientific knowledge into responses. In this study, RAG and GPT-4 by OpenAI were applied to develop GuideGPT, a context aware chatbot integrated with a knowledge database from 449 scientific publications designed to provide answers on the prevention, diagnosis, and treatment of medication-related osteonecrosis of the jaw (MRONJ). A comparison was made with a generic LLM (“PureGPT”) across 30 MRONJ-related questions. Ten international experts in MRONJ evaluated the responses based on content, language, scientific explanation, and agreement using 5-point Likert scales. Statistical analysis using the Mann–Whitney U test showed significantly better ratings for GuideGPT than PureGPT regarding content (p = 0.006), scientific explanation (p = 0.032), and agreement (p = 0.008), though not for language (p = 0.407). Thus, this study demonstrates RAG to be a promising tool to improve response quality and reliability of LLMs by incorporating domain-specific knowledge. This approach addresses the limitations of generic chatbots and can provide traceable and up-to-date responses essential for clinical practice. © 2024 The Authors",Yes,Pranav,,,,,,,,,,
What's the difference between human-written manuscripts versus ChatGPT-generated manuscripts involving “human touch”?,"Aim: To determine whether ChatGPT generates a manuscript with a “human touch” with appropriate inputs, and if yes, what's the difference between human writing versus ChatGPT writing. This is because the presence or absence of human touch may characterize human writing. Methods: A descriptive study. The first author wrote a Disagreement Letter (Letter 1). Then, disagreement points and “human touch” were provided as input into ChatGPT-4 and tasked with generating a Letter (Letter 2). The authors, seven experienced researchers, and ChatGPT evaluated the readability of Letters 1 and 2. Results: The authors, researchers, and ChatGPT, all reached the same conclusions: the human-written Letter 1 and the ChatGPT-generated Letter 2 had similar readability and similarly involved human touch. Some researchers and ChatGPT recognized slight differences in formal or informal and personal or nonpersonal tones between them, which they considered may not affect paper acceptance. Conclusions: Human touch is not humans' exclusive possession. The distinction between the human writing versus ChatGPT writing is considered to be present not in the output (manuscript) but in the process of writing, that is, the presence or absence of a joy of writing. Artificial intelligence should aid in enhancing, or at the very least, not impede the human joy. This discussion deserves ongoing exploration. © 2025 Japan Society of Obstetrics and Gynecology.",No,Pranav,,,,,,,,,,
Development of a Universal Prompt as a Scalable Generative AI-Assisted Tool for USMLE Step 1 Style Multiple-Choice Question Refinement in Medical Education,"We developed a generative artificial intelligence (genAI)-assisted tool enabling learners to receive feedback on, revise, and clone multiple-choice questions aligned with learning objectives. Initially designed as a custom GPT, we adapted it to a universal prompt for platform-agnostic, equitable access. This innovation exemplifies readily adaptable genAI-enhanced learning driven by pedagogy. © The Author(s) 2025.",No,Pranav,,,,,,,,,,
Detection of Experimental Colorectal Peritoneal Metastases by a Novel PDGFRβ-Targeting Nanobody,"Peritoneal metastases in colorectal cancer (CRC) belong to Consensus Molecular Subtype 4 (CMS4) and are associated with poor prognosis. Conventional imaging modalities, such as Computed Tomography (CT) and Fluorodeoxyglucose-Positron Emission Tomography (FDG-PET), perform very poorly in the detection of peritoneal metastases. However, the stroma-rich nature of these lesions provides a basis for developing molecular imaging strategies. In this study, conducted from 2019 to 2021, we aimed to generate a Platelet-Derived Growth Factor Receptor beta (PDGFRB)-binding molecular imaging tracer for the detection of CMS4 CRC, including peritoneal metastases. The expression of PDGFRB mRNA discriminated CMS4 from CMS1-3 (AUROC = 0.86 (95% CI 0.85–0.88)) and was associated with poor relapse-free survival. PDGFRB mRNA and protein levels were very high in all human peritoneal metastases examined (n = 66). Therefore, we generated a PDGFRB-targeting llama nanobody (VHH1E12). Biotin-labelled VHH1E12 bound to immobilized human and mouse PDGFRB with high affinity (EC50 human PDGFRB = 7 nM; EC50 murine PDGFRB = 0.8 nM), and to PDGFRB-expressing HEK293 cells grown in vitro. A pharmacokinetic analysis of IRDye-800CW-conjugated VHH1E12 in mice showed that the plasma half-life was 6 min. IRDye-800CW-conjugated VHH1E12 specifically accumulated in experimentally induced colorectal cancer peritoneal metastases in mice. A tissue analysis subsequently demonstrated co-localization of the nanobody with PDGFRB expression in the tumour stroma. Our results demonstrate the potential value of PDGFRB-targeted molecular imaging as a novel strategy for the non-invasive detection of CMS4 CRC, in particular, peritoneal metastases. © 2022 by the authors.",No,Pranav,,,,,,,,,,
"Development and validation of a HPLC method for the determination of chemical and radiochemical purity of O-(2-[(18)F]fluoroethyl-l-tyrosine ([(18)F]FET)), a PET radiotracer for the imaging of brain tumor","3870. Appl Radiat Isot. 2024 Oct;212:111444. doi: 10.1016/j.apradiso.2024.111444. Epub 
2024 Jul 10.

Development and validation of a HPLC method for the determination of chemical 
and radiochemical purity of O-(2-[(18)F]fluoroethyl-l-tyrosine ([(18)F]FET)), a 
PET radiotracer for the imaging of brain tumor.

Wang M(1), Arkins CA(2), Zheng QH(2), Glick-Wilson B(2), Snyder S(2).

Author information:
(1)Molecular Imaging Ligand Development Program, Department of Radiology and 
Imaging Sciences, Indiana University School of Medicine, Indianapolis, IN, USA. 
Electronic address: wang1@iu.edu.
(2)Molecular Imaging Ligand Development Program, Department of Radiology and 
Imaging Sciences, Indiana University School of Medicine, Indianapolis, IN, USA.

A novel HPLC method was developed and validated to determine radiochemical 
identity, radiochemical purity and chemical purity for the analysis of 
O-(2-[18F]fluoroethyl-l-tyrosine ([18F]FET). In this method, an analytical 
Phenomenex Gemini C18 column was used with an isocratic eluent of 7 % ethanol 
and 93 % 50 mM potassium phosphate buffer (pH = 6.9). The flow rate was 
1.0 mL/min and the injection volume was 10 μL. A photo-diode array detector set 
at 220 nm was used for UV mass detection and a single channel, high sensitivity 
radiation detector was used. The method validation assays including specificity, 
linearity, precision, accuracy, and robustness were evaluated. Results show that 
the method was suitable for qualitative and quantitative determination of 
radiochemical and chemical purity of [18F]FET. This system has been routinely 
used for the analysis of more than 120 batches of [18F]FET with radiochemical 
yield 23.7 ± 6 % (no decay corrected) and molar activity 593 ± 284 GBq/μmole in 
our facility to support human use.

Copyright © 2024 Elsevier Ltd. All rights reserved.",No,Pranav,,,,,,,,,,
Artificial Intelligence in Dental Education: Opportunities and Challenges of Large Language Models and Multimodal Foundation Models,"174. JMIR Med Educ. 2024 Sep 27;10:e52346. doi: 10.2196/52346.

Artificial Intelligence in Dental Education: Opportunities and Challenges of 
Large Language Models and Multimodal Foundation Models.

Claman D(1), Sezgin E(2)(3).

Author information:
(1)Pediatric Dentistry, Nationwide Children's Hospital, Columbus, OH, United 
States.
(2)Department of Pediatrics, The Ohio State University College of Medicine, 
Columbus, OH, United States.
(3)Center for Biobehavioral Health, The Abigail Wexner Research Institute at 
Nationwide Children's Hospital, 700, Children's Drive, Columbus, OH, 43205, 
United States, 1 6147223179.

Instructional and clinical technologies have been transforming dental education. 
With the emergence of artificial intelligence (AI), the opportunities of using 
AI in education has increased. With the recent advancement of generative AI, 
large language models (LLMs) and foundation models gained attention with their 
capabilities in natural language understanding and generation as well as 
combining multiple types of data, such as text, images, and audio. A common 
example has been ChatGPT, which is based on a powerful LLM-the GPT model. This 
paper discusses the potential benefits and challenges of incorporating LLMs in 
dental education, focusing on periodontal charting with a use case to outline 
capabilities of LLMs. LLMs can provide personalized feedback, generate case 
scenarios, and create educational content to contribute to the quality of dental 
education. However, challenges, limitations, and risks exist, including bias and 
inaccuracy in the content created, privacy and security concerns, and the risk 
of overreliance. With guidance and oversight, and by effectively and ethically 
integrating LLMs, dental education can incorporate engaging and personalized 
learning experiences for students toward readiness for real-life clinical 
practice.

© Daniel Claman, Emre Sezgin. Originally published in JMIR Medical Education 
(https://mededu.jmir.org).",No,Pranav,Opinion style piece wo primary results,,,,,,,,,
Developing an AI-Assisted Educational Chatbot for Radiotherapy Using the IBM Watson Assistant Platform,"Objectives: This study aims to make radiotherapy knowledge regarding healthcare accessible to the general public by developing an AI-powered chatbot. The interactive nature of the chatbot is expected to facilitate better understanding of information on radiotherapy through communication with users. Methods: Using the IBM Watson Assistant platform on IBM Cloud, the chatbot was constructed following a pre-designed flowchart that outlines the conversation flow. This approach ensured the development of the chatbot with a clear mindset and allowed for effective tracking of the conversation. The chatbot is equipped to furnish users with information and quizzes on radiotherapy to assess their understanding of the subject. Results: By adopting a question-and-answer approach, the chatbot can engage in human-like communication with users seeking information about radiotherapy. As some users may feel anxious and struggle to articulate their queries, the chatbot is designed to be user-friendly and reassuring, providing a list of questions for the user to choose from. Feedback on the chatbot’s content was mostly positive, despite a few limitations. The chatbot performed well and successfully conveyed knowledge as intended. Conclusions: There is a need to enhance the chatbot’s conversation approach to improve user interaction. Including translation capabilities to cater to individuals with different first languages would also be advantageous. Lastly, the newly launched ChatGPT could potentially be developed into a medical chatbot to facilitate knowledge transfer. © 2023 by the authors.",No,Sully,,,,,,,,,,
Implementation of Naive Bayes classification algorithm for Twitter user sentiment analysis on ChatGPT using Python programming language; [Implementación del algoritmo de clasificación Naive Bayes para el análisis del sentimiento de los usuarios de Twitter en ChatGPT utilizando el lenguaje de programación Python],"ChatGPT (Generative Pre-Trained Transformer) is a chatbot that is being widely used by the public. This technology is based on Artificial Intelligence and is capable of having conversational interactions with its users just like humans, but in the form of automated text. Because of this capability, online forums such as Brainly and the like can be overtaken by these smart chatbots. Therefore, this study was conducted to determine the positive and negative sentiments towards ChatGPT using Naive Bayes Classification algorithm on 5000 Twitter users. Data was collected by scraping technique and Python programming language was used in data analysis. The results showed that the majority of Twitter users had a positive sentiment of 57,6 % towards ChatGPT, while the negative sentiment reached 42,4 %. The resulting classification model had an accuracy of 80 %, indicating a good classification model in determining sentiment probabilities. These findings provide a basis for the development of better AI chatbot technology that can meet user needs. The results of this study provide insights into user sentiment towards ChatGPT and can be used as a reference for future AI chatbot development. © Este es un artículo en acceso abierto.",No,Pranav,,,,,,,,,,
"""MoSpec"": A customized and integrated system for model development, verification and validation","BACKGROUND AND OBJECTIVE: The growing availability of patient data from several 
clinical settings, fueled by advanced analysis systems and new diagnostics, 
presents a unique opportunity. These data can be used to understand disease 
progression and predict future outcomes. However, analysing this vast amount of 
data requires collaboration between physicians and experts from diverse fields 
like mathematics and engineering.
METHODS: Mathematical models play a crucial role in interpreting patient data 
and enable in-silico simulations for diagnosis and treatment. To facilitate the 
creation and sharing of such models, the CNR-IASI BioMatLab group developed the 
""Gemini"" (MoSpec/Autocoder) system, a framework allowing researchers with basic 
mathematical knowledge to quickly and correctly translate biological problems 
into Ordinary Differential Equations models. The system facilitates the 
development and computation of mathematical models for the interpretation of 
medical and biological phenomena, also using data from the clinical setting or 
laboratory experiments for parameter estimation.
RESULTS: Gemini automatically generates code in multiple languages (C++, Matlab, 
R, and Julia) and automatically creates documentation, including code, figures, 
and visualizations.
CONCLUSIONS: This user-friendly approach promotes model sharing and 
collaboration among researchers, besides vastly increasing group productivity.

Copyright: © 2025 Pompa et al. This is an open access article distributed under 
the terms of the Creative Commons Attribution License, which permits 
unrestricted use, distribution, and reproduction in any medium, provided the 
original author and source are credited.",No,Pranav,,,,,,,,,,
Perspectives on AI-based recommendations for mask-wearing and COVID-19 vaccination for transplant recipients in the post-COVID-19 era,"3558. Ren Fail. 2024 Dec;46(1):2337291. doi: 10.1080/0886022X.2024.2337291. Epub 2024 
Apr 7.

Perspectives on AI-based recommendations for mask-wearing and COVID-19 
vaccination for transplant recipients in the post-COVID-19 era.

Garcia Valencia OA(1), Thongprayoon C(1), Miao J(1), Bruminhent J(2)(3), Craici 
IM(1), Cheungpasitporn W(1).

Author information:
(1)Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
Rochester, MN, USA.
(2)Department of Medicine, Division of Infectious Diseases, Faculty of Medicine 
Ramathibodi Hospital, Mahidol University, Bangkok, Thailand.
(3)Ramathibodi Excellence Center for Organ Transplantation, Faculty of Medicine 
Ramathibodi Hospital, Mahidol University, Bangkok, Thailand.

In the aftermath of the COVID-19 pandemic, the ongoing necessity for preventive 
measures such as mask-wearing and vaccination remains particularly critical for 
organ transplant recipients, a group highly susceptible to infections due to 
immunosuppressive therapy. Given that many individuals nowadays increasingly 
utilize Artificial Intelligence (AI), understanding AI perspectives is 
important. Thus, this study utilizes AI, specifically ChatGPT 4.0, to assess its 
perspectives in offering precise health recommendations for mask-wearing and 
COVID-19 vaccination tailored to this vulnerable population. Through a series of 
scenarios reflecting diverse environmental settings and health statuses in 
December 2023, we evaluated the AI's responses to gauge its precision, 
adaptability, and potential biases in advising high-risk patient groups. Our 
findings reveal that ChatGPT 4.0 consistently recommends mask-wearing in crowded 
and indoor environments for transplant recipients, underscoring their elevated 
risk. In contrast, for settings with fewer transmission risks, such as outdoor 
areas where social distancing is possible, the AI suggests that mask-wearing 
might be less imperative. Regarding vaccination guidance, the AI strongly 
advocates for the COVID-19 vaccine across most scenarios for kidney transplant 
recipients. However, it recommends a personalized consultation with healthcare 
providers in cases where patients express concerns about vaccine-related side 
effects, demonstrating an ability to adapt recommendations based on individual 
health considerations. While this study provides valuable insights into the 
current AI perspective on these important topics, it is crucial to note that the 
findings do not directly reflect or influence health policy. Nevertheless, given 
the increasing utilization of AI in various domains, understanding AI's 
viewpoints on such critical matters is essential for informed decision-making 
and future research.",Yes,Daniel,Weak include. Probe of an LLM to provide clinically relevant recommendations. Would be a strong include if it use more clinical context like patient questions for the probe.,,,,,,,,,
ChatGPT has entered the classroom: how LLMs could transform education,"2722. Nature. 2023 Nov;623(7987):474-477. doi: 10.1038/d41586-023-03507-3.

ChatGPT has entered the classroom: how LLMs could transform education.

Extance A.",No,Pranav,,,,,,,,,,
A comparative study on the knowledge levels of artificial intelligence programs in diagnosing ophthalmic pathologies and intraocular tumors evaluated their superiority and potential utility,"Purpose: This study aimed to test the knowledge levels of ChatGPT, Bing, and Bard artificial intelligence chatbots, which have been released by three different manufacturers, about ophthalmic pathologies and intraocular tumors, to test their usability and to investigate the presence of superiority to each other. Methods: Thirty-six questions were obtained from the American Academy and Ophthalmology 2022–2023 Basic and Clinical Science Course Ophthalmic Pathology and Intraocular Tumor study questions section. Each question was asked separately for the ChatGPT, Bing, and Bard artificial intelligence programs. Answers to the questions were categorized as correct or incorrect. The statistical relationship between the correct and incorrect response rates of the artificial intelligence programs was determined. Results: From the artificial intelligence chatbots, ChatGPT gave the correct answer to 58.6% of the questions asked, Bing gave the correct answer to 63.9%, and Bard gave the correct answer to 69.4%. No statistical significance was found between the rates of correct answers to the questions in all 3 artificial intelligence programs (p = 0.705, Pearson Chi-square test). Conclusion: Artificial intelligence chatbots can be used to access information related to ophthalmic pathologies and intraocular tumors. However, in the evaluation of the data, it should be noted that not all questions can be answered correctly. Care should be taken when examining the answers. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.",Yes,Pranav,,,,,,,,,,
Implications of ChatGPT for cytopathology and recommendations for updating JASC guidelines on the responsible use of artificial intelligence,"2713. J Am Soc Cytopathol. 2023 Nov-Dec;12(6):389-394. doi: 
10.1016/j.jasc.2023.07.001. Epub 2023 Jul 7.

Implications of ChatGPT for cytopathology and recommendations for updating JASC 
guidelines on the responsible use of artificial intelligence.

Pantanowitz J(1), Pantanowitz L(2).

Author information:
(1)Department of Pathology, University of Pittsburgh, Pittsburgh, Pennsylvania, 
USA.
(2)Department of Pathology, University of Pittsburgh, Pittsburgh, Pennsylvania, 
USA. Electronic address: LIRON@pitt.edu.",No,Pranav,Editorial,,,,,,,,,
"ChatGPT, obstructive sleep apnea, and patient education","2761. J Clin Sleep Med. 2023 Dec 1;19(12):2133. doi: 10.5664/jcsm.10768.

ChatGPT, obstructive sleep apnea, and patient education.

Kleebayoon A(1), Wiwanitkit V(2)(3).

Author information:
(1)Private Academic Consultant, Samraong, Cambodia.
(2)Chandigarh University, Punjab, India.
(3)Joesph Ayobabalola University, Ikeji-Arakeji, Nigeria.

Comment in
    J Clin Sleep Med. 2023 Dec 1;19(12):2135-2136. doi: 10.5664/jcsm.10808.",No,Pranav,Letter,,,,,,,,,
Implementation and evaluation of an additional GPT-4-based reviewer in PRISMA-based medical systematic literature reviews,"Background: PRISMA-based literature reviews require meticulous scrutiny of extensive textual data by multiple reviewers, which is associated with considerable human effort. Objective: To evaluate feasibility and reliability of using GPT-4 API as a complementary reviewer in systematic literature reviews based on the PRISMA framework. Methodology: A systematic literature review on the role of natural language processing and Large Language Models (LLMs) in automatic patient-trial matching was conducted using human reviewers and an AI-based reviewer (GPT-4 API). A RAG methodology with LangChain integration was used to process full-text articles. Agreement levels between two human reviewers and GPT-4 API for abstract screening and between a single reviewer and GPT-4 API for full-text parameter extraction were evaluated. Results: An almost perfect GPT–human reviewer agreement in the abstract screening process (Cohen's kappa > 0.9) and a lower agreement in the full-text parameter extraction were observed. Conclusion: As GPT-4 has performed on a par with human reviewers in abstract screening, we conclude that GPT-4 has an exciting potential of being used as a main screening tool for systematic literature reviews, replacing at least one of the human reviewers. © 2024 The Author(s)",No,Pranav,Seems like a good article to review given it's similarity to our own paper's goals,,,,,,,,,
ProtoCode: Leveraging large language models (LLMs) for automated generation of machine-readable PCR protocols from scientific publications,"3539. SLAS Technol. 2024 Jun;29(3):100134. doi: 10.1016/j.slast.2024.100134. Epub 2024 
Apr 24.

ProtoCode: Leveraging large language models (LLMs) for automated generation of 
machine-readable PCR protocols from scientific publications.

Jiang S(1), Evans-Yamamoto D(2), Bersenev D(1), Palaniappan SK(3), 
Yachie-Kinoshita A(4).

Author information:
(1)SBX BioSciences, Inc. 1600 - 925 West Georgia Street, Vancouver, BC, V6C 3L2, 
Canada.
(2)The Systems Biology Institute, Saisei Ikedayama Bldg., 5-10-25, Higashi 
Gotanda, Shinagawa-ku, Tokyo, 141-0022, Japan.
(3)The Systems Biology Institute, Saisei Ikedayama Bldg., 5-10-25, Higashi 
Gotanda, Shinagawa-ku, Tokyo, 141-0022, Japan. Electronic address: 
sucheendra@sbi.jp.
(4)SBX BioSciences, Inc. 1600 - 925 West Georgia Street, Vancouver, BC, V6C 3L2, 
Canada; The Systems Biology Institute, Saisei Ikedayama Bldg., 5-10-25, Higashi 
Gotanda, Shinagawa-ku, Tokyo, 141-0022, Japan. Electronic address: 
yachie@sbx-biosci.com.

Protocol standardization and sharing are crucial for reproducibility in life 
sciences. In spite of numerous efforts for standardized protocol description, 
adherence to these standards in literature remains largely inconsistent. 
Curation of protocols are especially challenging due to the labor intensive 
process, requiring expert domain knowledge of each experimental procedure. 
Recent advancements in Large Language Models (LLMs) offer a promising solution 
to interpret and curate knowledge from complex scientific literature. In this 
work, we develop ProtoCode, a tool leveraging fine-tune LLMs to curate protocols 
into intermediate representation formats which can be interpretable by both 
human and machine interfaces. Our proof-of-concept, focused on polymerase chain 
reaction (PCR) protocols, retrieves information from PCR protocols at an 
accuracy ranging 69-100 % depending on the information content. In all tested 
protocols, we demonstrate that ProtoCode successfully converts literature-based 
protocols into correct operational files for multiple thermal cycler systems. In 
conclusion, ProtoCode can alleviate labor intensive curation and standardization 
of life science protocols to enhance research reproducibility by providing a 
reliable, automated means to process and standardize protocols. ProtoCode is 
freely available as a web server at https://curation.taxila.io/ProtoCode/.

Copyright © 2024 The Author(s). Published by Elsevier Inc. All rights reserved.",No,Pranav,,,,,,,,,,
Large language models outperform mental and medical health care professionals in identifying obsessive-compulsive disorder,"Despite the promising capacity of large language model (LLM)-powered chatbots to diagnose diseases, they have not been tested for obsessive-compulsive disorder (OCD). We assessed the diagnostic accuracy of LLMs in OCD using vignettes and found that LLMs outperformed medical and mental health professionals. This highlights the potential benefit of LLMs in assisting in the timely and accurate diagnosis of OCD, which usually entails a long delay in diagnosis and treatment. © The Author(s) 2024.",Yes,Pranav,,,,,,,,,,
Retinal Imaging Analysis Performed By ChatGPT-4o And Gemini Advanced: The Turning Point Of The Revolution?,"Purpose: To assess the diagnostic capabilities of the most recent chatbots releases, GPT-4o and Gemini Advanced, facing different retinal diseases. Methods: Exploratory analysis on 50 cases with different surgical (n=27) and medical (n=23) retinal pathologies, whose optical coherence tomography/angiography (OCT/OCTA) scans were dragged into ChatGPT and Gemini's interfaces. Then, we asked ""Please describe this image""and classified the diagnosis as: 1) Correct; 2) Partially correct; 3) Wrong; 4) Unable to assess exam type and 5) Diagnosis not given. Results: ChatGPT indicated the correct diagnosis in 31/50 cases (62%), significantly higher than Gemini Advanced 16/50 cases (p=0.0048). In 24% of cases, Gemini Advanced was not able to produce any answer, stating ""That's not something I'm able to do yet"". For both, primary misdiagnosis was macular edema, given erroneously in 16% and 14% of cases, respectively. ChatGPT-4o showed higher rates of correct diagnoses either in surgical (52% vs 30%) and medical retina (78% vs 43%). Notably, when presented without the corresponding structural image, in any case Gemini was able to recognize OCTA scans, confusing images for artworks. Conclusion: ChatGPT-4o outperformed Gemini Advanced in terms of diagnostic accuracy facing OCT/OCTA images, even if the range of diagnoses is still limited. Copyright © 2024 The Author(s). Published by Wolters Kluwer Health, Inc. on behalf of the Opthalmic Communications Society, Inc.",Yes,Pranav,,,,,,,,,,
Introducing AI as members of script concordance test expert reference panel: A comparative analysis,"BACKGROUND: The Script Concordance Test (SCT) is increasingly used in professional development to assess clinical reasoning, with linear progression in SCT performance observed as clinical experience increases. One challenge in implementing SCT is the potential burnout of expert reference panel (ERP) members. To address this, we introduced ChatGPT as panel members. The aim was to enhance the efficiency of SCT creation while maintaining educational content quality and to explore the effectiveness of different models as reference panels. METHODOLOGY: A quasi-experimental comparative design was employed, involving all undergraduate medical students and faculty members enrolled in the Ophthalmology clerkship. Two groups involved Traditional ERP which consisted of 15 experts, diversified in clinical experience: 5 senior residents, 5 lecturers, and 5 professors and AI-Generated ERP which is a panel generated using ChatGPT and o1 preview, designed to mirror diverse clinical opinions based on varying experience levels. RESULTS: Experts consistently achieved the highest mean scores across most vignettes, with ChatGPT-4 and o1 scores generally slightly lower. Notably, the o1 mean scores were closer to those of experts compared to ChatGPT-4. Significant differences were observed between ChatGPT-4 and o1 scores in certain vignettes. These values indicate a strong level of consistency, suggesting that both experts and AI models provided highly reliable ratings. CONCLUSION: These findings suggest that while AI models cannot replace human experts, they can be effectively used to train students, enhance reasoning skills, and help narrow the gap between student and expert performance.",No,Pranav,,,,,,,,,,
"72nd Southwestern Surgical Congress Claude H. Organ, Jr. memorial lecture: Rise of acute care robotic surgery for common emergency general surgery conditions","Dr. Claude Organ rose above poverty, racism, and untold insurmountable odds to become a masterful surgeon and revered leader in numerous academic and professional circles. But it's his impact on surgical education and his philosophy to “teach, give back, and keep advancing” that inspired this lecture. Acute care robotic surgery (ACRS) utilizes the strengths of robotic assisted laparoscopic surgery (RALS) for a high-volume population of emergency general surgery (EGS) patients. The future benefits of ACRS may include improvements in resident training, patient safety, and outcomes. General surgery residencies that have a robust ACRS program are likely to be more competitive than those without. © 2021",No,Pranav,,,,,,,,,,
Improving the Quality of Unstructured Cancer Data Using Large Language Models: A German Oncological Case Study,"With cancer being a leading cause of death globally, epidemiological and clinical cancer registration is paramount for enhancing oncological care and facilitating scientific research. However, the heterogeneous landscape of medical data presents significant challenges to the current manual process of tumor documentation. This paper explores the potential of Large Language Models (LLMs) for transforming unstructured medical reports into the structured format mandated by the German Basic Oncology Dataset. Our findings indicate that integrating LLMs into existing hospital data management systems or cancer registries can significantly enhance the quality and completeness of cancer data collection - a vital component for diagnosing and treating cancer and improving the effectiveness and benefits of therapies. This work contributes to the broader discussion on the potential of artificial intelligence or LLMs to revolutionize medical data processing and reporting in general and cancer care in particular. © 2024 The Authors.",No,Pranav,,,,,,,,,,
TCMRD-KG: Design and Development of a Rheumatism Knowledge Graph Based on Ancient Chinese Literature,"The use of Traditional Chinese medicineTCM in rheumatic diseases dates back to thousands of years ago. Compared with standardized treatment, TCM has the advantages of low cost, low side effects, and flexible medication. Ancient books of traditional Chinese medicine play an important role in clinical and scientific research. This study takes the content related to rheumatism in ancient books of traditional Chinese medicine as the research object, integrates the ontology theory and technology in the knowledge graph, realizes the reconstruction of traditional Chinese medicine information knowledge, and provides basic data structure for data mining and knowledge discovery. This study is the first rheumatism-specific knowledge graph constructed based on ancient books of traditional Chinese medicine; it has tried the construction method of knowledge graph of ancient books of traditional Chinese medicine by combining automatic labeling of mainstream large language models with manual review; and according to the knowledge characteristics of ancient books of traditional Chinese medicine, the existing word segmentation technology is difficult to accurately reproduce the accurate meaning of the original text of ancient books, a new type of entity extraction method is given.  © 2024 IEEE.",No,Sully,,,,,,,,,,
Pressure to Plagiarize and the Choice to Cheat: Toward a Pragmatic Reframing of the Ethics of Academic Integrity,"In light of the burgeoning influence of LLM AI programs like ChatGPT in a variety of academic contexts and the COVID-19 pandemic’s expansion of virtual classrooms and coursework, the philosophical framing of academic integrity and plagiarism is being re-examined. In concert with these technological changes, students are also facing increasing pressure to succeed in their academic pursuits. Inasmuch as the consequences of failure in these contexts are often dire academically, socially, and financially, we argue that students often weigh the choice to plagiarize not as an ethical issue but as a pragmatic mitigation of risk. Using three salient examples of plagiarism and cheating from higher education in North America as case studies, we explore the pressures and contexts that have influenced the choice to engage in plagiarism and cheating through this pragmatic lens. As an ethical framing of the issue of academic integrity has been less effective in ameliorating plagiarism in this pressurized climate, we propose a way in which educators, administrators and policy makers might approach the issue in this same pragmatic frame. In short, rather than combat plagiarism by teaching its moral repugnance, we propose educators could argue instead that plagiarism and cheating are pragmatically untenable simply because they are detrimental to learning. © 2024 by the authors.",No,Sully,,,,,,,,,,
Dear ChatGPT - Can you teach me how to program an app for laboratory medicine?,"Objectives: The multifaceted potential of ChatGPT in the medical domain remains underexplored, particularly regarding its application in software development by individuals with a medical background but limited information technology expertise. Methods: This study investigates ChatGPT's utility in creating a laboratory medicine application. Results: Despite minimal programming skills, the authors successfully developed an automated intra-assay, inter-device precision test for immunophenotyping with a shiny user interface, facilitated by ChatGPT. While the coding process was expedited, meticulous oversight and error correction by the authors were imperative. Conclusions: These findings highlight the value of large language models such as ChatGPT in code-based application development for automating work processes in a medical context. Particularly noteworthy is the facilitation of these tasks for non-technically trained medical professionals and its potential for digital medical education. © 2024 the author(s).",No,Sully,,,,,,,,,,
Can AI chatbots accurately answer patient questions regarding vasectomies?,"Artificial Intelligence (AI) has revolutionized the healthcare industry. There have been limited studies assessing AI model efficacy and accuracy in urology. To our knowledge, there is a lack in research looking at one of the most common urological procedures: the vasectomy. Ten frequently asked questions regarding vasectomies were individually entered into three different AI sources (ChatGPT, Bard & Bing) using free interfaces available to consumers. The responses were critically analyzed by three urologists and graded on a scale of 1 to 4 for clarity, accuracy, and evidence-based information, with 1 being the best and 4 being the worst. ChatGPT had the best average rating per question at 1.367, followed by Bard at 2.167 and Bing at 1.800(p = 0.000083). ChatGPT was found to provide significantly more satisfactory answers than both Bard (p = 0.00005) and Bing (p = 0.03988). The difference between Bard and Bing however was found to be insignificant (p = 0.09651). Overall, our study shows that AI Chatbots may provide mostly accurate information on frequently asked questions regarding vasectomies and is a reasonable resource for patients interested in the procedure to use. ChatGPT is the most accurate and concise of the chatbots assessed. © The Author(s), under exclusive licence to Springer Nature Limited 2024.",Yes,Sully,,,,,,,,,,
The Role of AI-Assisted Learning in Academic Writing: A Mixed-Methods Study on Chinese as a Second Language Students,"This mixed-methods study examines the role of artificial intelligence (AI)-assisted learning in academic writing for Chinese as a Second Language (CSL) students in a Chinese university context. Fifty international CSL students were randomly assigned to experimental—AI-assisted learning using ChatGPT—and control—traditional learning—groups. Writing samples from the participants were evaluated using established scoring rubrics for Chinese academic writing. Based on pre- and post-test quantitative data and supplementary qualitative interviews with six participants from the experimental group, this study reveals that AI-assisted learning can enhance student outcome by supporting knowledge acquisition, helping to create a supportive learning environment, and increasing student motivation. However, this study also highlights concerns regarding over-reliance on AI, particularly in relation to ethical concerns, technical and networking issues, and the unreliability of AI-generated content. These findings contribute to a nuanced understanding of the impact of AI on CSL learners’ academic writing performance. Finally, we also discuss practical implications for educational stakeholders regarding the integration of AI into language education. © 2025 by the authors.",No,Sully,,,,,,,,,,
Frail Older Adults' Needs and Preferences for Mobile Health Exercise Interventions Guided by Nudge Theory: AQualitative Analysis,"Aim: To explore frail older adults' preferences and needs regarding mobile health (mHealth) exercise interventions in China. Additionally, it sought to identify the nudge strategies necessary for initiating and sustaining exercise behaviours among frail older adults. Design: A qualitative study. Method: The semi-structured interviews were conducted between April and May 2024 from two communities in Changsha, China. The data were analysed using a deductive framework analysis aligned to nudge theory, and an inductive thematic analysis to gather relevant needs and preferences. Results: This study involved 14 participants with pre-frailty or frailty, aged 60–82 years (median age of 64 years). While participants were generally receptive to new technologies, lower levels of health literacy and competing priorities often hindered their participation. Three primary functionality requirements were as follows. (1) Profession engagement: tailored exercise prescription, professional and timely feedback and guidance; (2) personalised knowledge encompassing pain management, successful cases and inspiration; (3) beneficial, tailored, dynamic, fragmented, challenging exercise courses. Participants showed positive attitudes towards simplification nudges, gamification nudges, social nudges, trustworthy nudges, reminder nudges, economic nudges, feedback nudges and pre-commitment nudges. Addressing privacy concerns was essential to build trust and acceptance among older adults. Conclusion: These findings emphasised the importance of designing mHealth interventions that address frail older adults' specific needs and preferences while incorporating effective nudge strategies to promote engagement and adherence. Future researchers should explore wearables, ChatGPT language models, virtual coaching assistants, exercise snack to further optimise the experience and analyse the effects of nudges in mHealth exercise interventions among older adults. Implication for the Profession and/or Patient Care: Exercise systems or app development for frail older adults should meet three basic functionality and essential nudge strategies. Reporting Method: The consolidated criteria for reporting qualitative research (COREQ) guidelines were used for reporting. Patient or Public Contribution: Older adults' engagement and interview data contribute a lot. © 2024 John Wiley & Sons Ltd.",No,Sully,,,,,,,,,,
Transforming dentistry with ChatGPT: A guide to optimizing patient care,"2398. J Am Dent Assoc. 2024 Apr;155(4):273-274. doi: 10.1016/j.adaj.2023.06.003. Epub 
2023 Jul 21.

Transforming dentistry with ChatGPT: A guide to optimizing patient care.

Tussie C.",No,Sully,,,,,,,,,,
Predicting the Length of Stay in Neurosurgery with RuGPT-3 Language Model,"In this study, we update the evaluation of the Russian GPT3 model presented in our previous paper in predicting the length of stay (LOS) in neurosurgery. We aimed to assess the performance the Russian GPT-3 (ruGPT-3) language model in LOS prediction using narrative medical records in neurosurgery compared to doctors' and patients' expectations. Doctors appeared to have the most realistic LOS expectations (MAE = 2.54), while the model's predictions (MAE = 3.53) were closest to the patients' (MAE = 3.47) but inferior to them (p = 0.011). A detailed analysis showed a solid quality of ruGPT-3 performance based on narrative clinical texts. Considering our previous findings obtained with recurrent neural networks and FastText vector representation, we estimate the new result as important but probably improveable. © 2022 The authors and IOS Press.",Yes,Sully,,,,,,,,,,
A Compressed Language Model Embedding Dataset of ICD 10 CM Descriptions,"This paper presents novel datasets providing numerical representations of ICD-10-CM codes by generating description embeddings using a large language model followed by a dimension reduction via autoencoder. The embeddings serve as informative input features for machine learning models by capturing relationships among categories and preserving inherent context information. The model generating the data was validated in two ways. First, the dimension reduction was validated using an autoencoder, and secondly, a supervised model was created to estimate the ICD-10-CM hierarchical categories. Results show that the dimension of the data can be reduced to as few as 10 dimensions while maintaining the ability to reproduce the original embeddings, with the fidelity decreasing as the reduced-dimension representation decreases. Multiple compression levels are provided, allowing users to choose as per their requirements. The readily available datasets of ICD-10-CM codes are anticipated to be highly valuable for researchers in biomedical informatics, enabling more advanced analyses in the field. This approach has the potential to significantly improve the utility of ICD-10-CM codes in the biomedical domain.",No,Sully,,,,,,,,,,
Advancing Sentiment Understanding in social media through Dynamic Contextual Embedding,"In the current landscape of social media communication, believing sentiment expression is crucial for diverse applications, including brand management and public opinion analysis. The study explores ways to improvise sentiment analysis, in media by using contextual embeddings. It places its emphasis on well-settled models such as BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer). By tackling the force of these dynamic inserting, the study looks to beat the impediments of conventional feeling examination strategies in catching the nuanced and context-dependent nature of language prevalent in social media disclosure. Through a comprehensive examination of existing literature and recent developments, the paper systematically evaluates the impact of dynamic contextual embedding, emphasizing prominent models such as BERT and GPT. The main goal is to provide an in-depth overview of how these techniques have subsidized to the enhancement of sentiment analysis in the ever-evolving landscape of social media platforms. The research involves a comprehensive investigation into the fine-tuning and pre-training of these models on social media datasets. This paper provides an outline based on previous studies in the field of understanding sentiments in social media posts using algorithms like BERT and GPT. © 2024 IEEE.",No,Sully,,,,,,,,,,
Artificial intelligence (AI) in diagnostic and therapeutic decision-making—a tool or communication partner?; [Künstliche Intelligenz (KI) bei Diagnostik- und Therapieentscheidungen – Einsatz als Werkzeug oder als Kommunikationspartner?],"Artificial intelligence (AI) is a tool that is only as good as its user. In the case of humanoid robots, an AI system can be seen as a social counterpart. Decision intelligence (DI) is a term that stems from engineering. DI as a science is used to process data with findings from the social sciences and decision theories. The aim is to improve decision-making processes. However, AI should be categorized as a tool and not as a communication partner. AI analyzes information from studies, guidelines, and textbooks from the outset—taking individual patient information into account. Physicians with a high level of clinical expertise can ask more specific questions about the latter. ChatGPT is trained with millions of texts from the internet, social media, online forums, journal articles, and books; it covers almost all areas of life. © The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, ein Teil von Springer Nature 2024.",No,Sully,,,,,,,,,,
Muscle mass indicators as fat-free mass and lean soft tissue mass are associated with handgrip strength in HIV-diagnosed children and adolescents,"Objective: To verify the association between fat free mass (FFM) and lean soft tissue mass (LSTM) with handgrip strength (HGS) in HIV children and adolescents, according to sex. Method: This cross-sectional study included 65 HIV children and adolescents, aged from 8–15 years (30 boys and 35 girls). FFM and LSTM were measured by dual-energy X-ray absorptiometry (DXA). HGS was measured with hydraulic dynamometer. Bone age was assessed by radiography of the wrist of the left carpus and moderate to vigorous physical activity was obtained through the use of accelerometers. The use of antiretroviral drugs (ART) was obtained from the medical records of each participant. Results: For boys, the FFM model explained 86% the HGS variability (p < 0.001). For girls, the FFM model explained 90% the HGS variability (p < 0.001). LSTM explained 88% the HGS variability for both sexes. Conclusion: FFM and LSTM were directly associated with HGS. However, models with bone age, physical activity level and type of ART improved the explanatory power of LLM and LSTM in HGS. © 2022 Elsevier Ltd",No,Sully,,,,,,,,,,
Daily briefing: Stonehenge’s altar is surprisingly Scottish,"Part of Stonehenge came from far afield, many comatose people are conscious and how ChatGPT can be most useful to scientists.",No,Sully,,,,,,,,,,
"Reply Re: ""Orbital and Oculofacial Diseases and Artificial Intelligence: Evaluating the Accuracy and Readability of ChatGPT""","2624. Ophthalmic Plast Reconstr Surg. 2024 Mar-Apr 01;40(2):227. doi: 
10.1097/IOP.0000000000002637. Epub 2024 Mar 1.

Reply Re: ""Orbital and Oculofacial Diseases and Artificial Intelligence: 
Evaluating the Accuracy and Readability of ChatGPT"".

Ing EB, Balas M, Janic A, Daigle P, Nijhawan N, Hussain A, Gill H, Lahaie Luna 
G, Belliveau M, Crawford SA, Arjmand P.",No,Sully,,,,,,,,,,
"Comparison of ChatGPT-4o, Google Gemini 1.5 Pro, Microsoft Copilot Pro, and Ophthalmologists in the management of uveitis and ocular inflammation: A comparative study of large language models; [Comparaison de ChatGPT-4o, Google Gemini 1.5 Pro, Microsoft Copilot Pro et des ophtalmologues dans la gestion de l'uvéite et de l'inflammation oculaire : une étude comparative sur de grands modèles linguistiques]","Purpose: The aim of this study was to compare the latest large language models (LLMs) ChatGPT-4o, Google Gemini 1.5 Pro and Microsoft Copilot Pro developed by three different companies, with each other and with a group of ophthalmologists, to reveal the strengths and weaknesses of LLMs against each other and against ophthalmologists in the field of uveitis and ocular inflammation. Methods: Using a personal OphthoQuestions (www.ophthoquestions.com) account, a total of 100 questions from 201 questions on uveitis and ocular inflammation out of a total of 4551 questions on OphthoQuestions, including questions involving multimodal imaging, were included in the study using the randomization feature of the website. In November 2024, ChatGPT-4o, Microsoft Copilot Pro, and Google Gemini 1.5 Pro were asked the same 100 questions: 80 multiple-choice and 20 open-ended questions. Each question was categorized as either true or false. A statistical comparison of the accuracy rates was performed. Results: Among the 100 questions, ChatGPT-4o, Google Gemini 1.5 Pro, Microsoft Copilot Pro, and the human group (ophthalmologists) answered 80 (80.00%), 81 (81.00%), 80 (80.00%) and 72 (72.00%) questions, respectively, correctly. In the statistical comparisons between the groups for multiple-choice questions, no significant difference was found between the correct and incorrect response rates of the three LLMs and the human group (P = 0.207, Cochran's Q test). In the statistical comparisons of responses to open-ended questions, there was no significant difference between the correct and incorrect response rates of the three LLMs and the human group (P = 0.392, Cochran's Q test). Conclusion: Although ChatGPT-4o, Google Gemini 1.5 Pro, and Microsoft Copilot Pro answered higher percentages of questions correctly than the human group, the LLMs were not statistically superior to each other or to the human group in the management of uveitis and ocular inflammation. © 2025 Elsevier Masson SAS; Objectif: L'objectif de cette étude était de comparer les derniers grands modèles de langage (LLM) ChatGPT-4o, Google Gemini 1.5 Pro et Microsoft Copilot Pro développés par trois sociétés différentes, entre eux et avec un groupe d'ophtalmologistes, afin de révéler les forces et les faiblesses des LLM les uns par rapport aux autres et par rapport aux ophtalmologistes dans le domaine de l'uvéite et de l'inflammation oculaire. Méthodes: Par l'usage d'un compte personnel OphthoQuestions (www.ophthoquestions.com), un total de 100 questions parmi 201 questions sur l'uvéite et l'inflammation oculaire sur un total de 4551 questions sur OphthoQuestions, y compris les questions impliquant l'imagerie multimodale, ont été incluses dans l’étude en utilisant la fonction de randomisation du site Web. En novembre 2024, les mêmes 100 questions ont été posées à ChatGPT-4o, Microsoft Copilot Pro et Google Gemini 1.5 Pro : 80 questions à choix multiples et 20 questions ouvertes. Chaque question était classée comme vraie ou fausse. Une comparaison statistique des taux de précision a été effectuée. Résultats: Parmi les 100 questions, ChatGPT-4o, Google Gemini 1.5 Pro, Microsoft Copilot Pro et le groupe humain (ophtalmologues) ont répondu correctement à 80 (80,00 %), 81 (81,00 %), 80 (80,00 %) et 72 (72,00 %) d'entre elles, respectivement. Dans les comparaisons statistiques entre les groupes pour les questions à choix multiples, aucune différence significative n'a été trouvée entre les taux de réponses correctes et incorrectes des trois LLM et du groupe humain (p = 0,207, test Q de Cochran). Dans les comparaisons statistiques des réponses aux questions ouvertes, il n'y avait pas de différence significative entre les taux de réponses correctes et incorrectes des trois LLM et du groupe humain (p = 0,392, test Q de Cochran). Conclusion: Bien que ChatGPT-4o, Google Gemini 1.5 Pro et Microsoft Copilot Pro aient répondu correctement à un pourcentage plus élevé de questions que le groupe humain, les LLM n’étaient pas statistiquement supérieurs les uns aux autres ou au groupe humain dans la gestion de l'uvéite et de l'inflammation oculaire. © 2025 Elsevier Masson SAS",Yes,Sully,,,,,,,,,,
"Accuracy, satisfaction, and impact of custom GPT in acquiring clinical knowledge: Potential for AI-assisted medical education","BACKGROUND: Recent advancements in artificial intelligence (AI) have enabled the customization of large language models to address specific domains such as medical education. This study investigates the practical performance of a custom GPT model in enhancing clinical knowledge acquisition for medical students and physicians. METHODS: A custom GPT was developed by incorporating the latest readily available teaching resources. Its accuracy in providing clinical knowledge was evaluated using a set of clinical questions, and responses were compared against established medical guidelines. Satisfaction was assessed through surveys involving medical students and physicians at different stages and from various types of hospitals. The impact of the custom GPT was further evaluated by comparing its role in facilitating clinical knowledge acquisition with traditional learning methods. RESULTS: The custom GPT demonstrated higher accuracy (83.6%) compared to general AI models (65.5%, 69.1%) and was comparable to a professionally developed AI (Glass Health, 83.6%). Residents reported the highest satisfaction compared to clerks and physicians, citing improved learning independence, motivation, and confidence (p < 0.05). Physicians, especially those from teaching hospitals, showed greater eagerness to develop a custom GPT compared to clerks and residents (p < 0.05). The impact analysis revealed that residents using the custom GPT achieved better test scores compared to those using traditional resources (p < 0.05), though fewer perfect scores were obtained. CONCLUSIONS: The custom GPT demonstrates significant promise as an innovative tool for advancing medical education, particularly for residents. Its capability to deliver accurate, tailored information complements traditional teaching methods, aiding educators in promoting personalized and consistent training. However, it is essential for both learners and educators to remain critical in evaluating AI-generated information. With continued development and thoughtful integration, AI tools like custom GPTs have the potential to significantly enhance the quality and accessibility of medical education.[Box: see text].",Yes,Sully,,,,,,,,,,
ChatGPT versus expert arthroplasty surgeons in total knee arthroplasty patient counseling,"Background: This study aimed to assess the effectiveness of AI compared directly with expert arthroplasty surgeons regarding patient counseling for total knee arthroplasty (TKA). Methods: A set of 10 commonly asked generic and nonspecific, single-step patient questions were selected based on review of existing patient resources and expert consensus. Responses were then collected from ChatGPT-4.0 as well as five expert arthroplasty attendings at our institution. A, B, C, D, and E represent attending responses, while F represents the ChatGPT responses. The collected responses were then blinded and independently assessed by the same five arthroplasty surgeons using a five-point Likert scale in four performance areas including empathy, accuracy, completeness, and overall quality. Average scores for each question were determined. Results: Set F, the ChatGPT answers scored significantly higher than sets A, B, and D in all categories. However, set F did not differ significantly from set C, and E in all the categories. The mean score for set D was above a mean of 4, above neutral, for all four categories. This was only the case for sets C and E. When the attendings scores were combined and compared with ChatGPT, the latter had higher ratings for empathy (4.4 vs. 3.5), accuracy (4.4 vs. 3.7), completeness (4.4 vs. 3.5), and overall quality (4.4 vs. 3.6) (P < 0.001). Conclusion: A preliminary evaluation of ChatGPT-4.0 shows potential for large language AI models to serve as a supplementary resource of patients considering TKA. © 2025 Elsevier B.V.",Yes,Sully,,,,,,,,,,
Scientific novelty beyond the experiment,"2096. Microb Biotechnol. 2023 Jun;16(6):1131-1173. doi: 10.1111/1751-7915.14222. Epub 
2023 Feb 14.

Scientific novelty beyond the experiment.

Hallsworth JE(1), Udaondo Z(2), Pedrós-Alió C(3), Höfer J(4), Benison KC(5), 
Lloyd KG(6), Cordero RJB(7), de Campos CBL(8), Yakimov MM(9), Amils R(10)(11).

Author information:
(1)Institute for Global Food Security, School of Biological Sciences, Queen's 
University Belfast, Belfast, UK.
(2)Department of Biomedical Informatics, University of Arkansas for Medical 
Sciences, Little Rock, Arkansas, USA.
(3)Department of Systems Biology, Centro Nacional de Biotecnología (CSIC), 
Madrid, Spain.
(4)Escuela de Ciencias del Mar, Pontificia Universidad Católica de Valparaíso, 
Valparaíso, Chile.
(5)Department of Geology and Geography, West Virginia University, Morgantown, 
West Virginia, USA.
(6)Microbiology Department, University of Tennessee, Knoxville, Tennessee, USA.
(7)Department of Molecular Microbiology and Immunology, Johns Hopkins Bloomberg 
School of Public Health, Baltimore, Maryland, USA.
(8)Institute of Science and Technology, Universidade Federal de Sao Paulo 
(UNIFESP), São José dos Campos, SP, Brazil.
(9)Institute of Polar Sciences, ISP-CNR, Messina, Italy.
(10)Department of Molecular Biology, Centro de Biología Molecular Severo Ochoa 
(CSIC-UAM), Nicolás Cabrera n° 1, Universidad Autónoma de Madrid, Madrid, Spain.
(11)Department of Planetology and Habitability, Centro de Astrobiología 
(INTA-CSIC), Torrejón de Ardoz, Spain.

Practical experiments drive important scientific discoveries in biology, but 
theory-based research studies also contribute novel-sometimes 
paradigm-changing-findings. Here, we appraise the roles of theory-based 
approaches focusing on the experiment-dominated wet-biology research areas of 
microbial growth and survival, cell physiology, host-pathogen interactions, and 
competitive or symbiotic interactions. Additional examples relate to analyses of 
genome-sequence data, climate change and planetary health, habitability, and 
astrobiology. We assess the importance of thought at each step of the research 
process; the roles of natural philosophy, and inconsistencies in logic and 
language, as drivers of scientific progress; the value of thought experiments; 
the use and limitations of artificial intelligence technologies, including their 
potential for interdisciplinary and transdisciplinary research; and other 
instances when theory is the most-direct and most-scientifically robust route to 
scientific novelty including the development of techniques for practical 
experimentation or fieldwork. We highlight the intrinsic need for human 
engagement in scientific innovation, an issue pertinent to the ongoing 
controversy over papers authored using/authored by artificial intelligence (such 
as the large language model/chatbot ChatGPT). Other issues discussed are the way 
in which aspects of language can bias thinking towards the spatial rather than 
the temporal (and how this biased thinking can lead to skewed scientific 
terminology); receptivity to research that is non-mainstream; and the importance 
of theory-based science in education and epistemology. Whereas we briefly 
highlight classic works (those by Oakes Ames, Francis H.C. Crick and James D. 
Watson, Charles R. Darwin, Albert Einstein, James E. Lovelock, Lynn Margulis, 
Gilbert Ryle, Erwin R.J.A. Schrödinger, Alan M. Turing, and others), the focus 
is on microbiology studies that are more-recent, discussing these in the context 
of the scientific process and the types of scientific novelty that they 
represent. These include several studies carried out during the 2020 to 2022 
lockdowns of the COVID-19 pandemic when access to research laboratories was 
disallowed (or limited). We interviewed the authors of some of the featured 
microbiology-related papers and-although we ourselves are involved in laboratory 
experiments and practical fieldwork-also drew from our own research experiences 
showing that such studies can not only produce new scientific findings but can 
also transcend barriers between disciplines, act counter to scientific 
reductionism, integrate biological data across different timescales and levels 
of complexity, and circumvent constraints imposed by practical techniques. In 
relation to urgent research needs, we believe that climate change and other 
global challenges may require approaches beyond the experiment.

© 2023 The Authors. Microbial Biotechnology published by Applied Microbiology 
International and John Wiley & Sons Ltd.",No,Sully,,,,,,,,,,
Capsaicin-loaded alginate nanoparticles embedded polycaprolactone-chitosan nanofibers as a controlled drug delivery nanoplatform for anticancer activity,"3455. J Colloid Interface Sci. 2023 May 15;638:616-628. doi: 
10.1016/j.jcis.2023.01.139. Epub 2023 Jan 31.

Capsaicin-loaded alginate nanoparticles embedded polycaprolactone-chitosan 
nanofibers as a controlled drug delivery nanoplatform for anticancer activity.

Ahmady AR(1), Solouk A(2), Saber-Samandari S(3), Akbari S(4), Ghanbari H(5), 
Brycki BE(6).

Author information:
(1)Department of Biomedical Engineering, Amirkabir University of Technology 
(Tehran Polytechnic), Tehran, Iran; Composites Research Laboratory (CRLab), 
Amirkabir University of Technology, Tehran, Iran.
(2)Department of Biomedical Engineering, Amirkabir University of Technology 
(Tehran Polytechnic), Tehran, Iran. Electronic address: Atefeh.solouk@aut.ac.ir.
(3)New Technologies Research Center (NTRC), Amirkabir University of Technology 
(Tehran Polytechnic), Tehran, Iran; Composites Research Laboratory (CRLab), 
Amirkabir University of Technology, Tehran, Iran. Electronic address: 
saeedss@aut.ac.ir.
(4)Department of Textile Engineering, Amirkabir University of Technology (Tehran 
Polytechnic), Tehran, Iran.
(5)ENT and Head and Neck Research Center, Department of Otolaryngology, Head and 
Neck Surgery, The Five Senses Institute, Hazrat Rasoul Hospital, Iran University 
of Medical Sciences (IUMS), Tehran, Iran.
(6)Department of Bioactive Products, Faculty of Chemistry, Adam Mickiewicz 
University Poznan, 61-614 Poznan, Poland.

Nanocarrier-based drug delivery systems have been designed into various 
structures that can effectively prevent cancer progression and improve the 
therapeutic cancer index. However, most of these delivery systems are designed 
to be simple nanostructures with several limitations, including low stability 
and burst drug release features. A nano-in-nano delivery technique is explored 
to address the aforementioned concerns. Accordingly, this study investigated the 
release behavior of a novel nanoparticles-in-nanofibers delivery system composed 
of capsaicin-loaded alginate nanoparticles embedded in polycaprolactone-chitosan 
nanofiber mats. First, alginate nanoparticles were prepared with different 
concentrations of cationic gemini surfactant and using nanoemulsion templates. 
The optimized formulation of alginate nanoparticles was utilized for loading 
capsaicin and exhibited a diameter of 19.42 ± 1.8 nm and encapsulation 
efficiency of 98.7 % ± 0.6 %. Likewise, blend polycaprolactone-chitosan 
nanofibers were prepared with different blend ratios of their solutions (i.e., 
100:0, 80:20, 60:40) by electrospinning method. After the characterization of 
electrospun mats, the optimal nanofibers were employed for embedding 
capsaicin-loaded alginate nanoparticles. Our findings revealed that embedding 
capsaicin-loaded alginate nanoparticles in polycaprolactone-chitosan nanofibers, 
prolonged capsaicin release from 120 h to more than 500 h. Furthermore, the 
results of in vitro analysis demonstrated that the designed nanoplatform could 
effectively inhibit the proliferation of MCF-7 human breast cells while being 
nontoxic to human dermal fibroblasts (HDF). Collectively, the prepared 
nanocomposite drug delivery platform might be promising for the long-term and 
controlled release of capsaicin for the prevention and treatment of cancer.

Copyright © 2023 Elsevier Inc. All rights reserved.",No,Sully,,,,,,,,,,
ECGText: Human-Centric Text Generation with Enhanced Emotional Intelligence,"The recent improvements in the natural language processing (NLP) field have made it possible to create extremely powerful models such as Generative Pre-trained Transformers (GPT), used for generating human-sounding, contextually relevant text. Nevertheless, these types of models often fail to convey the proper emotional fidelity that we need for human communication. We propose ECGText (Emotional Controlled Generation of Text), a new framework that implements GPT to respond Emotion-controlled prompt with the assistance of RoBERTa-based GoEmotions model for emotion recognition in order to mitigate this limitation. ECGText generates emotionally aligned text while maintaining coherence and the author's writing style. The model supports multiple languages and is designed for applications requiring emotionally intelligent text. We evaluated ECGText using various datasets, including Obama speeches, film reviews, and Rabindranath Tagore's works. The results demonstrate that ECGText achieves superior performance in text diversity, coherence, and emotional alignment compared to baseline models. This work represents a significant step toward developing emotionally intelligent AI systems, with potential applications in affective computing and human-AI interaction.  © 2024 IEEE.",No,Sully,,,,,,,,,,
Deception abilities emerged in large language models,"3349. Proc Natl Acad Sci U S A. 2024 Jun 11;121(24):e2317967121. doi: 
10.1073/pnas.2317967121. Epub 2024 Jun 4.

Deception abilities emerged in large language models.

Hagendorff T(1).

Author information:
(1)Interchange Forum for Reflecting on Intelligent Systems, University of 
Stuttgart, Stuttgart 70569, Germany.

Large language models (LLMs) are currently at the forefront of intertwining AI 
systems with human communication and everyday life. Thus, aligning them with 
human values is of great importance. However, given the steady increase in 
reasoning abilities, future LLMs are under suspicion of becoming able to deceive 
human operators and utilizing this ability to bypass monitoring efforts. As a 
prerequisite to this, LLMs need to possess a conceptual understanding of 
deception strategies. This study reveals that such strategies emerged in 
state-of-the-art LLMs, but were nonexistent in earlier LLMs. We conduct a series 
of experiments showing that state-of-the-art LLMs are able to understand and 
induce false beliefs in other agents, that their performance in complex 
deception scenarios can be amplified utilizing chain-of-thought reasoning, and 
that eliciting Machiavellianism in LLMs can trigger misaligned deceptive 
behavior. GPT-4, for instance, exhibits deceptive behavior in simple test 
scenarios 99.16% of the time (P < 0.001). In complex second-order deception test 
scenarios where the aim is to mislead someone who expects to be deceived, GPT-4 
resorts to deceptive behavior 71.46% of the time (P < 0.001) when augmented with 
chain-of-thought reasoning. In sum, revealing hitherto unknown machine behavior 
in LLMs, our study contributes to the nascent field of machine psychology.",No,Sully,,,,,,,,,,
The JavaScript Package Selection Task: A Comparative Experiment Using ChatGPT,"When developing Java Script (JS) applications, the assessment and selection of JS packages have become challenging for developers due to the growing number of technology options available. Given a technology need, a common developers' strat-egy is to query Web repositories via search engines (e.g., NPM, Google) and shortlist candidate JS packages. However, these engines might return a long list of results. Furthermore, these results should be ranked according to the developer's criteria. To address these problems, we developed a recommender system called AIDT that assists developers in the package selection task. AIDT relies on meta-search and machine learning techniques to infer the relevant packages for a query. An initial evaluation of AIDT showed good search effectiveness. Recently, the emergence of ChatGPT has opened new opportunities for this kind of assistants, as reported by some experiments. Anyway, human developers should judge whether the recommendations (e.g., JS packages) of these tools are fit to purpose. In this paper, we report on a user study in which we used both AIDT and ChatGPT on a sample of JS-related queries, compared their results, and also validated them against developers' criteria and expectations for the task. Our initial findings show that ChatGPT is not yet on par with AIDT or even human efforts for the task at hand, but the model is flexible to be improved and furthermore, it can provide good arguments for its package choices.  © 2023 IEEE.",No,Sully,,,,,,,,,,
Quality of Information in Carpal Tunnel Syndrome: Social Media Platforms Versus Large Language Models,"Introduction Carpal tunnel syndrome (CTS) is the most common peripheral nerve entrapment disease, and it is a subject of great interest and concern to medical professionals and the general public. Our study aims to analyze and compare the quality and accuracy of the information related to CTS provided by social media platforms (SMPs) and the new large language models (LLM). Methods On YouTube, the first 20 videos in English and the first 20 videos in Spanish when searching for ""carpal tunnel syndrome""and ""síndrome túnel carpo""were selected. On Instagram, the first 20 videos with the hashtag #carpaltunnelsyndrome and #tunelcarpiano were chosen (in total 80 videos). Duration, number of likes, number of views, number of followers, upload date, and author category (medical specialist, patient, etc) were evaluated. Three specific questions about CTS were asked to 2 new LLMs (ChatGPT and Google Bard). The quality of information was analyzed and compared by two independent board-certified plastic surgeons using the Journal of American Medical Association (JAMA) and DISCERN scales. Results LLMs showed a significant higher quality of information when compared with SMPs based on the DISCERN scores (P < 0.05). Average DISCERN scores for answers given by ChatGPT and Google Bard were 52.83 and 57.83, respectively (good quality). In YouTube and Instagram, the average score for the 80 videos based on the JAMA scale was 1.92 (low reliability) and 25.18 (very low quality) on the DISCERN scale. Videos created by medical professionals in SMPs were associated with a higher JAMA and DISCERN scores (P < 0.05). 53.8% of the videos were made by a nonmedical author. Conclusions The quality of information from LLMs was good and significantly better than in SMP. A low participation of board-certified surgeons in SMP was found. Board-certified surgeons should be more involved in LLM and SMPs to increase leadership, improve education, and spread knowledge of peripheral nerve surgery.  © 2025 Wolters Kluwer Health, Inc. All rights reserved.",No,Sully,This is sentiment analysis applied to clinical medicine basically,,,,,,,,,
Comparing new tools of artificial intelligence to the authentic intelligence of our global health students,"Introduction: The transformative feature of Artificial Intelligence (AI) is the massive capacity for interpreting and transforming unstructured data into a coherent and meaningful context. In general, the potential that AI will alter traditional approaches to student research and its evaluation appears to be significant. With regard to research in global health, it is important for students and research experts to assess strengths and limitations of GenAI within this space. Thus, the goal of our research was to evaluate the information literacy of GenAI compared to expectations that graduate students meet in writing research papers. Methods: After completing the course, Fundamentals of Global Health (INTH 401) at Case Western Reserve University (CWRU), Graduate students who successfully completed their required research paper were recruited to compare their original papers with a paper they generated by ChatGPT-4o using the original assignment prompt. Students also completed a Google Forms survey to evaluate different sections of the AI-generated paper (e.g., Adherence to Introduction guidelines, Presentation of three perspectives, Conclusion) and their original papers and their overall satisfaction with the AI work. The original student to ChatGPT-4o comparison also enabled evaluation of narrative elements and references. Results: Of the 54 students who completed the required research paper, 28 (51.8%) agreed to collaborate in the comparison project. A summary of the survey responses suggested that students evaluated the AI-generated paper as inferior or similar to their own paper (overall satisfaction average = 2.39 (1.61–3.17); Likert scale: 1 to 5 with lower scores indicating inferiority). Evaluating the average individual student responses for 5 Likert item queries showed that 17 scores were < 2.9; 7 scores were between 3.0 to 3.9; 4 scores were ≥ 4.0, consistent with inferiority of the AI-generated paper. Evaluation of reference selection by ChatGPT-4o (n = 729 total references) showed that 54% (n = 396) were authentic, 46% (n = 333) did not exist. Of the authentic references, 26.5% (105/396) were relevant to the paper narrative; 14.4% of the 729 total references. Discussion: Our findings reveal strengths and limitations on the potential of AI tools to assist in understanding the complexities of global health topics. Strengths mentioned by students included the ability of ChatGPT-4o to produce content very quickly and to suggest topics that they had not considered in the 3-perspective sections of their papers. Consistently presenting up-to-date facts and references, as well as further examining or summarizing the complexities of global health topics, appears to be a current limitation of ChatGPT-4o. Because ChatGPT-4o generated references from highly credible biomedical research journals that did not exist, our findings conclude that ChatGPT-4o failed an important component in using information effectively. Moreover, misrepresenting trusted sources of public health information is highly concerning, particularly given recent experiences from the COVID-19 pandemic and more recently in reporting on the impact of, and response to natural disasters. This is a significant limitation of GenAI’s ability to meet information literacy standards expected of graduate students.",No,Sully,,,,,,,,,,
Can artificial intelligence help for scientific writing?,"This paper discusses the use of Artificial Intelligence Chatbot in scientific writing. ChatGPT is a type of chatbot, developed by OpenAI, that uses the Generative Pre-trained Transformer (GPT) language model to understand and respond to natural language inputs. AI chatbot and ChatGPT in particular appear to be useful tools in scientific writing, assisting researchers and scientists in organizing material, generating an initial draft and/or in proofreading. There is no publication in the field of critical care medicine prepared using this approach; however, this will be a possibility in the next future. ChatGPT work should not be used as a replacement for human judgment and the output should always be reviewed by experts before being used in any critical decision-making or application. Moreover, several ethical issues arise about using these tools, such as the risk of plagiarism and inaccuracies, as well as a potential imbalance in its accessibility between high- and low-income countries, if the software becomes paying. For this reason, a consensus on how to regulate the use of chatbots in scientific writing will soon be required. © 2023, The Author(s).",No,Sully,,,,,,,,,,
A novel model for detecting advanced fibrosis in patients with nonalcoholic fatty liver disease,"Aims: The study aimed to develop a novel noninvasive model to detect advanced fibrosis based on routinely available clinical and laboratory tests. Materials and Methods: A total of 309 patients who underwent liver biopsy were randomly divided into the estimation group (n = 201) and validation group (n = 108). The model was developed using multiple regression analysis in the estimation group and further verified in the validation group. Diagnostic accuracy was evaluated using the receiver operating characteristic (ROC) curve. Results: The model was named NAFLD Fibrosis Index (NFI): −10.844 + 0.046 × age − 0.01 × platelet count + 0.19 × 2h postprandial plasma glucose (PG) + 0.294 × conjugated bilirubin − 0.015 × ALT + 0.039 × AST + 0.109 × total iron binding capacity −0.033 × parathyroid hormone (PTH). The area under the ROC curve (AUC) of NFI was 0.86 (95% CI: 0.79–0.93, p < 0.001) in the estimation group and 0.80 (95% CI: 0.69–0.91, p < 0.001) in the validation group, higher than NFS, FIB4, APRI, and BARD, and similar to FibroScan (NFI AUC = 0.77, 95% CI: 0.66–0.89, p = 0.001 vs. FibroScan AUC = 0.76, 95% CI: 0.62–0.90, p = 0.002). By applying the low cut-off value (−2.756), advanced fibrosis could be excluded among 49.3% and 48% of patients in the estimation group (sensitivity: 93.1%, NPV: 97.9%, specificity: 55.2%, and PPV: 26.0%) and validation group (sensitivity: 81.3%, NPV: 94.2%, specificity: 53.3%, and PPV: 23.2%), respectively, allowing them to avoid liver biopsy. Conclusions: The study has established a novel model for advanced fibrosis, the diagnostic accuracy of which is superior to the current clinical scoring systems and is similar to FibroScan. © 2022 The Authors. Diabetes/Metabolism Research and Reviews published by John Wiley & Sons Ltd.",No,Sully,,,,,,,,,,
A multinational study on the factors influencing university students' attitudes and usage of ChatGPT,"Artificial intelligence models, like ChatGPT, have the potential to revolutionize higher education when implemented properly. This study aimed to investigate the factors influencing university students' attitudes and usage of ChatGPT in Arab countries. The survey instrument ""TAME-ChatGPT"" was administered to 2240 participants from Iraq, Kuwait, Egypt, Lebanon, and Jordan. Of those, 46.8% heard of ChatGPT, and 52.6% used it before the study. The results indicated that a positive attitude and usage of ChatGPT were determined by factors like ease of use, positive attitude towards technology, social influence, perceived usefulness, behavioral/cognitive influences, low perceived risks, and low anxiety. Confirmatory factor analysis indicated the adequacy of the ""TAME-ChatGPT"" constructs. Multivariate analysis demonstrated that the attitude towards ChatGPT usage was significantly influenced by country of residence, age, university type, and recent academic performance. This study validated ""TAME-ChatGPT"" as a useful tool for assessing ChatGPT adoption among university students. The successful integration of ChatGPT in higher education relies on the perceived ease of use, perceived usefulness, positive attitude towards technology, social influence, behavioral/cognitive elements, low anxiety, and minimal perceived risks. Policies for ChatGPT adoption in higher education should be tailored to individual contexts, considering the variations in student attitudes observed in this study.",No,Sully,,,,,,,,,,
"Comparison of large language models in management advice for melanoma: Google's AI BARD, BingAI and ChatGPT","Large language models (LLMs) are emerging artificial intelligence (AI) technology refining research and healthcare. Their use in medicine has seen numerous recent applications. One area where LLMs have shown particular promise is in the provision of medical information and guidance to practitioners. This study aims to assess three prominent LLMs—Google's AI BARD, BingAI and ChatGPT-4 in providing management advice for melanoma by comparing their responses to current clinical guidelines and existing literature. Five questions on melanoma pathology were prompted to three LLMs. A panel of three experienced Board-certified plastic surgeons evaluated the responses for reliability using reliability matrix (Flesch Reading Ease Score, the Flesch-Kincaid Grade Level and the Coleman-Liau Index), suitability (modified DISCERN score) and comparing them to existing guidelines. t-Test was performed to calculate differences in mean readability and reliability scores between LLMs and p value <0.05 was considered statistically significant. The mean readability scores across three LLMs were same. ChatGPT exhibited superiority with a Flesch Reading Ease Score of 35.42 (±21.02), Flesch–Kincaid Grade Level of 11.98 (±4.49) and Coleman–Liau Index of 12.00 (±5.10), however all of these were insignificant (p > 0.05). Suitability-wise using DISCERN score, ChatGPT 58 (±6.44) significantly (p = 0.04) outperformed BARD 36.2 (±34.06) and was insignificant to BingAI's 49.8 (±22.28). This study demonstrates that ChatGPT marginally outperforms BARD and BingAI in providing reliable, evidence-based clinical advice, but they still face limitations in depth and specificity. Future research should improve LLM performance by integrating specialized databases and expert knowledge to support patient-centred care. © 2023 The Authors. Skin Health and Disease published by John Wiley & Sons Ltd on behalf of British Association of Dermatologists.",Yes,Sully,,,,,,,,,,
"Long-Term Effects of Microfiltered Seawater and Resistance Training with Elastic Bands on Hepatic Parameters, Inflammation, Oxidative Stress, and Blood Pressure of Older Women: A 32-Week, Double-Blinded, Randomized, Placebo-Controlled Trial","The bulk of research on microfiltered seawater (SW) is based on its short-term effects. However, the long-term physiological adaptations to combining SW and resistance training (RT) are unknown. This study aimed to analyse the impact of an RT program using elastic bands combined with SW intake on hepatic biomarkers, inflammation, oxidative stress, and blood pressure in post-menopausal women. Ninety-three women voluntarily participated (age: 70 ± 6.26 years; body mass index: 22.05 ± 3.20 kg/m2; Up-and-Go Test: 6.66 ± 1.01 s). RT consisted of six exercises (32 weeks, 2 days/week). Nonsignificant differences were reported for hepatic biomarkers except for a reduction in glutamic-pyruvic transaminase (GPT) in both RT groups (RT + SW: p = 0.003, ES = 0.51; RT + Placebo: p = 0.012, ES = 0.36). Concerning oxidative stress, vitamin D increased significantly in RT + SW (p = 0.008, ES = 0.25). Regarding inflammation, interleukin 6 significantly decreased (p = 0.003, ES = 0.69) in RT + SW. Finally, systolic blood pressure significantly decreased in both RT groups (RT + placebo: p < 0.001, ES = 0.79; RT + SW: p < 0.001, ES = 0.71) as did diastolic blood pressure in both SW groups (RT + SW: p = 0.002, ES = 0.51; CON + SW: p = 0.028, ES = 0.50). Therefore, RT + SW or SW alone are safe strategies in the long term with no influences on hepatic and oxidative stress biomarkers. Additionally, SW in combination with RT positively influences vitamin D levels, inflammation, and blood pressure in older women. © 2024 by the authors.",No,Sully,,,,,,,,,,
"Letter to the Editor ""Utility of ChatGPT in Total Joint Arthroplasty""","2514. J Arthroplasty. 2023 Sep;38(9):e18. doi: 10.1016/j.arth.2023.05.058.

Letter to the Editor ""Utility of ChatGPT in Total Joint Arthroplasty"".

Dubin JA(1), Bains SS(1), Chen Z(1), Hameed D(1), Nace J(1), Mont MA(1), 
Delanois RE(1).

Author information:
(1)LifeBridge Health, Sinai Hospital of Baltimore, Rubin Institute for Advanced 
Orthopedics, Baltimore, Maryland.

Comment on
    J Arthroplasty. 2023 Jul;38(7):1195-1202. doi: 10.1016/j.arth.2023.04.007.
    J Arthroplasty. 2023 Sep;38(9):e17. doi: 10.1016/j.arth.2023.05.056.",No,Sully,,,,,,,,,,
ChatGPT-4 versus human assessment in cardiology peer review,"2536. Rev Esp Cardiol (Engl Ed). 2024 Jul;77(7):591-594. doi: 
10.1016/j.rec.2024.02.004. Epub 2024 Feb 27.

ChatGPT-4 versus human assessment in cardiology peer review.

[Article in English, Spanish]

Fernández-Cisnal A(1), Avanzas P(2), Filgueiras-Rama D(3), Garcia-Pavia P(4), 
Sanchis L(5), Sanchis J(6).

Author information:
(1)Department of Cardiology, Hospital Clínico Universitario de València, 
INCLIVA, Valencia, Spain.
(2)Department of Cardiology, Hospital Universitario Central de Asturias, Oviedo, 
Asturias, Spain; Instituto de Investigación del Principado de Asturias, Oviedo, 
Asturias, Spain; Facultad de Medicina, Universidad de Oviedo, Oviedo, Asturias, 
Spain; Centro de investigación Biomédica en Red de Enfermedades Cardiovasculares 
(CIBERCV), Spain.
(3)Centro de investigación Biomédica en Red de Enfermedades Cardiovasculares 
(CIBERCV), Spain; Instituto de Investigación Sanitaria del Hospital Clínico San 
Carlos (IdISSC), Instituto Cardiovascular, Madrid, Spain; Centro Nacional de 
Investigaciones Cardiovasculares (CNIC), Madrid, Spain.
(4)Centro de investigación Biomédica en Red de Enfermedades Cardiovasculares 
(CIBERCV), Spain; Centro Nacional de Investigaciones Cardiovasculares (CNIC), 
Madrid, Spain; Department of Cardiology, Hospital Universitario Puerta de 
Hierro-Majadahonda, Instituto de Investigación Sanitaria Puerta de 
Hierro-Segovia de Arana (IDIPHISA), Madrid, Spain.
(5)Department of Cardiology, Hospital Clínic, Barcelona, Spain; Institut 
d'Investigacions Biomèdiques Agustí Pi i Sunyer (IDIBAPS), Barcelona, Spain.
(6)Department of Cardiology, Hospital Clínico Universitario de València, 
INCLIVA, Valencia, Spain; Centro de investigación Biomédica en Red de 
Enfermedades Cardiovasculares (CIBERCV), Spain; Facultad de Medicina, 
Universidad de València, València, Spain. Electronic address: 
sanchis_juafor@gva.es.",No,Sully,,,,,,,,,,
"PIRO: A web-based search platform for pathology reports, leveraging large language models to generate discrete searchable insights","Pathologists rely on access to historical diagnostic case texts for research, education, and peer learning. However, many laboratory information systems (LIS), including Epic Beaker, lack optimized search tools tailored to pathology-specific text queries. To address this need, we developed PIRO (Pathology Information Retrieval Optimizer), a web-based platform enabling efficient text searches of diagnostic archives. Built using FastAPI, Angular, and Apache Solr, PIRO supports both basic and advanced search functionalities, faceted filtering, and data extraction, while ensuring compliance with institutional privacy protocols. PIRO's capabilities extend to case cohort building, search result export, and secure access control within the institutional network. In an 8-month study, we observed significantly higher PIRO adoption rates (67 %) among pathologists compared to Epic Beaker's SlicerDicer (9 %), underscoring PIRO's usability and relevance. Additionally, we implemented a large language model (LLM) to annotate reports with a “Malignancy Risk” label, enhancing search precision and enabling future expansion of automated annotations. Ongoing work focuses on integrating PIRO with our digital pathology platform, enabling direct access to digital slides from case results. PIRO's adaptable design makes it applicable across institutions, advancing search and retrieval efficiency in pathology archives and enhancing support for pathology research and education. © 2025 The Authors",No,Sully,,,,,,,,,,
The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BACKGROUND: Artificial intelligence (AI) applications in health care have been 
effective in many areas of medicine, but they are often trained for a single 
task using labelled data, making deployment and generalisability challenging. 
How well a general-purpose AI language model performs diagnosis and triage 
relative to physicians and laypeople is not well understood.
METHODS: We compared the predictive accuracy of Generative Pre-trained 
Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic 
case vignettes (<50 words; sixth-grade reading level or below) of both common 
(eg, viral illness) and severe (eg, heart attack) conditions to a nationally 
representative sample of 5000 lay people from the USA who could use the internet 
to find the correct options and 21 practising physicians at Harvard Medical 
School. There were 12 vignettes for each of four triage categories: emergent, 
within one day, within 1 week, and self-care. The correct diagnosis and triage 
category (ie, ground truth) for each vignette was determined by two general 
internists at Harvard Medical School. For each vignette, human respondents and 
GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette 
was marked as correct if the ground-truth diagnosis was in the top three of the 
listed diagnoses. For triage accuracy, we examined whether the human 
respondents' and GPT-3's selected triage was exactly correct according to the 
four triage categories, or matched a dichotomised triage variable (emergent or 
within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and 
triage confidence on a given vignette using a modified bootstrap resampling 
procedure, and examined how well calibrated GPT-3's confidence was by computing 
calibration curves and Brier scores. We also performed subgroup analysis by case 
acuity, and an error analysis for triage advice to characterise how its advice 
might affect patients using this tool to decide if they should seek medical care 
immediately.
FINDINGS: Among all cases, GPT-3 replied with the correct diagnosis in its top 
three for 88% (42/48, 95% CI 75-94) of cases, compared with 54% (2700/5000, 
53-55) for lay individuals (p<0.0001) and 96% (637/666, 94-97) for physicians 
(p=0·012). GPT-3 triaged 70% correct (34/48, 57-82) versus 74% (3706/5000, 
73-75; p=0.60) for lay individuals and 91% (608/666, 89-93%; p<0.0001) for 
physicians. As measured by the Brier score, GPT-3 confidence in its top 
prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and 
triage (Brier score=0·22). We observed an inverse relationship between case 
acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of -8·33% decrease 
in accuracy for every level of increase in case acuity. For triage error 
analysis, GPT-3 deprioritised truly emergent cases in seven instances.
INTERPRETATION: A general-purpose AI language model without any content-specific 
training could perform diagnosis at levels close to, but below, physicians and 
better than lay individuals. We found that GPT-3's performance was inferior to 
physicians for triage, sometimes by a large margin, and its performance was 
closer to that of lay individuals. Although the diagnostic performance of GPT-3 
was comparable to physicians, it was significantly better than a typical person 
using a search engine.
FUNDING: The National Heart, Lung, and Blood Institute.

Copyright © 2024 The Author(s). Published by Elsevier Ltd. This is an Open 
Access article under the CC BY-NC-ND 4.0 license. Published by Elsevier Ltd.. 
All rights reserved.",Yes,Sully,,,,,,,,,,
Evaluating ChatGPT-4’s Diagnostic Accuracy: Impact of Visual Data Integration,"Background: In the evolving field of health care, multimodal generative artificial intelligence (AI) systems, such as ChatGPT-4 with vision (ChatGPT-4V), represent a significant advancement, as they integrate visual data with text data. This integration has the potential to revolutionize clinical diagnostics by offering more comprehensive analysis capabilities. However, the impact on diagnostic accuracy of using image data to augment ChatGPT-4 remains unclear. Objective: This study aims to assess the impact of adding image data on ChatGPT-4’s diagnostic accuracy and provide insights into how image data integration can enhance the accuracy of multimodal AI in medical diagnostics. Specifically, this study endeavored to compare the diagnostic accuracy between ChatGPT-4V, which processed both text and image data, and its counterpart, ChatGPT-4, which only uses text data. Methods: We identified a total of 557 case reports published in the American Journal of Case Reports from January 2022 to March 2023. After excluding cases that were nondiagnostic, pediatric, and lacking image data, we included 363 case descriptions with their final diagnoses and associated images. We compared the diagnostic accuracy of ChatGPT-4V and ChatGPT-4 without vision based on their ability to include the final diagnoses within differential diagnosis lists. Two independent physicians evaluated their accuracy, with a third resolving any discrepancies, ensuring a rigorous and objective analysis. Results: The integration of image data into ChatGPT-4V did not significantly enhance diagnostic accuracy, showing that final diagnoses were included in the top 10 differential diagnosis lists at a rate of 85.1% (n=309), comparable to the rate of 87.9% (n=319) for the text-only version (P=.33). Notably, ChatGPT-4V’s performance in correctly identifying the top diagnosis was inferior, at 44.4% (n=161), compared with 55.9% (n=203) for the text-only version (P=.002, χ2 test). Additionally, ChatGPT-4’s self-reports showed that image data accounted for 30% of the weight in developing the differential diagnosis lists in more than half of cases. Conclusions: Our findings reveal that currently, ChatGPT-4V predominantly relies on textual data, limiting its ability to fully use the diagnostic potential of visual information. This study underscores the need for further development of multimodal generative AI systems to effectively integrate and use clinical image data. Enhancing the diagnostic performance of such AI systems through improved multimodal data integration could significantly benefit patient care by providing more accurate and comprehensive diagnostic insights. Future research should focus on overcoming these limitations, paving the way for the practical application of advanced AI in medicine. ©Takanobu Hirosawa, Yukinori Harada, Kazuki Tokumasu, Takahiro Ito, Tomoharu Suzuki, Taro Shimizu.",Yes,Sully,,,,,,,,,,
Amyloid-β Deposition Prediction with Large Language Model Driven and Task Oriented Learning of Brain Functional Networks,"Amyloid-β positron emission tomography can reflect the Amyloid-β protein deposition in the brain and thus serves as one of the golden standards for Alzheimer's disease (AD) diagnosis. However, its practical cost and high radioactivity hinder its application in large-scale early AD screening. Recent neuroscience studies suggest a strong association between changes in functional connectivity network (FCN) derived from functional MRI (fMRI), and deposition patterns of Amyloid-β protein in the brain. This enables an FCN-based approach to assess the Amyloid-β protein deposition with less expense and radioactivity. However, an effective FCN-based Amyloid-β assessment remains lacking for practice. In this paper, we introduce a novel deep learning framework tailored for this task. Our framework comprises three innovative components: 1) a pre-trained Large Language Model Nodal Embedding Encoder, designed to extract task-related features from fMRI signals; 2) a task-oriented Hierarchical-order FCN Learning module, used to enhance the representation of complex correlations among different brain regions for improved prediction of Amyloid-β deposition; and 3) task-feature consistency losses for promoting similarity between predicted and real Amyloid-β values and ensuring effectiveness of predicted Amyloid-β in downstream classification task. Experimental results show superiority of our method over several state-of-the-art FCN-based methods. Additionally, we identify crucial functional sub-networks for predicting Amyloid-β depositions. The proposed method is anticipated to contribute valuable insights into the understanding of mechanisms of AD and its prevention.  © 1982-2012 IEEE.",No,Sully,,,,,,,,,,
Impact and challenges of ChatGPT on medical science research management; [ChatGPT技术对医学科研管理的影响与挑战],"Objective To explore the influence and challenge of ChatGPT technology on medical scientific research management, and to provide references for better meeting the change of scientific research paradigm generated by artificial intelligence. Methods Through literature research and case testing, combined with the main characteristics of ChatGPT, the possible application scenarios, risks, and challenges of ChatGPT technology in medical scientific research management were analyzed. Results Countermeasures and suggestions were proposed from the perspective of medical institutions and research managers. Conclusions ChatGPT technology will have a broad application prospect in medical scientific research management, and bring new risks and challenges. It is suggested to comply with the trend and actively face it by improving laws, regulations, and institutional norms, strengthening research and supervision, and improving the ability and quality of medical scientific research management personnel. © 2023 Chinese Medical Journals Publishing House Co.Ltd. All rights reserved.",No,Sully,,,,,,,,,,
Development and evaluation of nanobody tracers for noninvasive nuclear imaging of the immune-checkpoint TIGIT,"Introduction: T cell Ig and ITIM domain receptor (TIGIT) is a next-generation immune checkpoint predominantly expressed on activated T cells and NK cells, exhibiting an unfavorable prognostic association with various malignancies. Despite the emergence of multiple TIGIT-blocking agents entering clinical trials, only a fraction of patients responded positively to anti-TIGIT therapy. Consequently, an urgent demand arises for noninvasive techniques to quantify and monitor TIGIT expression, facilitating patient stratification and enhancing therapeutic outcomes. Small antigen binding moieties such as nanobodies, are promising candidates for such tracer development. Methods: We generated a panel of anti-human or anti-mouse TIGIT nanobodies from immunized llamas. In addition, we designed a single-chain variable fragment derived from the clinically tested monoclonal antibody Vibostolimab targeting TIGIT, and assessed its performance alongside the nanobodies. In vitro characterization studies were performed, including binding ability and affinity to cell expressed or recombinant TIGIT. After Technetium-99m labeling, the nanobodies and the single-chain variable fragment were evaluated in vivo for their ability to detect TIGIT expression using SPECT/CT imaging, followed by ex vivo biodistribution analysis. Results: Nine nanobodies were selected for binding to recombinant and cell expressed TIGIT with low sub-nanomolar affinities and are thermostable. A six-fold higher uptake in TIGIT-overexpressing tumor was demonstrated one hour post- injection with Technetium-99m labeled nanobodies compared to an irrelevant control nanobody. Though the single-chain variable fragment exhibited superior binding to TIGIT-expressing peripheral blood mononuclear cells in vitro, its in vivo behavior yielded lower tumor-to-background ratios at one hour post- injection, indicating that nanobodies are better suited for in vivo imaging than the single-chain variable fragment. Despite the good affinity, high specificity and on-target uptake in mice in this setting, imaging of TIGIT expression on tumor- infiltrating lymphocytes within MC38 tumors remained elusive. This is likely due to the low expression levels of TIGIT in this model. Discussion: The excellent affinity, high specificity and rapid on-target uptake in mice bearing TIGIT- overexpressing tumors showed the promising diagnostic potential of nanobodies to noninvasively image high TIGIT expression within the tumor. These findings hold promise for clinical translation to aid patient selection and improve therapy response. Copyright © 2023 Zeven, De Groof, Ceuppens, Awad, Ertveldt, de Mey, Meeus, Raes, Breckpot and Devoogdt.",No,Sully,,,,,,,,,,
"Leveraging mobile NER for real-time capture of symptoms, diagnoses, and treatments from clinical dialogues","In the dynamic world of healthcare technology, efficiently and accurately extracting medical data from physician–patient conversations is vital. This paper presents a new approach in healthcare technology, employing Natural Language Processing (NLP) to identify and extract critical information from doctor–patient conversations on mobile devices. Unlike traditional methods that rely on Electronic Health Records, our novel application enables the extraction of symptoms, diagnoses, and treatments directly on a mobile device during medical consultations, significantly enhancing patient privacy. We managed to integrate both Bidirectional Encoder Representations from Transformers (BERT) models and optimized Large Language Models (LLMs) on a mobile device without compromising performance significantly. Our findings reveal that the BERT model attained an F1-score of 85.1%, while FLERT and its compressed variant DistilFLERT showed superior performance. The FLAN-T5 model outperformed all models we tested with scores up to 92.7%. These results highlight the efficacy of leveraging advanced NLP and LLM technologies in healthcare environments on a mobile device, offering a promising direction for accessible and efficient patient care. © 2024",No,Sully,Data extraction task,,,,,,,,,
Large language model-driven sentiment analysis for facilitating fibromyalgia diagnosis,"Background Fibromyalgia (FM) is a complex disorder with widespread pain and emotional distress, posing diagnostic challenges. FM patients show altered cognitive and emotional processing, with a preferential allocation of attention to pain-related information. This attentional bias towards pain cues can impair cognitive functions such as inhibitory control, affecting patients' ability to manage and express emotions. Sentiment analysis using large language models (LLMs) can provide insights by detecting nuances in pain expression. This study investigated whether open-source LLM-driven sentiment analysis could aid FM diagnosis. Methods 40 patients with FM, according to the 2016 American College of Rheumatology Criteria and 40 non-FM chronic pain controls referred to rheumatology clinics, were enrolled. Transcribed responses to questions on pain and sleep were machine translated to English and analysed by the LLM Mistral-7B-Instruct-v0.2 using prompt engineering targeting FM-associated language nuances for pain expression ( € prompt-engineered') or an approach without this targeting ( € ablated'). Accuracy, precision, recall, specificity and area under the receiver operating characteristic curve (AUROC) were calculated using rheumatologist diagnosis as ground truth. Results The prompt-engineered approach demonstrated accuracy of 0.87, precision of 0.92, recall of 0.84, specificity of 0.82 and AUROC of 0.86 for distinguishing FM. In comparison, the ablated approach had an accuracy of 0.76, precision of 0.75, recall of 0.77, specificity of 0.75 and AUROC of 0.76. The accuracy was superior to the ablated approach (McNemar's test p<0.001). Conclusion This proof-of-concept study suggests LLM-driven sentiment analysis, especially with prompt engineering, may facilitate FM diagnosis by detecting subtle differences in pain expression. Further validation is warranted, particularly the inclusion of secondary FM patients.  © 2024 BMJ Publishing Group. All rights reserved.",Yes,Sully,,,,,,,,,,
Artificial intelligence knowledge of evidence-based recommendations in gender affirmation surgery and gender identity: is ChatGPT aware of WPATH recommendations?,"Background: Artificial intelligence (AI) is evolving rapidly as are its uses in healthcare and scientific literature. There are concerns about whether AI like ChatGPT has implicit biases. This study explores ChatGPT’s ability to reference evidence-based recommendations related to gender-affirming surgery (GAS). Methods: ChatGPT was prompted using open-ended questions on GAS as well as the World Professional Association for Transgender Health Standards of Care (WPATH SOC) for the Health of Transgender and Gender Diverse People, Version 8’s statements of recommendations. Responses were analyzed based on agreement to and reference of WPATH SOC recommendations. Results: A total of 95 WPATH statements of recommendations were given to the chatbot. There were 70 (74%) agreements, 0 (0%) disagreements, and 25 (26%) neutral responses. WPATH was directly referenced in 12 (13%) responses. ChatGPT was successful in describing aspects of gender diversity, including the treatment of gender dysphoria. Conclusions: While often using neutral language, ChatGPT does intermittently reference WPATH and its evidence-based recommendations. As AI evolves, so can the spread of misinformation if it is not rooted in evidence-based recommendations. Furthermore, AI may serve as a viable tool for patient education on GAS. Level of evidence: Not gradable © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",Yes,Sully,,,,,,,,,,
Letter to the editor re: evaluating Microsoft Bing with ChatGPT-4 for the assessment of abdominal computed tomography and magnetic resonance imaging,,No,Sully,,,,,,,,,,
Promise and Perils of Large Language Models for Cancer Survivorship and Supportive Care,"2298. J Clin Oncol. 2024 May 10;42(14):1607-1611. doi: 10.1200/JCO.23.02439. Epub 2024 
Mar 7.

Promise and Perils of Large Language Models for Cancer Survivorship and 
Supportive Care.

Bitterman DS(1)(2), Downing A(3), Maués J(4), Lustberg M(5).

Author information:
(1)Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, 
Harvard Medical School, Boston, MA.
(2)Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber 
Cancer Institute, Boston, MA.
(3)The Light Collective, Eugene, OR.
(4)GRASP, Washington, DC.
(5)Department of Medical Oncology, Yale School of Medicine, New Haven, CT.

A call to action to bring stakeholders together to plan for the future of 
LLM-enhanced cancer survivorship.",No,Sully,,,,,,,,,,
LLMs get a medical education,A large language model designed to give high-quality answers to medical questions outperforms previous iterations — but remains inferior to clinicians.,No,Sully,,,,,,,,,,
Evaluating the Alignment of Artificial Intelligence-Generated Recommendations With Clinical Guidelines Focused on Soft Tissue Tumors,"Background: The integration of artificial intelligence (AI), particularly, in oncology, has significantly shifted the paradigms of medical diagnostics and treatment planning. However, the utility of AI, specifically OpenAI's ChatGPT, in soft tissue sarcoma treatment, remains unclear. Methods: We evaluated ChatGPT's alignment with the Japanese Orthopaedic Association (JOA) clinical practice guidelines on the management of soft tissue tumors 2020. Twenty-two clinical questions (CQs) were formulated to encompass various aspects of sarcoma diagnosis, treatment, and management. ChatGPT's responses were classified into “Complete Alignment,” “Partial Alignment,” or “Nonalignment” based on the recommendation and strength of evidence. Results: ChatGPT demonstrated an 86% alignment rate with the JOA guidelines. The AI provided two instances of complete alignment and 17 instances of partial alignment, indicating a strong capability to match guideline criteria for most questions. However, three discrepancies were identified in areas concerning the treatment of atypical lipomatous tumors, perioperative chemotherapy for synovial sarcoma, and treatment strategies for elderly patients with malignant soft tissue tumors. Reassessment with guideline input led to some adjustments, revealing both the potential and limitations of AI in complex sarcoma care. Conclusion: Our study demonstrates that AI, specifically ChatGPT, can align with clinical guidelines for soft tissue sarcoma treatment. It also underscores the need for continuous refinement and cautious integration of AI in medical decision-making, particularly in the context of treatment for soft tissue sarcoma. © 2024 Wiley Periodicals LLC.",Yes,Sully,,,,,,,,,,
Prompt Design for Medical Question Answering with Large Language Models,"Large language models (LLMs) are increasingly being evaluated in the medical domain. Given the lack of datasets and difficulties evaluating outputs represented by free text, datasets with multiple-choice questions are often used for such studies. We evaluated six large LLMs (belonging to LLM families such as Claude 3.5 Sonnet, Gemini 1.5-pro, Llama 3.1, Mistral) and six smaller models(originating from families such as Gemma 2B, Mistral Nemo, Llama 3.1, Gemini 1.5-flash) across five prompting techniques on neuro-oncology exam questions. Using the established MedQA datasetand a novel neuro-oncology question set, we compared basic prompting, chain-of-thought reasoning, and more complex agent-based methods incorporating external search capabilities. Results showedthat the Reasoning and Acting (ReAct) approach combined with giving LLM access to Google Search performed best on large models like Claude 3.5 Sonnet (81.7% accuracy). However, the performanceof prompting techniques varies across different foundational models. While large models significantly outperformed smaller open-source ones on the MedQA dataset (79.3% vs 51.2% accuracy), complexagentic patterns like Language Agent Tree Search provided minimal benefits despite 5x higher latency. We recommend practitioners keep experimenting with various techniques given their specific usecase and a chosen foundational model and favor simple prompting patterns with large models, as they offer the best balance of accuracy and efficiency.",Yes,Sully,,,,,,,,,,
The application of Chat Generative Pre-trained Transformer in nursing education,"Background: Nursing education is critical for nurses to deliver quality health care. Incorporating AI into education can enhance the learning process and better equip nurses for their health care roles. Purpose: This article explores the potential applications and challenges of ChatGPT in nursing education. Methods: A comprehensive literature review was conducted to explore the potential benefits and challenges of using ChatGPT in nursing education. Discussion: ChatGPT, an advanced large language model, has the potential to make valuable contributions to nursing education in various ways, including personalized learning, simulation scenarios, immediate feedback, and reducing educator workload. However, it is important to address the various challenges and limitations in order to realize its full potential. Conclusion: Nursing educators must carefully consider the potential uses, benefits, challenges, drawbacks, and limitations of ChatGPT to make informed decisions about its integration into nursing education. © 2023 Elsevier Inc.",No,Sully,,,,,,,,,,
Direct-acting antivirals (DAA) positively affect depression and cognitive function in patients with chronic hepatitis C,"3712. PLoS One. 2025 Apr 4;20(4):e0320221. doi: 10.1371/journal.pone.0320221. 
eCollection 2025.

Direct-acting antivirals (DAA) positively affect depression and cognitive 
function in patients with chronic hepatitis C.

Pawłowski T(1), Radkowski M(2), Perlejewski K(2), Szymańska B(3), Berak H(3), 
Horban A(4), Laskus T(4).

Author information:
(1)Department of Psychiatry, Wrocław Medical University, Wrocław, Poland.
(2)Department of Immunopathology of Infectious and Parasitic Diseases, Medical 
University of Warsaw, Warsaw, Poland.
(3)Outpatient Clinic, Warsaw Hospital for Infectious Diseases, Warsaw, Poland.
(4)Department of Adult Infectious Diseases, Medical University of Warsaw, 
Warsaw, Poland.

The aim of the study was to determine how depression and cognitive dysfunction 
in patients with chronic hepatitis C virus (HCV) infection are affected by 
treatment with direct-acting antivirals (DAA). Fifty-two chronic hepatitis C 
patients underwent neurocognitive and psychological evaluation before therapy 
and 5-6 months later. Depression was measured by Beck Depression Inventory 
(BDI), anxiety by State-Trait Anxiety inventory (STAI), neuroticism by Eysenck 
Personality Inventory (N/EPO-R), while Ruff Figural Fluency Test (RFFT), 
Wisconsin Card Sorting Test (WCST), The Grooved Pegboard Test (GPT), and 
California Verbal Learning Test (CVLT) were used to assess neurocognitive 
function. There was significant positive change in BDI scores (8.8 ± 6.6 vs 
6.1 ± 6.1; p < 0.0001) while the most striking improvement in cognitive tests 
was observed for CVLT sum of immediate recall from Trial-1 to Trial-5 
(50.9 ± 10.0 to 54.1 ± 10.0; p = 0.0005) and RFFT, where the number of unique 
designs increased from 77.2 ± 21.0 to 86.1 ± 28.3 (p < 0.0001). These 
differences remained significant when patients with advanced (METAVIR grade 
F3/F4) and those with mild (grade F0/F1/F2) liver disease were analyzed 
separately, although in general the improvements were more pronounced in the 
former group. In conclusion, in chronic HCV infection the brain function is 
markedly improved by DAA treatment.

Copyright: © 2025 Pawłowski et al. This is an open access article distributed 
under the terms of the Creative Commons Attribution License, which permits 
unrestricted use, distribution, and reproduction in any medium, provided the 
original author and source are credited.",No,Sully,,,,,,,,,,
Role of artificial intelligence-powered conversational agents (chatbots) in musculoskeletal disorders: A scoping review protocol,"Introduction Musculoskeletal disorders (MSDs) represent a significant global health burden that leads to substantial disability with socioeconomic impact. With the rise of artificial intelligence (AI), particularly large language model-driven conversational agents (chatbots), there is potential to enhance the management of MSDs. However, the application of AI-powered chatbots in this population has not been comprehensively synthesised. Therefore, this scoping review aims to explore the current and potential use of AI-powered chatbots in managing MSDs. The review will map out the targeted diseases, the purposes of chatbot interventions, the clinical tools or frameworks used in training these systems and the evaluated outcomes in clinical settings. Methods and analysis This scoping review will follow the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews guidelines, with a comprehensive search across multiple databases, including Medline (Ovid Medline), Embase (Ovid), ISI Web of Science (Clarivate) and ClinicalTrials.gov. We will include studies involving adults with MSDs, regardless of publication status, language or year. The scoping review will exclude studies using non-AI chatbots or human health coaches. Data extraction and synthesis will focus on demographic characteristics, chatbot methods, outcomes and thematic analysis. Ethics and dissemination Formal ethical approval is not required as this study involves neither human participants nor unpublished secondary data. The findings of this scoping review will be disseminated through professional networks, conference presentations and publication in a scientific journal.  © Author(s) (or their employer(s)) 2025.",No,Sully,,,,,,,,,,
RDguru: A Conversational Intelligent Agent for Rare Diseases,"Large language models (LLMs) hold significant promise in clinical practice, yet their real-world adoption is constrained by their propensity to produce erroneous and occasionally harmful outputs, particularly in the intricate domain of rare diseases (RDs). This study introduces RDguru, a conversational intelligent agent leveraging the LangChain framework and powered by GPT-3.5-turbo. RDguru offers a comprehensive suite of functionalities, encompassing evidence-traceable knowledge Q&A and professional medical consultations for differential diagnosis (DDX), integrating authoritative knowledge sources and reliable tools. A novel multi-source fusion diagnostic model, rooted in deep Q-network, amalgamates three diagnostic recommendation strategies (GPT-4, PheLR, and phenotype matching) to enhance diagnostic recall during medical consultations. Through tailored tools and advanced algorithms for retrieval-augmented generation, RDguru excels in knowledge Q&A, automated phenotype annotation, and RD DDX. A multi-aspect Q&A analysis demonstrates RDguru outperforms ChatGPT in generating descriptions aligned with authoritative knowledge, quantified by ROUGE scores, GPT-4-based automatic rating, and RAGAs evaluation metrics. Testing on 238 published RD cases reveals that RDguru's top 5 multi-source fusion diagnoses recapture 63.87% of actual diagnoses, marking a 5.47% improvement over the state-of-the-art diagnostic method PheLR. Furthermore, RDguru's consultation strategy proves effective in eliciting diagnostically beneficial phenotypes and refining the prioritization of genuine diagnoses through multi-round phenotype-orient questioning. Evaluations against established benchmarks and real-world patient data demonstrate RDguru's efficacy and reliability, highlighting its potential to enhance clinical decision-making in the realm of RDs.  © 2013 IEEE.",Yes,Sully,,,,,,,,,,
Quality of Large Language Model Responses to Radiation Oncology Patient Care Questions,"Importance: Artificial intelligence (AI) large language models (LLMs) demonstrate potential in simulating human-like dialogue. Their efficacy in accurate patient-clinician communication within radiation oncology has yet to be explored. Objective: To determine an LLM's quality of responses to radiation oncology patient care questions using both domain-specific expertise and domain-agnostic metrics. Design, Setting, and Participants: This cross-sectional study retrieved questions and answers from websites (accessed February 1 to March 20, 2023) affiliated with the National Cancer Institute and the Radiological Society of North America. These questions were used as queries for an AI LLM, ChatGPT version 3.5 (accessed February 20 to April 20, 2023), to prompt LLM-generated responses. Three radiation oncologists and 3 radiation physicists ranked the LLM-generated responses for relative factual correctness, relative completeness, and relative conciseness compared with online expert answers. Statistical analysis was performed from July to October 2023. Main Outcomes and Measures: The LLM's responses were ranked by experts using domain-specific metrics such as relative correctness, conciseness, completeness, and potential harm compared with online expert answers on a 5-point Likert scale. Domain-agnostic metrics encompassing cosine similarity scores, readability scores, word count, lexicon, and syllable counts were computed as independent quality checks for LLM-generated responses. Results: Of the 115 radiation oncology questions retrieved from 4 professional society websites, the LLM performed the same or better in 108 responses (94%) for relative correctness, 89 responses (77%) for completeness, and 105 responses (91%) for conciseness compared with expert answers. Only 2 LLM responses were ranked as having potential harm. The mean (SD) readability consensus score for expert answers was 10.63 (3.17) vs 13.64 (2.22) for LLM answers (P <.001), indicating 10th grade and college reading levels, respectively. The mean (SD) number of syllables was 327.35 (277.15) for expert vs 376.21 (107.89) for LLM answers (P =.07), the mean (SD) word count was 226.33 (191.92) for expert vs 246.26 (69.36) for LLM answers (P =.27), and the mean (SD) lexicon score was 200.15 (171.28) for expert vs 219.10 (61.59) for LLM answers (P =.24). Conclusions and Relevance: In this cross-sectional study, the LLM generated accurate, comprehensive, and concise responses with minimal risk of harm, using language similar to human experts but at a higher reading level. These findings suggest the LLM's potential, with some retraining, as a valuable resource for patient queries in radiation oncology and other medical fields.. © 2024 American Medical Association. All rights reserved.",Yes,Sully,,,,,,,,,,
Manual medicine in the outpatient PM&R practice: a scoping review; [Manuelle Medizin in der ambulanten PRM-Praxis: ein Scoping Review],"Background: Specialists in physical medicine and rehabilitation (PM&R) also work in private practice. The aim of this study was to describe the field of activity of colleagues in private practice and to identify published literature on this subject. Materials and methods: The PubMed database was searched using common specialist terms in various combinations. In a second step, ChatGPT was queried for possible content. Finally, a manual search was carried out in Google Scholar. Results: The database search in PubMed did not yield any exact matches. In addition to general publications such as position papers and consensus statements, no papers could be selected that met the content requirements. ChatGPT was unable to generate any hits. Only the manual search via Google Scholar yielded three hits after excluding duplicates. Discussion: General practitioners specializing in PM&R frequently use manual medicine. The field of activity ranges from acute treatment of isolated functional disorders to long-term or permanent care of handicapped or pain patients. It is possible that PM&R practices can be the point of contact and coordinating center for multiprofessional teams and can therefore manage rehabilitative processes across the entire lifespan and social environment. Adequate funding is not possible via manual medical reimbursement items. Conclusion: The treatment spectrum in PM&R practices is broad and diverse. The manual medical care of patients is of great importance. The legislator is called upon to provide adequate financial compensation to take this into account. © The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, ein Teil von Springer Nature 2024.",No,Sully,,,,,,,,,,
Can ChatGPT4-vision identify radiologic progression of multiple sclerosis on brain MRI?,"Background: The large language model ChatGPT can now accept image input with the GPT4-vision (GPT4V) version. We aimed to compare the performance of GPT4V to pretrained U-Net and vision transformer (ViT) models for the identification of the progression of multiple sclerosis (MS) on magnetic resonance imaging (MRI). Methods: Paired coregistered MR images with and without progression were provided as input to ChatGPT4V in a zero-shot experiment to identify radiologic progression. Its performance was compared to pretrained U-Net and ViT models. Accuracy was the primary evaluation metric and 95% confidence interval (CIs) were calculated by bootstrapping. We included 170 patients with MS (50 males, 120 females), aged 21–74 years (mean 42.3), imaged at a single institution from 2019 to 2021, each with 2–5 MRI studies (496 in total). Results: One hundred seventy patients were included, 110 for training, 30 for tuning, and 30 for testing; 100 unseen paired images were randomly selected from the test set for evaluation. Both U-Net and ViT had 94% (95% CI: 89–98%) accuracy while GPT4V had 85% (77–91%). GPT4V gave cautious nonanswers in six cases. GPT4V had precision (specificity), recall (sensitivity), and F1 score of 89% (75–93%), 92% (82–98%), 91 (82–97%) compared to 100% (100–100%), 88 (78–96%), and 0.94 (88–98%) for U-Net and 94% (87–100%), 94 (88–100%), and 94 (89–98%) for ViT. Conclusion: The performance of GPT4V combined with its accessibility suggests has the potential to impact AI radiology research. However, misclassified cases and overly cautious non-answers confirm that it is not yet ready for clinical use. Relevance statement: GPT4V can identify the radiologic progression of MS in a simplified experimental setting. However, GPT4V is not a medical device, and its widespread availability highlights the need for caution and education for lay users, especially those with limited access to expert healthcare. Key Points: Without fine-tuning or the need for prior coding experience, GPT4V can perform a zero-shot radiologic change detection task with reasonable accuracy. However, in absolute terms, in a simplified “spot the difference” medical imaging task, GPT4V was inferior to state-of-the-art computer vision methods. GPT4V’s performance metrics were more similar to the ViT than the U-net. This is an exploratory experimental study and GPT4V is not intended for use as a medical device. © The Author(s) 2025.",Yes,Sully,,,,,,,,,,
"Examining the ability of artificial intelligence with ChatGPT-4.0 to create an exercise program: Case scenario examples ""lumbar disc herniation, chronic migraine, and urge urinary incontinence""","Artificial Intelligence (AI) is increasingly utilized in healthcare as wearable technology, virtual assistants, or to aid decision-making. This study evaluates the feasibility, effectiveness, and limitations of AI-based ChatGPT-4.0 in developing 8-week exercise programs for cases with lumbar disc herniation (LDH), chronic migraine (CM), and urge urinary incontinence (UUI). ChatGPT-4.0 was questioned about exercise frequency, intensity, type, duration, targeted muscles, repetitions, theraband strengths, perceived difficulty, and aerobic exercise recommendations. The answers given were evaluated by experts. Expert evaluations determined that ChatGPT-4.0 successfully created literature-based programs for LDH, CM, and UUI, including cervical, lumbar stabilization, and pelvic floor exercises. However, issues arose: theraband resistances and plank-like challenging exercises for LDH were introduced too early, potentially causing rapid progression. In CM, isometric exercises risk triggering attacks, and progression rates were accelerated in all cases. These findings highlight ChatGPT-4.0’s inability to fully adapt programs to patient medical conditions, emphasizing the critical role of physical therapists in designing individualized exercise programs.",Yes,Sully,,,,,,,,,,
Engineering Students’ Use of Large Language Model Tools: An Empirical Study Based on a Survey of Students from 12 Universities,"Large language model (LLM) tools, such as ChatGPT, are rapidly transforming engineering education by enhancing tasks like information retrieval, coding, and writing refinement, which are critical to the problem-solving and technical focus of engineering disciplines. This study investigates how engineering students use LLM tools and the challenges they face, offering insights into the adoption of AI technologies in academic settings. A survey of 539 engineering students from 12 leading Chinese universities, using the UTAUT framework, examines factors such as technological expectations, environmental support, and personal characteristics. The key findings include the following: (1) Over 40% of engineering students use LLM tools, with 18.8% regarding them as indispensable. (2) Trust in AI-generated content remains a central challenge, as students must critically evaluate its accuracy and reliability. (3) Environmental support significantly affects usage, with notable regional disparities, particularly between eastern and other regions in China. (4) A persistent digital divide, influenced by gender, academic level, and socioeconomic background, affects the depth and effectiveness of tool use. These results underscore the need for targeted support to address regional and demographic disparities and optimize LLM tool integration in engineering education. © 2025 by the authors.",No,Sully,,,,,,,,,,
"Comparative analysis of the anti-depression effects of lorazepam, acupuncture, and curcumin utilizing the forced swimming test in experimental rats models; [Análisis comparativo de los efectos antidepresivos del lorazepam, la acupuntura y la curcumina utilizando la prueba de natación forzada en modelos experimentales de ratas]","Introduction: lorazepam is one of benzodiazepine medication that is usually used for its sedative and anxiolytic effect and has anti-depressant like effects. Turmeric is a plant that contain curcumin as main active compound that exert its antidepressant action inhibit monoamine oxidase and increase levels of dopamine and serotonin in brain. Aim: the present study investigate the depression effect of curcumin (natural selective serotonin inhibitors) in comparison with acupuncture and lorazepam. Method: 32 adult rats weighing (150 g−280 g) were divided equally into 8 groups each group contain 4 rats. The first 3 group of rats were treated with lorazepam, mixture of (curcumin, black pepper and olive oil) and pricked with insulin needle at point gb39, respectively, while second 4 groups of rats were received lorazepam and mixture, lorazepam and acupuncture, mixture and acupuncture, and lorazepam, mixture and acupuncture, separately, and the eighth group is control group don't receive any drugs. After 35 days, forced swimming test was made for all rats. Results: Liver parameters: - GOT increased in all group, GPT increased in rat's group that received lorazepam, mixture group and lorazepam + mixture group, This indicates the existence of problems previously with the liver of the rat used, and what remains is the high levels of GOT and GPT in the control group, while TSB is within the normal range for all groups. Kidney parameters:-blood urea levels increased in all groups and S. creatinine levels within normal range for all groups. Conclusion: the evaluation of natural SERMs in the forced swimming test showed promising antidepressant-like effects, comparable to lorazepam and acupuncture. Further research is needed to understand the mechanisms and determine optimal dosage and safety. Natural selective serotonin inhibitors hold potential as alternative or complementary treatments for depression. © 2023",No,Sully,,,,,,,,,,
Exploring the Potential of Code-Free Custom GPTs in Ophthalmology: An Early Analysis of GPT Store and User-Creator Guidance,"Introduction: OpenAI recently introduced the ability to create custom generative pre-trained transformers (cGPTs) using text-based instruction and/or external documents using retrieval-augmented generation (RAG) architecture without coding knowledge. This study aimed to analyze the features of ophthalmology-related cGPTs and explore their potential utilities. Methods: Data collection took place on January 20 and 21, 2024, and custom GPTs were found by entering ophthalmology keywords into the “Explore GPTS” section of the website. General and specific features of cGPTs were recorded, such as knowledge other than GPT-4 training data. The instruction and description sections were analyzed for compatibility using the Likert scale. We analyzed two custom GPTs with the highest Likert score in detail. We attempted to create a convincingly presented yet potentially harmful cGPT to test safety features. Results: We analyzed 22 ophthalmic cGPTs, of which 55% were for general use and the most common subspecialty was glaucoma (18%). Over half (55%) contained knowledge other than GPT-4 training data. The representation of the instructions through the description was between “Moderately representative” and “Very representative” with a median Likert score of 3.5 (IQR 3.0–4.0). The instruction word count was significantly associated with Likert scores (P = 0.03). Tested cGPTs demonstrated potential for specific conversational tone, information, retrieval and combining knowledge from an uploaded source. With these safety settings, creating a malicious GPT was possible. Conclusions: This is the first study to our knowledge to examine the GPT store for a medical field. Our findings suggest that these cGPTs can be immediately implemented in practice and may offer more targeted and effective solutions compared to the standard GPT-4. However, further research is necessary to evaluate their capabilities and limitations comprehensively. The safety features currently appear to be rather limited. It may be helpful for the user to review the instruction section before using a cGPT. © The Author(s) 2024.",Yes,Sully,,,,,,,,,,
Development and Preliminary Evaluation of Remote Pacemaker Monitoring System Using Large Language Model,"A remote monitoring system that periodically transmits information stored in the pacemaker from patients' homes to a hospital is now in widespread use. However, the system requires access to the vendor's cloud server via a browser and consists of date-by-date PDF files, making the creation of aggregate data a significant burden. Since the release of commercially available systems such as ChatG PT, various large language models (LLMs) have been widely used, leading to that semantic search, which can perform searches that take into account the meaning of language, has attracted attention. In this study, we constructed an LLM - based remote monitoring system. Then, as a preliminary evaluation, we examined its effectiveness for RM operations based on the accuracy of RM data aggregation and work time. © 2024 IEEE.",No,Sully,,,,,,,,,,
DrugAssist: a large language model for molecule optimization,"Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through human-machine dialogue by leveraging LLM's strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense potential in transferability and iterative optimization. In addition, we publicly release a large instruction-based dataset called 'MolOpt-Instructions' for fine-tuning language models on molecule optimization tasks. We have made our code and data publicly available at https://github.com/blazerye/DrugAssist, which we hope to pave the way for future research in LLMs' application for drug discovery.",No,Sully,,,,,,,,,,
Bailando++: 3D Dance GPT With Choreographic Memory,"Our proposed music-to-dance framework, Bailando++, addresses the challenges of driving 3D characters to dance in a way that follows the constraints of choreography norms and maintains temporal coherency with different music genres. Bailando++ consists of two components: a choreographic memory that learns to summarize meaningful dancing units from 3D pose sequences, and an actor-critic Generative Pre-trained Transformer (GPT) that composes these units into a fluent dance coherent to the music. In particular, to synchronize the diverse motion tempos and music beats, we introduce an actor-critic-based reinforcement learning scheme to the GPT with a novel beat-align reward function. Additionally, we consider learning human dance poses in the rotation domain to avoid body distortions incompatible with human morphology, and introduce a musical contextual encoding to allow the motion GPT to grasp longer-term patterns of music. Our experiments on the standard benchmark show that Bailando++ achieves state-of-the-art performance both qualitatively and quantitatively, with the added benefit of the unsupervised discovery of human-interpretable dancing-style poses in the choreographic memory.",No,Sully,,,,,,,,,,
Benchmarking open-source large language models on Portuguese Revalida multiple-choice questions,"Objective The study aimed to evaluate the top large language models (LLMs) in validated medical knowledge tests in Portuguese. Methods This study compared 31 LLMs in the context of solving the national Brazilian medical examination test. The research compared the performance of 23 open-source and 8 proprietary models across 399 multiple-choice questions. Results Among the smaller models, Llama 3 8B exhibited the highest success rate, achieving 53.9%, while the medium-sized model Mixtral 8×7B attained a success rate of 63.7%. Conversely, larger models like Llama 3 70B achieved a success rate of 77.5%. Among the proprietary models, GPT-4o and Claude Opus demonstrated superior accuracy, scoring 86.8% and 83.8%, respectively. Conclusions 10 out of the 31 LLMs attained better than human level of performance in the Revalida benchmark, with 9 failing to provide coherent answers to the task. Larger models exhibited superior performance overall. However, certain medium-sized LLMs surpassed the performance of some of the larger LLMs.  © Author(s) (or their employer(s)) 2025. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ Group.",Yes,Sully,,,,,,,,,,
AI in obstetrics: Evaluating residents’ capabilities and interaction strategies with ChatGPT,"In line with the digital transformation trend in medical training, students may resort to artificial intelligence (AI) for learning. This study assessed the interaction between obstetrics residents and ChatGPT during clinically oriented summative evaluations related to acute hepatic steatosis of pregnancy, and their self-reported competencies in information technology (IT) and AI. The participants in this semi-qualitative observational study were 14 obstetrics residents from two university hospitals. Students’ queries were categorized into three distinct types: third-party enquiries; search-engine-style queries; and GPT-centric prompts. Responses were compared against a standardized answer produced by ChatGPT with a Delphi-developed expert prompt. Data analysis employed descriptive statistics and correlation analysis to explore the relationship between AI/IT skills and response accuracy. The study participants showed moderate IT proficiency but low AI proficiency. Interaction with ChatGPT regarding clinical signs of acute hepatic steatosis gravidarum revealed a preference for third-party questioning, resulting in only 21% accurate responses due to misinterpretation of medical acronyms. No correlation was found between AI response accuracy and the residents’ self-assessed IT or AI skills, with most expressing dissatisfaction with their AI training. This study underlines the discrepancy between perceived and actual AI proficiency, highlighted by clinically inaccurate yet plausible AI responses – a manifestation of the ’stochastic parrot’ phenomenon. These findings advocate for the inclusion of structured AI literacy programmes in medical education, focusing on prompt engineering. These academic skills are essential to exploit AI's potential in obstetrics and gynaecology. The ultimate aim is to optimize patient care in AI-augmented health care, and prevent misleading and unsafe knowledge acquisition. © 2024 The Author(s)",No,Sully,,,,,,,,,,
The role of artificial intelligence in emergency medicine pharmacy practice,"DISCLAIMER: In an effort to expedite the publication of articles, AJHP is posting manuscripts online as soon as possible after acceptance. Accepted manuscripts have been peer-reviewed and copyedited, but are posted online before technical formatting and author proofing. These manuscripts are not the final version of record and will be replaced with the final article (formatted per AJHP style and proofed by the authors) at a later time. PURPOSE: This primer aims to serve as a foundational resource on artificial intelligence (AI) for pharmacists practicing in the emergency department (ED). SUMMARY: Artificial intelligence (AI) is increasingly recognized for its potential to transform healthcare, including emergency medicine (EM) and pharmacy practice. AI applications in EM include diagnostic evaluation, risk stratification, resource optimization, and therapeutic decision-making. AI's role in improving triage, diagnostics, and resource utilization in the emergency setting is discussed along with its application in the medication-use process, from prescribing to monitoring. Despite the promise of AI, significant barriers such as factual inaccuracies, ethical concerns, and data transparency prevent the widespread clinical adoption of AI tools. Challenges such as racial bias, data privacy, model transparency, and the phenomenon of hallucinations in large language model outputs are highlighted as critical considerations. AI's future success in EM will depend on responsible integration, guided by clinicians including pharmacists, and a careful consideration of ethical issues and patient-specific values. CONCLUSION: Pharmacists practicing in the ED should be familiar with AI tools and should understand the importance of their role in the development, implementation, and oversight of these tools to ensure safe, effective, and equitable patient care.",No,Sully,,,,,,,,,,
Using ChatGPT to Generate Research Ideas in Dysphagia: A Pilot Study,"2252. Dysphagia. 2024 Jun;39(3):407-411. doi: 10.1007/s00455-023-10623-9. Epub 2023 
Oct 31.

Using ChatGPT to Generate Research Ideas in Dysphagia: A Pilot Study.

Nachalon Y(1)(2), Broer M(3), Nativ-Zeltzer N(3).

Author information:
(1)Department of Otolaryngology, Head and Neck Surgery and Maxillofacial 
Surgery, Tel-Aviv Sourasky Medical Center, 6 Weizman Street, 6423906, Tel-Aviv, 
Israel. yuval.nachalon@gmail.com.
(2)Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel. 
yuval.nachalon@gmail.com.
(3)Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.

Current research in dysphagia faces challenges due to the rapid growth of 
scientific literature and the interdisciplinary nature of the field. To address 
this, the study evaluates ChatGPT, an AI language model, as a supplementary 
resource to assist clinicians and researchers in generating research ideas for 
dysphagia, utilizing recent advancements in natural language processing and 
machine learning. The research ideas were generated through ChatGPT's command to 
explore diverse aspects of dysphagia. A web-based survey was conducted, 45 
dysphagia experts were asked to rank each study on a scale of 1 to 5 according 
to feasibility, novelty, clinical implications, and relevance to current 
practice. A total of 26 experts (58%) completed the survey. The mean (± sd) 
rankings of research ideas were 4.03 (± 0.17) for feasibility, 3.5 (± 0.17) for 
potential impact on the field, 3.84 (± 0.12) for clinical relevance, and 3.08 
(± 0.36) for novelty and innovation. Results of this study suggest that ChatGPT 
offers a promising approach to generating research ideas in dysphagia. While its 
current capability to generate innovative ideas appears limited, it can serve as 
a supplementary resource for researchers.

© 2023. The Author(s), under exclusive licence to Springer Science+Business 
Media, LLC, part of Springer Nature.",No,Sully,,,,,,,,,,
ChatGPT as a Virtual Patient: Written Empathic Expressions During Medical History Taking,"Objective: Virtual patients are already utilized in the teaching of medical history taking. Since its emergence, ChatGPT has been integrated into several areas of medical education. This study aimed to examine whether ChatGPT can be used to train empathic history taking while fostering students’ subjective autonomy. Methods: Third-year medical students took histories with ChatGPT 3.5 after entering a predefined prompt covering cardiological diseases. Afterwards, students answered a questionnaire regarding their experienced autonomy. All chats were analyzed using the Empathic Communication Coding System measuring ChatGPT’s given empathic opportunities as well as students’ responses. Results: Out of 659 interactions, 93 were identified as empathic. ChatGPT provided opportunities mostly through reporting emotional statements or challenges. Students sometimes missed reacting adequately to ChatGPT’s opportunities but more often responded by implicit recognition of patient perspective and reported a high level of experienced autonomy. Conclusions: The study yielded preliminary results that ChatGPT might be suitable as a tool mimicking a virtual patient while enabling an empathic history taking. To date, ChatGPT seems valid as a supplement to training with simulated patients. Medical faculty could consider integrating ChatGPT into teaching, such as through a flipped classroom approach, to guide students in its use as ChatGPT continues to gain attention. © The Author(s) 2025.",No,Sully,,,,,,,,,,
Evaluating Use of Generative Artificial Intelligence in Clinical Pathology Practice Opportunities and the Way Forward,"• Context.—Generative artificial intelligence (GAI) technologies are likely to dramatically impact health care workflows in clinical pathology (CP). Applications in CP include education, data mining, decision support, result summaries, and patient trend assessments. Objective.—To review use cases of GAI in CP, with a particular focus on large language models. Specific examples are provided for the applications of GAI in the subspecialties of clinical chemistry, microbiology, hematopathology, and molecular diagnostics. Additionally, the review addresses potential pitfalls of GAI paradigms. Data Sources.—Current literature on GAI in health care was reviewed broadly. The use case scenarios for each CP subspecialty review common data sources generated in each subspecialty. The potential for utilization of CP data in the GAI context was subsequently assessed, focusing on issues such as future reporting paradigms, impact on quality metrics, and potential for translational research activities. Conclusions.—GAI is a powerful tool with the potential to revolutionize health care for patients and practitioners alike. However, GAI must be implemented with much caution considering various shortcomings of the technology such as biases, hallucinations, practical challenges of implementing GAI in existing CP workflows, and end-user acceptance. Human-in-the-loop models of GAI implementation have the potential to revolutionize CP by delivering deeper, meaningful insights into patient outcomes both at an individual and a population level. © 2025 College of American Pathologists. All rights reserved.",No,Sully,,,,,,,,,,
Editorial Commentary: ChatGPT Has the Potential to Be an Important Patient Education Tool and May Outperform Google,"1549. Arthroscopy. 2025 Mar;41(3):598-599. doi: 10.1016/j.arthro.2024.07.005. Epub 
2024 Jul 17.

Editorial Commentary: ChatGPT Has the Potential to Be an Important Patient 
Education Tool and May Outperform Google.

Sinkler MA(1), Li LT(1), Adelstein JM(1), Strony JT(1).

Author information:
(1)University Hospitals, Cleveland Medical Center.

With the growing popularity of artificial intelligence, more patients will begin 
to turn to chatbots such as ChatGPT for medical information. Recent research has 
shown that ChatGPT and Google can both provide accurate responses to 
numeric-based questions; ChatGPT bases its answers on more trustworthy, academic 
sources than Google, and the 2 tools have little overlap when queried to 
generate a list of frequently asked questions. Patients should use ChatGPT 
cautiously. The chatbot can struggle to generate appropriate responses to 
questions regarding patient-specific factors. Fortunately, many institutions 
offer evidence-based websites that provide quality information. However, if 
these sites do not address a specific patient's question, ChatGPT has the 
potential to be a powerful tool. Of importance, unlike Google, ChatGPT 
consistently provides patients with a reminder that they should follow up with a 
licensed medical provider to address their questions and concerns related to a 
topic.

Copyright © 2024 Arthroscopy Association of North America. Published by Elsevier 
Inc. All rights reserved.",No,Sully,,,,,,,,,,
Embracing the future—is artificial intelligence already better? A comparative study of artificial intelligence performance in diagnostic accuracy and decision-making,"Background and purpose: The integration of artificial intelligence (AI) in healthcare has the potential to revolutionize patient care and clinical decision-making. This study aimed to explore the reliability of large language models in neurology by comparing the performance of an AI chatbot with neurologists in diagnostic accuracy and decision-making. Methods: A cross-sectional observational study was conducted. A pool of clinical cases from the American Academy of Neurology's Question of the Day application was used as the basis for the study. The AI chatbot used was ChatGPT, based on GPT-3.5. The results were then compared to neurology peers who also answered the questions—a mean of 1500 neurologists/neurology residents. Results: The study included 188 questions across 22 different categories. The AI chatbot demonstrated a mean success rate of 71.3% in providing correct answers, with varying levels of proficiency across different neurology categories. Compared to neurology peers, the AI chatbot performed at a similar level, with a mean success rate of 69.2% amongst peers. Additionally, the AI chatbot achieved a correct diagnosis in 85.0% of cases and it provided an adequate justification for its correct responses in 96.1%. Conclusions: The study highlights the potential of AI, particularly large language models, in assisting with clinical reasoning and decision-making in neurology and emphasizes the importance of AI as a complementary tool to human expertise. Future advancements and refinements are needed to enhance the AI chatbot's performance and broaden its application across various medical specialties. © 2024 The Authors. European Journal of Neurology published by John Wiley & Sons Ltd on behalf of European Academy of Neurology.",Yes,Sully,,,,,,,,,,
Near-infrared and hysteroscopy-guided robotic excision of uterine isthmocele with laser fiber: a novel high-precision technique,"3932. Fertil Steril. 2023 Nov;120(5):1081-1083. doi: 10.1016/j.fertnstert.2023.08.006. 
Epub 2023 Aug 9.

Near-infrared and hysteroscopy-guided robotic excision of uterine isthmocele 
with laser fiber: a novel high-precision technique.

Walker Z(1), Gargiulo A(2).

Author information:
(1)Division of Reproductive Endocrinology and Infertility, Department of 
Obstetrics, Gynecology, and Reproductive Biology, Brigham & Women's Hospital, 
Harvard Medical School, Boston, Massachusetts. Electronic address: 
zwalker1@bwh.harvard.edu.
(2)Division of Reproductive Endocrinology and Infertility, Department of 
Obstetrics, Gynecology, and Reproductive Biology, Brigham & Women's Hospital, 
Harvard Medical School, Boston, Massachusetts.

OBJECTIVE: To describe a novel high-precision technique for robotic excision of 
uterine isthmocele, employing a carbon dioxide laser fiber, under hysteroscopic 
guidance, and near-infrared guidance.
DESIGN: Video article.
PATIENT(S): A 36-year-old multipara with 3 prior cesarean sections presented to 
our infertility clinic with secondary infertility. The patient had been trying 
to conceive for 6 months without success. The patient underwent a 
hystero-salpingo contrast sonography that identified a large cesarean scar 
defect with a 1.4-mm residual myometrial thickness (RMT). The patient was 
counseled on surgical management with robotic approach because of RMT <3 mm 
precluding her from hysteroscopic resection and the potential risk for a 
cesarean scar ectopic or abnormal placentation if she were to become pregnant in 
the future. She elected to undergo excision and repair and informed consent was 
obtained from the patient.
INTERVENTION(S): The robot was docked for traditional gynecologic robotic 
surgery. The uterus was injected with 5 units of vasopressin. We used a carbon 
dioxide laser fiber (Lumenis FIberLase) at a power of 5 watts as the sole energy 
source for dissection. The bladder was dissected off the uterus to identify the 
general area of the isthmocele. At that point, diagnostic hysteroscopy was 
performed using a 30-degree 5-mm hysteroscope (Karl Storz) to identify and enter 
the isthmocele. Near-infrared vision (da Vinci Firefly, Intuitive USA) was 
activated to precisely outline the extent of the isthmocele, which was not 
visible with simple transillumination from the hysteroscope. We proceeded with 
laser excision in infrared/gray scale using the laser at a power of 20 watts 
removing the entire area that was highlighted by the Firefly. After full 
excision of the isthmocele, the hysteroscope was removed and was eventually 
replaced by a uterine manipulator (ConMed VCare DX). The hysterotomy was closed 
with a 2-layer closure: 4 mattress sutures of 2-0 Vicryl (Ethicon) followed by a 
running 2-0 PDS Stratafix (Ethicon). The peritoneal layer was closed over these 
2 layers with 2-0 PDS Stratafix (Ethicon) in a running fashion. The uterine 
manipulator was removed and a 14 French Malecot catheter (Bard) was placed in 
the uterine cavity to allow the healing to proceed with minimal risk of cervical 
stenosis. The bladder was backfilled to ensure integrity of the bladder wall. 
Interceed adhesion barrier (Gynecare) was then placed over the area of the 
repair and the procedure was concluded. The patient included in this video gave 
consent for publication of the video and posting of the video online including 
social media, the journal website, scientific literature websites (such as 
PubMed, ScienceDirect, Scopus, etc.), and other applicable sites.
MAIN OUTCOME MEASURE(S): Completion of excision and repair of cesarean scar 
defect without surgical complications.
RESULT(S): Robotic excision and repair of a sizable uterine isthmocele with 
carbon dioxide laser fiber and da Vinci Firefly was completed successfully 
without any surgical complications. Diagnostic hysteroscopy was used to 
positively identify the isthmocele and provide transillumination. However, the 
thickness of the cervical myometrium only allows the hysteroscopic light to 
shine through the thinnest portion of myometrium at the apex of the isthmocele, 
whereas the near-infrared vision allowed by the da Vinci Firefly technology was 
used to precisely identify the borders of the defect. The carbon dioxide laser 
was used to completely remove the defect while avoiding damage to delicate 
reproductive tissue and over-excision. No complications were identified during 
the postoperative visit. Magnetic resonance imaging 3 months after the surgery 
revealed an RMT of 10 mm at the location of excision compared with the initial 
RMT of 1.4 mm.
CONCLUSION(S): Currently, there is no gold-standard technique for surgical 
management of isthmocele. This is the first description of the combined use of 
hysteroscopy, near-infrared vision, and laser fiber for the robotic excision of 
isthmocele. This specific setup proves to be a useful technical improvement. The 
use of near-infrared vision combined with precise hysteroscopic targeting allows 
much clearer definition of he isthmocele borders, and the flexible laser fiber 
allows millimetric xcision in the absence of appreciable lateral thermal spread. 
Further investigation is warranted to identify a gold-standard surgical 
technique for patients with cesarean scar defect.

Copyright © 2023 American Society for Reproductive Medicine. Published by 
Elsevier Inc. All rights reserved.",No,Sully,,,,,,,,,,
From gene modules to gene markers: an integrated AI-human approach selects CD38 to represent plasma cell-associated transcriptional signatures,"Background: Knowledge-driven prioritization of candidate genes derived from large-scale molecular profiling data for targeted transcriptional profiling assays is challenging due to the vast amount of biomedical literature that needs to be harnessed. We present a workflow leveraging Large Language Models (LLMs) to prioritize candidate genes within module M12.15, a plasma cell-associated module from the BloodGen3 repertoire, by integrating knowledge-driven prioritization with data-driven analysis of transcriptome profiles. Methods: The workflow involves a two-step process: (1) high-throughput screening using LLMs to score and rank the 17 genes of module M12.15 based on six predefined criteria, and (2) prioritization employing high-resolution scoring and fact-checking, with human experts validating and refining AI-generated scores. Results: The first step identified five candidate genes (CD38, TNFRSF17, IGJ, TOP2A, and TYMS). Following human-augmented LLM scoring and fact checking, as part of the second step, CD38 and TNFRSF17 emerged as the top candidates. Next, transcriptome profiling data from three datasets was incorporated in the workflow to assess expression levels and correlations with the module average across various conditions and cell types. It is on this basis that CD38 was prioritized as the top candidate, with TNFRSF17 and IGJ identified as promising alternatives. Conclusion: This study introduces a systematic framework that integrates LLMs with human expertise for gene prioritization. Our analysis identified CD38, TNFRSF17, and IGJ as the top candidates within the plasma cell-associated module M12.15 from the BloodGen3 repertoire, with their relative rankings varying systematically based on specific evaluation criteria, from plasma cell biology to therapeutic relevance. This criterion-dependent ranking demonstrates the ability of the framework to perform nuanced, multi-faceted evaluations. By combining knowledge-driven analysis with data-driven metrics, our approach provides a balanced and comprehensive method for biomarker selection. The methodology established here offers a reproducible and scalable approach that can be applied across diverse biological contexts and extended to analyze large module repertoires. Copyright © 2025 Syed Ahamed Kabeer, Subba, Rinchai, Toufiq, Khan, Yurieva and Chaussabel.",No,Pranav,,,,,,,,,,
"How prevalent and severe is addiction on GABAmimetic drugs in an elderly German general hospital population? Focus on gabapentinoids, benzodiazepines, and z-hypnotic drugs","Objective: Gabapentinoids (GPT) are reported to be increasingly misused by opioid- and polydrug-users, but the addictive potential of GPT outside of these populations remains understudied. Investigations comparing GPT abuse and dependence liability to that of other commonly prescribed Central Nervous System-acting medications are therefore warranted. We provide a comparison of GPT-abuse/dependence to that of other GABAmimetics within an elderly population. Design: DSM-IV-TR-based data (previously prospectively collected by SKID-I-interview) from a random sample of elderly patients admitted to a metropolitan German general hospital were reviewed. The prevalence and severity of GPT, benzodiazepine (BDZ), and z-hypnotic drug (ZD)-abuse and -dependence were compared, stratified also by mono-substance (no concurrent current or previous substance use) and de novo-substance (first)-abuse and -dependence states. Results: Among 400 patients (75 ± 6.4 years old; 63% females), neither current nor past abuse of BDZ, ZD or GPT, nor other illicit substances was observed. Dependence upon BDZ, ZD or GPT was observed among 55 (13.75%) individuals. The related lifetime/12-month prevalence-rates were: dependence condition (BDZ: 7%/2.45%; ZD: 4.25%/4.25%; GPT: 2.75/2.5%); mono-dependence condition (BDZ: 2.25%/0.75%; ZD: 1%/1%, GPT: 0%/0%); de novo-dependence condition (BDZ: 2.75%/1.75%; ZD: 1%/1%, GPT: 0.5%/0.5%). Opioid analgesic-dependence (N = 43/400) was significantly more frequently linked with BDZ than with GPT (p < 0.01) [Correction added on 29 December 2021, after first online publication: In the sentence ‘Opioid analgesic-dependence…’, the term ‘and ZD’ has been deleted]. For all three GABAmimetic classes, most mono- and de novo-dependence states were mild-to-moderate and lasted 2–6 years (median). Conclusion: GABAmimetic-dependence was usually mixed with other substance-dependences. Every third to fourth instance of BDZ- or ZD-dependence was a mono-dependence condition, while a pure GPT-dependence was absent in this elderly (and illicit substance-naïve) population. © 2021 The Authors. Human Psychopharmacology: Clinical and Experimental published by John Wiley & Sons Ltd.",No,Pranav,,,,,,,,,,
"Long COVID Discourse in Canada, the United States, and Europe: Topic Modeling and Sentiment Analysis of Twitter Data","BACKGROUND: Social media serves as a vast repository of data, offering insights 
into public perceptions and emotions surrounding significant societal issues. 
Amid the COVID-19 pandemic, long COVID (formally known as post-COVID-19 
condition) has emerged as a chronic health condition, profoundly impacting 
numerous lives and livelihoods. Given the dynamic nature of long COVID and our 
evolving understanding of it, effectively capturing people's sentiments and 
perceptions through social media becomes increasingly crucial. By harnessing the 
wealth of data available on social platforms, we can better track the evolving 
narrative surrounding long COVID and the collective efforts to address this 
pressing issue.
OBJECTIVE: This study aimed to investigate people's perceptions and sentiments 
around long COVID in Canada, the United States, and Europe, by analyzing 
English-language tweets from these regions using advanced topic modeling and 
sentiment analysis techniques. Understanding regional differences in public 
discourse can inform tailored public health strategies.
METHODS: We analyzed long COVID-related tweets from 2021. Contextualized topic 
modeling was used to capture word meanings in context, providing coherent and 
semantically meaningful topics. Sentiment analysis was conducted in a zero-shot 
manner using Llama 2, a large language model, to classify tweets into positive, 
negative, or neutral sentiments. The results were interpreted in collaboration 
with public health experts, comparing the timelines of topics discussed across 
the 3 regions. This dual approach enabled a comprehensive understanding of the 
public discourse surrounding long COVID. We used metrics such as normalized 
pointwise mutual information for coherence and topic diversity for diversity to 
ensure robust topic modeling results.
RESULTS: Topic modeling identified five main topics: (1) long COVID in people 
including children in the context of vaccination, (2) duration and suffering 
associated with long COVID, (3) persistent symptoms of long COVID, (4) the need 
for research on long COVID treatment, and (5) measuring long COVID symptoms. 
Significant concern was noted across all regions about the duration and 
suffering associated with long COVID, along with consistent discussions on 
persistent symptoms and calls for more research and better treatments. In 
particular, the topic of persistent symptoms was highly prevalent, reflecting 
ongoing challenges faced by individuals with long COVID. Sentiment analysis 
showed a mix of positive and negative sentiments, fluctuating with significant 
events and news related to long COVID.
CONCLUSIONS: Our study combines natural language processing techniques, 
including contextualized topic modeling and sentiment analysis, along with 
domain expert input, to provide detailed insights into public health monitoring 
and intervention. These findings highlight the importance of tracking public 
discourse on long COVID to inform public health strategies, address 
misinformation, and provide support to affected individuals. The use of social 
media analysis in understanding public health issues is underscored, emphasizing 
the role of emerging technologies in enhancing public health responses.

©Ahmed Ghassan Tawfiq AbuRaed, Emil Azuma Prikryl, Giuseppe Carenini, Naveed 
Zafar Janjua. Originally published in the Journal of Medical Internet Research 
(https://www.jmir.org), 09.12.2024.",No,Daniel,"Not a clinical question, just sentiment analysis",,,,,,,,,
Evaluating the performance of ChatGPT in answering questions related to benign prostate hyperplasia and prostate cancer,"BACKGROUND: The aim of this study was to evaluate the accuracy and 
reproducibility of ChatGPT's answers to frequently asked questions about benign 
prostate hyperplasia (BPH) and prostate cancer.
METHODS: Frequently asked questions on the websites of urology associations, 
hospitals, and social media about prostate cancer and BPH were evaluated. Also, 
strong recommendation-level data were noted in the recommendations tables of the 
European Urology Association (EAU) 2022 Guidelines on Prostate Cancer and 
Management of Non-neurogenic Male Lower Urinary Tract Symptoms sections. All 
questions were asked in order in ChatGPT Mar 23 Version. All answers were 
evaluated separately by two specialist urologists and scored between 1-4.
RESULTS: Forty questions about BPH and 86 questions about prostate cancer were 
included in the study. The answers to all BPH-related questions resulted in 
90.0% completely correct. This rate for questions about prostate cancer was 
94.2%. The completely correct rate in the questions prepared according to the 
strong recommendations of the EAU guideline was 77.8% for BPH and 76.2% for 
prostate cancer. The similarity rates of the answers to the repeated questions 
were 90.0% and 93% for questions related to BPH and prostate cancer, 
respectively.
CONCLUSIONS: ChatGPT has given satisfactory answers to questions about BPH and 
prostate cancer. Although it has limitations, it can be predicted that it will 
take an important place in the health sector in the future, as it is a 
constantly evolving platform. ChatGPT was able to provide helpful information 
about BPH and prostate cancer, although it is not perfect. It is constantly 
getting better, and may become an important resource in the healthcare field in 
the future.",Yes,Pranav,,,,,,,,,,
The large language model diagnoses tuberculous pleural effusion in pleural effusion patients through clinical feature landscapes,"Background: Tuberculous pleural effusion (TPE) is a challenging extrapulmonary manifestation of tuberculosis, with traditional diagnostic methods often involving invasive surgery and being time-consuming. While various machine learning and statistical models have been proposed for TPE diagnosis, these methods are typically limited by complexities in data processing and difficulties in feature integration. Therefore, this study aims to develop a diagnostic model for TPE using ChatGPT-4, a large language model (LLM), and compare its performance with traditional logistic regression and machine learning models. By highlighting the advantages of LLMs in handling complex clinical data, identifying interrelationships between features, and improving diagnostic accuracy, this study seeks to provide a more efficient and precise solution for the early diagnosis of TPE. Methods: We conducted a cross-sectional study, collecting clinical data from 109 TPE and 54 non-TPE patients for analysis, selecting 73 features from over 600 initial variables. The performance of the LLM was compared with logistic regression and machine learning models (k-Nearest Neighbors, Random Forest, Support Vector Machines) using metrics like area under the curve (AUC), F1 score, sensitivity, and specificity. Results: The LLM showed comparable performance to machine learning models, outperforming logistic regression in sensitivity, specificity, and overall diagnostic accuracy. Key features such as adenosine deaminase (ADA) levels and monocyte percentage were effectively integrated into the model. We also developed a Python package (https://pypi.org/project/tpeai/) for rapid TPE diagnosis based on clinical data. Conclusions: The LLM-based model offers a non-surgical, accurate, and cost-effective method for early TPE diagnosis. The Python package provides a user-friendly tool for clinicians, with potential for broader use. Further validation in larger datasets is needed to optimize the model for clinical application. © The Author(s) 2025.",Yes,Pranav,,,,,,,,,,
Molecular analysis of Sarcoptes scabiei infecting wild and domestic South American camelids in Argentina,"Sarcoptic mange, caused by the Sarcoptes scabiei mite, is a highly transmissible skin condition affecting many mammalian species worldwide. South American camelids (SAC) have the highest reported prevalence of mange in South America, causing economic losses and posing a conservation threat to wild SAC. This study investigated mite diversity in SAC in Argentina and assessed relationships between known outbreak areas. Distinct epidemiologic scenarios were explored: the San Juan-La Rioja region, where a mange outbreak decimated wild SAC populations, and the Puna region of Jujuy, where domestic and wild SAC coexist and infections often occur. The mitochondrial gene cox1 and ten microsatellites were analysed from mites collected in five sampling events in Jujuy and four in San Juan-La Rioja between 2017-2023. A single cox1 haplotype was observed regardless of mite origin or host species. Comparison with partial cox1 sequences from other camelids worldwide showed little variation. Microsatellite markers revealed lower diversity in mites from San Juan-La Rioja compared to Jujuy. A single strain common to vicuñas and guanacos was identified in San Juan-La Rioja, while three strains were detected in Jujuy affecting vicuñas and/or domestic llamas. Some mites from Jujuy exhibited mixed genetic composition between the two regions, and results confirmed that domestic and wild SAC shared mite strains. This study enhances understanding of sarcoptic mange transmission among SAC species, contributing to vicuña and guanaco conservation and high-altitude livestock farming. Additionally, these findings provide support for the development of intersectoral management strategies to address this significant threat.  © The Author(s), 2025.",No,Pranav,,,,,,,,,,
"ARTIFICIAL INTELLIGENCE IN SPORTS AND PHYSICAL EDUCATION: TRENDS, THREATS AND ADAPTATION TO THE NEW REALITY; [ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ В СПОРТЕ И ФИЗИЧЕСКОЙ КУЛЬТУРЕ: ТРЕНДЫ, УГРОЗЫ И АДАПТАЦИЯ К НОВОЙ РЕАЛЬНОСТИ]","Aim. This study identifies trends, threats, and prospects for a widespread use of artificial intelligence (AI) in physical education and sports. Materials and methods. Our methodology included a combination of comprehensive bibliometric analysis (publications on AI, official documents, and regulations), word frequency analysis (Google Books Ngram Viewer), and search query analysis (Google Trends). ChatGPT 3.5 was used to find a way of introducing AI into physical education and sports. Results. Modern dynamics is associated with a decreased interest in physical education and sports against a growing popularity of AI concepts. Our findings indicate the following principal areas of AI application in physical education: training program design, predictive analytics, wearable technologies for health monitoring, tactical decision support systems, and automated refereeing systems. Furthermore, our analysis suggests the emergence of new AI-driven sports as well as AI-enhanced sports journalism and data analytics. Conclusion. AI will profoundly reshape the professional landscape of physical education and sports and make certain roles obsolete. This study offers valuable insights, emphasizing the development of increasingly sophisticated AI systems capable of managing and optimizing existing infrastructure. The active use of AI promotes the transition towards an AI-centric future in sports and physical education. © Померанцев А.А., Уполовнева А.А., 2024.",No,Pranav,,,,,,,,,,
"Letter to the Editor Regarding the Article: ""Exploring the Capacities of ChatGPT: A Comprehensive Evaluation of Its Accuracy and Repeatability in Addressing Helicobacter pylori-Related Queries""","3082. Helicobacter. 2024 Jul-Aug;29(4):e13131. doi: 10.1111/hel.13131.

Letter to the Editor Regarding the Article: ""Exploring the Capacities of 
ChatGPT: A Comprehensive Evaluation of Its Accuracy and Repeatability in 
Addressing Helicobacter pylori-Related Queries"".

Yang P(1), Jiang J(2).

Author information:
(1)Department of Laboratory Medicine, People's Hospital of Qiannan Prefecture, 
Guizhou, China.
(2)Department of Hepatopancreatobiliary Surgery, Sichuan Cancer Hospital and 
Institute, Sichuan Cancer Center, School of Medicine, University of Electronic 
Science and Technology of China, Chengdu, China.",Yes,Pranav,,,,,,,,,,
Performance of ChatGPT on Registered Nurse License Exam in Taiwan: A Descriptive Study,"(1) Background: AI (artificial intelligence) chatbots have been widely applied. ChatGPT could enhance individual learning capabilities and clinical reasoning skills and facilitate students’ understanding of complex concepts in healthcare education. There is currently less emphasis on its application in nursing education. The application of ChatGPT in nursing education needs to be verified. (2) Methods: A descriptive study was used to analyze the scores of ChatGPT on the registered nurse license exam (RNLE) in 2022~2023, and to explore the response and explanations of ChatGPT. The process of data measurement encompassed input sourcing, encoding methods, and statistical analysis. (3) Results: ChatGPT promptly responded within seconds. The average score of four exams was around 51.6 to 63.75 by ChatGPT, and it passed the RNLE in 2022 1st and 2023 2nd. However, ChatGPT may generate misleading or inaccurate explanations, or it could lead to hallucination; confusion or misunderstanding about complicated scenarios; and languages bias. (4) Conclusions: ChatGPT may have the potential to assist with nursing education because of its advantages. It is recommended to integrate ChatGPT into different nursing courses, to assess its limitations and effectiveness through a variety of tools and methods. © 2023 by the author.",Yes,Pranav,,,,,,,,,,
Mid-term Results of Endovascular Reconstruction of Aortic Bifurcation Using COVERA Stent Graft,"Introduction: This article aims to evaluate the short-term and mid-term performance of a self-expanding covered stent (COVERA Plus, Bard Tempe, Arizona) during the treatment of Trans-Atlantic Inter-Society Consensus (TASC) C/D aortoiliac obstructive lesions involving the aortic bifurcation. Methods: A single-center retrospective review of all patients who underwent endovascular reconstruction of the aortoiliac bifurcation for obstructive disease, with the use of Covera, from January 2018 to March 2023. All patients received a postoperative CTA (computed tomography angiography) scan within 1 month from the intervention. Precision of deployment, stent conformation, and stent symmetry were evaluated at the arterial phase of the CTA. Early outcomes were technical success and freedom from open aortic reintervention and/or mortality. Late outcomes were primary and assisted primary patency rates and freedom from reintervention. Results: During the study period, 35 patients underwent primary endovascular treatment of obstructive lesions involving the aortic bifurcation with parallel COVERA stents. Aortoiliac lesions were classified as TASC-IIC in 23 (65.7%) patients and TASC D in 12 (34.2%). Median follow-up was 49 months (interquartile [IQR]: 18–60). Overall survival was 97.1% (95% confidence interval [CI]=91–100) at 60 months. During follow-up, there were one early stent stenosis, treated with an angioplasty and stent relining with an estimated primary patency at 60 months of 97.1% (95% CI=94–100) and a primary-assisted patency of 100%. Estimated freedom from all types of reinterventions at 60 months was 94.3% (95% CI=89–99.3). Conclusions: The new self-expanding covered Bard COVERA Plus stent used for endovascular treatment of TASC C/D aorto iliac disease proved to be safe and feasible with high technical procedural success rates. Comparison with other types of stents is necessary to further assess the role of the COVERA Plus stent in aortic bifurcation repair. Clinical Impact: This study investigates the safety and feasibility of the new self-expanding covered Bard Covera Plus stent used for endovascular treatment of TASC C/D aorto iliac disease. The retrospective analysis of 35 patients highlights high technical success and primary patency rate at 60 months. The geometric analysis also helped to underline how this stent can be used precisely in particular conditions. These findings suggest the need for further research to compare COVERA with other types of stents in aortic bifurcation repair. © The Author(s) 2024.",No,Pranav,,,,,,,,,,
Unveiling GPT-4V's hidden challenges behind high accuracy on USMLE questions: Observational Study,"Background: Recent advancements in artificial intelligence, such as GPT-3.5 Turbo (OpenAI) and GPT-4, have demonstrated significant potential by achieving good scores on text-only United States Medical Licensing Examination (USMLE) exams and effectively answering questions from physicians. However, the ability of these models to interpret medical images remains underexplored. Objective: This study aimed to comprehensively evaluate the performance, interpretability, and limitations of GPT-3.5 Turbo, GPT-4, and its successor, GPT-4 Vision (GPT-4V), specifically focusing on GPT-4V’s newly introduced image-understanding feature. By assessing the models on medical licensing examination questions that require image interpretation, we sought to highlight the strengths and weaknesses of GPT-4V in handling complex multimodal clinical information, thereby exposing hidden flaws and providing insights into its readiness for integration into clinical settings. Methods: This cross-sectional study tested GPT-4V, GPT-4, and ChatGPT-3.5 Turbo on a total of 227 multiple-choice questions with images from USMLE Step 1 (n=19), Step 2 clinical knowledge (n=14), Step 3 (n=18), the Diagnostic Radiology Qualifying Core Exam (DRQCE) (n=26), and AMBOSS question banks (n=150). AMBOSS provided expert-written hints and question difficulty levels. GPT-4V’s accuracy was compared with 2 state-of-the-art large language models, GPT-3.5 Turbo and GPT-4. The quality of the explanations was evaluated by choosing human preference between an explanation by GPT-4V (without hint), an explanation by an expert, or a tie, using 3 qualitative metrics: comprehensive explanation, question information, and image interpretation. To better understand GPT-4V’s explanation ability, we modified a patient case report to resemble a typical “curbside consultation” between physicians. Results: For questions with images, GPT-4V achieved an accuracy of 84.2%, 85.7%, 88.9%, and 73.1% in Step 1, Step 2 clinical knowledge, Step 3 of USMLE, and DRQCE, respectively. It outperformed GPT-3.5 Turbo (42.1%, 50%, 50%, 19.2%) and GPT-4 (63.2%, 64.3%, 66.7%, 26.9%). When GPT-4V answered correctly, its explanations were nearly as good as those provided by domain experts from AMBOSS. However, incorrect answers often had poor explanation quality: 18.2% (10/55) contained inaccurate text, 45.5% (25/55) had inference errors, and 76.3% (42/55) demonstrated image misunderstandings. With human expert assistance, GPT-4V reduced errors by an average of 40% (22/55). GPT-4V accuracy improved with hints, maintaining stable performance across difficulty levels, while medical student performance declined as difficulty increased. In a simulated curbside consultation scenario, GPT-4V required multiple specific prompts to interpret complex case data accurately. Conclusions: GPT-4V achieved high accuracy on multiple-choice questions with images, highlighting its potential in medical assessments. However, significant shortcomings were observed in the quality of explanations when questions were answered incorrectly, particularly in the interpretation of images, which could not be efficiently resolved through expert interaction. These findings reveal hidden flaws in the image interpretation capabilities of GPT-4V, underscoring the need for more comprehensive evaluations beyond multiple-choice questions before integrating GPT-4V into clinical settings. ©Zhichao Yang, Zonghai Yao, Mahbuba Tasmin, Parth Vashisht, Won Seok Jang, Feiyun Ouyang, Beining Wang, David McManus, Dan Berlowitz, Hong Yu.",Yes,Pranav,,,,,,,,,,
Using Large Language Models to Abstract Complex Social Determinants of Health From Original and Deidentified Medical Notes: Development and Validation Study,"Background: Social determinants of health (SDoH) such as housing insecurity are known to be intricately linked to patients’ health status. More efficient methods for abstracting structured data on SDoH can help accelerate the inclusion of exposome variables in biomedical research and support health care systems in identifying patients who could benefit from proactive outreach. Large language models (LLMs) developed from Generative Pre-trained Transformers (GPTs) have shown potential for performing complex abstraction tasks on unstructured clinical notes. Objective: Here, we assess the performance of GPTs on identifying temporal aspects of housing insecurity and compare results between both original and deidentified notes. Methods: We compared the ability of GPT-3.5 and GPT-4 to identify instances of both current and past housing instability, as well as general housing status, from 25,217 notes from 795 pregnant women. Results were compared with manual abstraction, a named entity recognition model, and regular expressions. Results: Compared with GPT-3.5 and the named entity recognition model, GPT-4 had the highest performance and had a much higher recall (0.924) than human abstractors (0.702) in identifying patients experiencing current or past housing instability, although precision was lower (0.850) compared with human abstractors (0.971). GPT-4’s precision improved slightly (0.936 original, 0.939 deidentified) on deidentified versions of the same notes, while recall dropped (0.781 original, 0.704 deidentified). Conclusions: This work demonstrates that while manual abstraction is likely to yield slightly more accurate results overall, LLMs can provide a scalable, cost-effective solution with the advantage of greater recall. This could support semiautomated abstraction, but given the potential risk for harm, human review would be essential before using results for any patient engagement or care decisions. Furthermore, recall was lower when notes were deidentified prior to LLM abstraction. © Alexandra Ralevski, Nadaa Taiyab, Michael Nossal, Lindsay Mico, Samantha Piekos, Jennifer Hadlock.",No,Daniel,Data extraction task,,,,,,,,,
Diagnostic Accuracy of ChatGPT for Patients’ Triage; a Systematic Review and Meta-Analysis,"Introduction: Artificial intelligence (AI), particularly ChatGPT developed by OpenAI, has shown the potential to improve diagnostic accuracy and efficiency in emergency department (ED) triage. This study aims to evaluate the diagnostic performance and safety of ChatGPT in prioritizing patients based on urgency in ED settings. Methods: A systematic review and meta-analysis were conducted following PRISMA guidelines. Comprehensive literature searches were performed in Scopus, Web of Science, PubMed, and Embase. Studies evaluating ChatGPT’s diagnostic performance in ED triage were included. Quality assessment was conducted using the QUADAS-2 tool. Pooled accuracy estimates were calculated using a random-effects model, and heterogeneity was assessed with the I2 statistic. Results: Fourteen studies with a total of 1, 412 patients or scenarios were included. ChatGPT 4.0 demonstrated a pooled accuracy of 0.86 (95% CI: 0.64–0.98) with substantial heterogeneity (I2 = 93%). ChatGPT 3.5 showed a pooled accuracy of 0.63 (95% CI: 0.43–0.81) with significant heterogeneity (I2 = 84%). Funnel plots indicated potential publication bias, particularly for ChatGPT 3.5. Quality assessments revealed varying levels of risk of bias and applicability concerns. Conclusions: ChatGPT, especially version 4.0, shows promise in improving ED triage accuracy. However, significant variability and potential biases highlight the need for further evaluation and enhancement. This open-access article distributed under the terms of the Creative Commons Attribution NonCommercial 3.0 License (CC BY-NC 3.0). Downloaded from: https://journals.sbmu.ac.ir/aaem/index.php/AAEM/index",Yes,Pranav,,,,,,,,,,
Artificial intelligence and obesity management: An Obesity Medicine Association (OMA) Clinical Practice Statement (CPS) 2023,"Background: This Obesity Medicine Association (OMA) Clinical Practice Statement (CPS) provides clinicians an overview of Artificial Intelligence, focused on the management of patients with obesity. Methods: The perspectives of the authors were augmented by scientific support from published citations and integrated with information derived from search engines (i.e., Chrome by Google, Inc) and chatbots (i.e., Chat Generative Pretrained Transformer or Chat GPT). Results: Artificial Intelligence (AI) is the technologic acquisition of knowledge and skill by a nonhuman device, that after being initially programmed, has varying degrees of operations autonomous from direct human control, and that performs adaptive output tasks based upon data input learnings. AI has applications regarding medical research, medical practice, and applications relevant to the management of patients with obesity. Chatbots may be useful to obesity medicine clinicians as a source of clinical/scientific information, helpful in writings and publications, as well as beneficial in drafting office or institutional Policies and Procedures and Standard Operating Procedures. AI may facilitate interactive programming related to analyses of body composition imaging, behavior coaching, personal nutritional intervention & physical activity recommendations, predictive modeling to identify patients at risk for obesity-related complications, and aid clinicians in precision medicine. AI can enhance educational programming, such as personalized learning, virtual reality, and intelligent tutoring systems. AI may help augment in-person office operations and telemedicine (e.g., scheduling and remote monitoring of patients). Finally, AI may help identify patterns in datasets related to a medical practice or institution that may be used to assess population health and value-based care delivery (i.e., analytics related to electronic health records). Conclusions: AI is contributing to both an evolution and revolution in medical care, including the management of patients with obesity. Challenges of Artificial Intelligence include ethical and legal concerns (e.g., privacy and security), accuracy and reliability, and the potential perpetuation of pervasive systemic biases. © 2023 The Authors",No,Pranav,,,,,,,,,,
Letter to the editor 'Evaluating ChatGPT responses in the context of a 53-year-old male with a femoral neck fracture: a qualitative analysis',"3135. Eur J Orthop Surg Traumatol. 2024 Feb;34(2):957-958. doi: 
10.1007/s00590-023-03766-w. Epub 2023 Oct 21.

Letter to the editor 'Evaluating ChatGPT responses in the context of a 
53-year-old male with a femoral neck fracture: a qualitative analysis'.

Ray PP(1).

Author information:
(1)Department of Computer Applications, Sikkim University, 6th Mile, PO-Tadong, 
Gangtok, Sikkim, 737102, India. ppray@cus.ac.in.",No,Pranav,,,,,,,,,,
The Transformers' Ability to Implement for Solving Intricacies of Language Processing,"AI (Artificial Intelligence) tools have reached a surprising level of linguistic frequency. The best and biggest (little complex) of these are based on an architecture called the transformers. A transformer in AI is a tool that acts as a kind of training model to train the pre-trained models. Available pre-trained models can reduce computational cost, carbon foot print and saves time. A transformer model can be used for different modalities such as text, images, audio and even for multi-model including video classification and visual question answering. Latest version of transformers (Transformers 4.18.0) has been released by Pypi.org on 6th Apr 2022 as part of the Hugging Face logo which claims SOTA (state-of-the-art), NLP (Natural Language Processing for Tensorflow 2.0 and PyTorch. This paper is one the first papers using this latest release of transformer tool for NLP (Natural Language Processing) in Python. Using latest Transformers this paper overviews, represents implements its powerful tools BERT (Bidirectional Encoder Representation from Transformers), GPT (Generative Pre-Trained), BART (Bidirectional Abstractive Representation from Transformers), & other utilities of highly efficient linear algebra libraries of Python for Natural Language Processing. So, this proposal implements Natural Language Processing introducing POS (Parts of Speech) Tags, Bigrams and implementing pipeline, summarizer, paraphrasing, sentiment-analysis using transformers. For sentiment Analysis multilingual (English & French) have been selected & matching sentiment results are 94% to 98 % for four test cases which are far better than conventional methods. © 2022 IEEE.",No,Pranav,,,,,,,,,,
From Small Data Modeling to Large Language Model Screening: A Dual-Strategy Framework for Materials Intelligent Design,"Small data in materials present significant challenges to constructing highly accurate machine learning models, severely hindering the widespread implementation of data-driven materials intelligent design. In this study, the Dual-Strategy Materials Intelligent Design Framework (DSMID) is introduced, which integrates two innovative methods. The Adversarial domain Adaptive Embedding Generative network (AAEG) transfers data between related property datasets, even with only 90 data points, enhancing material composition characterization and improving property prediction. Additionally, to address the challenge of screening and evaluating numerous alloy designs, the Automated Material Screening and Evaluation Pipeline (AMSEP) is implemented. This pipeline utilizes large language models with extensive domain knowledge to efficiently identify promising experimental candidates through self-retrieval and self-summarization. Experimental findings demonstrate that this approach effectively identifies and prepares new eutectic High Entropy Alloy (EHEA), notably Al14(CoCrFe)19Ni28, achieving an ultimate tensile strength of 1085 MPa and 24% elongation without heat treatment or extra processing. This demonstrates significantly greater plasticity and equivalent strength compared to the typical as-cast eutectic HEA AlCoCrFeNi2.1. The DSMID framework, combining AAEG and AMSEP, addresses the challenges of small data modeling and extensive candidate screening, contributing to cost reduction and enhanced efficiency of material design. This framework offers a promising avenue for intelligent material design, particularly in scenarios constrained by limited data availability. © 2024 The Author(s). Advanced Science published by Wiley-VCH GmbH.",No,Pranav,,,,,,,,,,
Evaluating the performance and clinical decision-making impact of ChatGPT-4 in reproductive medicine,"Background: ChatGPT, a sophisticated language model developed by OpenAI, has the potential to offer professional and patient-friendly support. We aimed to assess the accuracy and reproducibility of ChatGPT-4 in answering questions related to knowledge, management, and support within the field of reproductive medicine. Methods: ChatGPT-4 was used to respond to queries sourced from a domestic attending physician examination database, as well as to address both local and international treatment guidelines within the field of reproductive medicine. Each response generated by ChatGPT-4 was independently evaluated by a trio of experts specializing in reproductive medicine. The experts used four qualitative measures—relevance, accuracy, completeness, and understandability—to assess each response. Results: We found that ChatGPT-4 demonstrated extensive knowledge in reproductive medicine, with median scores for relevance, accuracy, completeness, and comprehensibility of objective questions being 4, 3.5, 3, and 3, respectively. However, the composite accuracy rate for multiple-choice questions was 63.38%. Significant discrepancies were observed among the three experts' scores across all four measures. Expert 1 generally provided higher and more consistent scores, while Expert 3 awarded lower scores for accuracy. ChatGPT-4's responses to both domestic and international guidelines showed varying levels of understanding, with a lack of knowledge on regional guideline variations. However, it offered practical and multifaceted advice regarding next steps and adjusting to new guidelines. Conclusions: We analyzed the strengths and limitations of ChatGPT-4's responses on the management of reproductive medicine and relevant support. ChatGPT-4 might serve as a supplementary informational tool for patients and physicians to improve outcomes in the field of reproductive medicine. © 2024 International Federation of Gynecology and Obstetrics.",Yes,Pranav,,,,,,,,,,
Association of reviewer experience with discriminating human-written versus ChatGPT-written abstracts,"ChatGPT-written abstracts.

Levin G(1), Pareja R(2), Viveros-Carreño D(3)(4), Sanchez Diaz E(5), Yates 
EM(6), Zand B(7), Ramirez PT(8).

Author information:
(1)Division of Gynecologic Oncology, Jewish General Hospital, McGill University, 
Montreal, Quebec, Canada Gabriel.levin2@mail.mcgill.ca.
(2)Gynecologic Oncology, Clinica ASTORGA, Medellin, and Instituto Nacional de 
Cancerología, Bogotá, Colombia.
(3)Unidad Ginecología Oncológica, Grupo de Investigación GIGA, Centro de 
Tratamiento e Investigación sobre Cáncer Luis Carlos Sarmiento Angulo - CTIC, 
Bogotá, Colombia.
(4)Department of Gynecologic Oncology, Clínica Universitaria Colombia, Bogotá, 
Colombia.
(5)Universidad Pontificia Bolivariana Clinica Universitaria Bolivariana, 
Medellin, Colombia.
(6)Obstetrics and Gynecology, Houston Methodist Hospital, Houston, Texas, USA.
(7)Gynecologic Oncology, Houston Methodist, Shenandoah, Texas, USA.
(8)Department of Obstetrics and Gynecology, Houston Methodist Hospital, Houston, 
Texas, USA.

OBJECTIVE: To determine if reviewer experience impacts the ability to 
discriminate between human-written and ChatGPT-written abstracts.
METHODS: Thirty reviewers (10 seniors, 10 juniors, and 10 residents) were asked 
to differentiate between 10 ChatGPT-written and 10 human-written (fabricated) 
abstracts. For the study, 10 gynecologic oncology abstracts were fabricated by 
the authors. For each human-written abstract we generated a ChatGPT matching 
abstract by using the same title and the fabricated results of each of the human 
generated abstracts. A web-based questionnaire was used to gather demographic 
data and to record the reviewers' evaluation of the 20 abstracts. Comparative 
statistics and multivariable regression were used to identify factors associated 
with a higher correct identification rate.
RESULTS: The 30 reviewers discriminated 20 abstracts, giving a total of 600 
abstract evaluations. The reviewers were able to correctly identify 300/600 
(50%) of the abstracts: 139/300 (46.3%) of the ChatGPT-generated abstracts and 
161/300 (53.7%) of the human-written abstracts (p=0.07). Human-written abstracts 
had a higher rate of correct identification (median (IQR) 56.7% (49.2-64.1%) vs 
45.0% (43.2-48.3%), p=0.023). Senior reviewers had a higher correct 
identification rate (60%) than junior reviewers and residents (45% each; 
p=0.043 and p=0.002, respectively). In a linear regression model including the 
experience level of the reviewers, familiarity with artificial intelligence (AI) 
and the country in which the majority of medical training was achieved (English 
speaking vs non-English speaking), the experience of the reviewer (β=10.2 (95% 
CI 1.8 to 18.7)) and familiarity with AI (β=7.78 (95% CI 0.6 to 15.0)) were 
independently associated with the correct identification rate (p=0.019 and 
p=0.035, respectively). In a correlation analysis the number of publications by 
the reviewer was positively correlated with the correct identification rate 
(r28)=0.61, p<0.001.
CONCLUSION: A total of 46.3% of abstracts written by ChatGPT were detected by 
reviewers. The correct identification rate increased with reviewer and 
publication experience.

© IGCS and ESGO 2024. No commercial re-use. See rights and permissions. 
Published by BMJ.",No,Pranav,,,,,,,,,,
The Challenges of Using Large Language Models: Balancing Traditional Learning Methods with New Technologies in the Pedagogy of Sociology,"The increasing use of artificial intelligence (hereafter AI) in education, particularly through large-scale language models such as ChatGPT and Bing, offers both challenges and opportunities. These models facilitate interaction in conversations and can perform tasks that require natural language processing, from answering questions to solving problems. However, their integration into education raises concerns about the credibility and reliability of the information they provide and about the role of the teacher, emphasizing the need for guided use in educational environments. This article contributes to the discourse from the perspective of the pedagogy of sociology, focusing on the role of chatbots in analyzing texts within the social sciences and humanities fields. Our pilot study, conducted with 17 first-year master’s students studying sociology, reveals that while chatbots can optimize the creation of summaries and the provision of basic information, their reliance on sources such as Wikipedia calls into question the depth and impartiality of the content. In addition, students have criticized chatbots for providing biased or inaccurate outputs. A significant part of our research has compared the epistemological and methodological approaches of chatbots with a traditional, independent literature analysis (deep reading), and we found notable differences in learning outcomes. However, a hybrid approach that combines AI tools with conventional methods offers a promising way to improve learning and teaching strategies and can enhance the critical analytical skills that are crucial for future pedagogies. © 2025 by the authors.",No,Pranav,,,,,,,,,,
Assessing clinical acuity in the Emergency Department using the GPT-3.5 Artificial Intelligence Model,"This paper evaluates the performance of the Chat Generative Pre-trained Transformer (ChatGPT; GPT-3.5) in accurately identifying higher acuity patients in a real-world clinical context. Using a dataset of 10,000 pairs of patient Emergency Department (ED) visits with varying acuity levels, we demonstrate that GPT-3.5 can successfully determine the patient with higher acuity based on clinical history sections extracted from ED physician notes. The model achieves an accuracy of 84% and an F1 score of 0.83, with improved performance for more disparate acuity scores. Among the 500 pair subsample that was also manually classified by a resident physician, GPT-3.5 achieved similar performance (Accuracy = 0.84; F1 score = 0.85) compared to the physician (Accuracy = 0.86, F1 score = 0.87). Our results suggest that, in real-world settings, GPT-3.5 can perform comparably to physicians on the clinical reasoning task of ED acuity determination.",Yes,Pranav,,,,,,,,,,
Harnessing Generative Artificial Intelligence to Improve Efficiency Among Urologists: Welcome ChatGPT,"16.

Harnessing Generative Artificial Intelligence to Improve Efficiency Among 
Urologists: Welcome ChatGPT.

Gabrielson AT(1), Odisho AY(2)(3), Canes D(4).

Author information:
(1)The James Buchanan Brady Urological Institute, Johns Hopkins University 
School of Medicine, Baltimore, Maryland.
(2)Department of Urology, University of California San Francisco School of 
Medicine, San Francisco, California.
(3)Center for Digital Health Innovation, University of California San Francisco 
School of Medicine, San Francisco, California.
(4)Lahey Institute of Urology, Lahey Hospital & Medical Center, Beth Israel and 
Lahey Health, Burlington, Massachusetts.",No,Pranav,editorial esque,,,,,,,,,
TDAG: A multi-agent framework based on dynamic Task Decomposition and Agent Generation,"The emergence of Large Language Models (LLMs) like ChatGPT has inspired the development of LLM-based agents capable of addressing complex, real-world tasks. However, these agents often struggle during task execution due to methodological constraints, such as error propagation and limited adaptability. To address this issue, we propose a multi-agent framework based on dynamic Task Decomposition and Agent Generation (TDAG). This framework dynamically decomposes complex tasks into smaller subtasks and assigns each to a specifically generated subagent, thereby enhancing adaptability in diverse and unpredictable real-world tasks. Simultaneously, existing benchmarks often lack the granularity needed to evaluate incremental progress in complex, multi-step tasks. In response, we introduce ItineraryBench in the context of travel planning, featuring interconnected, progressively complex tasks with a fine-grained evaluation system. ItineraryBench is designed to assess agents’ abilities in memory, planning, and tool usage across tasks of varying complexity. Our experimental results reveal that TDAG significantly outperforms established baselines, showcasing its superior adaptability and context awareness in complex task scenarios.",No,Pranav,,,,,,,,,,
Computer Vision Meets Large Language Models: Performance of ChatGPT 4.0 on Dermatology Boards-Style Practice Questions,"Background: ChatGPT is a generative artificial intelligence that has numerous professional applications. Applications in medical education are currently being explored. ChatGPT 4.0 performance on image-based dermatology boards-style practice questions has not been assessed. Objective: The objective of this study was to determine the accuracy with which ChatGPT can answer dermatology boards examination practice questions. Methods: 150 multiple-choice questions from the popular question bank DermQbank were inputted into ChatGPT in December 2023. Of these, 83 were text-only questions and 67 had associated images. These same questions were inputted into ChatGPT again in July 2024. An additional 150 questions were inputted for a total of 300 different questions where 169 were text-only and 133 had associated images. Results: Of the aggregate 300 question data, ChatGPT answered 232 questions correctly (77.3%). ChatGPT performed significantly better with text-only questions than with questions that included images (85.2% (144/169) vs 67.7% (90/133), P<.001). Of image-based questions, ChatGPT performed better with clinical image questions than with dermatopathology questions (69.0% (78/133) vs. 58.8% (10/17), P=.40), but this difference was not statistically significant partially due to the sample size of the dermatopathology questions. Compared to post-graduate year 4 (PGY-4) residents, ChatGPT performed above the 46th percentile. ChatGPT agreed with the answer choice picked by the majority of question bank users 75.3% of the time. Multivariable regression demonstrated that significant predictive variables for ChatGPT answering a question correctly included the percent of dermatology trainees who answered a question correctly and whether the question was text-based (P<.001and P=.004, respectively). Conclusions: ChatGPT answered 77.3% of dermatology board examination practice questions correctly, performing above the 46th percentile of PGY-4 question bank users. If using ChatGPT as a study resource for dermatology board examination preparation, residents should be judicious with exactly how they employ ChatGPT to avoid learning incorrect information. © 2024, National Society for Cutaneous Medicine. All rights reserved.",Yes,Pranav,,,,,,,,,,
Time-resolved fluorescence based direct two-site apoA-I immunoassays and their clinical application in patients with suspected obstructive coronary artery disease,"Objective: High-density lipoprotein (HDL) is a heterogeneous group of subpopulations differing in protein/lipid composition and in their anti-atherogenic function. There is a lack of assays that can target the functionality of HDL particles related to atherosclerosis. The objective of this study was to construct two-site apolipoprotein A-I (apoA-I) assays and to evaluate their clinical performance in patients with suspected obstructive coronary artery disease (CAD). Approach and results: Direct two-site apoA-I assays (named 109–121 and 110–525) were developed to identify the presence of apoA-I in the HDL of patients with CAD using apoA-I antibodies as a single-chain variable fragment fused with alkaline phosphatase. ApoA-I109−121 and apoA-I110−525 were measured in 197 patients undergoing coronary computed tomography angiography (CTA) and myocardial positron emission tomography perfusion imaging due to suspected obstructive CAD. Among patients not using lipid-lowering medication (LLM, n = 125), the level of apoA-I110−525 was higher in the presence than in the absence of coronary atherosclerosis [21.88 (15.89–27.44) mg/dl vs. 17.66 (13.38–24.48) mg/dl, P = 0.01)], whereas there was no difference in apoA-I109−121, HDL cholesterol, and apoA-I determined using a polyclonal apoA-I antibody. The levels of apoA-I109−121 and apoA-I110−525 were similar in the presence or absence of obstructive CAD. Among patients not using LLM, apoA-I110−525 adjusted for age and sex identified individuals with coronary atherosclerosis with a similar accuracy to traditional risk factors [area under the curve [AUC] (95% CI): 0.75(0.66–0.84) 0.71 (0.62–0.81)]. However, a combination of apoA-I110−525 with risk factors did not improve the accuracy [AUC (95% CI): 0.73 (0.64–0.82)]. Conclusion: Direct two-site apoA-I assays recognizing heterogeneity in reactivity with apoA-I could provide a potential approach to identify individuals at a risk of coronary atherosclerosis. However, their clinical value remains to be studied in larger cohorts. Copyright © 2022 Negi, Heikkilä, Vuorenpää, Tuunainen, Nammas, Maaniitty, Knuuti, Metso, Lövgren, Jauhiainen, Lamminmäki, Pettersson and Saraste.",No,Pranav,,,,,,,,,,
"Large language models from OpenAI, Google, Meta, X and Co.: The role of “closed” and “open” models in radiology; [Große Sprachmodelle von OpenAI, Google, Meta, X und Co.: Die Rolle von „closed“ und „open“ Modellen in der Radiologie]","Background: In 2023, the release of ChatGPT triggered an artificial intelligence (AI) boom. The underlying large language models (LLM) of the nonprofit organization “OpenAI” are not freely available under open-source licenses, which does not allow on-site implementation inside secure clinic networks. However, efforts are being made by open-source communities, start-ups and large tech companies to democratize the use of LLMs. This opens up the possibility of using LLMs in a data protection-compliant manner and even adapting them to our own data. Objectives: This paper aims to explain the potential of privacy-compliant local LLMs for radiology and to provide insights into the “open” versus “closed” dynamics of the currently rapidly developing field of AI. Materials and methods: PubMed search for radiology articles with LLMs and subjective selection of references in the sense of a narrative key topic article. Results: Various stakeholders, including large tech companies such as Meta, Google and X, but also European start-ups such as Mistral AI, contribute to the democratization of LLMs by publishing the models (open weights) or by publishing the model and source code (open source). Their performance is lower than current “closed” LLMs, such as GPT‑4 from OpenAI. Conclusion: Despite differences in performance, open and thus locally implementable LLMs show great promise for improving the efficiency and quality of diagnostic reporting as well as interaction with patients and enable retrospective extraction of diagnostic information for secondary use of clinical free-text databases for research, teaching or clinical application. © The Author(s), under exclusive licence to Springer Medizin Verlag GmbH, ein Teil von Springer Nature 2024.",No,Pranav,,,,,,,,,,
How I GPT It: Development of Custom Artificial Intelligence (AI) Chatbots for Surgical Education,"3414. J Surg Educ. 2024 Jun;81(6):772-775. doi: 10.1016/j.jsurg.2024.03.004. Epub 2024 
Apr 16.

How I GPT It: Development of Custom Artificial Intelligence (AI) Chatbots for 
Surgical Education.

Sathe TS(1), Roshal J(2), Naaseh A(3), L'Huillier JC(4), Navarro SM(5), 
Silvestri C(6).

Author information:
(1)University of California San Francisco, San Francisco, California; Columbia 
University Irving Medical Center, New York, New York; The Collaboration of 
Surgical Education Fellows (CoSEF). Electronic address: tejas.sathe@ucsf.edu.
(2)The University of Texas Medical Branch, Galveston, Texas; Brigham and Women's 
Hospital, Harvard Medical School, Boston, Massachusetts; The Collaboration of 
Surgical Education Fellows (CoSEF).
(3)Washington University in St. Louis, St. Louis, Missouri; The Collaboration of 
Surgical Education Fellows (CoSEF).
(4)Jacobs School of Medicine and Biomedical Sciences, University at Buffalo, 
Buffalo, New York; The Collaboration of Surgical Education Fellows (CoSEF).
(5)University of Minnesota, Minneapolis, Minnesota; Mayo Clinic, Rochester, 
Minnesota; The Collaboration of Surgical Education Fellows (CoSEF).
(6)Columbia University Irving Medical Center, New York, New York; The 
Collaboration of Surgical Education Fellows (CoSEF).

Artificial Intelligence (AI) chatbots provide a novel format for individuals to 
interact with large language models (LLMs). Recently released tools allow 
nontechnical users to develop chatbots using natural language. Surgical 
education is an exciting area in which chatbots developed in this manner may be 
rapidly deployed, though additional work will be required to ensure their 
accuracy and safety. In this paper, we outline our initial experience with AI 
chatbot creation in surgical education and offer considerations for future use 
of this technology.

Copyright © 2024 The Author(s). Published by Elsevier Inc. All rights reserved.",No,Pranav,,,,,,,,,,
Detection of enzymatic levels in patients with thalassemia in Dewanyah province,"This study deals with the knowledge of the relationship and the negative impact of thalassemia disease on liver function. The study included 60 children with thalassemia in the age group (2-14) years, and the study included 20 children as a control group and in the same age group. The study included measuring liver function represented by measuring the activity of liver enzymes. The current study aimed to find the immune differences for people with thalassemia anemia in Al-Diwaniyah Governorate, where samples were collected from pathological analysis laboratories in Al-Diwaniyah hospitals. They were randomly selected with gender and age proportional to the group of patients, and patient groups and control groups were distributed as follows (31 males and 29 females) for patients and (10 males 10 females) for the control group. The current study examined the differences in the effect of sex on the average concentrations of components in the blood serum at a probability level of 5% in the serum of thalassemia patients. Liver enzymes were included in the study of GOT enzyme and were for ages 2-5 years (25.6±17.6), age 6-9 years (25.9±6.93), and age 10-14 years (28.5±8.61) without significant difference, and GPT enzyme also did not appear. Any significant difference between the age groups was determined for ages 2-5 years (14.2±21), ages 6-9 years (17.25±8.46), and ages 10-14 years (25.52±3.76). In the same study context, it was found that the glucose concentration was not significant for age groups, as it was 2-5 years old (123±5.94), 6-9 years old (120.6±4.43), and 10-14 years old (122.9±5.7), although it was significantly higher with the healthy control group.",No,Pranav,,,,,,,,,,
Behind the ChatGPT Hype: Are Its Suggestions Contributing to Addiction?,"1483. Ann Biomed Eng. 2023 Jun;51(6):1128-1129. doi: 10.1007/s10439-023-03201-5. Epub 
2023 Apr 15.

Behind the ChatGPT Hype: Are Its Suggestions Contributing to Addiction?

Haman M(1), Školník M(2).

Author information:
(1)Department of Humanities, Faculty of Economics and Management, Czech 
University of Life Sciences Prague, Kamýcká 129, 165 00, Prague-Suchdol, 
Czechia. haman@pef.czu.cz.
(2)Department of Humanities, Faculty of Economics and Management, Czech 
University of Life Sciences Prague, Kamýcká 129, 165 00, Prague-Suchdol, 
Czechia.

ChatGPT has been a frequent topic of discussion lately. All over the Internet, 
from YouTube to blogs, there have been reports about how ChatGPT is able to plan 
people's daily activities, even for a whole month. However, what matters is what 
activities ChatGPT recommends. When ChatGPT was trained on a vast amount of data 
from the Internet, we wondered if it would suggest activities that can lead to 
addiction. In our test, not once did ChatGPT recommend an activity related to 
alcohol, drug use, or any other activity that can lead to addiction with serious 
health consequences. Suggestions seemed more like self-improvement posts on 
blogs than discussion forums where people might mention drinking in the 
evenings. Thus, if a person were to use ChatGPT as a personal lifestyle advisor, 
it does not appear on the basis of this test that ChatGPT would recommend 
activities that would be fundamentally detrimental to their health. However, 
more detailed long-term testing of similar tools is needed before 
recommendations for use in practice can be made.

© 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.",No,Pranav,,,,,,,,,,
ChatGPT-4 performance in rhinology: A clinical case series,"Keypoints: Chatbot Generative Pre-trained Transformer (ChatGPT)-4 indicated more than twice additional examinations than practitioners in the management of clinical cases in rhinology. The consistency between ChatGPT-4 and practitioner in the indication of additional examinations may significantly vary from one examination to another. The ChatGPT-4 proposed a plausible and correct primary diagnosis in 62.5% cases, while pertinent and necessary additional examinations and therapeutic regimen were indicated in 7.5%–30.0% and 7.5%–32.5% of cases, respectively. The stability of ChatGPT-4 responses is moderate-to-high. The performance of ChatGPT-4 was not influenced by the human-reported level of difficulty of clinical cases. © 2024 ARS-AAOA, LLC.",Yes,Pranav,,,,,,,,,,
"In Reference to “Role of Chat GPT in Public Health”, to Highlight the AI’s Incorrect Reference Generation",,No,Daniel,Comment,,,,,,,,,
Multiple voices and lockdown; [Polyphonie et confinement],"Between January 2019 and December 2022, a student (named L.A.) doing a BTS (a senior technologist's certificate) in Management was treated using a trimodal system of care by the BAPU of the Claude Bernard Center. How was this original system organized, and how did changes related to the lockdown of March–May 2020 allow for progress in the proposed treatment? The consulting psychologist, Ms. Beaudré, received the initial request: L.A. had multiple difficulties (learning, language, social, psychic, somatic, etc.). Rapid guidance was recommended in an individual space dedicated to educational psychology, while continuing with consultations. In the educational psychology space, L.A. met with Mr. Sanchez and first explained to him her concerns about her difficulties with the French language, her rejection of her mother tongue and her accent. Her learning difficulties made her fear she would fail the BTS. L.A. had low self-esteem. At the start of the lockdown of March–May 2020, the educational psychological support was done at a distance (by telephone), and this did not help to reduce L.A.’s anxiety. Shortly before the start of the lockdown, L.A. had met with Ms. Dziwulski, psychologist-psychotherapist, as part of a therapeutic relaxation session. The question of the physical isolation was an overwhelming concern. The isolation imposed by COVID-19 posed a serious problem for the continued use of this trimodal system of care: how to continue working with L.A.? Within the parameters of this trimodal care, an attempt was made to adapt the follow-up for L.A. around the question of the verbal contact via telephone and the physical presence (distant or real), in a way which would allow this young woman to question/examine the orders given by her inner voice that she called her “policeman”. The temporary suspension of in person contact, as well as work on her self-image and imagination, the exclusivity of her inner voice and then the application of the telephone voice/real physical presence at the BAPU leading to the questioning of the role of the body in her difficulties, allowed L.A to exist differently. The establishment of and the modifications made to this system of care ultimately functioned as a mediation, which provided L.A. the possibility of acquiring another voice, another space in which to think. © 2023",No,Pranav,,,,,,,,,,
ChatGPT as a decision-support tool for better self-monitoring of hearing,"Background The rapid development of large language model chatbots, such as ChatGPT, has created new possibilities for healthcare support. This study investigates the feasibility of integrating self-monitoring of hearing (via a mobile app) with ChatGPT’s decision-making capabilities to assess whether specialist consultation is required. In particular, the study evaluated how ChatGPT's accuracy to make a recommendation changed over periods of up to 12 months. Methods ChatGPT-4.0 was tested on a dataset of 1,000 simulated cases, each containing monthly hearing threshold measurements over periods of up to 12 months. Its recommendations were compared to the opinions of 5 experts using percent agreement and Cohen’s Kappa. A multiple-response strategy, selecting the most frequent recommendation from 5 trials, was also analyzed. Results ChatGPT aligned strongly with the experts’ judgments, with agreement scores ranging from 0.80 to 0.84. Accuracy scores improved to 0.87 when the multiple-query strategy was employed. In those cases where all 5 experts unanimously agreed, ChatGPT achieved a near-perfect agreement score of 0.99. It adapted its decision-making criteria with extended observation periods, seemingly accounting for potential random fluctuations in hearing thresholds. Conclusions ChatGPT has significant potential as a decision-support tool for monitoring hearing, able to match expert recommendations and adapting effectively to time-series data. Existing hearing self-testing apps lack capabilities for tracking and evaluating changes over time; integrating ChatGPT could fill this gap. While not without its limitations, ChatGPT offers a promising complement to self-monitoring. It can enhance decision-making processes and potentially encourage patients to seek clinical expertise when needed.",Yes,Daniel,,,,,,,,,,
The Diagnostic Performance of Large Language Models and General Radiologists in Thoracic Radiology Cases: A Comparative Study,"Purpose: To investigate and compare the diagnostic performance of 10 different large language models (LLMs) and 2 board-certified general radiologists in thoracic radiology cases published by The Society of Thoracic Radiology. Materials and Methods: We collected publicly available 124 ""Case of the Month""from the Society of Thoracic Radiology website between March 2012 and December 2023. Medical history and imaging findings were input into LLMs for diagnosis and differential diagnosis, while radiologists independently visually provided their assessments. Cases were categorized anatomically (parenchyma, airways, mediastinum-pleura-chest wall, and vascular) and further classified as specific or nonspecific for radiologic diagnosis. Diagnostic accuracy and differential diagnosis scores (DDxScore) were analyzed using the χ2, Kruskal-Wallis, Wilcoxon, McNemar, and Mann-Whitney U tests. Results: Among the 124 cases, Claude 3 Opus showed the highest diagnostic accuracy (70.29%), followed by ChatGPT 4/Google Gemini 1.5 Pro (59.75%), Meta Llama 3 70b (57.3%), ChatGPT 3.5 (53.2%), outperforming radiologists (52.4% and 41.1%) and other LLMs (P<0.05). Claude 3 Opus DDxScore was significantly better than other LLMs and radiologists, except ChatGPT 3.5 (P<0.05). All LLMs and radiologists showed greater accuracy in specific cases (P<0.05), with no DDxScore difference for Perplexity and Google Bard based on specificity (P>0.05). There were no significant differences between LLMs and radiologists in the diagnostic accuracy of anatomic subgroups (P>0.05), except for Meta Llama 3 70b in the vascular cases (P=0.040). Conclusions: Claude 3 Opus outperformed other LLMs and radiologists in text-based thoracic radiology cases. LLMs hold great promise for clinical decision systems under proper medical supervision.  Copyright © 2024 Wolters Kluwer Health, Inc. All rights reserved.",Yes,Pranav,,,,,,,,,,
MENTALER: Toward Professional Mental Health Support with LLMs via Multi-Role Collaboration,"As mental health issues such as anxiety and depression are increasingly prevalent nowadays, we introduce MENTALER, an advanced multi-role collaboration framework specifically designed to enhance large language models (LLMs) in the diagnosis and treatment of mental health issues. In the MENTALER framework, the mental health support process comprises three specialized roles: Analyzer, Knowledge-Collector, and Strategy-Planner. Analyzer guides LLMs to achieve a in-depth diagnosis via multi-stage chain-of-thought prompting. Knowledge-Collector focus on involving domain-specific knowledge from exemplars retrieval. Strategy-Planner integrates professional support strategies into the generation process to further improve the professionalism among the generated texts. Through extensive automatic and human evaluations, we have validated that the mental health support counseling texts generated by MENTALER demonstrate a high degree of fluency and professionalism, closely aligning with real professional counseling texts. Our research advances the application of LLMs in the field of mental health support, providing an innovative and effective tool for those with psychological problems. © 2024 IEEE.",Yes,Daniel,,,,,,,,,,
Diagnosis of Epstein-Barr and cytomegalovirus infections using decision trees: an effective way to avoid antibiotic overuse in paediatric tonsillopharyngitis,"BACKGROUND: The incidence of tonsillopharyngitis is especially prevalent in 
children. Despite the fact that viruses cause the majority of infections, 
antibiotics are frequently used as a treatment, contrary to international 
guidelines. This is not only an inappropriate method of treatment for viral 
infections, but it also significantly contributes to the emergence of 
antibiotic-resistant strains. In this study, EBV and CMV-related 
tonsillopharyngitis were distinguished from other pathogens by using machine 
learning techniques to construct a classification tree based on clinical 
characteristics.
MATERIALS AND METHODS: In 2016 and 2017, we assessed information regarding 242 
children with tonsillopharyngitis. Patients were categorized according to 
whether acute cytomegalovirus or Epstein-Barr virus infections were confirmed 
(n = 91) or not (n = 151). Based on symptoms and blood test parameters, we 
constructed decision trees to discriminate the two groups. The classification 
efficiency of the model was characterized by its sensitivity, specificity, 
positive predictive value, and negative predictive value. Fisher's exact and 
Welch's tests were used to perform univariable statistical analyses.
RESULTS: The best decision tree distinguished EBV/CMV infection from non-EBV/CMV 
group with 83.33% positive predictive value, 88.90% sensitivity and 90.30% 
specificity. GPT (U/l) was found to be the most discriminatory variable 
(p < 0.0001). Using the model, unnecessary antibiotic treatment could be reduced 
by 66.66% (p = 0.0002).
DISCUSSION: Our classification model can be used as a diagnostic decision 
support tool to distinguish EBC/CMV infection from non EBV/CMV 
tonsillopharyngitis, thereby significantly reducing the overuse of antibiotics. 
It is hoped that the model may become a tool worth considering in routine 
clinical practice and may be developed to differentiate between viral and 
bacterial infections.

© 2023. The Author(s).",No,Pranav,,,,,,,,,,
Diagnostic accuracy of GPT-4 on common clinical scenarios and challenging cases,"Introduction: Large language models (LLMs) have a high diagnostic accuracy when they evaluate previously published clinical cases. Methods: We compared the accuracy of GPT-4's differential diagnoses for previously unpublished challenging case scenarios with the diagnostic accuracy for previously published cases. Results: For a set of previously unpublished challenging clinical cases, GPT-4 achieved 61.1% correct in its top 6 diagnoses versus the previously reported 49.1% for physicians. For a set of 45 clinical vignettes of more common clinical scenarios, GPT-4 included the correct diagnosis in its top 3 diagnoses 100% of the time versus the previously reported 84.3% for physicians. Conclusions: GPT-4 performs at a level at least as good as, if not better than, that of experienced physicians on highly challenging cases in internal medicine. The extraordinary performance of GPT-4 on diagnosing common clinical scenarios could be explained in part by the fact that these cases were previously published and may have been included in the training dataset for this LLM. © 2024 The Author(s). Learning Health Systems published by Wiley Periodicals LLC on behalf of University of Michigan.",Yes,Pranav,,,,,,,,,,
EpiPathAI: Using Large Language Models to Explore Mechanisms of Life Course Exposure-Outcome Associations,"Large language models (LLMs) enhanced with Graph Retrieval-Augmented Generation (GRAG) are promising for life-course epidemiology, which typically depends on costly and incomplete cohort data. Inspired by the epidemiological pathway model, we introduce EpiPathAI, which combines literature-derived causal knowledge graphs with LLMs to mine bridging variables and synthesize potential mechanisms between gestational diabetes and dementia. We test four GRAG strategies on GPT-4 and evaluate the identified mediators with clinical experts and three other LLM reviewers. The knowledge graph identifies 118 bridging variables, including coronary heart disease and chronic kidney disease, previously validated in our data-driven approach through the UK Biobank. EpiPathAI has identified additional clinically meaningful mediators, including high-level low-density lipoprotein (9.8% of effect, 95% CI: 3.7%-23.2%), and depression, which is a reasonable but statistically non-significant mediator in UK Biobank. EpiPathAI serves as a knowledge-driven mechanism mining agent that complements the data-driven approach, providing a compelling foundation for investigating other mediating pathways in future longitudinal cohort studies.",No,Pranav,,,,,,,,,,
Accuracy of a ChatGPT in Diagnosing Urologic Conditions From Cross-sectional Imaging,"Objective: To evaluate ChatGPT's effectiveness in medical imaging interpretation within urology, addressing the critical need for safe AI application in healthcare by identifying its strengths and limitations as a diagnostic and educational resource. Material and Methods: Using publicly available cases from Radiopaedia.com, we entered 1-3 CT or MRI images into ChatGPT. A standard prompt instructed the model to provide a differential diagnosis ranked by probability. This task was repeated a second time with organ guidance (OG), which provided the organ of diagnostic interest to the model (eg, kidney). Primary outcomes included whether the model's top or differential diagnosis correctly identified the underlying pathology. Results: ChatGPT correctly identified the pathologic condition as its top diagnosis in 14% of CT (7/50) and 28% (14/50) of MRI cases (P = .08). OG increased the model's ability to recognize the top diagnosis by 18% (P = .03) when interpreting CT images, a benefit not shared when interpreting MRI images (P = .4). At baseline the differential diagnosis contained the final diagnosis for 30% and 56% of CT and MRI cases (P = .03). With the inclusion of OG, the model's differential diagnosis was able to correctly identify the underlying condition in 62% of both CT and MRI cases (CT: P = .001, MRI: P = .31). Conclusion: ChatGPT's effectiveness in medical imaging diagnostics is initially limited, yet it substantially benefits from the addition of user guidance. The study underscores AI's current shortcomings but also its considerable capacity to improve clinical operations when enriched with more data and expert direction. © 2025 The Authors",Yes,Pranav,,,,,,,,,,
Large Language Model−Based Chatbot vs Surgeon-Generated Informed Consent Documentation for Common Procedures,"IMPORTANCE Informed consent is a critical component of patient care before invasive procedures, yet it is frequently inadequate. Electronic consent forms have the potential to facilitate patient comprehension if they provide information that is readable, accurate, and complete; it is not known if large language model (LLM)-based chatbots may improve informed consent documentation by generating accurate and complete information that is easily understood by patients. OBJECTIVE To compare the readability, accuracy, and completeness of LLM-based chatbot- vs surgeon-generated information on the risks, benefits, and alternatives (RBAs) of common surgical procedures. DESIGN, SETTING, AND PARTICIPANTS This cross-sectional study compared randomly selected surgeon-generated RBAs used in signed electronic consent forms at an academic referral center in San Francisco with LLM-based chatbot-generated (ChatGPT-3.5, OpenAI) RBAs for 6 surgical procedures (colectomy, coronary artery bypass graft, laparoscopic cholecystectomy, inguinal hernia repair, knee arthroplasty, and spinal fusion). MAIN OUTCOMES AND MEASURES Readability was measured using previously validated scales (Flesh-Kincaid grade level, Gunning Fog index, the Simple Measure of Gobbledygook, and the Coleman-Liau index). Scores range from 0 to greater than 20 to indicate the years of education required to understand a text. Accuracy and completeness were assessed using a rubric developed with recommendations from LeapFrog, the Joint Commission, and the American College of Surgeons. Both composite and RBA subgroup scores were compared. RESULTS The total sample consisted of 36 RBAs, with 1 RBA generated by the LLM-based chatbot and 5 RBAs generated by a surgeon for each of the 6 surgical procedures. The mean (SD) readability score for the LLM-based chatbot RBAs was 12.9 (2.0) vs 15.7 (4.0) for surgeon-generated RBAs (P = .10). The mean (SD) composite completeness and accuracy score was lower for surgeons’ RBAs at 1.6 (0.5) than for LLM-based chatbot RBAs at 2.2 (0.4) (P < .001). The LLM-based chatbot scores were higher than the surgeon-generated scores for descriptions of the benefits of surgery (2.3 [0.7] vs 1.4 [0.7]; P < .001) and alternatives to surgery (2.7 [0.5] vs 1.4 [0.7]; P < .001). There was no significant difference in chatbot vs surgeon RBA scores for risks of surgery (1.7 [0.5] vs 1.7 [0.4]; P = .38). CONCLUSIONS AND RELEVANCE The findings of this cross-sectional study suggest that despite not being perfect, LLM-based chatbots have the potential to enhance informed consent documentation. If an LLM were embedded in electronic health records in a manner compliant with the Health Insurance Portability and Accountability Act, it could be used to provide personalized risk information while easing documentation burden for physicians. © 2023 American Medical Association. All rights reserved.",Yes,Daniel,,,,,,,,,,
"Comparison of resistance training using barbell half squats and trap bar deadlifts on maximal strength, power performance, and lean mass in recreationally active females: an eight-week randomised trial","Background: The aim of this study was to investigate the effect of high load resistance training using barbell half squats compared with trap bar deadlifts on maximal strength, power performance, and lean mass in recreationally active females. Methods: Twenty-two recreationally active female participants (age: 26.9 ± 7.7 yrs.; height: 166.0 ± 5.1 cm; weight: 68.6 ± 9.9 kg) were randomly assigned to either a barbell half squat group (SG: n = 10) or trap bar deadlift group (DG: n = 12). Training consisted of twice-weekly sessions for eight weeks. Both groups completed one-repetition maximum (1RM) testing for both barbell half squat and trap bar deadlift groups. Countermovement jump (CMJ) and sprint performance were also assessed. Total body (TBLM) and leg lean mass (LLM) were measured with dual-energy x-ray absorptiometry. Between-group differences were analysed using analysis of covariance. Results: SG tended to improve 1RM half squat (21.0 ± 11.5 kg vs. 13.1 ± 7.5 kg) more than DG (mean difference (MD): 8.0 kg, 95% CI: -0.36 – 16.3 kg). A similar pattern in favour of DG (18.4 ± 11.2 vs. 11.7 ± 8.1 kg) compared to SG was observed (MD: 6.5 kg, 95% CI: -2.5 – 15.6 kg). No between-group differences for sprint, jump or lean body mass changes was observed. For groups combined, the following changes in CMJ (2.0 ± 2.4 cm), 5-m sprint (-0.020 ± 0.039 s), 15-m sprint (-0.055 ± 0.230 s), TBLM (0.84 ± 1.12 kg), and LLM (0.27 ± 0.59 kg) was observed. Conclusions: An exercise intervention consisting of half squats or trap bar deadlift were associated with improved muscle strength, power, and lean mass. Our findings suggests that in recreationally active females, exercise selection is less of a concern provided that heavy loads are applied, and relevant muscle groups are targeted. © The Author(s) 2024.",No,Pranav,,,,,,,,,,
"Custom GPTs Enhancing Performance and Evidence Compared with GPT-3.5, GPT-4, and GPT-4o? A Study on the Emergency Medicine Specialist Examination","Given the widespread application of ChatGPT, we aim to evaluate its proficiency in the emergency medicine specialty written examination. Additionally, we compare the performance of GPT-3.5, GPT-4, GPTs, and GPT-4o. The research seeks to ascertain whether custom GPTs possess the essential capabilities and access to knowledge bases necessary for providing accurate information, and to explore the effectiveness and potential of personalized knowledge bases in supporting the education of medical residents. We evaluated the performance of ChatGPT-3.5, GPT-4, custom GPTs, and GPT-4o on the Emergency Medicine Specialist Examination in Taiwan. Two hundred single-choice exam questions were provided to these AI models, and their responses were recorded. Correct rates were compared among the four models, and the McNemar test was applied to paired model data to determine if there were significant changes in performance. Out of 200 questions, GPT-3.5, GPT-4, custom GPTs, and GPT-4o correctly answered 77, 105, 119, and 138 questions, respectively. GPT-4o demonstrated the highest performance, significantly better than GPT-4, which, in turn, outperformed GPT-3.5, while custom GPTs exhibited superior performance compared to GPT-4 but inferior performance compared to GPT-4o, with all p < 0.05. In the emergency medicine specialty written exam, our findings highlight the value and potential of large language models (LLMs), and highlight their strengths and limitations, especially in question types and image-inclusion capabilities. Not only do GPT-4o and custom GPTs facilitate exam preparation, but they also elevate the evidence level in responses and source accuracy, demonstrating significant potential to transform educational frameworks and clinical practices in medicine. © 2024 by the authors.",Yes,Pranav,,,,,,,,,,
"Aligning, Autoencoding and Prompting Large Language Models for Novel Disease Reporting","Given radiology images, automatic radiology report generation aims to produce informative text that reports diseases. It can benefit current clinical practice in diagnostic radiology. Existing methods typically rely on large-scale medical datasets annotated by clinicians to train desirable models. However, for novel diseases, sufficient training data are typically not available. We propose a prompt-based deep learning framework, i.e., PromptLLM, to align, autoencode, and prompt the (large) language model to generate reports for novel diseases accurately and efficiently. Our method includes three major steps: (1) aligning visual images and textual reports to learn general knowledge across modalities from diseases where labeled data are sufficient, (2) autoencoding the LLM using unlabeled data of novel diseases to learn the specific knowledge and writing styles of the novel disease, and (3) prompting the LLM with learned knowledge and writing styles to report the novel diseases contained in the radiology images. Through the above three steps, with limited labels on novel diseases, we show that PromptLLM can rapidly learn the corresponding knowledge for accurate novel disease reporting. The experiments on COVID-19 and diverse thorax diseases show that our approach, utilizing 1% of the training data, achieves desirable performance compared to previous methods. It shows that our approach allows us to relax the reliance on labeled data that is common to existing methods. It could have a real-world impact on data analysis during the early stages of novel diseases. Our code and data are available at https://github.com/ai-in-health/PromptLLM.",Maybe?,Pranav,,,,,,,,,,
"Stability Indicating RP-HPLC Method for Simultaneous Estimation of Lamivudine, Stavudine and Nevirapine in Pure and Tablet form","A new, simple, accurate, precise, reproducible, economical RP-HPLC method was developed for the simultaneous estimation of Lamivudine, Stavudine and Nevirapine in pure and pharmaceutical dosage form. A Phenomenex Gemini C6 Phenyl column (250mm × 4.6mm, 5µ) forms the stationary phase in isocratic mode, with the mobile phase consisting of 0.02 M Ammonium dihydrogen phosphate buffer having pH 2.5, adjusted with formic acid (98%). Buffer and methanol were used in the ratio of (50:50) to obtain well-resolved peaks of Lamivudine, Stavudine and Nevirapine from the combined dosage form. The flow rate and run time were set at 1 ml/min and 30 minutes respectively. The effluent was monitored at 264nm. The retention times for Lamivudine, Stavudine and Nevirapine were 2.837, 3.590, and 8.037 min respectively. The linearity for lamivudine, Stavudine and Nevirapine were in the range of 12-84, 24-160 and 16-112μg/ml respectively. The method was validated as per ICH guidelines Q 2B. © RJPT All right reserved.",No,Pranav,,,,,,,,,,
Artificial Intelligence and Public Health: Evaluating ChatGPT Responses to Vaccination Myths and Misconceptions,"Artificial intelligence (AI) tools, such as ChatGPT, are the subject of intense debate regarding their possible applications in contexts such as health care. This study evaluates the Correctness, Clarity, and Exhaustiveness of the answers provided by ChatGPT on the topic of vaccination. The World Health Organization’s 11 “myths and misconceptions” about vaccinations were administered to both the free (GPT-3.5) and paid version (GPT-4.0) of ChatGPT. The AI tool’s responses were evaluated qualitatively and quantitatively, in reference to those myth and misconceptions provided by WHO, independently by two expert Raters. The agreement between the Raters was significant for both versions (p of K < 0.05). Overall, ChatGPT responses were easy to understand and 85.4% accurate although one of the questions was misinterpreted. Qualitatively, the GPT-4.0 responses were superior to the GPT-3.5 responses in terms of Correctness, Clarity, and Exhaustiveness (Δ = 5.6%, 17.9%, 9.3%, respectively). The study shows that, if appropriately questioned, AI tools can represent a useful aid in the health care field. However, when consulted by non-expert users, without the support of expert medical advice, these tools are not free from the risk of eliciting misleading responses. Moreover, given the existing social divide in information access, the improved accuracy of answers from the paid version raises further ethical issues. © 2023 by the authors.",Yes,Daniel,,,,,,,,,,
Variability of Guidelines and Disclosures for AI-Generated Content in Top Surgical Journals,"Background: When properly utilized, artificial intelligence generated content 
(AIGC) may improve virtually every aspect of research, from data gathering to 
synthesis. Nevertheless, when used inappropriately, the use of AIGC may lead to 
the dissemination of inaccurate information and introduce potential ethical 
concerns.Research Design: Cross-sectional. Study Sample: 65 top surgical 
journals. Data Collection: Each journals submission guidelines and portal was 
queried for guidelines regarding AIGC use.Results: We found that, in July 2023, 
60% of the top 65 surgical journals had introduced guidelines for use, with more 
surgical journals (68%) introducing guidelines than surgical subspecialty 
journals (52.5%), including otolaryngology (40%). Furthermore, of the 39 with 
guidelines, only 69.2% gave specific use guidelines. No included journal, at the 
time of analysis, explicitly disallowed AIGC use.Conclusions: Altogether, this 
data suggests that while many journals have quickly reacted to AIGC usage, the 
quality of such guidelines is still variable. This should be pre-emptively 
addressed within academia.",No,Daniel,,,,,,,,,,
Assessing the Performance of Zero-Shot Visual Question Answering in Multimodal Large Language Models for 12-Lead ECG Image Interpretation,"Large Language Models (LLM) are increasingly multimodal, and Zero-Shot Visual Question Answering (VQA) shows promise for image interpretation. If zero-shot VQA can be applied to a 12-lead electrocardiogram (ECG), a prevalent diagnostic tool in the medical field, the potential benefits to the field would be substantial. This study evaluated the diagnostic performance of zero-shot VQA with multimodal LLMs on 12-lead ECG images. The results revealed that multimodal LLM tended to make more errors in extracting and verbalizing image features than in describing preconditions and making logical inferences. Even when the answers were correct, erroneous descriptions of image features were common. These findings suggest a need for improved control over image hallucination and indicate that performance evaluation using the percentage of correct answers to multiple-choice questions may not be sufficient for performance assessment in VQA tasks.",Yes,Daniel,,,,,,,,,,
DepInferAttack: Framework for Membership Inference Attack in Depression Dataset,"Online social networks (OSNs), such as Reddit, capture a variety of human interactions, including sensitive discussions about depression. The study uses posts related to depression on Reddit, which gives an authentic view of how individuals express their feelings and experiences. Emotional-rich and highly disparate content makes this type of data difficult for machine learning models to process. Existing literature on membership inference attacks (MIAs) focusses on simple structured data and does not consider emotional aspects in these datasets. Our research addresses this gap by investigating MIAs with respect to emotionality, showing potential privacy concerns when using sensitive information. This paper introduces DepInferAttack a new framework designed specifically for performing MIAs over the OSN platform's depression-related content. Three different classifiers are employed in the target model: random forest, support vector machine, and neural network. A large-language model is used to generate synthetic datasets for the shadow model. The CNN architecture is employed by the shadow model, while the attack model uses a random forest classifier. The results show that DepInfer Attack framework is very effective at MIAs as it achieves a high accuracy of 94% to correctly classify whether the data point is a member of the target model's training dataset or not.  © 2024 IEEE.",No,Daniel,,,,,,,,,,
How Sensitive Are the Free AI-detector Tools in Detecting AI-generated Texts? A Comparison of Popular AI-detector Tools,"Background: Recently, Artificial intelligence (AI) has significantly influenced academic writing. We aimed to investigate the sensitivity of the free versions of popular AI-detection software programs in detecting AI-generated text. Methods: We searched for AI-content-detection software on Google and selected the first 10 free versions that allowed a minimum of 500 words for text analysis. Then, we gave ChatGPT 3.5 version a command to generate a scientific article on the “Role of Electroconvulsive Therapy (ECT) in Treatment-resistant Depression” under 500 words. After generating the primary text, we rephrased it using three different software tools. We then used AI-detection software to analyse the original and paraphrase texts. Results: 10 AI-detector tools were tested on their ability to detect AI-generated text. The sensitivity ranged from 0% to 100%. 5 out of 10 tools detected AI-generated content with 100% accuracy. For paraphrased texts, Sapling and Undetectable AI detected all three software-generated contents with 100% accuracy. Meanwhile, Copyleaks, QuillBot, and Wordtune identified content generated by two software programs with 100% accuracy. Conclusion: The integration of AI technology in academic writing is becoming more prevalent. Nonetheless, relying solely on AI-generated content can diminish the author’s credibility, leading most academic journals to suggest limiting its use. AI-content-detection software programs have been developed to detect AI-generated or AI-assisted texts. Currently, some of the platforms are equally sensitive. However, future upgrades may enhance their ability to detect AI-generated text more accurately. © 2024 The Author(s).",No,Daniel,,,,,,,,,,
Evaluation of community pharmacists’ perceptions and willingness to integrate ChatGPT into their pharmacy practice: A study from Jordan,"Objectives: This study aimed to examine the extent of community pharmacists’ awareness of Chat Generative Pretraining Transformer (ChatGPT), their willingness to embark on this new development of artificial intelligence (AI) development, and barriers that face the incorporation of this nonconventional source of information into pharmacy practice. Methods: A cross-sectional study was conducted among community pharmacists in Jordanian cities between April 26, 2023, and May 10, 2023. Convenience and snowball sampling techniques were used to select study participants owing to resource and time constraints. The questionnaire was distributed by research assistants through popular social media platforms. Logistic regression analysis was used to assess predictors affecting their willingness to use this service in the future. Results: A total of 221 community pharmacists participated in the current study (response rate was not calculated because opt-in recruitment strategies were used). Remarkably, nearly half of the pharmacists (n = 107, 48.4%) indicated a willingness to incorporate the ChatGPT into their pharmacy practice. Nearly half of the pharmacists (n = 105, 47.5%) demonstrated a high perceived benefit score for ChatGPT, whereas approximately 37% of pharmacists (n = 81) expressed a high concern score about ChatGPT. More than 70% of pharmacists believed that ChatGPT lacked the ability to use human judgment and make complicated ethical judgments in its responses (n = 168). Finally, logistics regression analysis showed that pharmacists who had previous experience in using ChatGPT were more willing to integrate ChatGPT in their pharmacy practice than those with no previous experience in using ChatGPT (odds ratio 2.312, P = 0.035). Conclusion: Although pharmacists show a willingness to incorporate ChatGPT into their practice, especially those with previous experience, there are major concerns. These mainly revolve around the tool's ability to make human-like judgments and ethical decisions. These findings are crucial for the future development and integration of AI tools in pharmacy practice. © 2023 American Pharmacists Association®",No,Daniel,Asks clinicians about their opinion on AI tools; not clinical use.,,,,,,,,,
The Effect of Active Compounds and Trace Elements Extracted from Artemisia Fruit on Some Liver Enzymes in Humans,"3174. Arch Razi Inst. 2023 Feb 28;78(1):175-180. doi: 10.22092/ARI.2022.359354.2409. 
eCollection 2023 Feb.

The Effect of Active Compounds and Trace Elements Extracted from Artemisia Fruit 
on Some Liver Enzymes in Humans.

Mahmood AR(1), Abdullah MR(1).

Author information:
(1)Department of Chemistry, College of Education for Pure Science (Ibn Al- 
Haitham), University of Baghdad, Baghdad, Iraq.

Artemisia is a perennial wild shrub with large branches and compound leaves. 
Artemisia contains about 400 types, and its medical importance is due to the 
presence of many active substances and compounds such as volatile oils, 
alkaloids and flavonoids, glycosides, saponins, tannins, and coumarins. This 
study was designed to study the effect of the aqueous extract of the fruit of 
the Artemisia plant on the organs of the body, as well as to know its ability to 
activate the hepatic enzyme alanine transaminase (ALT/GPT). The fruit of this 
shrub was extracted using the measurement technique gas chromatography-mass 
spectrometry (GC/MASS) and organic solvent hexane and ethyl acetate in one to 
one ratio. It contained 21 compounds, a high percentage of their terpenes, 
essential aromatic oils, alkaloids, and phenolic compounds. The results showed a 
significant improvement in the enzyme (ALT/GPT) level after adding different 
concentrations of hot aqueous extract to the fruit of the Artemisia plant. The 
fruit of the Artemisia plant can be used to treat many diseases and improve the 
activity of liver enzymes.",No,Daniel,,,,,,,,,,
Lorcaserin and phentermine exert anti-obesity effects with modulation of the gut microbiota,"Although drugs have been reported to modulate the gut microbiota, the effects of anti-obesity drugs on the gut microbiota remain unclear. Lorcaserin (LS) and phentermine (PT) are commonly used anti-obesity drugs. However, to our best knowledge, no studies have simultaneously assessed the effects of LS and PT on obesity and gut microbiota. This study aimed to explore the relationship between the anti-obesity effects of LS and PT and re-modulation of host gut microbiota. To test hypothesis, we fed C57BL/6J mice with a high-fat diet supplemented with LS and PT via oral gavage for 8 weeks. After sacrifice, body weight, fat accumulation, and serum biomarkers were measured, and the gut microbial composition was analyzed using 16 s rRNA amplicon sequencing. LS and PT were observed to modulate the gut microbial composition and restore gut microbial dysbiosis, as indicated by an increased Firmicutes/Bacteroidetes ratio. Significantly modulated genera by LS and PT treatment were strongly correlated with obesity-related markers. Additionally, LS and PT increased the mRNA level of G protein-coupled receptor 120 (GPR120) in the colon tissue. ASV3566, which corresponds to Eubacterium coprostanoligenes, was correlated with GPR120 and obesity-related markers such as glutamic pyruvic transaminase (GPT) and serum triglyceride (TG). In conclusion, LS and PT can modulate the gut microbiota dysbiosis and the gut microbiota plays a role in mediating the anti-obesity effect of drugs. Copyright © 2023 Song, Shin, Jeon, Nam and Kim.",No,Daniel,,,,,,,,,,
Can large language models predict antimicrobial peptide activity and toxicity?,"Antimicrobial peptides (AMPs) are naturally occurring or designed peptides up to a few tens of amino acids which may help address the antimicrobial resistance crisis. However, their clinical development is limited by toxicity to human cells, a parameter which is very difficult to control. Given the similarity between peptide sequences and words, large language models (LLMs) might be able to predict AMP activity and toxicity. To test this hypothesis, we fine-tuned LLMs using data from the Database of Antimicrobial Activity and Structure of Peptides (DBAASP). GPT-3 performed well but not reproducibly for activity prediction and hemolysis, taken as a proxy for toxicity. The later GPT-3.5 performed more poorly and was surpassed by recurrent neural networks (RNN) trained on sequence-activity data or support vector machines (SVM) trained on MAP4C molecular fingerprint-activity data. These simpler models are therefore recommended, although the rapid evolution of LLMs warrants future re-evaluation of their prediction abilities.",No,Daniel,,,,,,,,,,
"Evaluation of social and assistive robotics in geriatric institutions: Dimensions of usability, acceptability and ethics","Purpose Older adults suffering from neurocognitive disorders require multimodal support. Social assistant robots, mechanical entities capable of interacting socially with their users in a variety of contexts (informational, recreational, educational), could be used to improve their physical and psychological well-being and maintain their quality of life. Today, however, these robot assistants are not sufficiently advanced to engage in satisfactory social interactions that would lead to their adoption. This project is part of the European SPRING project, which aims to develop a social assistance robot, ARI, capable of interacting with several speakers in hospital environments. ARI is designed to inform, guide and entertain users and support healthcare professionals in their work. Methods The evaluation of the ARI robotic system was carried out with two stakeholders in a Paris hospital department (France): patients and their accompanying persons, who used the ARI robot. The study was conducted in two experimental waves to measure the system’s progress and effectiveness. The first wave included 20 participants, comprising both patients and accompanying persons, while the second wave expanded the evaluation to 49 participants. This structure allowed us to iteratively improve the robot’s usability based on feedback received after the first wave. The study focused on the usability of the system and the analysis of human-robot interactions in order to identify areas for ergonomic improvement. To assess usability, we used the System Usability Scale. The robot’s acceptability in hospital settings was assessed using the French version of the Acceptability E-Scale questionnaire and a semi-directive interview, asking users about the ethical issues involved in implementing social robots in hospital settings. Results Two waves of experiments have been carried out since March 2023, involving 20 and 49 participants respectively, with an average age of 76.7 and 73.89. The second wave introduced a major innovation: the integration of a Large Language Model (LLM) into interaction with the ARI robot. The results showed an improvement in the acceptability and usability of the social robot during this second phase. Mean scores on the Acceptability Evaluation Scale (AES) rose from 15.4 to 20.8/30, while those on the System Usability Scale (SUS) increased from 47.5 to 57/100. Conclusion In conclusion, our study within the European SPRING project aimed to evaluate the ARI social assistance robot in hospital settings, focusing on usability and human-robot interaction. The integration of a Large Language Model (LLM) in the second phase marked a significant advancement, leading to improved acceptability and usability scores. These findings highlight the potential of advanced technologies in enhancing social robots’ effectiveness in healthcare contexts. As we continue to refine ARI based on user feedback, our research contributes to the ongoing development of assistive technologies tailored to the needs of older individuals and their caregivers. © (2024), (International Society for Gerontechnology). All rights reserved.",No,Daniel,,,,,,,,,,
LLM Based 3D Avatar Assistant,"The Existing Applications Such as Amazon Alexa, Google Assistant etc. still lack the use of a 3D avatar and LLM in their voice assistants thereby making it less interactive. Also, these do not process real time camera feed. A proposed solution to the problem is a 3D Avatar Based Assistant that utilizes LLM technology. These virtual beings, known as avatars, make use of LLMs' abilities to converse, comprehend, and help users in a way that is both highly engaging and immersive. These avatars provide users with a more engaging and human-like interface by fusing state-of-the-art natural language processing algorithms with three-dimensional depictions. This makes it simpler for users to obtain information, get help, and do a variety of digital chores. This abstract examines the idea of LLM-based 3D avatar assistants, emphasizing the changing field of human-computer interaction they represent as well as their possible uses in customer service, education, entertainment, and other areas. © 2024 IEEE.",No,Daniel,,,,,,,,,,
“A Great Reinforcing Organ”: the Cerebellum According to Silas Weir Mitchell,"This Cerebellar Classic highlights a work by the physician and novelist, Silas Weir Mitchell (1829–1914), a pupil of Claude Bernard and a founding father of American neurology. Published in the aftermath of the American Civil War, the article reported observations on cerebellar physiology based on ablation and tissue freezing experiments in pigeons, rabbits, and guinea pigs. Mitchell communicated his results before the Academy of Natural Sciences of Philadelphia, and proposed a general theory of the cerebellum as an augmenting and reinforcing organ to the cerebrospinal motor system. After reviewing and contrasting previous theories of Flourens and Bouillaud, Mitchell formulated his own theory, which was in line with the views of Rolando and Luys. The theory emphasized the necessity, initially suggested by Brown-Séquard, of distinguishing between phenomena due to loss of function and those due to irritation as a central principle that should guide any physiological research. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.",No,Daniel,,,,,,,,,,
Medical Text Prediction and Suggestion Using Generative Pretrained Transformer Models with Dental Medical Notes,"Background  Generative pretrained transformer (GPT) models are one of the latest large pretrained natural language processing models that enables model training with limited datasets and reduces dependency on large datasets, which are scarce and costly to establish and maintain. There is a rising interest to explore the use of GPT models in health care. Objective  We investigate the performance of GPT-2 and GPT-Neo models for medical text prediction using 374,787 free-text dental notes. Methods  We fine-tune pretrained GPT-2 and GPT-Neo models for next word prediction on a dataset of over 374,000 manually written sections of dental clinical notes. Each model was trained on 80% of the dataset, validated on 10%, and tested on the remaining 10%. We report model performance in terms of next word prediction accuracy and loss. Additionally, we analyze the performance of the models on different types of prediction tokens for categories. For comparison, we also fine-tuned a non-GPT pretrained neural network model, XLNet (large), for next word prediction. We annotate each token in 100 randomly sampled notes by category (e.g., names, abbreviations, clinical terms, punctuation, etc.) and compare the performance of each model by token category. Results  Models present acceptable accuracy scores (GPT-2: 76%; GPT-Neo: 53%), and the GPT-2 model also performs better in manual evaluations, especially for names, abbreviations, and punctuation. Both GPT models outperformed XLNet in terms of accuracy. The results suggest that pretrained models have the potential to assist medical charting in the future. We share the lessons learned, insights, and suggestions for future implementations. Conclusion  The results suggest that pretrained models have the potential to assist medical charting in the future. Our study presented one of the first implementations of the GPT model used with medical notes. © 2022 Georg Thieme Verlag. All rights reserved.",No,Sully,This is a weird study,,,,,,,,,
Application of a general LLM-based classification system to retrieve information about oncological trials,"Purpose: The automated classification of clinical trials and medical literature is increasingly relevant, particularly in oncology, as the volume of publications and trial reports continues to expand. Large Language Models (LLMs) may provide new opportunities for automated diverse classification tasks. In this study, we developed a general-purpose text classification framework using LLMs and evaluated its performance on oncological trial classification tasks. Methods and Materials: A general text classification framework with adaptable prompt, model and categories for the classification was developed. The framework was tested with four datasets comprising nine binary classification questions related to oncological trials. Evaluation was conducted using a locally hosted version of Mixtral-8x7B-Instruct v0.1 and three cloud-based LLMs: Mixtral-8x7BInstruct v0.1, Llama3.1-70B-Instruct, and Qwen-2.5-72B. Results: The system consistently produced valid responses with the local Mixtral-8x7B-Instruct model and the Llama3.1-70B-Instruct model. It achieved a response validity rate of 99.70% and 99.88% for the cloud-based Mixtral and Qwen models, respectively. Across all models, the framework achieved an overall accuracy of >94%, precision of >92%, recall of >90%, and an F1-score of >92%. Question-specific accuracy ranged from 86.33% to 99.83% for the local Mixtral model, 85.49% to 99.83% for the cloud-based Mixtral model, 90.50% to 99.83% for the Llama3.1 model, and 77.13% to 99.83% for the Qwen model. Conclusions: The LLM-based classification framework exhibits robust accuracy and adaptability across various oncological trial classification tasks. The findings highlight the potential of automated, LLM-driven trial classification systems, which may become increasingly used in oncology.",No,Sully,,,,,,,,,,
Research on a traditional Chinese medicine case-based question-answering system integrating large language models and knowledge graphs,"Introduction: Traditional Chinese Medicine (TCM) case records encapsulate vast clinical experiences and theoretical insights, holding significant research and practical value. However, traditional case studies face challenges such as large data volumes, complex information, and difficulties in efficient retrieval and analysis. This study aimed to address these issues by leveraging modern data techniques to improve access and analysis of TCM case records. Methods: A total of 679 case records from Wang Zhongqi, a renowned physician of Xin’an Medicine, a branch of TCM, covering 41 diseases, were selected. The study involved four stages: pattern layer construction, knowledge extraction, integration, and data storage and visualization. A large language model (LLM) was employed to automatically extract key entities, including symptoms, pathogenesis, treatment principles, and prescriptions. These were structured into a TCM case knowledge graph. Results: The LLM successfully identified and extracted relevant entities, which were then organized into relational triples. A TCM case query system based on natural language input was developed. The system’s performance, evaluated using the RAGAS framework, achieved high scores: 0.9375 in faithfulness, 0.9686 in answer relevancy, and 0.9500 in context recall; In human evaluations, the levels of safety and usability are significantly higher than those of LLMs without using RAG. Discussion: The results demonstrate that integrating LLMs with a knowledge graph significantly enhances the efficiency and accuracy of retrieving TCM case information. This approach could play a crucial role in modernizing TCM research and improving access to clinical insights. Future research may explore expanding the dataset and refining the query system for broader applications. Copyright © 2025 Duan, Zhou, Li, Qin, Wang, Kan and Hu.",Yes,Sully,,,,,,,,,,
Off-label use of an iliac branch device and a reversed iliac limb for a patient with a unilateral common iliac artery aneurysm and a narrow distal aorta: A case report,"INTRODUCTION: Current bifurcated aortic endografts are unsuitable for patients 
with a narrow distal aorta except AFX2, which is unavailable in South Korea. An 
iliac branch device (IBD) was introduced to exclude iliac aneurysms while 
preserving the pelvic circulation. With advancements in endovascular techniques, 
various attempts for outside instructions for use have been reported to be 
practicable in certain patients.
PATIENT CONCERNS: A 58-year-old man was referred to our emergency room with an 
incidentally found left common iliac artery aneurysm (CIAA) in a general 
checkup.
DIAGNOSES: Computed tomography angiogram showed a narrow distal aorta that 
tapered from 20 mm just below the renal artery to 13 mm at aortic bifurcation 
and a left isolated CIAA with a maximal diameter of 40 mm and 70 mm in length.
INTERVENTIONS: After left hypogastric artery embolization, the Cook IBD was 
placed at the aortic bifurcation, and the Bard Covera Plus stent-graft was 
deployed from the IBD cuff to the left external iliac artery. Then, a reversed 
Medtronic Endurant iliac limb was implanted into the infrarenal aorta down to 
the proximal IBD.
OUTCOMES: The stent grafts were patent without endoleak at the 6-month 
follow-up.
LESSONS: In selected patients with an isolated CIAA with a narrow distal aorta, 
IBD can be used as a main body at the aortic bifurcation for successful aneurysm 
exclusion. However, considering the application of outside instructions for use, 
special attention and careful planning must be taken before the procedure.

Copyright © 2023 the Author(s). Published by Wolters Kluwer Health, Inc.",No,Daniel,,,,,,,,,,
A scientific-article key-insight extraction system based on multi-actor of fine-tuned open-source large language models,"The exponential growth of scientific articles has presented challenges in information organization and extraction. Automation is urgently needed to streamline literature reviews and enhance insight extraction. We explore the potential of Large Language Models (LLMs) in key-insights extraction from scientific articles, including OpenAI's GPT-4.0, MistralAI's Mixtral 8 × 7B, 01AI's Yi, and InternLM's InternLM2. We have developed an article-level key-insight extraction system based on LLMs, calling it ArticleLLM. After evaluating the LLMs against manual benchmarks, we have enhanced their performance through fine-tuning. We propose a multi-actor LLM approach, merging the strengths of multiple fine-tuned LLMs to improve overall key-insight extraction performance. This work demonstrates not only the feasibility of LLMs in key-insight extraction, but also the effectiveness of cooperation of multiple fine-tuned LLMs, leading to efficient academic literature survey and knowledge discovery.",No,Pranav,,,,,,,,,,
Expanding horizons and navigating challenges for enhanced clinical workflows: ChatGPT in urology,"Purpose of review: ChatGPT has emerged as a potential tool for facilitating doctors' workflows. However, when it comes to applying these findings within a urological context, there have not been many studies. Thus, our objective was rooted in analyzing the pros and cons of ChatGPT use and how it can be exploited and used by urologists. Recent findings: ChatGPT can facilitate clinical documentation and note-taking, patient communication and support, medical education, and research. In urology, it was proven that ChatGPT has the potential as a virtual healthcare aide for benign prostatic hyperplasia, an educational and prevention tool on prostate cancer, educational support for urological residents, and as an assistant in writing urological papers and academic work. However, several concerns about its exploitation are presented, such as lack of web crawling, risk of accidental plagiarism, and concerns about patients-data privacy. Summary: The existing limitations mediate the need for further improvement of ChatGPT, such as ensuring the privacy of patient data and expanding the learning dataset to include medical databases, and developing guidance on its appropriate use. Urologists can also help by conducting studies to determine the effectiveness of ChatGPT in urology in clinical scenarios and nosologies other than those previously listed. 2023 Talyshinskii, Naik, Hameed, Zhanbyrbekuly, Khairli, Guliev, Juliebø-Jones, Tzelves and Somani.",No,Pranav,Review,,,,,,,,,
A scoping review on generative AI and large language models in mitigating medication related harm,"Medication-related harm has a significant impact on global healthcare costs and patient outcomes. Generative artificial intelligence (GenAI) and large language models (LLM) have emerged as a promising tool in mitigating risks of medication-related harm. This review evaluates the scope and effectiveness of GenAI and LLM in reducing medication-related harm. We screened 4 databases for literature published from 1st January 2012 to 15th October 2024. A total of 3988 articles were identified, and 30 met the criteria for inclusion into the final review. Generative AI and LLMs were applied in three key applications: drug-drug interaction identification and prediction, clinical decision support, and pharmacovigilance. While the performance and utility of these models varied, they generally showed promise in early identification, classification of adverse drug events, and supporting decision-making for medication management. However, no studies tested these models prospectively, suggesting a need for further investigation into integration and real-world application. © The Author(s) 2025.",No,Pranav,Review,,,,,,,,,
Cardiac surgery and acute hepatitis B - Use of the Seraph™ 100 hemofilter,"We present a case of a 55-year-old male, presenting with angina symptoms with electrocardiographic changes and a panfocal systolic murmur radiating to the carotids. He had a primary HBV infection 8 months ago, without antiviral treatment. Echocardiography showed critical aortic valve stenosis (area: 0.53 cm2/m2). No coronary lesions were found on coronary angiography. Blood analysis revealed AST/GOT of 96 U/L and ALT/GPT 150 U/L. The serological profile revealed positive IgM anti-HBc, anti-HBc, anti-HBs and anti-HBe antibodies, with an increasing viral load (VL). The abdominal ultrasound identified mild hepatic fibrosis (F3) with minimal steatosis. Mechanical aortic prosthetic valve replacement was performed under CPB. The Seraph™ 100 filter was incorporated into the CPB circuit to reduce the risk of HBV contamination, infection and liver failure. The postoperative VL was monitored (Table 1). Liver function tests showed peak levels of bilirubin 0.66 mg/dL, AST/GOT 58 U/L, ALT/GPT 74 U/L at 6 hours post-surgery, with recovery of normal ranges at 48 hours post-surgery.",No,Pranav,,,,,,,,,,
A Future of Self-Directed Patient Internet Research: Large Language Model-Based Tools Versus Standard Search Engines,"Purpose: As generalist large language models (LLMs) become more commonplace, patients will inevitably increasingly turn to these tools instead of traditional search engines. Here, we evaluate publicly available LLM-based chatbots as tools for patient education through physician review of responses provided by Google, Bard, GPT-3.5 and GPT-4 to commonly searched queries about prevalent chronic health conditions in the United States. Methods: Five distinct commonly Google-searched queries were selected for (i) hypertension, (ii) hyperlipidemia, (iii) diabetes, (iv) anxiety, and (v) mood disorders and prompted into each model of interest. Responses were assessed by board-certified physicians for accuracy, comprehensiveness, and overall quality on a five-point Likert scale. The Flesch-Kincaid Grade Levels were calculated to assess readability. Results: GPT-3.5 (4.40 ± 0.48, 4.29 ± 0.43) and GPT-4 (4.35 ± 0.30, 4.24 ± 0.28) received higher ratings in comprehensiveness and quality than Bard (3.79 ± 0.36, 3.87 ± 0.32) and Google (1.87 ± 0.42, 2.11 ± 0.47), all p < 0.05. However, Bard (9.45 ± 1.35) and Google responses (9.92 ± 5.31) had a lower average Flesch-Kincaid Grade Level compared to GPT-3.5 (14.69 ± 1.57) and GPT-4 (12.88 ± 2.02), indicating greater readability. Conclusion: This study suggests that publicly available LLM-based tools may provide patients with more accurate responses to queries on chronic health conditions than answers provided by Google search. These results provide support for the use of these tools in place of traditional search engines for health-related queries.",Yes,Pranav,,,,,,,,,,
OpenAI's ChatGPT and Its Role in Plastic Surgery Research,"2482. Plast Reconstr Surg. 2023 May 1;151(5):1111-1113. doi: 
10.1097/PRS.0000000000010342. Epub 2023 Apr 26.

OpenAI's ChatGPT and Its Role in Plastic Surgery Research.

Weidman AA(1), Valentine L(1), Chung KC(2), Lin SJ(1).

Author information:
(1)From the Division of Plastic Surgery, Beth Israel Deaconess Medical Center, 
Harvard Medical School.
(2)Section of Plastic Surgery, University of Michigan.",No,Pranav,Opinion style piece without primary research ,,,,,,,,,
Cross-platform social dynamics: an analysis of ChatGPT and COVID-19 vaccine conversations,"3124. Sci Rep. 2024 Feb 2;14(1):2789. doi: 10.1038/s41598-024-53124-x.

Cross-platform social dynamics: an analysis of ChatGPT and COVID-19 vaccine 
conversations.

Alipour S(1), Galeazzi A(2), Sangiorgio E(3), Avalle M(4), Bojic L(5)(6), 
Cinelli M(4), Quattrociocchi W(4).

Author information:
(1)Department of Computer Science, Sapienza University of Rome, Rome, Italy. 
shayan.alipour@uniroma1.it.
(2)Ca'Foscari University of Venice, DAIS, Venice, Italy.
(3)Department of Social Sciences and Economics, Sapienza University of Rome, 
Rome, Italy.
(4)Department of Computer Science, Sapienza University of Rome, Rome, Italy.
(5)The Institute for Artificial Intelligence Research and Development of Serbia, 
Beograd, Serbia.
(6)Institute for Philosophy and Social Theory, University of Belgrade, Beograd, 
Serbia.

The role of social media in information dissemination and agenda-setting has 
significantly expanded in recent years. By offering real-time interactions, 
online platforms have become invaluable tools for studying societal responses to 
significant events as they unfold. However, online reactions to external 
developments are influenced by various factors, including the nature of the 
event and the online environment. This study examines the dynamics of public 
discourse on digital platforms to shed light on this issue. We analyzed over 12 
million posts and news articles related to two significant events: the release 
of ChatGPT in 2022 and the global discussions about COVID-19 vaccines in 2021. 
Data was collected from multiple platforms, including Twitter, Facebook, 
Instagram, Reddit, YouTube, and GDELT. We employed topic modeling techniques to 
uncover the distinct thematic emphases on each platform, which reflect their 
specific features and target audiences. Additionally, sentiment analysis 
revealed various public perceptions regarding the topics studied. Lastly, we 
compared the evolution of engagement across platforms, unveiling unique patterns 
for the same topic. Notably, discussions about COVID-19 vaccines spread more 
rapidly due to the immediacy of the subject, while discussions about ChatGPT, 
despite its technological importance, propagated more gradually.

© 2024. The Author(s).",No,Pranav,,,,,,,,,,
Navigating the path to precision: ChatGPT as a tool in pathology,"In recent years, the integration of Artificial Intelligence (AI) into medicine has marked a transformative shift in healthcare practices. This study explores the application of ChatGPT 3.5, an AI-based natural language processing model, in the field of pathology, with a focus on Clinical Pathology, Histopathology, and Hematology. Leveraging a dataset of 30 clinical cases from an online source, the model's performance was evaluated, revealing moderate proficiency in data analysis and decision support. While ChatGPT demonstrated strengths in swift narrative comprehension and foundational insights, limitations were observed in generating detailed and comprehensive information. The study emphasizes the evolving nature of AI in pathology, highlighting the need for ongoing refinement and collaborative efforts between AI researchers and healthcare professionals. © 2024 Elsevier GmbH",Yes,Pranav,,,,,,,,,,
Differentiating between GPT-generated and human-written feedback for radiology residents,"Purpose: Recent competency-based medical education (CBME) implementation within Canadian radiology programs has required faculty to conduct more assessments. The rise of narrative feedback in CBME, coinciding with the rise of large language models (LLMs), raises questions about the potential of these models to generate informative comments matching human experts and associated challenges. This study compares human-written feedback to GPT-3.5-generated feedback for radiology residents, and how well raters can differentiate between these sources. Methods: Assessments were completed by 28 faculty members for 10 residents within a Canadian Diagnostic Radiology program (2019–2023). Comments were extracted from Elentra, de-identified, and parsed into sentences, of which 110 were randomly selected for analysis. 11 of these comments were entered into GPT-3.5, generating 110 synthetic comments that were mixed with actual comments. Two faculty raters and GPT-3.5 read each comment to predict whether it was human-written or GPT-generated. Results: Actual comments from humans were often longer and more specific than synthetic comments, especially when describing clinical procedures and patient interactions. Source differentiation was more difficult when both feedback types were similarly vague. Low agreement (k=-0.237) between responses provided by GPT-3.5 and humans was observed. Human raters were also more accurate (80.5 %) at identifying actual and synthetic comments than GPT-3.5 (50 %). Conclusion: Currently, GPT-3.5 cannot match human experts in delivering specific, nuanced feedback for radiology residents. Compared to humans, GPT-3.5 also performs worse in distinguishing between actual and synthetic comments. These insights could guide the development of more sophisticated algorithms to produce higher-quality feedback, supporting faculty development. © 2025 The Author(s)",No,Pranav,Not doing a patient care related task,,,,,,,,,
Is the Education System Prepared for the Irruption of Artificial Intelligence? A Study on the Perceptions of Students of Primary Education Degree from a Dual Perspective: Current Pupils and Future Teachers,"The recent irruption of ChatGPT, a powerful chatbot that uses a “Chat Generative Pretrained Transformer” language model, could revolutionize education worldwide since it can greatly affect the competence development that students need to achieve for their professional future. The aim of this work is to assess the level of knowledge of ChatGPT and the perception of its possibilities of use in education by students studying the Primary Education Degree at the University of León (Spain) from a double perspective: as students and future teachers, respectively. For this purpose, a descriptive, cross-sectional, non-experimental, and quantitative research design was carried out, with the design and elaboration of a questionnaire. The questionnaire data were statistically processed by calculating relative frequencies. The main results highlight that students have a positive perception of ChatGPT use, with potential applications in education, and do not perceive it as a threat to the deterioration of the educational system as long as the sources of the data generated by the tool are verified. In addition, as students and future teachers, they need more knowledge about the operation of ChatGPT to ensure its correct use and maintain the quality of the education system. Thus, to overcome ChatGPT irruption in education, digital literacy is crucial at all educational levels. © 2023 by the authors.",No,Pranav,,,,,,,,,,
Ubie Symptom Checker: A Clinical Vignette Simulation Study,"Background AI-driven symptom checkers (SC) are increasingly adopted in healthcare for their potential to provide users with accessible and immediate preliminary health education. These tools, powered by advanced artificial intelligence algorithms, assist patients in quickly assessing their symptoms. Previous studies using clinical vignette approaches have evaluated SC accuracy, highlighting both strengths and areas for improvement. Objective This study aims to evaluate the performance of the Ubie Symptom Checker (Ubie SC) using an innovative large language model-assisted (LLM) simulation method. Methods The study employed a three-phase methodology: gathering 400 publicly available clinical vignettes, medical entity linking these vignettes to the Ubie SC using large language models and physician supervision, and evaluation of accuracy metrics. The analysis focused on 328 vignettes that were within the scope of the Ubie SC with accuracy measured by Top-5 hit rates. Results Ubie achieved a Top-5 hit accuracy of 63.4% and a Top-10 hit accuracy of 71.6%, indicating its effectiveness in providing relevant information based on symptom input. The system performed particularly well in domains such as the nervous system and respiratory conditions, though variability in accuracy was observed across different ICD groupings, highlighting areas for further refinement. When compared to physicians and comparator SC’s that used the same clinical vignettes set, Ubie compared favorably to the median physician hit accuracy. Conclusions The Ubie Symptom Checker shows considerable promise as a supportive education tool in healthcare. While the study highlights the system's strengths, it also identifies areas for improvement suggesting continued refinement and real-world testing are essential to fully realize Ubie's potential in AI-assisted healthcare.",Yes,Pranav,,,,,,,,,,
"Performance assessment of ChatGPT 4, ChatGPT 3.5, Gemini Advanced Pro 1.5 and Bard 2.0 to problem solving in pathology in French language","Digital teaching diversifies the ways of knowledge assessment, as natural language processing offers the possibility of answering questions posed by students and teachers. Objective: This study evaluated ChatGPT's, Bard's and Gemini's performances on second year of medical studies’ (DFGSM2) Pathology exams from the Health Sciences Center of Dijon (France) in 2018–2022. Methods: From 2018 to 2022, exam scores, discriminating powers and discordance rates were retrieved. Seventy questions (25 first-order single response questions and 45 second-order multiple response questions) were submitted on May 2023 to ChatGPT 3.5 and Bard 2.0, and on September 2024 to Gemini 1.5 and ChatGPT-4. Chatbot's and student's average scores were compared, as well as discriminating powers of questions answered by chatbots. The percentage of student–chatbot identical answers was retrieved, and linear regression analysis correlated the scores of chatbots with student's discordance rates. Chatbot's reliability was assessed by submitting the questions in four successive rounds and comparing score variability using a Fleiss’ Kappa and a Cohen's Kappa. Results: Newer chatbots outperformed both students and older chatbots as for the overall scores and multiple-response questions. All chatbots outperformed students on less discriminating questions. Oppositely, all chatbots were outperformed by students to questions with a high discriminating power. Chatbot's scores were correlated to student discordance rates. ChatGPT 4 and Gemini 1.5 provided variable answers, due to effects linked to prompt engineering. Conclusion: Our study in line with the literature confirms chatbot's moderate performance for questions requiring complex reasoning, with ChatGPT outperforming Google chatbots. The use of NLP software based on distributional semantics remains a challenge for the generation of questions in French. Drawbacks to the use of NLP software in generating questions include the generation of hallucinations and erroneous medical knowledge which have to be taken into count when using NLP software in medical education. © The Author(s) 2025.",Maybe?,Pranav,"Could see an arguemnt either way for this, but these questions for MS2 are likely patient care related concepts. ",,,,,,,,,
DeepAIP: Deep learning for anti-inflammatory peptide prediction using pre-trained protein language model features based on contextual self-attention network,"3806. Int J Biol Macromol. 2024 Nov;280(Pt 4):136172. doi: 
10.1016/j.ijbiomac.2024.136172. Epub 2024 Sep 30.

DeepAIP: Deep learning for anti-inflammatory peptide prediction using 
pre-trained protein language model features based on contextual self-attention 
network.

Zhu L(1), Yang Q(2), Yang S(3).

Author information:
(1)School of Computer Science and Artificial Intelligence Aliyun School of Big 
Data School of Software, Changzhou University, Changzhou 213164, China; The 
Affiliated Changzhou No.2 People's Hospital of Nanjing Medical University, 
Changzhou 213164, China.
(2)School of Computer Science and Artificial Intelligence Aliyun School of Big 
Data School of Software, Changzhou University, Changzhou 213164, China.
(3)School of Computer Science and Artificial Intelligence Aliyun School of Big 
Data School of Software, Changzhou University, Changzhou 213164, China; The 
Affiliated Changzhou No.2 People's Hospital of Nanjing Medical University, 
Changzhou 213164, China. Electronic address: ys@cczu.edu.cn.

Non-steroidal anti-inflammatory drugs (NSAIDs), glucocorticoids, and other 
immunosuppressants are commonly used medications for treating inflammation. 
However, these drugs often come with numerous side effects. Therefore, finding 
more effective methods for inflammation treatment has become more necessary. The 
study of anti-inflammatory peptides can effectively address these issues. In 
this work, we propose a contextual self-attention deep learning model, coupled 
with features extracted from a pre-trained protein language model, to predict 
Anti-inflammatory Peptides (AIP). The contextual self-attention module can 
effectively enhance and learn the features extracted from the pre-trained 
protein language model, resulting in high accuracy to predict AIP. Additionally, 
we compared the performance of features extracted from popular pre-trained 
protein language models available in the market. Finally, Prot-T5 features 
demonstrated the best comprehensive performance as the input for our deep 
learning model named DeepAIP. Compared with existing methods on benchmark test 
dataset, DeepAIP gets higher Matthews Correlation Coefficient and Accuracy score 
than the second-best method by 16.35 % and 6.91 %, respectively. Performance 
comparison analysis was conducted using a dataset of 17 novel anti-inflammatory 
peptide sequences. DeepAIP demonstrates outstanding accuracy, correctly 
identifying all 17 peptide types as AIP and predicting values closer to the true 
ones. Data and code are available at https://github.com/YangQingGuoCCZU/DeepAIP.

Copyright © 2024 Elsevier B.V. All rights reserved.",No,Pranav,,,,,,,,,,
ChatGPT and Artificial Intelligence in Graduate Medical Education Program Applications,"2719. J Grad Med Educ. 2024 Aug;16(4):391-394. doi: 10.4300/JGME-D-23-00823.1. Epub 
2024 Aug 15.

ChatGPT and Artificial Intelligence in Graduate Medical Education Program 
Applications.

Quinonez SC(1), Stewart DA(2), Banovic N(3).

Author information:
(1)is Clinical Associate Professor, Department of Pediatrics and Internal 
Medicine, and Associate Program Director, Pediatrics Residency Program, 
University of Michigan, Ann Arbor, Michigan, USA.
(2)is Clinical Assistant Professor, Department of Pediatrics, and Associate 
Program Director, Pediatrics Residency Program, University of Michigan, Ann 
Arbor, Michigan, USA; and.
(3)is Associate Professor, Department of Electrical Engineering and Computer 
Science, University of Michigan, Ann Arbor, Michigan, USA.",No,Pranav,,,,,,,,,,
Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts,"Automatic coding patient behaviors is essential to support decision making for psychotherapists during the motivational interviewing (MI), a collaborative communication intervention approach to address psychiatric issues, such as alcohol and drug addiction. While the behavior coding task has rapidly adapted language models to predict patient states during the MI sessions, lacking of domain-specific knowledge and overlooking patient-therapist interactions are major challenges in developing and deploying those models in real practice. To encounter those challenges, we introduce the Chain-of- Interaction (CoI) prompting method aiming to contextualize large language models (LLMs) for psychiatric decision support by the dyadic interactions. The CoI prompting approach systematically breaks down the coding task into three key reasoning steps, extract patient engagement, learn therapist question strategies, and integrates dyadic interactions between patients and therapists. This approach enables large language models to leverage the coding scheme, patient state, and domain knowledge for patient behavioral coding. Experiments on real-world datasets can prove the effectiveness and flexibility of our prompting method with multiple state-of-the-art LLMs over existing prompting baselines. We have conducted extensive ablation analysis and demonstrate the critical role of dyadic interactions in applying LLMs for psychotherapy behavior understanding. © 2024 IEEE.",Yes,Pranav,,,,,,,,,,
Building a Human Digital Twin (HDTwin) Using Large Language Models for Cognitive Diagnosis: Algorithm Development and Validation,"BACKGROUND: Human digital twins have the potential to change the practice of 
personalizing cognitive health diagnosis because these systems can integrate 
multiple sources of health information and influence into a unified model. 
Cognitive health is multifaceted, yet researchers and clinical professionals 
struggle to align diverse sources of information into a single model.
OBJECTIVE: This study aims to introduce a method called HDTwin, for unifying 
heterogeneous data using large language models. HDTwin is designed to predict 
cognitive diagnoses and offer explanations for its inferences.
METHODS: HDTwin integrates cognitive health data from multiple sources, 
including demographic, behavioral, ecological momentary assessment, n-back test, 
speech, and baseline experimenter testing session markers. Data are converted 
into text prompts for a large language model. The system then combines these 
inputs with relevant external knowledge from scientific literature to construct 
a predictive model. The model's performance is validated using data from 3 
studies involving 124 participants, comparing its diagnostic accuracy with 
baseline machine learning classifiers.
RESULTS: HDTwin achieves a peak accuracy of 0.81 based on the automated 
selection of markers, significantly outperforming baseline classifiers. On 
average, HDTwin yielded accuracy=0.77, precision=0.88, recall=0.63, and Matthews 
correlation coefficient=0.57. In comparison, the baseline classifiers yielded 
average accuracy=0.65, precision=0.86, recall=0.35, and Matthews correlation 
coefficient=0.36. The experiments also reveal that HDTwin yields superior 
predictive accuracy when information sources are fused compared to single 
sources. HDTwin's chatbot interface provides interactive dialogues, aiding in 
diagnosis interpretation and allowing further exploration of patient data.
CONCLUSIONS: HDTwin integrates diverse cognitive health data, enhancing the 
accuracy and explainability of cognitive diagnoses. This approach outperforms 
traditional models and provides an interface for navigating patient information. 
The approach shows promise for improving early detection and intervention 
strategies in cognitive health.

©Gina Sprint, Maureen Schmitter-Edgecombe, Diane Cook. Originally published in 
JMIR Formative Research (https://formative.jmir.org), 23.12.2024.",No,Pranav,,,,,,,,,,
Bardoxolone Methyl Ameliorates Compression-Induced Oxidative Stress Damage of Nucleus Pulposus Cells and Intervertebral Disc Degeneration Ex Vivo,"Intervertebral disc degeneration (IDD) is the main cause of low back pain, and little is known about its molecular and pathological mechanisms. According to reports, excessive compression is a high-risk factor for IDD; compressive stress can induce oxidative stress in nucleus pulposus (NP) cells during IDD progression that, in turn, promotes cell apoptosis and extracellular matrix (ECM) degradation. Currently, NP tissue engineering is considered a potential method for IDD treatment. However, after transplantation, NP cells may experience oxidative stress and induce apoptosis and ECM degradation due to compressive stress. Therefore, the development of strategies to protect NP cells under excessive compressive stress, including pretreatment of NP cells with antioxidants, has important clinical significance. Among the various antioxidants, bardoxolone methyl (BARD) is used to protect NP cells from damage caused by compressive stress. Our results showed that BARD can protect the viability of NP cells under compression. BARD inhibits compression-induced oxidative stress in NP cells by reducing compression-induced overproduction of reactive oxygen species (ROS) and malondialdehyde. Thus, BARD has a protective effect on the compression-induced apoptosis of NP cells. This is also supported by changes in the expression levels of proteins related to the mitochondrial apoptosis pathway. In addition, BARD can inhibit ECM catabolism and promote ECM anabolism in NP cells. Finally, the experimental results of the mechanism show that the activation of the Nrf2 signaling pathway participates in the protection induced by BARD in compressed NP cells. Therefore, to improve the viability and biological functions of NP cells under compression, BARD should be used during transplantation. Copyright © 2022 Tian, Duan, Cao, Zhou, Diwan and Tu.",No,Pranav,,,,,,,,,,
Assessing the accuracy and utility of ChatGPT responses to patient questions regarding posterior lumbar decompression,"Aim: To examine the clinical accuracy and applicability of ChatGPT answers to commonly asked questions from patients considering posterior lumbar decompression (PLD). Methods: A literature review was conducted to identify 10 questions that encompass some of the most common questions and concerns patients may have regarding lumbar decompression surgery. The selected questions were then posed to ChatGPT. Initial responses were then recorded, and no follow-up or clarifying questions were permitted. Two attending fellowship-trained spine surgeons then graded each response from the chatbot using a modified Global Quality Scale to evaluate ChatGPT’s accuracy and utility. The surgeons then analyzed each question, providing evidence-based justifications for the scores. Results: Minimum scores across all ten questions would lead to a total score of 20, whereas a maximum score would be 100. ChatGPT’s responses in this analysis earned a score of 59, just under an average score of 3, when evaluated by two attending spine surgeons. A score of 3 denoted a somewhat useful response of moderate quality, with some important information adequately discussed but some poorly discussed. Conclusion: ChatGPT has the ability to provide broadly useful responses to common preoperative questions that patients may have when considering undergoing PLD. ChatGPT has excellent utility in providing background information to patients and in helping them become more informed about their pathology in general. However, it often lacks the specific patient context necessary to provide patients with personalized, accurate insights into their prognosis and medical options. © The Author(s) 2024.",Yes,Pranav,,,,,,,,,,
Evaluation of Prompts to Simplify Cardiovascular Disease Information Using a Large Language Model,"AI chatbots powered by large language models (LLMs) are emerging as an important source of public-facing medical information. Generative models hold promise for producing tailored guidance at scale, which could advance health literacy and mitigate well-known disparities in the accessibility of health-protective information. In this study, we highlight an important limitation of basic approaches to AI-powered text simplification: when given a zero-shot or one-shot simplification prompt, GPT-4 often responds by omitting critical details. To address this limitation, we developed a new prompting strategy, which we term rubric prompting. Rubric prompts involve a combination of a zero-shot simplification prompt with brief reminders about important topics to address. Using rubric prompts, we generate recommendations about cardiovascular disease prevention that are more complete, more readable, and have lower syntactic complexity than baseline responses produced without prompt engineering. This analysis provides a blueprint for rigorous evaluation of AI model outputs in medicine.",Yes,Pranav,,,,,,,,,,
Evaluating the Performance of ChatGPT in Urology: A Comparative Study of Knowledge Interpretation and Patient Guidance,"Background/Aim: To evaluate the performance of Chat Generative Pre-trained Transformer (ChatGPT), a large language model trained by Open artificial intelligence. Materials and Methods: This study has three main steps to evaluate the effectiveness of ChatGPT in the urologic field. The first step involved 35 questions from our institution’s experts, who have at least 10 years of experience in their fields. The responses of ChatGPT versions were qualitatively compared with the responses of urology residents to the same questions. The second step assesses the reliability of ChatGPT versions in answering current debate topics. The third step was to assess the reliability of ChatGPT versions in providing medical recommendations and directives to patients’ commonly asked questions during the outpatient and inpatient clinic. Results: In the first step, version 4 provided correct answers to 25 questions out of 35 while version 3.5 provided only 19 (71.4% vs 54%). It was observed that residents in their last year of education in our clinic also provided a mean of 25 correct answers, and 4th year residents provided a mean of 19.3 correct responses. The second step involved evaluating the response of both versions to debate situations in urology, and it was found that both versions provided variable and inappropriate results. In the last step, both versions had a similar success rate in providing recommendations and guidance to patients based on expert ratings. Conclusion: The difference between the two versions of the 35 questions in the first step of the study was thought to be due to the improvement of ChatGPT’s literature and data synthesis abilities. It may be a logical approach to use ChatGPT versions to inform the nonhealth care providers’ questions with quick and safe answers but should not be used to as a diagnostic tool or make a choice among different treatment modalities. © Mary Ann Liebert, Inc.",Yes,Pranav,,,,,,,,,,
Response to Letter to the Editor Regarding Column: Neonatal Nutrition and ChatGPT,"2577. J Perinat Neonatal Nurs. 2024 Apr-Jun 01;38(2):112. doi: 
10.1097/JPN.0000000000000825. Epub 2024 May 13.

Response to Letter to the Editor Regarding Column: Neonatal Nutrition and 
ChatGPT.

Kenner C.",No,Pranav,,,,,,,,,,
Evaluation of online chat-based artificial intelligence responses about inflammatory bowel disease and diet,"Introduction The USA has the highest age-standardized prevalence of inflammatory bowel disease (IBD). Both genetic and environmental factors have been implicated in IBD flares and multiple strategies are centered around avoiding dietary triggers to maintain remission. Chat-based artificial intelligence (CB-AI) has shown great potential in enhancing patient education in medicine. We evaluate the role of CB-AI in patient education on dietary management of IBD. Methods Six questions evaluating important concepts about the dietary management of IBD which then were posed to three CB-AI models - ChatGPT, BingChat, and YouChat three different times. All responses were graded for appropriateness and reliability by two physicians using dietary information from the Crohn's and Colitis Foundation. The responses were graded as reliably appropriate, reliably inappropriate, and unreliable. The expert assessment of the reviewing physicians was validated by the joint probability of agreement for two raters. Results ChatGPT provided reliably appropriate responses to questions on dietary management of IBD more often than BingChat and YouChat. There were two questions that more than one CB-AI provided unreliable responses to. Each CB-AI provided examples within their responses, but the examples were not always appropriate. Whether the response was appropriate or not, CB-AIs mentioned consulting with an expert in the field. The inter-rater reliability was 88.9%. Discussion CB-AIs have the potential to improve patient education and outcomes but studies evaluating their appropriateness for various health conditions are sparse. Our study showed that CB-AIs have the ability to provide appropriate answers to most questions regarding the dietary management of IBD.  Copyright © 2024 Wolters Kluwer Health, Inc. All rights reserved.",Yes,Pranav,,,,,,,,,,
Attitude and utilization of ChatGPT among registered nurses: A cross-sectional study,"Aim: This study explores the influencing factors of attitudes and behaviors toward use of ChatGPT based on the Technology Acceptance Model among registered nurses in Taiwan. Background: The complexity of medical services and nursing shortages increases workloads. ChatGPT swiftly answers medical questions, provides clinical guidelines, and assists with patient information management, thereby improving nursing efficiency. Introduction: To facilitate the development of effective ChatGPT training programs, it is essential to examine registered nurses’ attitudes toward and utilization of ChatGPT across diverse workplace settings. Methods: An anonymous online survey was used to collect data from over 1000 registered nurses recruited through social media platforms between November 2023 and January 2024. Descriptive statistics and multiple linear regression analyses were conducted for data analysis. Results: Among respondents, some were unfamiliar with ChatGPT, while others had used it before, with higher usage among males, higher-educated individuals, experienced nurses, and supervisors. Gender and work settings influenced perceived risks, and those familiar with ChatGPT recognized its social impact. Perceived risk and usefulness significantly influenced its adoption. Discussion: Nurse attitudes to ChatGPT vary based on gender, education, experience, and role. Positive perceptions emphasize its usefulness, while risk concerns affect adoption. The insignificant role of perceived ease of use highlights ChatGPT's user-friendly nature. Conclusion: Over half of the surveyed nurses had used or were familiar with ChatGPT and showed positive attitudes toward its use. Establishing rigorous guidelines to enhance their interaction with ChatGPT is crucial for future training. Implications for nursing and health policy: Nurse managers should understand registered nurses’ attitudes toward ChatGPT and integrate it into in-service education with tailored support and training, including appropriate prompt formulation and advanced decision-making, to prevent misuse. © 2024 International Council of Nurses.",No,Pranav,,,,,,,,,,
Adversarial contrastive representation training with external knowledge injection for zero-shot stance detection,"Zero-shot stance detection (ZSSD) is a task that involves identifying the author's perspective on specific issues in text, particularly when the target topic has not been encountered during the model training process, to address rapidly evolving topics on social media. This paper introduces a ZSSD framework named KEL-CA. To enable the model to more effectively utilize transferable stance features for representing unseen targets, the framework incorporates a multi-layer contrastive learning and adversarial domain transfer module. Unlike traditional contrastive or adversarial learning, our framework captures both correlations and distinctions between invariant and specific features, as well as between different stance labels, and enhances the generalization ability and robustness of the features. Subsequently, to address the problem of insufficient information about the target context, we designed a dual external knowledge injection module that uses a large language model (LLM) to extract external knowledge from a Wikipedia-based local knowledge base and a Chain-of-Thought (COT) process to ensure the timeliness and relevance of the knowledge to infer the stances of unseen targets. Experimental results demonstrate that our approach outperforms existing models on two benchmark datasets, thereby validating its efficacy in ZSSD tasks.",No,Pranav,,,,,,,,,,
LLM Based Public Message Refinedly Grading Method,"para>In order to grade the urgency of public messages, this paper presents a LLM Based Public Message Refinedly Grading Method. This method designs a set of key factors for message classification, including sentiment polarity and type, as well as event type and domain. It utilizes pre-trained large-scale language models to identify these factors in the message content. Through a genetic algorithm, the weights of various factors are optimized for comprehensive scoring, enabling automated message classification. Experimental results demonstrate that this approach effectively improves the accuracy of message classification. © 2023 IEEE.",No,Pranav,,,,,,,,,,
Do ChatGPT and Gemini Provide Appropriate Recommendations for Pediatric Orthopaedic Conditions?,"Background: Artificial intelligence (AI), and in particular large language models (LLMs) such as Chat Generative Pre-Trained Transformer (ChatGPT) and Gemini have provided additional resources for patients to research the management of healthcare conditions, for their own edification and the advocacy in the care of their children. The accuracy of these models, however, and the sources from which they draw conclusions, have been largely unstudied in pediatric orthopaedics. This research aimed to assess the reliability of machine learning tools in providing appropriate recommendations for the care of common pediatric orthopaedic conditions. Methods: ChatGPT and Gemini were queried using plain language generated from the American Academy of Orthopaedic Surgeons (AAOS) Clinical Practice Guidelines (CPGs) listed on the Pediatric Orthopedic Society of North America (POSNA) web page. Two independent reviewers assessed the accuracy of the responses, and chi-square analyses were used to compare the 2 LLMs. Inter-rater reliability was calculated via Cohen’s Kappa coefficient. If research studies were cited, attempts were made to assess their legitimacy by searching the PubMed and Google Scholar databases. Results: ChatGPT and Gemini performed similarly, agreeing with the AAOS CPGs at a rate of 67% and 69%. No significant differences were observed in the performance between the 2 LLMs. ChatGPT did not reference specific studies in any response, whereas Gemini referenced a total of 16 research papers in 6 of 24 responses. 12 of the 16 studies referenced contained errors and either were unable to be identified (7) or contained discrepancies (5) regarding publication year, journal, or proper accreditation of authorship. Conclusion: The LLMs investigated were frequently aligned with the AAOS CPGs; however, the rate of neutral statements or disagreement with consensus recommendations was substantial and frequently contained errors with citations of sources. These findings suggest there remains room for growth and transparency in the development of the models which power AI, and they may not yet represent the best source of up-to-date healthcare information for patients or providers. © 2024 Wolters Kluwer Health, Inc.",Yes,Pranav,,,,,,,,,,
[ChatGPT in clinical practice: prospects and challenges],"[Article in French; Abstract available in French from the publisher]

Roustan D(1), Galland-Decker C(2)(3), Marinoni C(2)(3), Bastardot F(2)(3).

Author information:
(1)Service de médecine interne, Centre hospitalier universitaire vaudois, 1011 
Lausanne.
(2)Direction médicale, Centre hospitalier universitaire vaudois, 1011 Lausanne.
(3)Direction de l'innovation et de la recherche clinique, Centre hospitalier 
universitaire vaudois, 1011 Lausanne.

Virtually unknown to the greater public before November 2022, ChatGPT was made 
available in open access in Autumn 2022, driving the perspective of artificial 
intelligence integration to the forefront of daily life. The field of medicine 
hasn't been left aside, and sparks as much interest as it does questions. 
Although this tool has considerable potential for use in clinical practice, it, 
like others, has limitations that need to be clearly understood to avoid misuse. 
In addition, the legal framework and issues of data confidentiality are 
currently poorly defined, and clinicians will need to keep a close eye on 
legislative developments in this area.

Publisher: Quasiment inconnu avant novembre 2022, la mise à disposition en libre 
accès de ChatGPT (Chat Generative Pre-trained Transformer) en automne 2022 a 
permis au grand public d’être exposé pour la première fois à une forme 
d’intelligence artificielle (IA). La médecine n’a pas échappé à cette révolution 
technologique qui suscite autant d’intérêt que de questionnements. Bien que doté 
d’importantes capacités avec de nombreuses perspectives pour une utilisation en 
pratique clinique, cet outil, comme d’autres, présente des limites qu’il 
convient de bien comprendre pour éviter un mésusage. Par ailleurs, le cadre 
légal et les enjeux de confidentialité des données sont pour l’heure mal 
définis, et le clinicien devra suivre de manière attentive l’évolution de la 
législation en ce sens.",No,Pranav,Editorial-y,,,,,,,,,
Evaluating the reliability of the responses of large language models to keratoconus-related questions,"Clinical relevance: Artificial intelligence has undergone a rapid evolution and large language models (LLMs) have become promising tools for healthcare, with the ability of providing human-like responses to questions. The capabilities of these tools in addressing questions related to keratoconus (KCN) have not been previously explored. Background: In this study, the responses were evaluated from three LLMs–ChatGPT-4, Copilot, and Gemini–to common patient questions regarding KCN. Methods: Fifty real-life patient inquiries regarding general information, aetiology, symptoms and diagnosis, progression, and treatment of KCN were presented to the LLMs. Evaluations of the answers were conducted by three ophthalmologists with a 5-point Likert scale ranging from ‘strongly disagreed’ to ‘strongly agreed’. The reliability of the responses provided by LLMs was evaluated using the DISCERN and the Ensuring Quality Information for Patients (EQIP) scales. Readability metrics (Flesch Reading Ease Score, Flesch-Kincaid Grade Level, and Coleman-Liau Index) were calculated to evaluate the complexity of responses. Results: ChatGPT-4 consistently scored 3 points or higher for all (100%) its responses, while Copilot had five (10%) and Gemini had two (4%) responses scoring 2 points or below. ChatGPT-4 achieved a ‘strongly agree’ rate of 74% across all questions, markedly superior to Copilot at 34% and Gemini at 42% (p < 0.001); and recorded the highest ‘strongly agree’ rates in general information and symptoms & diagnosis categories (90% for both). The median Likert scores differed among LLMs (p < 0.001), with ChatGPT-4 scoring highest and Copilot scoring lowest. Although ChatGPT-4 exhibited more reliability based on the DISCERN scale, it was characterised by lower readability and higher complexity. While all LLMs provided responses categorised as ‘extremely difficult to read’, the responses provided by Copilot showed higher readability. Conclusions: Despite the responses provided by ChatGPT-4 exhibiting lower readability and greater complexity, it emerged as the most proficient in answering KCN-related questions. © 2024 Optometry Australia.",Yes,Pranav,,,,,,,,,,
Generative Artificial Intelligence Responses to Common Patient-Centric Hand and Wrist Surgery Questions: A Quality and Usability Analysis,"Background: Due to the rapid evolution of generative artificial intelligence (AI) and its implications on patient education, there is a pressing need to evaluate AI responses to patients’ medical questions. This study assessed the quality and usability of responses received from two prominent AI platforms to common patient-centric hand and wrist surgery questions. Methods: Twelve commonly encountered hand and wrist surgery patient questions were inputted twice into both Gemini and ChatGPT, generating 48 responses. Each response underwent a content analysis, followed by assessment for quality and usability with three scoring tools: DISCERN, Suitability Assessment of Materials (SAM) and the AI Response Metric (AIRM). Statistical analyses compared the features and scores of the outputs when stratified by platform, question type and response order. Results: Responses earned mean overall scores of 55.7 (‘good’), 57.2% (‘adequate’) and 4.4 for DISCERN, SAM and AIRM, respectively. No responses provided citations. Wrist question responses had significantly higher DISCERN (p < 0.01) and AIRM (p = 0.02) scores compared to hand responses. Second responses had significantly higher AIRM (p < 0.01), but similar DISCERN (p = 0.76) and SAM (p = 0.11), scores compared to the first responses. Gemini’s DISCERN (p = 0.04) and SAM (p < 0.01) scores were significantly higher than ChatGPT’s corresponding metrics. Conclusions: Although responses are generally ‘good’ and ‘adequate’, there is variable quality with respect to platform used, type of question and response order. Given the diversity of publicly available AI platforms, it is important to understand the quality and usability of information patients may encounter during their search for answers to common hand and wrist surgery questions. Level of Evidence: Level IV (Therapeutic). © 2025 World Scientific. All rights reserved.",Yes,Pranav,,,,,,,,,,
Clinical significance of hepatic function in Graves disease with type 2 diabetic mellitus: A single-center retrospective cross-sectional study in Taiwan,"Graves disease (GD) and type 2 diabetes mellitus (T2DM) both impair liver function; we therefore explored the possibility of a relationship among diabetic control, thyroid function, and liver function. This retrospective, cross-sectional study compared serum liver function biomarkers of primary GD patients in a single center between 2016 and 2020, derived from clinical databases, and clarified the correlation of liver function in GD patients with or without T2DM. Furthermore, the diabetes mellitus group was divided into glycated hemoglobin A1C (HbA1C) <6.5% group and ≥6.5% group to further analyze the effect by disease control in patients. Statistical differences between groups were assessed using independent t tests to clarify the association of serum biomarkers between GD with T2DM. Pearson test was applied to assess within-group statistical correlation of serum biomarkers. The correlation of factors in each group was demonstrated by using the Kendall tau-b method and stepwise regression analysis. A total of 77 patients were included in the study. In the study population, glutamate pyruvate transaminase (GPT) was significantly correlated with thyroid-stimulating hormone, and HbA1C was significantly correlated with alkaline phosphatase (ALK-P), glutamate oxaloacetate transaminase (GOT), and GPT. An examination of GOT, GPT, free thyroxine (FT4), and HbA1C levels revealed a significant difference between the non-T2DM and T2DM groups. GPT also exhibited a significant correlation with triiodothyronine in the T2DM group. The T2DM group was further divided into groups: HbA1C <6.5% and ≥6.5%. The results demonstrated that ALK-P, GOT, GPT, and FT4 levels were significantly different between the groups. A significant correlation between ALK-P and thyroid-stimulating hormone and between GOT and FT4 was also identified in the HbA1C <6.5% group. Our single-center study revealed that diabetes affects liver function in patients with GD. For patients with T2DM, when liver function becomes impaired, thyroid function control deteriorates. GPT was correlated with triiodothyronine but not with FT4, which indicated the impairment of deiodination in the liver. This phenomenon was not observed in the non-T2DM population. The early detection of abnormal liver function in patients with GD and T2DM may help limit the development of comorbidities and improve disease management.  © 2022 the Author(s). Published by Wolters Kluwer Health, Inc.",No,Pranav,,,,,,,,,,
ChatGPT: Temptations of Progress,"2232. Am J Bioeth. 2023 Apr;23(4):6-8. doi: 10.1080/15265161.2023.2180110. Epub 2023 
Feb 28.

ChatGPT: Temptations of Progress.

Doshi RH(1)(2), Bajaj SS(3), Krumholz HM(1)(2)(4).

Author information:
(1)Yale School of Medicine.
(2)Yale New Haven Hospital.
(3)Harvard University.
(4)Yale School of Public Health.",No,Pranav,,,,,,,,,,
Protective effects of N-acetyl cysteine against oxidative stress in ibuprofen-induced hepatotoxicity in rats,"This study sought to evaluate the role of N-acetyl cysteine (NAC) on ibuprofen-induced hepatotoxicity in rats. The rats were divided into six groups. Group 1 (control group) received carboxy-methyl cellulose. Group 2 (untreated group) was given ibuprofen. Group 3 administrated with ibuprofen and silymarin. Groups 4, 5, and 6 were given ibuprofen and NAC. We assessed histopathological examinations and serum biochemical parameters such as alkaline phosphatase (ALP), glutamate pyruvate transaminase (GPT), urea, glutamate oxaloacetate transaminase (GOT), uric acid, lipid profile, serum interleukin-1 beta (IL-1β), catalase (CAT), superoxide dismutase (SOD), vitamin C (Vit C), protein carbonyl (PC), and ferric reducing antioxidant power (FRAP). Group 2 revealed a remarkable elevation (p < 0.05) in serum ALP, GPT, GOT, lipid profile (except HDL-C), PC, uric acid, MDA, serum IL-1β, and its hepatic gene expressions relate to group 1. Also in group 2, plasma FRAP and liver CAT, SOD, and Vit C significantly reduced (p < 0.05) as opposed to group 1. Nevertheless, NAC and silymarin led to improvement in the above parameters in contrast with those of group 2 in the treated rats. Our results confirmed protective effects of NAC on ibuprofen-induced hepatoxicity in male rats through increasing parameters such as CAT, SOD, Vit C, and FRAP. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",No,Pranav,,,,,,,,,,
Comparative Evaluation of Advanced AI Reasoning Models in Pediatric Clinical Decision Support: ChatGPT O1 vs. DeepSeek-R1,"Introduction: The adoption of advanced reasoning models, such as ChatGPT O1 and DeepSeek-R1, represents a pivotal step forward in clinical decision support, particularly in pediatrics. ChatGPT O1 employs”chain-of-thought reasoning” (CoT) to enhance structured problem-solving, while DeepSeek-R1 introduces self-reflection capabilities through reinforcement learning. This study aimed to evaluate the diagnostic accuracy and clinical utility of these models in pediatric scenarios using the MedQA dataset. Materials and Methods: A total of 500 multiple-choice pediatric questions from the MedQA dataset were presented to ChatGPT O1 and DeepSeek-R1. Each question included four or more options, with one correct answer. The models were evaluated under uniform conditions, with performance metrics including accuracy, Cohen’s Kappa, and chi-square tests applied to assess agreement and statistical significance. Responses were analyzed to determine the models effectiveness in addressing clinical questions. Results: ChatGPT O1 achieved a diagnostic accuracy of 92.8%, significantly outperforming DeepSeek-R1, which scored 87.0% (p < 0.00001). The CoT reasoning technique used by ChatGPT O1 allowed for more structured and reliable responses, reducing the risk of errors. Conversely, DeepSeek-R1, while slightly less accurate, demonstrated superior accessibility and adaptability due to its open-source nature and emerging self-reflection capabilities. Cohen’s Kappa (K=0.20) indicated low agreement between the models, reflecting their distinct reasoning strategies. Conclusions: This study highlights the strengths of ChatGPT O1 in providing accurate and coherent clinical reasoning, making it highly suitable for critical pediatric scenarios. DeepSeek-R1, with its flexibility and accessibility, remains a valuable tool in resource-limited settings. Combining these models in an ensemble system could leverage their complementary strengths, optimizing decision support in diverse clinical contexts. Further research is warranted to explore their integration into multidisciplinary care teams and their application in real-world clinical settings.",Yes,Pranav,,,,,,,,,,
"Evaluation of quality of Valeriana officinalis from different origins based on multi indicator component quantitative combined chemometrics, weighted TOPSIS, and grey relational degree fusion model","Objective To establish a method to evaluate the quality difference of Valeriana officinalis from different producing areas by multi-index component quantitative combined with chemometrics, weighted TOPSIS and grey correlation degree fusion model. Methods Using HPLC to detection the contents of hesperidin, diosmetin, valtrate, acevaltrate, valechlorine, hydroxyvalerenic acid, acetoxyvalerenic acid, valerenic acid, β-sitosterol and ursolic acid in 16 batches of V. officinalis samples with Phenomenex Gemini C(18) column, and mobile phase was consisted of acetonitrile-0.05% phosphoric acid solution, gradient elution. The quality difference was comprehensively assessed by chemometrics, weighted TOPSIS and GRA fusion models. Results The validation of HPLC methodology met the requirements of Chinese Pharmacopoeia. The 10 components showed good linearity in their ranges (R(2) > 0.999), and the average recovery (n = 9) were 96.83%—100.08% (RSD < 2.0%). The results of chemometrics analysis showed that 16 batches of Valeriana officinalis were divided into three categories, and acetoxyvalerenic acid, hesperidin, valtrate and hydroxyvalerenic acid were the main markers of the quality differences. The results of weighted TOPSIS and grey correlation degree fusion technology showed that the relative closeness of 16 batches of samples was 0.279 2—0.666 5, and the overall quality of Valerian from Hubei and Guizhou provinces was good (relative closeness was 0.579 0—0.666 5). Conclusion With the content of 10 components such as hesperidin as the evaluation index, the fusion model of chemometrics, weighted TOPSIS and grey relational analysis fusion model can be used to evaluate the quality of Valeriana Officinalis.",No,Pranav,,,,,,,,,,
"Antimicrobial, Cytotoxic and Mutagenic Activity of Gemini QAS Derivatives of 1,4:3,6-Dianhydro-l-iditol","A series of quaternary diammonium salts derivatives of 1,4:3,6-dianhydro-l-iditol were synthesized, using isommanide (1,4:3,6-dianhydro-d-mannitol) as a starting material. Both aromatic (pyridine, 4-(N,N-dimethylamino)pyridine (DMAP), (3-carboxamide)pyridine; N-methylimidazole) and aliphatic (trimethylamine, N,N-dimethylhexylamine, N,N-dimethyloctylamine, N,N-dimethyldecylamine) amines were used, giving eight gemini quaternary ammonium salts (QAS). All salts were tested for their antimicrobial activity against yeasts, Candida albicans and Candida glabrata, as well as bacterial Staphylococcus aureus and Escherichia coli reference strains. Moreover, antibacterial activity against 20 isolates of S. aureus collected from patients with skin and soft tissue infections (n = 8) and strains derived from subclinical bovine mastitis milk samples (n = 12) were evaluated. Two QAS with octyl and decyl residues exhibited antimicrobial activity, whereas those with two decyl residues proved to be the most active against the tested pathogens, with MIC of 16-32, 32, and 8 µg/mL for yeast, E. coli, and S. aureus reference and clinical strains, respectively. Only QAS with decyl residues proved to be cytotoxic in MTT assay against human keratinocytes (HaCaT), IC50 12.8 ± 1.2 μg/mL. Ames test was used to assess the mutagenic potential of QAS, and none of them showed mutagenic activity in the concentration range 4-2000 µg/plate.",No,Pranav,,,,,,,,,,
Cardiac auscultation predicts mortality in elderly patients admitted for COVID-19,"Introduction: COVID-19 has had a great impact on the elderly population. All admitted patients underwent cardiac auscultation at the Emergency Department. However, to our knowledge, there is no literature that explains the implications of cardiac auscultation at the Emergency Department. Material and methods: Data collection from our hospital records. Our cohort consists of 300 admissions with a mean age of 81.6 years and 50.7% men. Results: Pathological cardiac auscultation at the Emergency Department was a risk factor for in-hospital mortality (RR = 1.9; 95% CI 1.3–2.8), heart failure (RR = 3.2; 95% CI = 1.8–5.6), respiratory failure (RR = 1.8; 95% CI = 1.3–2.5), acute kidney injury (RR = 2.6; 95% CI = 2–3.2), and ICU admission (RR = 3.3; 95% CI = 1.3–8.2). The findings in patients with pathological cardiac auscultation were that oxygen saturation in the Emergency Department, arterial pH, and HCO3− were significantly lower, and the ALT/GPT, LDH, and lactate determinations were significantly higher, which is compatible and correlates with the fact that the main variable is indeed a risk factor for a more severe clinical course. Among the findings from pathological auscultation, arrhythmic tone/arrhythmia was the most frequent (50%) and a risk factor for in-hospital mortality (RR = 2.3; 95% CI = 1.6–3.4). Logistic regression was performed from a multivariate analysis that showed that the initial ex novo arrhythmia correlated with pathological cardiac auscultation is an independent risk factor for in-hospital mortality. Conclusion: Continuous rhythm monitoring makes it possible to detect ex novo arrhythmias and act proactively, and to offer greater care and attention to these patients who have a higher risk of in-hospital mortality and a worse prognosis. Cardiac auscultation can alert us in order to perform more electrocardiograms in these patients and thus have better monitoring. © 2022 Informa UK Limited, trading as Taylor & Francis Group.",No,Pranav,,,,,,,,,,
A Hybrid Approach to Extraction of Knowledge From Scientific Texts Based on Large Language Models and Domain Dictionaries,"The vast information landscape of the Internet constitute a significant challenge for extracting valuable content. The lack of standardized data models and structures necessitates ad hoc solutions, often requiring expert knowledge that developers may lack. While Large Language Models (LLMs) hold promise for addressing this challenge, their susceptibility to AI hallucinations and inaccuracies necessitates ongoing research. This paper introduces a hybrid approach for extracting information on computational methods that combines domain-specific dictionaries with LLMs in order to improve the accuracy of method categorization. Our system incorporates explainability, allowing users to understand the reasoning behind method assignments. Furthermore, user-driven training is facilitated by allowing users to select theories and highlight relevant keywords, enhancing learning capabilities of the system. Its implementation demonstrates the effectiveness of this approach, achieving an impressive Fl-score of up to 90.3 %. This research contributes to the ongoing effort to develop robust and accurate knowledge extraction systems for navigating the ever-expanding landscape of online information.  © 2024 IEEE.",No,Pranav,,,,,,,,,,
ChatGPT's Influence on Dental Education: Methodological Challenges and Ethical Considerations,,No,Pranav,Letter/Editorial-y,,,,,,,,,
The Performance of Chatbots and the AAPOS Website as a Tool for Amblyopia Education,"Purpose: To evaluate the understandability, actionability, and readability of responses provided by the website of the American Association for Pediatric Ophthalmology and Strabismus (AAPOS), ChatGPT-3.5, Bard, and Bing Chat about amblyopia and the appropriateness of the responses generated by the chatbots. Method: Twenty-five questions provided by the AAPOS website were directed three times to fresh ChatGPT-3.5, Bard, and Bing Chat interfaces. Two experienced pediatric ophthalmologists categorized the responses of the chatbots in terms of their appropriateness. Flesch Reading Ease (FRE), Flesch Kincaid Grade Level (FKGL), and Coleman-Liau Index (CLI) were used to evaluate the readability of the responses of the AAPOS website and chatbots. Furthermore, the understandability scores were evaluated using the Patient Education Materials Assessment Tool (PEMAT). Results: The appropriateness of the chatbots’ responses was 84% for ChatGPT-3.5 and Bard and 80% for Bing Chat (P > .05). For understandability (mean PEMAT-U score AAPOS website: 81.5%, Bard: 77.6%, ChatGPT-3.5: 76.1%, and Bing Chat: 71.5%, P < .05) and actionability (mean PEMAT-A score AAPOS website: 74.6%, Bard: 69.2%, ChatGPT-3.5: 67.8%, and Bing Chat: 64.8%, P < .05), the AAPOs website scored better than the chatbots. Three readability analyses showed that Bard had the highest mean score, followed by the AAPOS website, Bing Chat, and ChatGPT-3.5, and these scores were more challenging than the recommended level. Conclusions: Chatbots have the potential to provide detailed and appropriate responses at acceptable levels. The AAPOS website has the advantage of providing information that is more understandable and actionable. The AAPOS website and chatbots, especially ChatGPT, provided difficult-to-read data for patient education regarding amblyopia. © 2024 Slack Incorporated. All rights reserved.",Yes,Pranav,,,,,,,,,,
ChatGPT as a teaching tool,,No,Pranav,Editorial,,,,,,,,,
Assessing ChatGPT’s Role in Sarcopenia and Nutrition: Insights from a Descriptive Study on AI-Driven Solutions,"Background: Sarcopenia, an age-related decline in muscle mass and function, poses significant health risks. While AI tools like ChatGPT-4 (ChatGPT-4o) are increasingly used in healthcare, their accuracy in addressing sarcopenia remains unclear. Methods: ChatGPT-4’s responses to 20 frequently asked sarcopenia-related questions were evaluated by 34 experts using a four-criterion scale (relevance, accuracy, clarity, Ccmpleteness). Responses were rated from 1 (low) to 5 (high), and interrater reliability was assessed via intraclass correlation coefficient (ICC). Results: ChatGPT-4 received consistently high median scores (5.0), with ≥90% of evaluators rating responses ≥4. Relevance had the highest mean score (4.7 ± 0.5), followed by accuracy (4.6 ± 0.6), clarity (4.6 ± 0.6), and completeness (4.6 ± 0.7). ICC analysis showed poor agreement (0.416), with Completeness displaying moderate agreement (0.569). Conclusions: ChatGPT-4 provides highly relevant and structured responses but with variability in accuracy and clarity. While it shows potential for patient education, expert oversight remains essential to ensure clinical validity. Future studies should explore patient-specific data integration and AI comparisons to refine its role in sarcopenia management. © 2025 by the authors.",Yes,Sully,,,,,,,,,,
"The perceived relevance, utility and retention of basic sciences in general practice","BACKGROUND: Basic sciences are crucial for clinical medicine, yet studies 
focusing on their perceived utility among general practitioners (GPs) are 
sparse. Considering the broad scope of GPs' practice, an in-depth understanding 
of basic sciences is fundamental for making informed clinical decisions. This 
study evaluated GP registrars' retention and perceptions of the utility of basic 
sciences in clinical practice.
METHODS: Using sequential explanatory mixed methods study design, knowledge 
retention was assessed by a multiple-choice question (MCQ) examination followed 
by interviews on the perception of the relevance and utility of basic sciences 
among GP registrars at James Cook University's (JCU) General Practice Training 
(GPT) program. Descriptive and inferential statistical analyses were conducted 
on the MCQ exam data, while thematic analysis was employed for the qualitative 
interview data.
RESULTS: Sixty-one GP registrars participated in the MCQ exam, while 11 of them 
were involved in the interviews. The highest mean score was obtained in 
biochemistry (75.1 ± 2.23) while the lowest mean score was in anatomy 
(56.07 ± 3.16). Key performance predictors included the formative clinical 
examination scores (β = 0.83, 95% CI: 0.45 to 1.2, p < 0.001) and gender 
(β = -9.7, 95% CI: -17 to -2.3, p = 0.011). The qualitative data analysis 
revealed five themes, including the backbone of clinical medicine, varying 
utility over time and by specialty, clinical synthesis integrates encapsulated 
knowledge, professional pressures hinder revisitation of knowledge and knowledge 
renewal enhances updates.
CONCLUSION: Basic sciences were considered relevant in clinical practice. 
Development of continuing professional development (CPDs) sessions and 
clinically relevant online resources were measures proposed to enhance the 
retention of knowledge. Future research could focus on innovative educational 
strategies for GPs.

© 2024. The Author(s).",No,Sully,,,,,,,,,,
Modelling the impact of environmental and social determinants on mental health using generative agents,"Mental health is shaped by socio-environmental determinants, yet traditional research approaches struggle to capture their complex interactions. This review explores the potential of generative agents, powered by large language models, to simulate human-like behaviour in virtual environments for mental health research. We outline potential applications including the modelling of adverse life events, urbanicity, climate change, discuss potential challenges and describe how generative agents could transform mental health research. © The Author(s) 2025.",No,Sully,,,,,,,,,,
Exploring artificial intelligence literacy and the use of ChatGPT and copilot in instruction on nursing academic report writing,"BACKGROUND: Nursing education increasingly emphasizes academic writing and 
communication, critical for delivering quality patient care and professional 
advancement. Rapidly emerging artificial intelligence (AI) tools such as ChatGPT 
and Copilot are transforming educational methodologies, and a focus is being 
placed on embedding AI literacy to effectively bridge the gap between 
theoretical knowledge and clinical practice. These technologies have the 
potential to reshape nursing education in a technology-driven health-care 
landscape.
AIM: This study investigated the effectiveness of AI literacy and the 
application of ChatGPT and Copilot in academic nursing report writing. It 
assessed the level of AI literacy of nursing students, examined the integration 
of basic AI concepts into a curriculum, and analyzed the impact of these tools 
compared with traditional teaching methods.
METHODS: The study adopted a sample of 203 senior nursing students from Southern 
Taiwan to compare an AI-enhanced teaching approach using ChatGPT and Copilot 
with conventional methods. The curriculum, centered on the ""Writing Case Reports 
and Seminars"" course, employed the Analyze, Design, Develop, Implement, Evaluate 
model and incorporated scaffolding techniques to synergistically integrate 
clinical skills with academic learning. AI literacy was measured using the Meta 
AI Literacy Scale (MAILS). Summative assessments, adhering to the Taiwan Nursing 
Association standards, focused on individual and group case report evaluations.
FINDINGS: Following an 18-week AI intervention, the experimental group 
demonstrated significant improvements in all dimensions of the MAILS. A ChatGPT 
usage of 100 % was found, with a notable enhancement discovered in the ""Nursing 
Plan"" section of case reports. Although the experimental group outperformed the 
control group in overall case report evaluations, the connections between 
identified problems and proposed plans were weaker and nursing interventions 
tended to be less individualized for the experimental group.
CONCLUSIONS: The incorporation of AI tools such as ChatGPT and Copilot into a 
scaffolding teaching framework significantly boosted students' AI literacy and 
performance in summative assessments. Effective AI training for students, 
supervised use of these tools, and continuous professional development for 
educators are paramount to successful implementation. Addressing the current 
limitations of AI has the potential to further improve academic writing, foster 
critical thinking, and ensure responsible application in patient care, 
ultimately leading to higher-quality and more effective nursing education.

Copyright © 2025 Elsevier Ltd. All rights reserved.",No,Sully,,,,,,,,,,
Explainability to Business: Demystify Transformer Models with Attention-based Explanations,"Recently, many companies are relying on Natural Language Processing (NLP) techniques to understand the text data generated daily. It has become very critical to deal with this data because finding the sentiments of text and summarizing them will help the company understand the pain points of the customers posting reviews on social media or understand the experience of the customer. These requirements have increasingly demanded many advanced algorithms to deal the text data. The introduction of Transformers led to businesses adopting NLP methods more and more to keep up with their needs. Models like Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformers (GPT), state-of-the-art results were achieved with billions of parameters learned. Although these advancements improved the accuracy and expanded the use of algorithms to a wide range of NLP tasks like language translation, text summarization, and language modeling. Businesses are more interested in the Explainability of the model compared to its accuracy. Explainable Artificial Intelligence (XAI) plays an important role to comprehend the complexities of the model as well as the influence of weights on predictions. In this paper, the complexities of the transformer model are unraveled by presenting a straightforward method for computing explainable predictions. The DistilBERT model is chosen as an example to implement the explainable system due to its lighter nature. Combining the strengths of a Posthoc expla-nation with those of a self-learning neural network, the method makes it simple to scale it to other algorithms to implement. With technologies like python, PyTorch, and Hugging Face, a detailed step-by-step algorithmic computation is demonstrated to explain the predictions from the attention-based explanations. © 2023 IEEE.",No,Sully,,,,,,,,,,
Provision of Radiology Reports Simplified with Large Language Models to Patients with Cancer: Impact on Patient Satisfaction,"PURPOSETo explore the perceived utility and effect of simplified radiology reports on oncology patients' knowledge and feasibility of large language models (LLMs) to generate such reports.MATERIALS AND METHODSThis study was approved by the Institute Ethics Committee. In phase I, five state-of-the-art LLMs (Generative Pre-Trained Transformer-4o [GPT-4o], Google Gemini, Claude Opus, Llama-3.1-8B, and Phi-3.5-mini) were tested to simplify 50 oncology computed tomography (CT) report impressions using five distinct prompts with each LLM. The outputs were evaluated quantitatively using readability indices. Five LLM-prompt combinations with best average readability scores were also assessed qualitatively, and the best LLM-prompt combination was selected. In phase II, 100 consecutive oncology patients were randomly assigned into two groups: original report (received original report impression) and simplified report (received LLM-generated simplified versions of their CT report impressions under the supervision of a radiologist). A questionnaire assessed the impact of these reports on patients' knowledge and perceived utility.RESULTSIn phase I, Claude Opus-Prompt 3 (explain to a 15-year-old) performed slightly better than other LLMs, although scores for GPT-4o, Gemini, Claude Opus, and Llama-3.1 were not significantly different (P >.0033 on Wilcoxon signed-rank test with Bonferroni correction). In phase II, simplified report group patients demonstrated significantly better knowledge of primary site and extent of their disease as well as showed significantly higher confidence and understanding of the report (P <.05 for all). Only three (of 50) simplified reports required corrections by the radiologist.CONCLUSIONSimplified radiology reports significantly enhanced patients' understanding and confidence in comprehending their medical condition. LLMs performed very well at this simplification task; therefore, they can be potentially used for this purpose, although there remains a need for human oversight.  © American Society of Clinical Oncology.",Yes,Sully,,,,,,,,,,
Exploring the Impact of ChatGPT Literacy on User Satisfaction: The Mediating Role of User Motivations,"The introduction of chat generative pretrained transformer (ChatGPT), the 
fastest growing large language model, has changed the landscape of artificial 
intelligence-human interaction in everyday life. As the social influence of 
ChatGPT increases, competencies in it become important life skills. This study 
aims to explore the determinants of ChatGPT user satisfaction to provide 
practical implications by suggesting a significant independent variable and 
mediators between the independent variable and user satisfaction. To this end, 
this study recruited 822 college students with prior experience using ChatGPT 
(407 males and 415 females) and conducted an online survey. We tested the 
effects of ChatGPT literacy on user satisfaction and the mediating roles of 
different motives (i.e., information and knowledge acquisition and entertainment 
and leisure) in the relationship between ChatGPT literacy and user satisfaction. 
The results suggest that ChatGPT literacy significantly increases user 
satisfaction and that information and knowledge acquisition and entertainment 
and leisure partially mediate the relationship between the effect of ChatGPT 
literacy and user satisfaction. The results may have implications for large 
language model developers and practitioners, such as educators.",No,Sully,,,,,,,,,,
A comparison of drug information question responses by a drug information center and by ChatGPT,"DISCLAIMER: In an effort to expedite the publication of articles, AJHP is posting manuscripts online as soon as possible after acceptance. Accepted manuscripts have been peer-reviewed and copyedited, but are posted online before technical formatting and author proofing. These manuscripts are not the final version of record and will be replaced with the final article (formatted per AJHP style and proofed by the authors) at a later time. PURPOSE: A study was conducted to assess the accuracy and ability of Chat Generative Pre-trained Transformer (ChatGPT) to systematically respond to drug information inquiries relative to responses of a drug information center (DIC). METHODS: Ten drug information questions answered by the DIC in 2022 or 2023 were selected for analysis. Three pharmacists created new ChatGPT accounts and submitted each question to ChatGPT at the same time. Each question was submitted twice to identify consistency in responses. Two days later, the same process was conducted by a fourth pharmacist. Phase 1 of data analysis consisted of a drug information pharmacist assessing all 84 ChatGPT responses for accuracy relative to the DIC responses. In phase 2, 10 ChatGPT responses were selected to be assessed by 3 blinded reviewers. Reviewers utilized an 8-question predetermined rubric to evaluate the ChatGPT and DIC responses. RESULTS: When comparing the ChatGPT responses (n = 84) to the DIC responses, ChatGPT had an overall accuracy rate of 50%. Accuracy across the different question types varied. In regards to the overall blinded score, ChatGPT responses scored higher than the responses by the DIC according to the rubric (overall scores of 67.5% and 55.0%, respectively). The DIC responses scored higher in the categories of references mentioned and references identified. CONCLUSION: Responses generated by ChatGPT have been found to be better than those created by a DIC in clarity and readability; however, the accuracy of ChatGPT responses was lacking. ChatGPT responses to drug information questions would need to be carefully reviewed for accuracy and completeness.",No,Sully,,,,,,,,,,
ChatGPT: Threat or boon to the future of pharmacy practice?,"2550. Res Social Adm Pharm. 2023 Jul;19(7):975-976. doi: 
10.1016/j.sapharm.2023.03.012. Epub 2023 Apr 3.

ChatGPT: Threat or boon to the future of pharmacy practice?

Jairoun AA(1), Al-Hemyari SS(2), Shahwan M(3), Humaid Alnuaimi GR(4), Zyoud 
SH(5), Jairoun M(4).

Author information:
(1)Health and Safety Department, Dubai Municipality, Dubai, United Arab 
Emirates; School of Pharmaceutical Sciences, Universiti Sains Malaysia (USM), 
Pulau Pinang, 11500, Malaysia. Electronic address: Dr_ammar_91_@hotmail.com.
(2)School of Pharmaceutical Sciences, Universiti Sains Malaysia (USM), Pulau 
Pinang, 11500, Malaysia; Pharmacy Department, Emirates Health Services, Dubai, 
United Arab Emirates. Electronic address: drsabasaleh@hotmail.com.
(3)Centre of Medical and Bio-allied Health Sciences Research, Ajman University, 
Ajman, Ajman, 346, United Arab Emirates; Department of Clinical Sciences, 
College of Pharmacy and Health Sciences, Ajman University, Ajman, 346, United 
Arab Emirates. Electronic address: moyad76@hotmail.com.
(4)Department of Clinical Sciences, College of Pharmacy and Health Sciences, 
Ajman University, Ajman, 346, United Arab Emirates.
(5)Department of Clinical and Community Pharmacy, College of Medicine and Health 
Sciences, An-Najah National University, Nablus, 44839, Palestine; Clinical 
Research Centre, An-Najah National University Hospital, Nablus, 44839, 
Palestine.",No,Sully,,,,,,,,,,
The rise of artificial intelligence: addressing the impact of large language models such as ChatGPT on scientific publications,"2760. Singapore Med J. 2023 Apr;64(4):219-221. doi: 
10.4103/singaporemedj.SMJ-2023-055.

The rise of artificial intelligence: addressing the impact of large language 
models such as ChatGPT on scientific publications.

Ang TL(1), Choolani M(1), See KC(2), Poh KK(3).

Author information:
(1)Deputy Editor, Singapore Medical Journal, Singapore.
(2)Specialty Editor, Singapore Medical Journal, Singapore.
(3)Editor-in-Chief, Singapore Medical Journal, Singapore.",No,Sully,,,,,,,,,,
Accuracy and Completeness of ChatGPT-Generated Information on Interceptive Orthodontics: A Multicenter Collaborative Study,"Background: this study aims to investigate the accuracy and completeness of ChatGPT in answering questions and solving clinical scenarios of interceptive orthodontics. Materials and Methods: ten specialized orthodontists from ten Italian postgraduate orthodontics schools developed 21 clinical open-ended questions encompassing all of the subspecialities of interceptive orthodontics and 7 comprehensive clinical cases. Questions and scenarios were inputted into ChatGPT4, and the resulting answers were evaluated by the researchers using predefined accuracy (range 1–6) and completeness (range 1–3) Likert scales. Results: For the open-ended questions, the overall median score was 4.9/6 for the accuracy and 2.4/3 for completeness. In addition, the reviewers rated the accuracy of open-ended answers as entirely correct (score 6 on Likert scale) in 40.5% of cases and completeness as entirely correct (score 3 n Likert scale) in 50.5% of cases. As for the clinical cases, the overall median score was 4.9/6 for accuracy and 2.5/3 for completeness. Overall, the reviewers rated the accuracy of clinical case answers as entirely correct in 46% of cases and the completeness of clinical case answers as entirely correct in 54.3% of cases. Conclusions: The results showed a high level of accuracy and completeness in AI responses and a great ability to solve difficult clinical cases, but the answers were not 100% accurate and complete. ChatGPT is not yet sophisticated enough to replace the intellectual work of human beings. © 2024 by the authors.",Yes,Sully,,,,,,,,,,
Modification and Validation of the System Causability Scale Using AI-Based Therapeutic Recommendations for Urological Cancer Patients: A Basis for the Development of a Prospective Comparative Study,"The integration of artificial intelligence, particularly Large Language Models (LLMs), has the potential to significantly enhance therapeutic decision-making in clinical oncology. Initial studies across various disciplines have demonstrated that LLM-based treatment recommendations can rival those of multidisciplinary tumor boards (MTBs); however, such data are currently lacking for urological cancers. This preparatory study establishes a robust methodological foundation for the forthcoming CONCORDIA trial, including the validation of the System Causability Scale (SCS) and its modified version (mSCS), as well as the selection of LLMs for urological cancer treatment recommendations based on recommendations from ChatGPT-4 and an MTB for 40 urological cancer scenarios. Both scales demonstrated strong validity, reliability (all aggregated Cohen’s K > 0.74), and internal consistency (all Cronbach’s Alpha > 0.9), with the mSCS showing superior reliability, internal consistency, and clinical applicability (p < 0.01). Two Delphi processes were used to define the LLMs to be tested in the CONCORDIA study (ChatGPT-4 and Claude 3.5 Sonnet) and to establish the acceptable non-inferiority margin for LLM recommendations compared to MTB recommendations. The forthcoming ethics-approved and registered CONCORDIA non-inferiority trial will require 110 urological cancer scenarios, with an mSCS difference threshold of 0.15, a Bonferroni corrected alpha of 0.025, and a beta of 0.1. Blinded mSCS assessments of MTB recommendations will then be compared to those of the LLMs. In summary, this work establishes the necessary prerequisites prior to initiating the CONCORDIA study and validates a modified score with high applicability and reliability for this and future trials. © 2024 by the authors.",Yes,Sully,,,,,,,,,,
AI-Driven Home Climate Optimization: The Role of ChatGPT in Enhancing AC Efficiency,"The convergence of Internet of Things (IoT) and Artificial Intelligence (AI) has revolutionized home automation, yet traditional air-conditioning (AC) systems still struggle with energy inefficiency. Our research presents a novel solution, integrating AI, IoT, and user-centric design with ChatGPT, to optimize AC systems responsively to occupants' needs. Our methodology employs ChatGPT's capability to analyze historical data, discern patterns, and provide intelligent recommendations for AC operation. This transcends the functions of standard smart thermostats through AI-driven decision-making, optimizing every AC operational moment for both comfort and energy conservation. The system's foundation in data-driven decisions ensures alignment with external and internal conditions, enhancing energy efficiency and user comfort.  © 2024 IEEE.",No,Sully,,,,,,,,,,
Chemical composition analysis and multi-index content determination of alkaloids in Jiawei Qingluo Granules by HPLC-Q-TOF-MS/MS; [基于 HPLC-Q-TOF-MS/MS 加味清络颗粒生物碱类化学成分分析及多指标含量测定],"Objective To qualitatively identify and analyze the alkaloids in Jiawei Qingluo Granules (加味清络颗粒), and establish a method for the determination of alkaloids in Jiawei Qingluo Granules. Methods HPLC-Q-TOF-MS/MS technology was used to scan Jiawei Qingluo Granules in positive and negative ion mode, the precise molecular weight of the compound was calculated by MassHunter software, combined with secondary fragment information of mass spectrometry and comparison of reference substance, to identify the alkaloids in Jiawei Qingluo Granules qualitatively, and the cracking law of the compound was summarized; Determination of six alkaloids in Jiawei Qingluo Granules by HPLC, detection condition: Phenomenex Gemini C18 column (250 mm× 4.6 mm, 5 μm); Acetonitrile as mobile phase A and phosphate buffer solution (pH 5.8) as mobile phase B, gradient elution (0—25 min, 5% A; 25—35 min, 5%—7% A; 35—50 min, 7%—15% A; 50—60 min, 15%—19% A; 60—80 min, 19%—20% A; 80—90 min, 20%—35% A; 90—115 min, 35% A; 15—120 min, 35%—44% A; 120—145 min, 44%—48% A), the column temperature was 30 ℃, the flow rate was 0.9 mL/min, the sample size was 10 μL, and the detection wavelength was 210 nm. Results A total of 50 alkaloids were identified in Jiawei Qingluo Granules, which were derived from Qingfengteng (Sinomenii Caulis), Kushen (Sophorae Flavescentis Radix), Yanhusuo (Corydalis Rhizoma) and Zhimu (Anemarrhenae Rhizoma), including 16 quinolizidine alkaloids, 31 benzyl tetrahydroisoquinoline alkaloids and three other types alkaloids; A multi-index HPLC method for simultaneous determination of matrine, sophocarpine, sinomenine, protopine, tetrahydropalmatine and corydaline in Jiawei Qingluo Granules was established, the six components in the method had good linear relationship in the concentration range (r ≥ 0.999 9), the relative standard deviations (RSD) of precision, repeatability and stability were all less than 4%, the average recoveries of matrine, sophocarpine, sinomenine, protopine, tetrahydropalmatine and corydaline were 94.32%, 96.89%, 97.83%, 109.53%, 99.32%, 87.13%, and RSD values were 3.24%, 4.99%, 4.95%, 4.85%, 2.52%, 5.95%, respectively. Conclusion The established method can accurately and sensitively analyze the chemical components of alkaloids in Jiawei Qingluo Granules, which lays a foundation for the follow-up material basic research, quality control and preparation development of Jiawei Qingluo Granules. © 2024 Editorial Office of Chinese Traditional and Herbal Drugs. All rights reserved.",No,Sully,,,,,,,,,,
Utility of word embeddings from large language models in medical diagnosis,"Objective: This study evaluates the utility of word embeddings, generated by large language models (LLMs), for medical diagnosis by comparing the semantic proximity of symptoms to their eponymic disease embedding (""eponymic condition"") and the mean of all symptom embeddings associated with a disease (""ensemble mean""). Materials and Methods: Symptom data for 5 diagnostically challenging pediatric diseases - CHARGE syndrome, Cowden disease, POEMS syndrome, Rheumatic fever, and Tuberous sclerosis - were collected from PubMed. Using the Ada-002 embedding model, disease names and symptoms were translated into vector representations in a high-dimensional space. Euclidean and Chebyshev distance metrics were used to classify symptoms based on their proximity to both the eponymic condition and the ensemble mean of the condition's symptoms. Results: The ensemble mean approach showed significantly higher classification accuracy, correctly classifying between 80% (Cowden disease) to 100% (Tuberous sclerosis) of the sample disease symptoms using the Euclidean distance metric. In contrast, the eponymic condition approach using Euclidian distance metric and Chebyshev distances, in general, showed poor symptom classification performance, with erratic results (0%-100% accuracy), largely ranging between 0% and 3% accuracy. Discussion: The ensemble mean captures a disease's collective symptom profile, providing a more nuanced representation than the disease name alone. However, some misclassifications were due to superficial semantic similarities, highlighting the need for LLM models trained on medical corpora. Conclusion: The ensemble mean of symptom embeddings improves classification accuracy over the eponymic condition approach. Future efforts should focus on medical-specific training of LLMs to enhance their diagnostic accuracy and clinical utility.  © 2025 The Author(s).",Yes,Sully,,,,,,,,,,
AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories,"3602. Perspect Psychol Sci. 2024 Sep;19(5):808-826. doi: 10.1177/17456916231214460. 
Epub 2024 Jan 2.

AI Psychometrics: Assessing the Psychological Profiles of Large Language Models 
Through Psychometric Inventories.

Pellert M(1), Lechner CM(2), Wagner C(2)(3)(4), Rammstedt B(2), Strohmaier 
M(1)(2)(4).

Author information:
(1)Business School, University of Mannheim.
(2)GESIS-Leibniz Institute for the Social Sciences.
(3)Department of Society, Technology and Human Factors, RWTH Aachen University.
(4)Complexity Science Hub Vienna, Vienna, Austria.

We illustrate how standard psychometric inventories originally designed for 
assessing noncognitive human traits can be repurposed as diagnostic tools to 
evaluate analogous traits in large language models (LLMs). We start from the 
assumption that LLMs, inadvertently yet inevitably, acquire psychological traits 
(metaphorically speaking) from the vast text corpora on which they are trained. 
Such corpora contain sediments of the personalities, values, beliefs, and biases 
of the countless human authors of these texts, which LLMs learn through a 
complex training process. The traits that LLMs acquire in such a way can 
potentially influence their behavior, that is, their outputs in downstream tasks 
and applications in which they are employed, which in turn may have real-world 
consequences for individuals and social groups. By eliciting LLMs' responses to 
language-based psychometric inventories, we can bring their traits to light. 
Psychometric profiling enables researchers to study and compare LLMs in terms of 
noncognitive characteristics, thereby providing a window into the personalities, 
values, beliefs, and biases these models exhibit (or mimic). We discuss the 
history of similar ideas and outline possible psychometric approaches for LLMs. 
We demonstrate one promising approach, zero-shot classification, for several 
LLMs and psychometric inventories. We conclude by highlighting open challenges 
and future avenues of research for AI Psychometrics.",No,Sully,,,,,,,,,,
ChatGPT: beneficial or detrimental in the absence of professional mental health care?,"2814. J Public Health (Oxf). 2024 Feb 23;46(1):e208. doi: 10.1093/pubmed/fdad184.

ChatGPT: beneficial or detrimental in the absence of professional mental health 
care?

Haman M(1), Školník M(1).

Author information:
(1)Department of Humanities, Faculty of Economics and Management, Czech 
University of Life Sciences Prague, Praha 16500, Czech Republic.",No,Sully,,,,,,,,,,
KGLM-QA: A Novel Approach for Knowledge Graph-Enhanced Large Language Models for Question Answering,"Large language models excel in various natural language processing tasks but often struggle with knowledge-intensive queries, particularly those involve rare entities or require precise factual information. This paper presents a novel framework that enhances capabilities of an LLM-based question answering system by incorporating structured knowledge from knowledge graphs. Our approach employs entity extraction, semantic similarity scoring, and adaptive graph exploration to efficiently navigate and extract relevant information from knowledge graphs. The core of the presented solution is a knowledge graph-enhanced language model process that iteratively refines subgraph exploration and answer generation, complemented by a fallback mechanism for robustness across diverse question types. Experiments on location-based questions from the Entity Questions dataset demonstrate significant improvements in the quality of responses. Using the Gemini 1.5 Flash model, our system achieved an accuracy increase from 36% to 71% for partially correct answers and from 22% to 69% for exactly correct answers, as evaluated by human assessors. This approach offers a promising direction for developing more reliable and accurate question answering systems, particularly for queries involving long-tail entities or specific factual knowledge. © 2024 IEEE.",No,Sully,,,,,,,,,,
Promise and pitfalls of ChatGPT for patient education on coronary angiogram,"2593. Ann Acad Med Singap. 2023 Jul 28;52(7):338-339. doi: 
10.47102/annals-acadmedsg.2023225.

Promise and pitfalls of ChatGPT for patient education on coronary angiogram.

Honda S(1), Noguchi T(1).

Author information:
(1)Cardiovascular Medicine, National Cerebral and Cardiovascular Center, Suita, 
Osaka, Japan.",No,Sully,,,,,,,,,,
An Artificial Intelligence Chatbot is an Accurate and Useful Online Patient Resource Prior to Total Knee Arthroplasty,"Background: Online information is a useful resource for patients seeking advice on their orthopaedic care. While traditional websites provide responses to specific frequently asked questions (FAQs), sophisticated artificial intelligence tools may be able to provide the same information to patients in a more accessible manner. Chat Generative Pretrained Transformer (ChatGPT) is a powerful artificial intelligence chatbot that has been shown to effectively draw on its large reserves of information in a conversational context with a user. The purpose of this study was to assess the accuracy and reliability of ChatGPT-generated responses to FAQs regarding total knee arthroplasty. Methods: We distributed a survey that challenged arthroplasty surgeons to identify which of the 2 responses to FAQs on our institution's website was human-written and which was generated by ChatGPT. All questions were total knee arthroplasty–related. The second portion of the survey investigated the potential to further leverage ChatGPT to assist with translation and accessibility as a means to better meet the needs of our diverse patient population. Results: Surgeons correctly identified the ChatGPT-generated responses 4 out of 10 times on average (range: 0 to 7). No consensus was reached on any of the responses to the FAQs. Additionally, over 90% of our surgeons strongly encouraged the use of ChatGPT to more effectively accommodate the diverse patient populations that seek information from our hospital's online resources. Conclusions: ChatGPT provided accurate, reliable answers to our website's FAQs. Surgeons also agreed that ChatGPT's ability to provide targeted, language-specific responses to FAQs would be of benefit to our diverse patient population. © 2024 Elsevier Inc.",Yes,Sully,This is such a weak study but technically meets our inclusion criteria,,,,,,,,,
Delayed diagnosis of a transient ischemic attack caused by ChatGPT,"2661. Wien Klin Wochenschr. 2024 Apr;136(7-8):236-238. doi: 
10.1007/s00508-024-02329-1. Epub 2024 Feb 2.

Delayed diagnosis of a transient ischemic attack caused by ChatGPT.

Saenger JA(1)(2), Hunger J(3), Boss A(4)(5), Richter J(6)(7).

Author information:
(1)Diagnostic and interventional Radiology, University Hospital Zurich, 
University Zurich, Zurich, Switzerland. jonathan.saenger@usz.ch.
(2)Institute of Radiology and Nuclear Medicine, GZO Hospital Wetzikon, Wetzikon, 
Switzerland. jonathan.saenger@usz.ch.
(3)Department of Internal Medicine, GZO Hospital Wetzikon, Wetzikon, 
Switzerland.
(4)Diagnostic and interventional Radiology, University Hospital Zurich, 
University Zurich, Zurich, Switzerland. andreas.boss@gzo.ch.
(5)Institute of Radiology and Nuclear Medicine, GZO Hospital Wetzikon, Wetzikon, 
Switzerland. andreas.boss@gzo.ch.
(6)Institute of Radiology and Nuclear Medicine, GZO Hospital Wetzikon, Wetzikon, 
Switzerland.
(7)Neurology and Stroke Unit, GZO Hospital Wetzikon, Wetzikon, Switzerland.

Techniques of artificial intelligence (AI) are increasingly used in the 
treatment of patients, such as providing a diagnosis in radiological imaging, 
improving workflow by triaging patients or providing an expert opinion based on 
clinical symptoms; however, such AI techniques also hold intrinsic risks as AI 
algorithms may point in the wrong direction and constitute a black box without 
explaining the reason for the decision-making process.This article outlines 
a case where an erroneous ChatGPT diagnosis, relied upon by the patient to 
evaluate symptoms, led to a significant treatment delay and a potentially 
life-threatening situation. With this case, we would like to point out the 
typical risks posed by the widespread application of AI tools not intended for 
medical decision-making.

© 2024. The Author(s).",No,Sully,This is scary but doesn't meet inclusion criteria,,,,,,,,,
Improving the quality of image generation in art with top-k training and cyclic generative methods,"The creation of artistic images through the use of Artificial Intelligence is an area that has been gaining interest in recent years. In particular, the ability of Neural Networks to separate and subsequently recombine the style of different images, generating a new artistic image with the desired style, has been a source of study and attraction for the academic and industrial community. This work addresses the challenge of generating artistic images that are framed in the style of pictorial Impressionism and, specifically, that imitate the style of one of its greatest exponents, the painter Claude Monet. After having analysed several theoretical approaches, the Cycle Generative Adversarial Networks are chosen as base model. From this point, a new training methodology which has not been applied to cyclical systems so far, the top-k approach, is implemented. The proposed system is characterised by using in each iteration of the training those k images that, in the previous iteration, have been able to better imitate the artist's style. To evaluate the performance of the proposed methods, the results obtained with both methodologies, basic and top-k, have been analysed from both a quantitative and qualitative perspective. Both evaluation methods demonstrate that the proposed top-k approach recreates the author's style in a more successful manner and, at the same time, also demonstrate the ability of Artificial Intelligence to generate something as creative as impressionist paintings.",No,Sully,,,,,,,,,,
Lung Cancer Staging Using Chest CT and FDG PET/CT Free-Text Reports: Comparison Among Three ChatGPT Large Language Models and Six Human Readers of Varying Experience,"BACKGROUND. Although radiology reports are commonly used for lung cancer staging, this task can be challenging given radiologists' variable reporting styles as well as reports' potentially ambiguous and/or incomplete staging-related information. OBJECTIVE. The purpose of this study was to compare the performance of ChatGPT large language models (LLMs) and human readers of varying experience in lung cancer staging using chest CT and FDG PET/CT free-text reports. METHODS. This retrospective study included 700 patients (mean age, 73.8 } 29.5 [SD] years; 509 men, 191 women) from four institutions in Korea who underwent chest CT or FDG PET/CT for non-small cell lung cancer initial staging from January 2020 to December 2023. Examinations' reports used a free-text format, written exclusively in English or in mixed English and Korean. Two thoracic radiologists in consensus determined the overall stage group (IA, IB, IIA, IIB, IIIA, IIIB, IIIC, IVA, or IVB) for each report using the 8th-edition AJCC Cancer Staging Manual to establish the reference standard. Three ChatGPT models (GPT-4o, GPT-4, GPT-3.5) determined an overall stage group for each report using a script-based application programming interface, zero- shot learning, and a prompt incorporating a staging system summary. The code for this web application was made publicly available through a GitHub repository (https://github.com/elmidion/GPT_Information_Extractor). Six human readers (two fellowship-trained radiologists with less experience than the radiologists who determined the reference standard, two fellows, and two residents) also independently determined overall stage groups. GPT-4o's overall accuracy for determining the correct stage among the nine groups was compared with that of the other LLMs and human readers using McNemar tests. RESULTS. GPT-4o had an overall staging accuracy of 74.1%, significantly better than the accuracy of GPT-4 (70.1%, p = .02), GPT-3.5 (57.4%, p < .001), and resident 2 (65.7%, p < .001); significantly worse than the accuracy of fellowship-trained radiologist 1 (82.3%, p < .001) and fellowship-trained radiologist 2 (85.4%, p < .001); and not significantly different from the accuracy of fellow 1 (77.7%, p = .09), fellow 2 (75.6%, p = .53), and resident 1 (72.3%, p = .42). CONCLUSION. The best-performing model, GPT-4o, showed no significant difference in staging accuracy versus fellows but showed significantly worse performance versus fellowship-trained radiologists. The findings do not support use of LLMs for lung cancer staging in place of expert health care professionals. CLINICAL IMPACT. The findings indicate the importance of domain expertise for performing complex specialized tasks such as cancer staging. © 2024 American Roentgen Ray Society. All rights reserved.",Yes,Sully,This is actually a bit surprising,,,,,,,,,
The ChatGPT (Generative Artificial Intelligence) Revolution Has Made Artificial Intelligence Approachable for Medical Professionals,"195. J Med Internet Res. 2023 Jun 22;25:e48392. doi: 10.2196/48392.

The ChatGPT (Generative Artificial Intelligence) Revolution Has Made Artificial 
Intelligence Approachable for Medical Professionals.

Mesko B(1)(2).

Author information:
(1)The Medical Futurist Institute, Budapest, Hungary.
(2)Department of Behavioural Sciences, Semmelweis University, Budapest, Hungary.

In November 2022, OpenAI publicly launched its large language model (LLM), 
ChatGPT, and reached the milestone of having over 100 million users in only 2 
months. LLMs have been shown to be useful in a myriad of health care-related 
tasks and processes. In this paper, I argue that attention to, public access to, 
and debate about LLMs have initiated a wave of products and services using 
generative artificial intelligence (AI), which had previously found it hard to 
attract physicians. This paper describes what AI tools have become available 
since the beginning of the ChatGPT revolution and contemplates how it they might 
change physicians' perceptions about this breakthrough technology.

©Bertalan Mesko. Originally published in the Journal of Medical Internet 
Research (https://www.jmir.org), 22.06.2023.",No,Sully,,,,,,,,,,
Navigating autism treatment: unlocking new frontiers with ChatGPT,"Autism Spectrum disorder is a significant neurodevelopmental behavioral disorder. Children with Autism display a wide array of ambiguous symptoms resulting making the diagnosis quite challenging thus resulting in delayed management. Traditionally, its diagnosis and management require the collaboration of services from the three P’s namely the pediatrician, psychiatrist, and child psychologist. The management requires an intensive multi-disciplinary approach which would help minimize the disease symptoms and facilitate development and learning during childhood. Recently, with the advent of widespread testing and usage of various artificial intelligence tools across various domains, AI tools such as Chatbots are being incorporated into medical treatments, especially in behavioral therapy. Considering the increasing use of AI, we believe that the natural language processing techniques employed by ChatGPT algorithms have the potential to identify speech and linguistic patterns in children with ASD. Therefore, through this letter, we have tried to explore the scope of Artificial intelligence (ChatGPT) for behavioral therapy in children affected with autism spectrum disorder.",No,Sully,,,,,,,,,,
The Role of Artificial Intelligence in the Future of Pharmacy Education,"1240. Am J Pharm Educ. 2023 Oct;87(10):100135. doi: 10.1016/j.ajpe.2023.100135. Epub 
2023 May 26.

The Role of Artificial Intelligence in the Future of Pharmacy Education.

Cain J(1), Malcom DR(2), Aungst TD(3).

Author information:
(1)University of Kentucky College of Pharmacy, Department of Pharmacy Practice & 
Science, Lexington, KY, USA. Electronic address: jeff.cain@uky.edu.
(2)Sullivan University College of Pharmacy and Health Sciences, Clinical and 
Administrative Sciences, Louisville, KY, USA.
(3)Massachusetts College of Pharmacy and Health Sciences, Department of Pharmacy 
Practice, Worcester, MA, USA.

Recent developments making an artificial intelligence (AI) large language model 
available for public use have generated significant interest and angst among 
educators. Viewed as both a time saver and a threat to academic integrity, 
several questions have arisen about AI's role in education. Numerous 
opportunities exist to use AI for teaching and learning, but new questions have 
also arisen regarding AI's impact on the future of healthcare. The pharmacy 
Academy should be at the center of these discussions to address the technical, 
philosophical, and ethical issues that AI presents for the future of pharmacy 
and pharmacy education.

Copyright © 2023 American Association of Colleges of Pharmacy. Published by 
Elsevier Inc. All rights reserved.",No,Sully,,,,,,,,,,
BIOINFO-BENCH: A SIMPLE BENCHMARK FRAMEWORK FOR LLM BIOINFORMATICS SKILLS EVALUATION,"Large Language Models (LLMs) have garnered significant recognition in the life sciences for their capacity to comprehend and utilize knowledge. The contemporary expectation in diverse industries extends beyond employing LLMs merely as chatbots; instead, there is a growing emphasis on harnessing their potential as adept analysts proficient in dissecting intricate issues within these sectors. The realm of bioinformatics is no exception to this trend. In this paper, we introduce BIOINFO-BENCH, a novel yet straightforward benchmark framework suite crafted to assess the academic knowledge and data mining capabilities of foundational models in bioinformatics. BIOINFO-BENCH systematically gathered data from three distinct perspectives: knowledge acquisition, knowledge analysis, and knowledge application, facilitating a comprehensive examination of LLMs. Our evaluation encompassed prominent models ChatGPT, Llama, and Galactica. The findings revealed that these LLMs excel in knowledge acquisition, drawing heavily upon their training data for retention. However, their proficiency in addressing practical professional queries and conducting nuanced knowledge inference remains constrained. Given these insights, we are poised to delve deeper into this domain, engaging in further extensive research and discourse. It is pertinent to note that project BIOINFO-BENCH is currently in progress, and all associated materials will be made publicly accessible.",No,Sully,,,,,,,,,,
Integrating Sensor Technologies with Conversational AI: Enhancing Context-Sensitive Interaction Through Real-Time Data Fusion,"This article examines how sensor technologies (such as environmental sensors, biometric sensors, and IoT devices) intersect with conversational AI models like ChatGPT 4.0. In particular, this article explores how data from different sensors in real time can improve AI models' comprehension of surroundings, user contexts, and physical conditions. Lastly, this article delves into the scientific principles supporting sensor technologies, data processing methods, and their fusion with generative models such as ChatGPT to develop adaptable, dynamic systems that engage with humans intelligently in real time. Some of the specific topics that are investigated include the science behind sensor networks and acquiring real-time data, how ChatGPT can analyze sensor data to generate dialogue that is sensitive to context, instances in healthcare (such as using wearable sensors along with AI chatbots for patient treatment), and smart homes (interaction with AI assistants driven by sensors). These subjects will prove advantageous for researchers in sensor technology as well as AI development, showcasing interdisciplinary progress in smart systems.",No,Sully,,,,,,,,,,
Integrative diagnosis of psychiatric conditions using ChatGPT and fMRI data,"BACKGROUND: Traditional diagnostic methods for psychiatric disorders often rely 
on subjective assessments, leading to inconsistent diagnoses. Integrating 
advanced natural language processing (NLP) techniques with neuroimaging data may 
improve diagnostic accuracy.
METHODS: We propose a novel approach that uses ChatGPT to conduct interactive 
patient interviews, capturing nuanced emotional and psychological data. By 
analyzing these dialogues using NLP, we generate a comprehensive feature matrix. 
This matrix, combined with 4D fMRI data, is input into a neural network to 
predict psychiatric diagnoses. We conducted comparative analysis with 
survey-based and app-based methods, providing detailed statistical validation.
RESULTS: Our model achieved an accuracy of 85.7%, significantly outperforming 
traditional methods. Statistical analysis confirmed the superiority of the 
ChatGPT-based approach in capturing nuanced patient information, with p-values 
indicating significant improvements over baseline models.
CONCLUSIONS: Integrating NLP-driven patient interactions with fMRI data offers a 
promising approach to psychiatric diagnosis, enhancing precision and 
reliability. This method could advance clinical practice by providing a more 
objective and comprehensive diagnostic tool, although more research is needed to 
generalize these findings.

© 2025. The Author(s).",Yes,Sully,Technically should be included but oh my gosh this is so sus,,,,,,,,,
Can ChatGPT be guide in pediatric dentistry?,"BACKGROUND: The use of ChatGPT in the field of health has recently gained popularity. In the field of dentistry, ChatGPT can provide services in areas such as, dental education and patient education. The aim of this study was to evaluate the quality, readability and originality of pediatric patient/parent information and academic content produced by ChatGPT in the field of pediatric dentistry. METHODS: A total of 60 questions were asked to ChatGPT for each topic (dental trauma, fluoride, and tooth eruption/oral health) consisting of pediatric patient/parent questions and academic questions. The modified Global Quality Scale (the scoring ranges from 1: poor quality to 5: excellent quality) was used to evaluate the quality of the answers and Flesch Reading Ease and Flesch-Kincaid Grade Level were used to evaluate the readability. A similarity index was used to compare the quantitative similarity of the answers given by the software with the guidelines and academic references in different databases. RESULTS: The evaluation of answers quality revealed an average score of 4.3 ± 0.7 for pediatric patient/parent questions and 3.7 ± 0.8 for academic questions, indicating a statistically significant difference (p < 0.05). Academic questions regarding dental trauma received the lowest scores (p < 0.05). However, no significant differences were observed in readability and similarity between ChatGPT answers for different question groups and topics (p > 0.05). CONCLUSIONS: In pediatric dentistry, ChatGPT provides quality information to patients/parents. ChatGPT, which is difficult to readability for patients/parents and offers an acceptable similarity rate, needs to be improved in order to interact with people more efficiently and fluently.",Yes,Sully,,,,,,,,,,
A Novel Full-Length Recombinant Human Complement Factor H (CFH; GEM103) for the Treatment of Age-Related Macular Degeneration Shows Similar In Vitro Functional Activity to Native CFH,"Purpose: GEM103 is a recombinantly produced full-length version of the human complement factor H (CFH) under clinical investigation for treatment of age-related macular degeneration (AMD) in individuals carrying an AMD risk-associated genetic variant of CFH. This study aimed to investigate the complement pathway-related functions of GEM103 in comparison with those of native human CFH. Methods: Key biological activities of GEM103 and human serum-derived CFH (sdCFH) were compared using four independent functional assays. Assays of C3b binding and C3 convertase decay-accelerating activity (DAA) were performed by surface plasmon resonance (SPR). Cofactor activity (CA) was measured using 8-anilinonaphthalene-1-sulfonic acid as a fluorescent probe of C3b integrity. The abilities of GEM103 and sdCFH to protect sheep erythrocytes from hemolysis by CFH-depleted normal human serum were assessed colorimetrically. Results: In multiple SPR-based assays of C3b binding and DAA, the performance of GEM103 was consistently comparable to that of sdCFH across a range of matching concentrations. The EC50 ± SD in the fluorescence-based fluid-phase CA assay was 0.21 ± 0.06 µM for GEM103 compared to 0.20 ± 0.09 µM for sdCFH. In hemolysis assays, the EC50 value of 0.33 ± 0.16 µM for GEM103 versus 0.46 ± 0.06 µM for sdCFH were not significantly different (p = 0.81). Conclusions: GEM103, a recombinant CFH developed by Gemini Therapeutics, shows activity profiles comparable to sdCFH in all complement-related assays employed in this study, suggesting that GEM103 is equivalent to the native glycoprotein in terms of its in vitro functional activity. These results support further study of GEM103 as a potential therapy for AMD. © 2022 Gemini Therapeutics Inc. Published with license by Taylor & Francis Group, LLC.",No,Sully,,,,,,,,,,
Human-Written vs AI-Generated Texts in Orthopedic Academic Literature: Comparative Qualitative Analysis,"Background: As large language models (LLMs) are becoming increasingly integrated into different aspects of health care, questions about the implications for medical academic literature have begun to emerge. Key aspects such as authenticity in academic writing are at stake with artificial intelligence (AI) generating highly linguistically accurate and grammatically sound texts. Objective: The objective of this study is to compare human-written with AI-generated scientific literature in orthopedics and sports medicine. Methods: Five original abstracts were selected from the PubMed database. These abstracts were subsequently rewritten with the assistance of 2 LLMs with different degrees of proficiency. Subsequently, researchers with varying degrees of expertise and with different areas of specialization were asked to rank the abstracts according to linguistic and methodological parameters. Finally, researchers had to classify the articles as AI generated or human written. Results: Neither the researchers nor the AI-detection software could successfully identify the AI-generated texts. Furthermore, the criteria previously suggested in the literature did not correlate with whether the researchers deemed a text to be AI generated or whether they judged the article correctly based on these parameters. Conclusions: The primary finding of this study was that researchers were unable to distinguish between LLM-generated and human-written texts. However, due to the small sample size, it is not possible to generalize the results of this study. As is the case with any tool used in academic research, the potential to cause harm can be mitigated by relying on the transparency and integrity of the researchers. With scientific integrity at stake, further research with a similar study design should be conducted to determine the magnitude of this issue. © 2024 JMIR Publications Inc.. All rights reserved.",No,Sully,,,,,,,,,,
PhosF3C: A Feature Fusion Architecture with Fine-Tuned Protein Language Model and Conformer for prediction of general phosphorylation site,"Protein phosphorylation, a key post-translational modification (PTM), provides essential insight into protein properties, making its prediction highly significant. Using the emerging capabilities of large language models (LLMs), we apply LoRA fine-tuning to ESM2, a powerful protein large language model, to efficiently extract features with minimal computational resources, optimizing task-specific text alignment. Additionally, we integrate the conformer architecture with the Feature Coupling Unit (FCU) to enhance local and global feature exchange, further improving prediction accuracy. Our model achieves state-of-the-art (SOTA) performance, obtaining AUC scores of 79.5%, 76.3%, and 71.4% at the S, T, and Y sites of the general data sets. Based on the powerful feature extraction capabilities of LLMs, we conduct a series of analyses on protein representations, including studies on their structure, sequence, and various chemical properties (such as Hydrophobicity (GRAVY), Surface Charge, and Isoelectric Point). We propose a test method called Linear Regression Tomography (LRT) which is a top-down method using representation to explore the model’s feature extraction capabilities, offering a pathway to improved interpretability.",No,Sully,,,,,,,,,,
Reply to Letter-to-the-Editor on ChatGPT for the Diagnosis and Treatment of Low Back Pain: A Comparative Analysis,"3017. Spine (Phila Pa 1976). 2024 May 15;49(10):E152. doi: 
10.1097/BRS.0000000000004961. Epub 2024 Feb 19.

Reply to Letter-to-the-Editor on ChatGPT for the Diagnosis and Treatment of Low 
Back Pain: A Comparative Analysis.

Shrestha N(1), Cho SK.

Author information:
(1)Department of Orthopedic Surgery, Icahn School of Medicine at Mount Sinai, 
New York, NY.",No,Sully,,,,,,,,,,
Identifying Gender Bias in Generative Models for Mental Health Synthetic Data,"Natural language generation (NLG) systems have proven to be effective tools to create domain-specific synthetic data. The mental health research field could benefit from data augmentation techniques, given the challenges associated with obtaining and utilizing protected health information. Yet, NLG systems are often trained using datasets that are biased with respect to key demographic factors such as ethnicity, religion, and gender. This can perpetuate and propagate systematic human biases that exist and ultimately lead to inequitable treatment for marginalized groups. In this research we studied and characterized biases present in the Generative Pre-trained Transformer 3 (GPT-3), which is an autoregressive language model that produces human-like text. The prompts used to generate text via GPT-3 were based on the Brief Cognitive Behavioral Therapy framework, and each prompt also specified to write the answer as a female or male patient. By controlling the sex distributions within our prompts, we observed the impact of each trait in the generated text. The synthetic data was analysed using the Linguistic Inquiry and Word Count software (LIWC-22) and ccLDA for cross-collection topic modeling. LIWC-22 results show that stereotypical competence features such as money, work, and cognition are more present in the male's synthetic text, whereas warmth features such as home, feeling, and emotion are highly present in female's generated data. The ccLDA results also associate competence features with males and warmth features with females. © 2023 IEEE.",No,Sully,,,,,,,,,,
The vicious cycle of status insecurity,"3368. J Pers Soc Psychol. 2025 Jan;128(1):101-122. doi: 10.1037/pspi0000473. Epub 2024 
Dec 2.

The vicious cycle of status insecurity.

Hoff M(1), Rucker DD(2), Galinsky AD(3).

Author information:
(1)Department of Marketing, Columbia Business School, Columbia University.
(2)Department of Marketing, Kellogg School of Management, Northwestern 
University.
(3)Department of Management, Columbia Business School, Columbia University.

The current research presents and tests a new model: The Vicious Cycle of Status 
Insecurity. We define status insecurity as doubting whether one is respected and 
admired by others. Status insecurity leads people to view status as a limited 
and zero-sum resource, where a boost in the status of one individual inherently 
decreases that of other individuals. As a result, the insecure become reluctant 
to share status in the form of highlighting the contributions of others. 
However, we suggest this reluctance to give others credit is often 
counterproductive. In contrast to the zero-sum beliefs of the insecure, we 
propose that giving credit to others boosts the status of both the sharer and 
the recipient, expanding the overall status pie. Because the insecure miss 
opportunities to gain status by not elevating others, they reinforce their 
initial insecurity. We provide evidence for this vicious cycle across 17 
studies, including a content analysis of people's personal experiences with 
status insecurity, an archival analysis of the final speeches held on the 
reality TV show Survivor (using ChatGPT), and more than a dozen experimental 
studies. To enhance generalizability and external validity, our experimental 
contexts include consulting pitches, venture capital competitions, and idea 
generation contests. To demonstrate discriminant validity, we differentiate 
status insecurity from self-esteem insecurity. Across the studies, status 
insecurity consistently decreased status sharing while status sharing reliably 
increased one's status. Ultimately, status insecurity paradoxically lowers one's 
status because it reduces the propensity to elevate and celebrate others. 
(PsycInfo Database Record (c) 2025 APA, all rights reserved).",No,Sully,,,,,,,,,,
"Exploring artificial intelligence in the Nigerian medical educational space: An online cross-sectional study of perceptions, risks and benefits among students and lecturers from ten universities","BACKGROUND: The impact of artificial intelligence (AI) has been compared to that 
of the Internet and printing, evoking both apprehension and anticipation in an 
uncertain world.
OBJECTIVE: This study aimed to explore the perceptions of medical students and 
faculty members from ten universities across Nigeria regarding AI.
METHODS: Using Google Forms and WhatsApp, a cross-sectional online survey was 
administered to clinical year medical students and their lecturers from ten 
medical schools representing all the six geopolitical zones of Nigeria.
RESULTS: The survey received 1003 responses, of which 708 (70.7%) were from 
students and 294 (29.3%) were from lecturers. Both groups displayed an average 
level of knowledge, with students (Median:4, range -5 to 12) significantly 
outperforming lecturers (Median:3, range -5 to 15). Social media (61.2%) was the 
most common form of first contact with AI. Participants demonstrated a 
favourable attitude towards AI, with a median score of 6.8 out of 10. Grammar 
checkers (62.3%) were the most commonly reported AI tool used, while ChatGPT 
(43.6%) was the most frequently mentioned dedicated AI tool. Students were 
significantly more likely than lecturers to have used AI tools in the past but 
<5% of both groups had received prior AI training. Excitement about the 
potential of AI slightly outweighed concerns regarding future risks. A 
significantly higher proportion of students compared to lecturers believed that 
AI could dehumanise health care (70.6% vs. 60.8%), render physicians redundant 
(57.6% vs. 34.7%), diminish physicians' skills (79.3% vs. 71.3%) and ultimately 
harm patients (28.6% vs. 20.6%).
CONCLUSION: The simultaneous fascination and apprehension with AI observed among 
both lecturers and students in our study mirrors the global trend. This finding 
was particularly evident in students who, despite possessing greater knowledge 
of AI compared to their lecturers, did not exhibit a corresponding reduction in 
their fear of AI.",No,Sully,,,,,,,,,,
Applications of Large Language Models (LLMs) in Breast Cancer Care,"Purpose: Recently introduced Large Language Models (LLMs) such as ChatGPT have already shown promising results in natural language processing in healthcare. The aim of this study is to systematically review the literature on the applications of LLMs in breast cancer diagnosis and care. Methods: A literature search was conducted using MEDLINE, focusing on studies published up to October 22nd, 2023, using the following terms: “large language models”, “LLM”, “GPT”, “ChatGPT”, “OpenAI”, and “breast”. Results: Five studies met our inclusion criteria. All studies were published in 2023, focusing on ChatGPT-3.5 or GPT-4 by OpenAI. Applications included information extraction from clinical notes, question-answering based on guidelines, and patients’ management recommendations. The rate of correct answers varied from 64-98%, with the highest accuracy (88-98%) observed in information extraction and question-answering tasks. Notably, most studies utilized real patient data rather than data sourced from the internet. Limitations included inconsistent accuracy, prompt sensitivity, and overlooked clinical details, highlighting areas for cautious LLM integration into clinical practice. Conclusion: LLMs demonstrate promise in text analysis tasks related to breast cancer care, including information extraction and guideline-based question-answering. However, variations in accuracy and the occurrence of erroneous outputs necessitate validation and oversight. Future works should focus on improving reliability of LLMs within clinical workflow.",Yes,Sully,,,,,,,,,,
ChatGPT and the Future of Health Policy Analysis: Potential and Pitfalls of Using ChatGPT in Policymaking,"Scholars increasingly rely on new artificial intelligence models for convenience and simple access to necessities due to the rapid evolution of scientific literature and technology. The invention of ChatGPT by OpenAI stands out as a key example of how significant advances in large language model technology have recently changed the field of artificial intelligence (AI). Since ChatGPT’s development, it has been tested by multiple sectors on various topics to see how well it functions in a natural and conversational mode. The crucial question is how much ChatGPT can influence global health policy analysis. In this article, the researcher briefly explains ChatGPT’s potential and the difficulties that users, such as researchers or policymakers, may continue to face.",No,Sully,,,,,,,,,,
Thematic analysis: exploring teacher and student perspectives on utilizing ChatGPT for content generation; [Análisis temático: exploración de las perspectivas de profesores y alumnos sobre la utilización de ChatGPT para la generación de contenidos],"Introduction: the research investigated the effects of ChatGPT, an AI-driven language model, on students and academic institutions. The analysis incorporated viewpoints from academics, research scholars, and graduate or postgraduate students. The increasing use of AI in education requires a comprehensive understanding of its potential benefits and drawbacks, especially within higher education and research. Method: a thematic content analysis was used to investigate the viewpoints of 46 graduate and postgraduate students, 8 research scholars, and 4 educators. The investigation sought to find repeating themes and principal concepts concerning the influence of AI in educational environments. Results: the research examined remarks regarding the function of ChatGPT for students, researchers, and educators, pinpointing eight major themes. The most prevalent were Content Writing (45 mentions), Creation of Thought (35 references), and Collection of Information (33 mentions), underscoring ChatGPT’s influence on content development, ideation, and data organization. Additional themes encompassed Language Utilization, Innovation Generation, Model Development, Idea Formation, and Supportive Tools. The results demonstrated that ChatGPT is perceived as revolutionary for writing, cognitive processes, and information acquisition. Conclusions: the research determined that ChatGPT has considerable ramifications for students and universities, as revealed by thematic content analysis. It emphasized eight primary themes: content, creativity, language, tools, models, information, generations, and ideas. It highlighted AI as an augmentation of the human intellect while acknowledging the significance of human traits. The results highlighted the necessity for additional research into privacy issues, ethical considerations, and optimal procedures for incorporating AI in education. The report emphasized the necessity of recognizing both the benefits and drawbacks of AI in current research and higher education. © 2025; Los autores.",No,Sully,,,,,,,,,,
Artificial Intelligence-Based Virtual Assistant for the Diagnostic Approach of Chronic Ataxias,"Background: Chronic ataxias, a complex group of over 300 diseases, pose significant diagnostic challenges because of their clinical and genetic heterogeneity. Here, we propose that artificial intelligence (AI) can aid in the identification and understanding of these disorders through the utilization of a smart virtual assistant. Objectives: The aim is to develop and validate an AI-powered virtual assistant for diagnosing chronic ataxias. Methods: A non-commercial virtual assistant was developed using advanced algorithms, decision trees, and large language models. In the validation process, 453 clinical cases from the literature were selected from 151 causes of chronic ataxia. The diagnostic accuracy was compared with that of 21 neurologists specializing in movement disorders and GPT-4. Usability regarding time and number of questions needed were also evaluated. Results: The virtual assistant accuracy was 90.9%, higher than neurologists (18.3%), and GPT-4 (19.4%). It also significantly outperformed in causes of ataxia distributed by age, inheritance, frequency, associated clinical manifestations, and treatment availability. Neurologists and GPT-4 mentioned 110 incorrect diagnoses, 83.6% of which were made by GPT-4, which also generated seven data hallucinations. The virtual assistant required an average of 14 questions and 1.5 minutes to generate a list of differential diagnoses, significantly faster than the neurologists (mean, 19.4 minutes). Conclusions: The virtual assistant proved to be accurate and easy fast-use for the diagnosis of chronic ataxias, potentially serving as a support tool in neurological consultation. This diagnostic approach could also be expanded to other neurological and non-neurological diseases. © 2025 International Parkinson and Movement Disorder Society. © 2025 International Parkinson and Movement Disorder Society.",Yes,Sully,,,,,,,,,,
Investigating the Accuracy and Completeness of an Artificial Intelligence Large Language Model About Uveitis: An Evaluation of ChatGPT,"Purpose: To assess the accuracy and completeness of ChatGPT-generated answers regarding uveitis description, prevention, treatment, and prognosis. Methods: Thirty-two uveitis-related questions were generated by a uveitis specialist and inputted into ChatGPT 3.5. Answers were compiled into a survey and were reviewed by five uveitis specialists using standardized Likert scales of accuracy and completeness. Results: In total, the median accuracy score for all the uveitis questions (n = 32) was 4.00 (between “more correct than incorrect” and “nearly all correct”), and the median completeness score was 2.00 (“adequate, addresses all aspects of the question and provides the minimum amount of information required to be considered complete”). The interrater variability assessment had a total kappa value of 0.0278 for accuracy and 0.0847 for completeness. Conclusion: ChatGPT can provide relatively high accuracy responses for various questions related to uveitis; however, the answers it provides are incomplete, with some inaccuracies. Its utility in providing medical information requires further validation and development prior to serving as a source of uveitis information for patients. © 2024 Taylor & Francis Group, LLC.",Yes,Sully,,,,,,,,,,
Comparing AI- versus clinician-authored summaries of simulated primary care electronic health records,"Objective: To compare clinical summaries generated from simulated patient primary care electronic health records (EHRs) by ChatGPT-4 to summaries generated by clinicians on multiple domains of quality including utility, concision, accuracy and bias. Materials and Methods: Seven primary care physicians generated 70 simulated patient EHR notes, each representing 10 appointments with the practice over at least two years. Each record was summarised by a different clinician and by ChatGPT-4. AI- and clinician-authored summaries were rated blind by clinicians according to eight domains of quality and an overall rating. Results: The median time taken for a clinician to read through and assimilate the information in the EHRs before summarising, was seven minutes. Clinicians rated clinician-authored summaries higher than AI-authored summaries overall (7.39 versus 7.00 out of 10; p=0.02), but with greater variability in clinician-authored summary ratings. AI and clinician-authored summaries had similar accuracy and AI-authored summaries were less likely to omit important information and more likely to use patient-friendly language. Discussion: Although AI-authored summaries were rated slightly lower overall compared with clinician-authored summaries, they demonstrated similar accuracy and greater consistency. This demonstrates potential applications for generating summaries in primary care, particularly in the context of the substantial time taken for clinicians to undertake this work. Conclusion: The results suggest the feasibility, utility and acceptability of using AI-authored summaries to integrate into EHRs to support clinicians in primary care. AI summarisation tools have the potential to improve healthcare productivity, including by enabling clinicians to spend more time on direct patient care.",Yes,Sully,,,,,,,,,,
Artificial intelligence meets medical expertise: evaluating GPT-4's proficiency in generating medical article abstracts; [Yapay zeka tıbbi uzmanlıkla buluşuyor: GPT-4'ün tıbbi makale özetleri oluşturmadaki yeterliliğinin değerlendirilmesi],"Purpose: The advent of large language models like GPT-4 has opened new possibilities in natural language processing, with potential applications in medical literature. This study assesses GPT-4's ability to generate medical abstracts. It compares their quality to original abstracts written by human authors, aiming to understand the effectiveness of artificial intelligence in replicating complex, professional writing tasks. Materials and methods: A total of 250 original research articles from five prominent radiology journals published between 2021 and 2023 were selected. The body of these articles, excluding the abstracts, was fed into GPT-4, which then generated new abstracts. Three experienced radiologists blindly and independently evaluated all 500 abstracts using a five-point Likert scale for quality and understandability. Statistical analysis included mean score comparison inter-rater reliability using Fleiss' Kappa and Bland-Altman plots to assess agreement levels between raters. Results: Analysis revealed no significant difference in the mean scores between original and GPT-4 generated abstracts. The inter-rater reliability yielded kappa values indicating moderate to substantial agreement: 0.497 between Observers 1 and 2, 0.753 between Observers 1 and 3, and 0.645 between Observers 2 and 3. Bland-Altman analysis showed a slight systematic bias but was within acceptable limits of agreement. Conclusion: The study demonstrates that GPT-4 can generate medical abstracts with a quality comparable to those written by human experts. This suggests a promising role for artificial intelligence in facilitating the abstract writing process and improving its quality. © 2024, Pamukkale University. All rights reserved.",No,Sully,,,,,,,,,,
Traditional Chinese Medicine Formula Classification Using Large Language Models,"Objective: In this study, we aim to investigate the utilization of large language models (LLMs) for traditional Chinese medicine (TCM) formula classification by fine-tuning the LLMs and prompt template. Methods: We refined and cleaned the data from the Coding Rules for Chinese Medicinal Formulas and Their Codes [1], the Chinese National Medical Insurance Catalog for Proprietary Chinese Medicines [2], and Textbooks of Formulas of Chinese Medicine [3] to address the standardization of TCM formula information, and finally we extracted 2308 TCM formula data as a dataset in this study. We designed a prompt template for the TCM formula classification task and randomly divided the formula dataset into three subsets: a training set (2000 formulas), a test set (208 formulas), and a validation set (100 formulas). We fine-tuned the open-source LLMs such as ChatGLM-6b and ChatGLM2-6b. Finally, we evaluate all selected LLMs in our study: ChatGLM-6b (original), ChatGLM2-6b (original), ChatGLM-130b, InternLM-20b, ChatGPT, ChatGLM-6b (fine-tuned), and ChatGLM2-6b (fine-tuned). Results: The results showed that ChatGLM2-6b (fine-tuned) and ChatGLM-6b (fine-tuned) achieved the highest accuracy rates of 71% and 70% on the validation set, respectively. The accuracy rates of other models were ChatGLM-130b 58%, ChatGPT 53%, InternLM-20b 52%, ChatGLM2-6b (original) 41%, and ChatGLM-6b (original) 23%. Conclusion: LLMs achieved an impressive 71% accuracy in the formula classification task in our study. This was achieved through fine-tuning and the utilization of prompt templates. And provided a novel option for the utilization of LLMs in the field of TCM.  © 2023 IEEE.",No,Sully,,,,,,,,,,
Evaluation and practical application of prompt-driven ChatGPTs for EMR generation,"This study investigates the application of prompt engineering to optimize prompt-driven ChatGPT for generating electronic medical records (EMRs) during lung nodule screening. We assessed the performance of ChatGPT in generating EMRs from patient–provider verbal consultations and integrated this approach into practical tools, such as WeChat mini-programs, accessible to patients before hospital visits. The findings highlight ChatGPT’s potential to enhance workflow efficiency and improve diagnostic processes in clinical settings. © The Author(s) 2025.",Yes,Sully,,,,,,,,,,
Assessment of ChatGPT in the Prehospital Management of Ophthalmological Emergencies - An Analysis of 10 Fictional Case Vignettes,"BACKGROUND: The artificial intelligence (AI)-based platform ChatGPT (Chat 
Generative Pre-Trained Transformer, OpenAI LP, San Francisco, CA, USA) has 
gained impressive popularity in recent months. Its performance on case vignettes 
of general medical (non-ophthalmological) emergencies has been assessed - with 
very encouraging results. The purpose of this study was to assess the 
performance of ChatGPT on ophthalmological emergency case vignettes in terms of 
the main outcome measures triage accuracy, appropriateness of recommended 
prehospital measures, and overall potential to inflict harm to the user/patient.
METHODS: We wrote ten short, fictional case vignettes describing different acute 
ophthalmological symptoms. Each vignette was entered into ChatGPT five times 
with the same wording and following a standardized interaction pathway. The 
answers were analyzed following a systematic approach.
RESULTS: We observed a triage accuracy of 93.6%. Most answers contained only 
appropriate recommendations for prehospital measures. However, an overall 
potential to inflict harm to users/patients was present in 32% of answers.
CONCLUSION: ChatGPT should presently not be used as a stand-alone primary source 
of information about acute ophthalmological symptoms. As AI continues to evolve, 
its safety and efficacy in the prehospital management of ophthalmological 
emergencies has to be reassessed regularly.

Publisher: HINTERGRUND: Die auf künstlicher Intelligenz (KI) basierende 
Plattform ChatGPT (Chat Generative Pre-Trained Transformer, OpenAI LP, San 
Francisco, CA, USA) hat in den vergangenen Monaten rasant an Popularität 
gewonnen. Vorangegange Studien zeigen ein vielversprechendes Abschneiden von 
ChatGPT in der Beantwortung allgemeinmedizinischer Notfallvignetten. Ziel dieser 
Studie war es, die Antworten von ChatGPT auf ophthalmologische Fallvignetten 
hinsichtlich Triagegenauigkeit, Angemessenheit empfohlener präklinischer 
Maßnahmen sowie Schadenspotenzial zu beurteilen.
METHODEN: Wir erstellten 10 kurze, fiktive Fallvignetten aus dem Bereich 
augenheilkundlicher Akutsymptomatik. Jede Vignette wurde entsprechend einem 
standardisierten Interaktionspfad 5-mal in ChatGPT eingegeben. Die Antworten 
wurden anhand eines strukturierten Evaluationsmanuals ausgewertet.
ERGEBNISSE: Wir beobachteten eine Triagegenauigkeit von 93,6%. Die meisten 
Antworten enthielten nur angemessene Empfehlungen bezüglich präklinischer 
Maßnahmen. Insgesamt zeigte sich jedoch in 32% der Antworten ein 
Schadenspotenzial für den Nutzer/Patienten.
SCHLUSSFOLGERUNG: ChatGPT sollte derzeit nicht als einzige Informationsquelle 
zur Beurteilung akuter ophthalmologischer Symptome herangezogen werden. 
Neuentwicklungen auf dem Bereich der KI sollten regelmäßig im Hinblick auf 
Chancen und Risiken im Bereich der augenärztlichen Notfallversorgung evaluiert 
werden.

Thieme. All rights reserved.",Yes,Sully,Seriously? Ten fictional vignettes?,,,,,,,,,
Nurses' Perspectives on ChatGPT: A Survey Study,"The aim of this study was to assess nurses' awareness and use of ChatGPT. The study was conducted in October 2023 with an online questionnaire for 124 nurses in the nursing education programme at West China Hospital. The questionnaire included participants' demographic information, awareness of ChatGPT, and actual experience of using it. A total of 57.3% (71/124) of the nurses completed the survey. Of these, 56.3% (40/71) were aware of ChatGPT and 43.7% (31/71) were not aware of ChatGPT. In terms of use, of the 20 who used ChatGPT, 13 used it for studying, 10 for essay writing, five for research and two for chatting. This study highlights the potential of ChatGPT to improve nurses' professional competence and effectiveness. Further research will focus on how ChatGPT can be used more effectively to support nurses' professional development and growth.  © 2024 The Authors.",No,Sully,,,,,,,,,,
Identification of kidney-related medications using AI from self-captured pill images,"Introduction: ChatGPT, a state-of-the-art large language model, has shown potential in analyzing images and providing accurate information. This study aimed to explore ChatGPT-4 as a tool for identifying commonly prescribed nephrology medications across different versions and testing dates. Methods: 25 nephrology medications were obtained from an institutional pharmacy. High-quality images of each medication were captured using an iPhone 13 Pro Max and uploaded to ChatGPT-4 with the query, ‘What is this medication?’ The accuracy of ChatGPT-4’s responses was assessed for medication name, dosage, and imprint. The process was repeated after 2 weeks to evaluate consistency across different versions, including GPT-4, GPT-4 Legacy, and GPT-4.Ø. Results: ChatGPT-4 correctly identified 22 out of 25 (88%) medications across all versions. However, it misidentified Hydrochlorothiazide, Nifedipine, and Spironolactone due to misreading imprints. For instance, Nifedipine ER 90 mg was mistaken for Metformin Hydrochloride ER 500 mg because ‘NF 06’ was misread as ‘NF 05’. Hydrochlorothiazide 50 mg was confused with the 25 mg version due to imprint errors, and Spironolactone 25 mg was misidentified as Naproxen Sodium or Diclofenac Sodium. Despite these errors, ChatGPT-4 showed 100% consistency when retested, correcting misidentifications after receiving feedback on the correct imprints. Conclusion: ChatGPT-4 shows strong potential in identifying nephrology medications from self-captured images, though challenges with difficult-to-read imprints remain. Providing feedback improved accuracy, suggesting ChatGPT-4 could be a valuable tool in digital health for medication identification. Future research should enhance the model’s ability to distinguish similar imprints and explore broader integration into digital health platforms. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",Yes,Sully,,,,,,,,,,
Dr. Google to Dr. ChatGPT: assessing the content and quality of artificial intelligence-generated medical information on appendicitis,"Introduction: Generative artificial intelligence (AI) chatbots have recently been posited as potential sources of online medical information for patients making medical decisions. Existing online patient-oriented medical information has repeatedly been shown to be of variable quality and difficult readability. Therefore, we sought to evaluate the content and quality of AI-generated medical information on acute appendicitis. Methods: A modified DISCERN assessment tool, comprising 16 distinct criteria each scored on a 5-point Likert scale (score range 16–80), was used to assess AI-generated content. Readability was determined using the Flesch Reading Ease (FRE) and Flesch-Kincaid Grade Level (FKGL) scores. Four popular chatbots, ChatGPT-3.5 and ChatGPT-4, Bard, and Claude-2, were prompted to generate medical information about appendicitis. Three investigators independently scored the generated texts blinded to the identity of the AI platforms. Results: ChatGPT-3.5, ChatGPT-4, Bard, and Claude-2 had overall mean (SD) quality scores of 60.7 (1.2), 62.0 (1.0), 62.3 (1.2), and 51.3 (2.3), respectively, on a scale of 16–80. Inter-rater reliability was 0.81, 0.75, 0.81, and 0.72, respectively, indicating substantial agreement. Claude-2 demonstrated a significantly lower mean quality score compared to ChatGPT-4 (p = 0.001), ChatGPT-3.5 (p = 0.005), and Bard (p = 0.001). Bard was the only AI platform that listed verifiable sources, while Claude-2 provided fabricated sources. All chatbots except for Claude-2 advised readers to consult a physician if experiencing symptoms. Regarding readability, FKGL and FRE scores of ChatGPT-3.5, ChatGPT-4, Bard, and Claude-2 were 14.6 and 23.8, 11.9 and 33.9, 8.6 and 52.8, 11.0 and 36.6, respectively, indicating difficulty readability at a college reading skill level. Conclusion: AI-generated medical information on appendicitis scored favorably upon quality assessment, but most either fabricated sources or did not provide any altogether. Additionally, overall readability far exceeded recommended levels for the public. Generative AI platforms demonstrate measured potential for patient education and engagement about appendicitis. © The Author(s) 2024.",Yes,Sully,,,,,,,,,,
Embracing the future of physician-patient communication: GPT-4 in gastroenterology,"The integration of artificial intelligence (AI) into healthcare, particularly GPT-4, opens up transformative opportunities for enhancing physician-patient communication, especially in the field of gastroenterology. This advanced language model can automate routine tasks, thereby freeing up physicians' time for complex patient care. Additionally, GPT-4 plays a pivotal role in patient education, simplifying complex medical jargon into understandable language, resulting in an informed patient base more likely to adhere to their care plans. This is crucial for gastroenterology, where patient understanding significantly influences treatment outcomes. Moreover, GPT-4's ability to provide continuous patient care bridges the gap inherent in traditional healthcare models, ensuring regular interaction and a proactive approach to patient care. Nonetheless, as we usher in this transformative era, it is crucial to remember that technology should augment, not replace, the human touch in healthcare. Physicians' empathy, emotional understanding, and judgement are irreplaceable. Furthermore, implementing AI technologies, such as GPT-4, in healthcare settings must be carried out responsibly, abiding by ethical considerations, data privacy standards, and accountability guidelines. This balance allows the exploitation of AI's true potential in healthcare, without compromising ethical standards. © 2023 The Authors",No,Sully,,,,,,,,,,
Personalized glucose forecasting for people with type 1 diabetes using large language models,"Background and objective: Type 1 Diabetes (T1D) is an autoimmune disease that requires exogenous insulin via Multiple Daily Injections (MDIs) or subcutaneous pumps to maintain targeted glucose levels. Despite the advances in Continuous Glucose Monitoring (CGM), controlling glucose levels remains challenging. Large Language Models (LLMs) have produced impressive results in text processing, but their performance with other data modalities remains unexplored. The aim of this study is three-fold. First, to evaluate the effectiveness of LLM-based models for glucose forecasting. Second, to compare the performance of different models for predicting glucose in T1D individuals treated with MDIs and pumps. Lastly, to create a personalized approach based on patient-specific training and adaptive model selection. Methods: CGM data from the T1DEXI study were used for forecasting glucose levels. Different predictive models were evaluated using the mean absolute error (MAE) and the root mean squared error and considering the Prediction Horizons (PHs) of 60, 90, and 120 min. Results: For short-term PHs (60 and 90 min), the personalized approach achieved the best results, with an average MAE of 15.7 and 20.2 for MDIs, and a MAE of 15.2 and 17.2 for pumps. For long-term PH (120 min), TIDE obtained an MAE of 19.8 for MDIs, whereas Patch-TST obtained a MAE of 18.5. Conclusion: LLM-based models provided similar MAE values to state-of-the-art models but presented a reduced variability. The proposed personalized approach obtained the best results for short-term periods. Our work contributes to developing personalized glucose prediction models for enhancing glycemic control, reducing diabetes-related complications. © 2025",Yes,Sully,,,,,,,,,,
Use of large language models in radiological reports: A study on simplifying turkish MRI findings,"Aim: Advanced Large Language Models (LLMs), like ChatGPT, are known for their human-like expression and reasoning abilities. They are used in many fields, including radiology. This study is pioneering in evaluating and comparing the effectiveness of LLMs in simplifying Magnetic Resonance Imaging (MRI) findings in Turkish. Material and Methods: In our study, we simplified 50 fictional MRI findings in Turkish language using different LLMs, including ChatGPT-4, Gemini Pro 1.5, Claude 3 Opus and Perplexity. We compared the responses based on Ateşman’s readability index and word count. Additionally, three radiologists assessed the medical accuracy, consistency of suggestions, and comprehensibility of the answers, scoring each model on a scale of 1 to 5. Results: There was no statistically significant difference between the scores of Gemini 1.5 Pro (average: 4.9; median: 5.0), Opus (average: 4.8; median: 5.0), and ChatGPT-4 (average: 4.8; median: 5.0) (p>0.05). However, there was a significant difference between the scores of Gemini 1.5 Pro and Perplexity (average: 3.7; median: 4.0) (p<0.001). According to the readability index, Gemini 1.5 Pro had the highest average score of 59.3, which was significantly higher than the other LLMs (p<0.005). In terms of word count, ChatGPT-4 used the most words (151.5), while Perplexity used the fewest (88.4). Discussion: This study is the first to evaluate the ability of LLMs to simplify MRI findings in Turkish. The results suggest that radiologists find these models effective in making radiology reports more understandable. However, additional research is necessary to confirm these findings.",Yes,Sully,,,,,,,,,,
"ChatGPT v4 outperforming v3.5 on cancer treatment recommendations in quality, clinical guideline, and expert opinion concordance","Objectives: To assess the quality and alignment of ChatGPT's cancer treatment recommendations (RECs) with National Comprehensive Cancer Network (NCCN) guidelines and expert opinions. Methods: Three urologists performed quantitative and qualitative assessments in October 2023 analyzing responses from ChatGPT-4 and ChatGPT-3.5 to 108 prostate, kidney, and bladder cancer prompts using two zero-shot prompt templates. Performance evaluation involved calculating five ratios: expert-approved/expert-disagreed and NCCN-aligned RECs against total ChatGPT RECs plus coverage and adherence rates to NCCN. Experts rated the response's quality on a 1-5 scale considering correctness, comprehensiveness, specificity, and appropriateness. Results: ChatGPT-4 outperformed ChatGPT-3.5 in prostate cancer inquiries, with an average word count of 317.3 versus 124.4 (p < 0.001) and 6.1 versus 3.9 RECs (p < 0.001). Its rater-approved REC ratio (96.1% vs. 89.4%) and alignment with NCCN guidelines (76.8% vs. 49.1%, p = 0.001) were superior and scored significantly better on all quality dimensions. Across 108 prompts covering three cancers, ChatGPT-4 produced an average of 6.0 RECs per case, with an 88.5% approval rate from raters, 86.7% NCCN concordance, and only a 9.5% disagreement rate. It achieved high marks in correctness (4.5), comprehensiveness (4.4), specificity (4.0), and appropriateness (4.4). Subgroup analyses across cancer types, disease statuses, and different prompt templates were reported. Conclusions: ChatGPT-4 demonstrated significant improvement in providing accurate and detailed treatment recommendations for urological cancers in line with clinical guidelines and expert opinion. However, it is vital to recognize that AI tools are not without flaws and should be utilized with caution. ChatGPT could supplement, but not replace, personalized advice from healthcare professionals. © The Author(s) 2024.",Yes,Sully,,,,,,,,,,
Liver Fibrosis Scores as Predictors of Long-term Outcomes in Patients with ST-segment Elevation Myocardial Infarction,"Background: Liver fibrosis scores (LFSs) are novel tools for predicting cardiovascular events in patients with coronary artery disease. This study was aimed at examining the prognostic value of LFSs in patients with ST-segment elevation myocardial infarction (STEMI). Methods: Between 2015 and 2019, 866 patients diagnosed with STEMI were consecutively enrolled. The definition of major cardiovascular events (MACEs) was all-cause death, nonfatal myocardial infarction, nonfatal ischemic stroke, and acute limb ischemia. We evaluated the predictive values of LFSs for MACEs with receiver operating characteristic (ROC) curve and restricted cubic spline (RCS) analysis. Kaplan-Meier (K-M) analysis was conducted to explore the relationship between LFSs and MACEs. Results: During a median follow-up of 4 years, 155 MACEs were observed. K-M analysis of MACEs revealed significantly lower event-free survival rates in patients with intermediate or high, rather than low, NFS, FIB-4, BARD, and Forns scores. The multivariable-adjusted hazard ratios (95% CI) for MACEs in patients with high versus low risk scores were 1.343 (0.822–2.197) for NFS, 1.922 (1.085–3.405) for FIB-4, 2.395 (1.115–5.142) for BARD, and 2.271 (1.250–4.125) for Forns. The ROC curve indicated that the predictive ability for MACEs was non significantly improved by addition of the NFS (AUC = 0.7274), FIB-4 (AUC = 0.7199), BARD (AUC = 0.7235), and Forns (AUC = 0.7376) scores into the basic model (AUC = 0.7181). RCS revealed a tendency toward a nonlinear positive association of MACEs with NFS, FIB-4, and particularly Forns scores. Conclusion: LFSs have potential utility for predicting adverse outcomes in patients with STEMI, thus indicating the importance of managing metabolic dysregulation. © 2024 Cardiovascular Innovations and Applications. Creative Commons Attribution-NonCommercial 4.0 International License",No,Sully,,,,,,,,,,
ChatGPT for Visually Impaired and Blind,"According to the World Health Organization (WHO), hundreds of million people have some type of visual disability. Vision impairment has a personal impact with lifelong consequences because more than 80 % of our perception, cognition, learning, and daily activities are mediated through vision. Moreover, in the era of rapid advancements in artificial intelligence (AI), visually impaired and blind people face challenges at work and in education because of inaccessibility to AI technologies. In this regard, we present an assistive mobile application with an intuitive user interface (UI) for visually impaired and blind people to interact with ChatGPT via natural conversation. The app employs automatic speech recognition (ASR), text-To-speech (TTS), keyword spotting (KWS), voice activity detection (VAD), and a convenient UI to interact with ChatGPT effortlessly. We have made the source code, pre-Trained models, and VI publicly available at https://github.com/IS2AI/talk-llm to stimulate the development of assistive mobile applications. © 2024 IEEE.",No,Sully,,,,,,,,,,
ChatGPT and Google Assistant as a Source of Patient Education for Patients With Amblyopia: Content Analysis,"Background: We queried ChatGPT (OpenAI) and Google Assistant about amblyopia and compared their answers with the keywords found on the American Association for Pediatric Ophthalmology and Strabismus (AAPOS) website, specifically the section on amblyopia. Out of the 26 keywords chosen from the website, ChatGPT included 11 (42%) in its responses, while Google included 8 (31%). Objective: Our study investigated the adherence of ChatGPT-3.5 and Google Assistant to the guidelines of the AAPOS for patient education on amblyopia. Methods: ChatGPT-3.5 was used. The four questions taken from the AAPOS website, specifically its glossary section for amblyopia, are as follows: (1) What is amblyopia? (2) What causes amblyopia? (3) How is amblyopia treated? (4) What happens if amblyopia is untreated? Approved and selected by ophthalmologists (GW and DL), the keywords from AAPOS were words or phrases that deemed significant for the education of patients with amblyopia. The “Flesch-Kincaid Grade Level” formula, approved by the US Department of Education, was used to evaluate the reading comprehension level for the responses from ChatGPT, Google Assistant, and AAPOS. Results: In their responses, ChatGPT did not mention the term “ophthalmologist,” whereas Google Assistant and AAPOS both mentioned the term once and twice, respectively. ChatGPT did, however, use the term “eye doctors” once. According to the Flesch-Kincaid test, the average reading level of AAPOS was 11.4 (SD 2.1; the lowest level) while that of Google was 13.1 (SD 4.8; the highest required reading level), also showing the greatest variation in grade level in its responses. ChatGPT’s answers, on average, scored 12.4 (SD 1.1) grade level. They were all similar in terms of difficulty level in reading. For the keywords, out of the 4 responses, ChatGPT used 42% (11/26) of the keywords, whereas Google Assistant used 31% (8/26). Conclusions: ChatGPT trains on texts and phrases and generates new sentences, while Google Assistant automatically copies website links. As ophthalmologists, we should consider including “see an ophthalmologist” on our websites and journals. While ChatGPT is here to stay, we, as physicians, need to monitor its answers. ©Gloria Wu, David A Lee, Weichen Zhao, Adrial Wong, Rohan Jhangiani, Sri Kurniawan.",Yes,Sully,,,,,,,,,,
Image Captioning with Audio Reinforcement using RNN and CNN,"Image captioning involves generating a descriptive text that encapsulates the visual information contained in an image. This ppt proposes a deep learning model for image captioning that utilizes a Vision Transformer (ViT) and a GPT-2 network. Specifically, the ViT is employed to extract image features, which are then used by the GPT-2 network to generate captions for the images. To evaluate the effectiveness of the model, experiments are conducted on a Stanford dataset comprising images and their corresponding captions, and demonstrate that our model achieves performance comparable to other state-of-the-art image captioning models. Proposed results suggest that our model has the potential to generate accurate and semantically meaningful captions for images, and could be useful for various applications such as improving the accessibility of visual media.  © 2023 IEEE.",No,Sully,,,,,,,,,,
Acute and sub-lethal toxicity of a common water contaminant (copper sulfate) on edible freshwater fish: assessment of hemato-biochemical and tissue morphological biomarkers,"Copper is an essential trace nutrient element, but excess copper could cause stress on organisms. Different animal models are available to assess the toxicity, in which, fish are highly recommended models for eco-toxicology. Different biomarkers can be used to determine the potential health impacts of stressors. We aimed to study the potential toxicity of waterborne copper on freshwater fish, Catla catla. We determined the median-lethal concentration of copper sulfate on edible freshwater fish. Then, we exposed Catla catla to the acute (24 h) and sub-lethal (35 days) concentrations of copper sulfate and analyzed hormonal, inorganic ions, hematological, enzymological, biochemical, and histological (only sub-lethal) biomarkers. The homeostasis of the studied biomarkers was significantly (p < 0.05) affected in copper sulfate exposed groups (acute and sub-lethal studies) when compared to the control group. Hormonal levels were accelerated in both studies. Inorganic ions were declined in acute and sub-lethal studies. Similarly, hematological biomarkers were predominantly declined in both studies. Changes in biochemical biomarkers were not similar with studies (acute and sub-lethal); glucose and protein levels were declined under acute study, whereas in the sub-lethal, only protein level was declined. Like biochemical biomarker, the observed changes in enzymological biomarker were not similar (except LDH and ATPase activity), and the GOT and GPT activity was inhibited under acute study. In contrast, in the sub-lethal study, the activity was accelerated. A series of morphological anomalies were observed in the gills, liver, and kidney tissues under copper sulfate exposure (acute and sub-lethal). This study provides additional information on biological responses (the primary, secondary stress responses, and morphological changes) to the waterborne stressor. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.",No,Sully,,,,,,,,,,
Exploring the Accuracy and Readability of ChatGPT in Providing Information to Patients With Keratoconus,"Patients with keratoconus may lack sufficient understanding of their illness. The authors assessed the accuracy and readability of ChatGPT (OpenAI) responses to common questions regarding keratoconus and found that the provided data are precise, with minor inaccuracies. The complexity of responses requires a high reading level, which may be unsuitable for many patients. © SLACK Incorporated.",Yes,Sully,,,,,,,,,,
Dual-Stream Heterogeneous Graph Neural Network Based on Zero-Shot Embeddings for Predicting miRNA-Drug Sensitivity,"MicroRNAs (miRNAs) are a class of non-coding RNA molecules that have been shown to be closely associated with the sensitivity of chemotherapeutic drugs in cancer treatment. Given the high cost and extended duration of traditional biological experiments, there is an urgent need to develop computational models to predict the sensitivity scores between miRNAs and drugs. In this study, we proposed a dual-stream graph neural network method based on Zero-Shot Embeddings, named DSHGZS, to explore the potential sensitivity scores between miRNAs and drugs. DSHGZS first constructs two heterogeneous graphs with different isomorphic subgraphs based on zero-shot embeddings obtained from large language models (LLMs) and known miRNA-drug association data. It then utilized the enhanced LLM-derived node feature representations, embedding them into the layer feature learning process of the two heterogeneous graphs to generate high-quality vector representations of miRNAs and drugs. The learned high-quality feature embeddings are subsequently used in a segmented inner product decoder to evaluate the sensitivity association scores between miRNAs and drugs. To address the model's excessive reliance on high-quality feature representations, we employed PCA to extract the core representations of the LLM-derived node features for data augmentation. Case studies demonstrated that DSHGZS is an effective tool for predicting potential sensitivity scores between miRNAs and drugs. © 2024 IEEE.",No,Sully,,,,,,,,,,
Addressing ChatGPT-Associated Academic Integrity Concerns via Reference Management Software,"2809. Nurse Educ. 2024 Jul-Aug 01;49(4):E223-E225. doi: 10.1097/NNE.0000000000001599. 
Epub 2024 Jan 16.

Addressing ChatGPT-Associated Academic Integrity Concerns via Reference 
Management Software.

Sebach AM(1), Leach KF.

Author information:
(1)By Aaron M. Sebach , PhD, DNP, AGACNP-BC, FNP-BC, CNE, CNEcl, FNAP, FAANP, 
and Kathryn F. Leach , DNP, CPNP, College of Health Professions and Natural 
Sciences, Wilmington University, New Castle, Delaware, aaron.m.sebach@wilmu.edu 
.",No,Sully,,,,,,,,,,
Assessment of ChatGPT generated educational material for head and neck surgery counseling,"Background: ChatGPT is becoming very popular as an information source for the public. The adequacy of ChatGPT generated patient counseling material has not yet been extensively assessed. Methods: ChatGPT was presented with perioperative counseling and complication questions regarding five different procedure, and accuracy of responses was assessed. The chat was then asked to present an explanation of each procedure, and quality of the responses were compared to online educational material. Results: ChatGPT responses were comprehensive when discussing counseling points commonly discussed by a provider prior to a procedure. Responses to questions on surgical complications were less accurate and comprehensive. In comparison to online educational material, ChatGPT scored at or above the median SAM and PEMAT scores for all procedures. Conclusions: ChatGPT did well addressing basic counseling points during the perioperative period, although it did not perform as well when addressing surgical complications. Chat response quality was comparable to currently available online educational material. © 2024 Elsevier Inc.",Yes,Sully,,,,,,,,,,
Visual-Textual Integration in LLMs for Medical Diagnosis: A Quantitative Analysis,"Background and Aim: Visual data from images is essential for many medical diagnoses. This study evaluates the performance of multimodal Large Language Models (LLMs) in integrating textual and visual information for diagnostic purposes. Methods: We tested GPT-4o and Claude Sonnet 3.5 on 120 clinical vignettes with and without accompanying images. Each vignette included patient demographics, a chief complaint, and relevant medical history. Vignettes were paired with either clinical or radiological images from two sources: 100 images from the OPENi database and 20 images from recent NEJM challenges, ensuring they were not in the LLMs' training sets. Three primary care physicians served as a human benchmark. We analyzed diagnostic accuracy and the models' explanations for a subset of cases. Results: LLMs outperformed physicians in text-only scenarios (GPT-4o: 70.8%, Claude Sonnet 3.5: 59.5%, Physicians: 39.5%). With image integration, all improved, but physicians showed the largest gain (GPT-4o: 84.5%, p<0.001; Claude Sonnet 3.5: 67.3%, p=0.060; Physicians: 78.8%, p<0.001). LLMs changed their explanations in 45-60% of cases when presented with images, demonstrating some level of visual data integration. Conclusion: Multimodal LLMs show promise in medical diagnosis, with improved performance when integrating visual evidence. However, this improvement is inconsistent and smaller compared to physicians, indicating a need for enhanced visual data processing in these models.",Yes,Sully,,,,,,,,,,
Evaluation of the integration of retrieval-augmented generation in large language model for breast cancer nursing care responses,"Breast cancer is one of the most common malignant tumors in women worldwide. Although large language models (LLMs) can provide breast cancer nursing care consultation, inherent hallucinations can lead to inaccurate responses. Retrieval-augmented generation (RAG) technology can improve LLM performance, offering a new approach for clinical applications. In the present study, we evaluated the performance of a LLM in breast cancer nursing care using RAG technology. In the control group (GPT-4), questions were answered directly using the GPT-4 model, whereas the experimental group (RAG-GPT) used the GPT-4 model combined with RAG. A knowledge base for breast cancer nursing was created for the RAG-GPT group, and 15 of 200 real-world clinical care questions were answered randomly. The primary endpoint was overall satisfaction, and the secondary endpoints were accuracy and empathy. RAG-GPT included a curated knowledge base related to breast cancer nursing care, including textbooks, guidelines, and traditional Chinese therapy. The RAG-GPT group showed significantly higher overall satisfaction than that of the GPT-4 group (8.4 ± 0.84 vs. 5.4 ± 1.27, p < 0.01) as well as an improved accuracy of responses (8.6 ± 0.69 vs. 5.6 ± 0.96, p < 0.01). However, there was no inter-group difference in empathy (8.4 ± 0.85 vs. 7.8 ± 1.22, p > 0.05). Overall, this study revealed that RAG technology could improve LLM performance significantly, likely because of the increased accuracy of the answers without diminishing empathy. These findings provide a theoretical basis for applying RAG technology to LLMs in clinical nursing practice and education.",Yes,Sully,,,,,,,,,,
Comparison of Large Language Models in Diagnosis and Management of Challenging Clinical Cases,"Purpose: Compare large language models (LLMs) in analyzing and responding to a difficult series of ophthalmic cases. Design: A comparative case series involving LLMs that met inclusion criteria tested on twenty difficult case studies posed in open-text format. Methods: Fifteen LLMs accessible to ophthalmologists were tested against twenty case studies published in JAMA Ophthalmology. Each case was presented in identical, open-ended text fashion to each LLM and open-ended responses regarding differential diagnosis, next diagnostic tests and recommended treatments were requested. Responses were recorded and assessed for accuracy against published correct answers. The main outcome was accuracy of LLMs against the correct answers. Secondary outcomes included comparative performance on the differential diagnosis, ancillary testing, and treatment subtests; and readability of responses. Results: Scores were normally distributed and ranged from 0–35 (with a maximum score of 60) with a mean ± standard deviation of 19 ± 9. Scores for three of the LLMs (ChatGPT 3.5, Claude Pro, and Copilot Pro) were statistically significantly higher than the mean. Two of the high-performing LLMs were paid subscription (Claude Pro and Copilot Pro) and one was free (ChatGPT 3.5). While there were no clinical or statistical differences between ChatGPT 3.5 and Claude Pro, a separation of +5 points, or 0.56 standard deviations, between Copilot Pro and the other highly ranked LLMs was present. Readability of all tested programs were above the AMA (American Medical Association) reading level recommendations to public consumers of eight grade. Conclusion: Subscription LLMs were more prevalent among highly ranked LLMs suggesting that these perform better as ophthalmic assistants. While readability was poor for the average person, the content was understood by a board-certified ophthalmologist. The accuracy of LLMs is not high enough to recommend patient care in standalone mode, but aiding clinicians in patient care and prevent oversights is promising. © 2024 Shanmugam and Browning.",Yes,Sully,,,,,,,,,,
Effects of anatomical deviation of the human tibial plateau on knee prosthesis design based on human evolutionary rhythm differences; [基于人类进化节奏差异造成的人种胫骨平台解剖偏差对膝关节假体设计的影响],"Objective This work aimed to explore the differences in human evolutionary rhythm, analyze the matching rate of imported knee prosthesis and the tibial plateau osteotomy surface of Chinese adults, and determine the influence of the tibial plateau on the design of knee prostheses. Methods In this study, 60 patients (120 knees) with non-knee diseases and 20 healthy volunteers (40 knees) were selected from the Department of Orthopedics, Beijing Chaoyang Hospital, Capital Medical University from January 2018 to January 2020. The patients included 46 males (92 knees) and 34 females (68 knees). The patients were 24-72 years old, with an average age of 46.8 years. Bilateral knee CT scan and 3D reconstruction were performed, and 3D reconstructed tibial images were rotated and cut on GE ADW 4.3 Advanced Image Workstation. Linear parameters such as transverse diameter and anteroposterior diameter of tibial plateau osteotomy surface were measured and calculated, and the differences in parameters between men and women were compared. Statistical analysis was performed. The matching rates of three imported knee prostheses designed based on Caucasian physique parameters (Depuy PFC Sigma [prosthesis A], Link-Gemini MK-II [prosthesis B], and Zimmer Nexgen [prosthesis C]) and the tibial plateau osteotomy surface of Chinese adults were evaluated using the 5 mm tolerance range method. Pairwise comparison was performed by χ2 test. Results The mean cross diameter of the tibial plateau was (74.2±2.8) mm in 80 Chinese adults with 160 knees; that of males was (76.2±2.7) mm, which was higher than that of females (68.1 mm± 2.9 mm), and the difference was significant (t=18.18, P <0.001). The mean diameter was (48.2±2.6) mm; that of males was (50.5±2.5) mm, which was higher than that of females (46.3 mm±2.7 mm), with statistical significance (t=10.15, P <0.001). The matching rates of prostheses A, B, and C with the tibial plateau osteotomy surface of Chinese adults were 41.25% (66/160), 46.88% (75/160), and 26.25% (42/160), respectively. The matching rates of prosthesis C were lower than those of prostheses A and B, and the differences were statistically significant (χ2=8.05, 14.67, all P values <0.05). No significant difference was found between prostheses A and B (χ2=1.03, P=0.184). Conclusion A significant difference is noted between Chinese adults and Caucasians in the normal bearing surface of the tibial plateau. The matching degree between imported knee prosthesis and the tibial plateau osteotomy surface of Chinese adults is generally low. The tibial plateau section of Chinese adults is relatively round, which suggests that in the course of human evolution, Chinese walked from four limbs to upright maybe earlier than Caucasians. © Chinese Medical Journals Publishing House Co.Ltd. All Rights Reserved.",No,Sully,,,,,,,,,,
Online patient education in body contouring: A comparison between Google and ChatGPT,"Appropriate patient education and preparation prior to surgery represent a fundamental step in managing expectations, avoiding unnecessary encounters and eventually achieving optimal outcomes. Thus, the objective of this study is to evaluate ChatGPT's potential as a viable source for patient education by comparing its responses and provided references to frequently asked questions on body contouring, with Google's. A Google search was conducted on July 15th, 2023, using the search term “body contouring surgery”. The first 15 questions under the “People also ask” section and answers provided by Google were recorded. The 15 questions were then asked to ChatGPT-3.5. Four plastic surgeons evaluated the answers from 1 to 5 according to the Global Quality Scale. The mean score for responses given by Google was 2.55 ± 1.29, indicating poor quality but some information present, of very limited use to patients. The mean score for responses produced by ChatGPT was 4.38 ± 0.67, suggesting that the content was of good quality, useful to patients, and encompassed the most important topics. The difference was statistically significant (p = 0.001). Deficiencies in providing references represent one of the most evident weaknesses of ChatGPT. However, ChatGPT did not appear to spread misinformation, and the content of the generated responses was deemed of good quality and useful to patients. The integration of AI technology as a source for patient education has the potential to optimize patient queries on body contouring questions. © 2023 British Association of Plastic, Reconstructive and Aesthetic Surgeons",Yes,Sully,,,,,,,,,,
Learning to fake it: limited responses and fabricated references provided by ChatGPT for medical questions,"Background: ChatGPT have gained public notoriety and recently supported manuscript preparation. Our objective was to evaluate the quality of the answers and the references provided by ChatGPT for medical questions. Methods: Three researchers asked ChatGPT a total of 20 medical questions and prompted it to provide the corresponding references. The responses were evaluated for quality of content by medical experts using a verbal numeric scale going from 0 to 100%. These experts were the corresponding author of the 20 articles from where the medical questions were derived. We planned to evaluate three references per response for their pertinence, but this was amended based on preliminary results showing that most references provided by ChatGPT were fabricated. Results: ChatGPT provided responses varying between 53 and 244 words long and reported two to seven references per answer. Seventeen of the 20 invited raters provided feedback. The raters reported limited quality of the responses with a median score of 60% (1(st) and 3(rd) quartile: 50% and 85%). Additionally, they identified major (n=5) and minor (n=7) factual errors among the 17 evaluated responses. Of the 59 references evaluated, 41 (69%) were fabricated, though they appeared real. Most fabricated citations used names of authors with previous relevant publications, a title that seemed pertinent and a credible journal format. Interpretation: When asked multiple medical questions, ChatGPT provided answers of limited quality for scientific publication. More importantly, ChatGPT provided deceptively real references. Users of ChatGPT should pay particular attention to the references provided before integration into medical manuscripts.",Yes,Sully,,,,,,,,,,
Human-AI collaboration in large language model-assisted brain MRI differential diagnosis: a usability study,"Objectives: This study investigated the impact of human-large language model (LLM) collaboration on the accuracy and efficiency of brain MRI differential diagnosis. Materials and methods: In this retrospective study, forty brain MRI cases with a challenging but definitive diagnosis were randomized into two groups of twenty cases each. Six radiology residents with an average experience of 6.3 months in reading brain MRI exams evaluated one set of cases supported by conventional internet search (Conventional) and the other set utilizing an LLM-based search engine and hybrid chatbot. A cross-over design ensured that each case was examined with both workflows in equal frequency. For each case, readers were instructed to determine the three most likely differential diagnoses. LLM responses were analyzed by a panel of radiologists. Benefits and challenges in human-LLM interaction were derived from observations and participant feedback. Results: LLM-assisted brain MRI differential diagnosis yielded superior accuracy (70/114; 61.4% (LLM-assisted) vs 53/114; 46.5% (conventional) correct diagnoses, p = 0.033, chi-square test). No difference in interpretation time or level of confidence was observed. An analysis of LLM responses revealed that correct LLM suggestions translated into correct reader responses in 82.1% of cases (60/73). Inaccurate case descriptions by readers (9.2% of cases), LLM hallucinations (11.5% of cases), and insufficient contextualization of LLM responses were identified as challenges related to human-LLM interaction. Conclusion: Human-LLM collaboration has the potential to improve brain MRI differential diagnosis. Yet, several challenges must be addressed to ensure effective adoption and user acceptance. Key Points: Question While large language models (LLM) have the potential to support radiological differential diagnosis, the role of human-LLM collaboration in this context remains underexplored. Findings LLM-assisted brain MRI differential diagnosis yielded superior accuracy over conventional internet search. Inaccurate case descriptions, LLM hallucinations, and insufficient contextualization were identified as potential challenges. Clinical relevance Our results highlight the potential of an LLM-assisted workflow to increase diagnostic accuracy but underline the necessity to study collaborative efforts between humans and LLMs over LLMs in isolation. © The Author(s) 2025.",Yes,Sully,,,,,,,,,,
Generation and Characterization of Novel Pan-Cancer Anti-uPAR Fluorescent Nanobodies as Tools for Image-Guided Surgery,"Fluorescence molecular imaging plays a vital role in image-guided surgery. In this context, the urokinase plasminogen activator receptor (uPAR) is an interesting biomarker enabling the detection and delineation of various tumor types due to its elevated expression on both tumor cells and the tumor microenvironment. In this study, anti-uPAR Nanobodies (Nbs) are generated through llama immunization with human and murine uPAR protein. Extensive in vitro characterization and in vivo testing with radiolabeled variants are conducted to assess their pharmacokinetics and select lead compounds. Subsequently, the selected Nbs are converted into fluorescent agents, and their application for fluorescence-guided surgery is evaluated in various subcutaneous and orthotopic tumor models. The study yields a panel of high-affinity anti-uPAR Nbs, showing specific binding across multiple types of cancer cells in vitro and in vivo. Lead fluorescently-labeled compounds exhibit high tumor uptake with high contrast at 1 h after intravenous injection across all assessed uPAR-expressing tumor models, outperforming a non-targeting control Nb. Additionally, rapid and accurate tumor localization and demarcation are demonstrated in an orthotopic human glioma model. Utilizing these Nbs can potentially enhance the precision of surgical tumor resection and, consequently, improve survival rates in the clinic. © 2024 The Authors. Advanced Science published by Wiley-VCH GmbH.",No,Sully,,,,,,,,,,
ChatGPT and the Future of Medical Writing,"2377. Radiology. 2023 Apr;307(2):e223312. doi: 10.1148/radiol.223312. Epub 2023 Feb 2.

ChatGPT and the Future of Medical Writing.

Biswas S(1).

Author information:
(1)From the Department of Radiology, Le Bonheur Children's Hospital, University 
of Tennessee Health Science Center College of Medicine, Memphis, TN 38103.

Comment in
    Radiology. 2023 Apr;307(2):e230163. doi: 10.1148/radiol.230163.
    Radiology. 2023 Apr;307(2):e230171. doi: 10.1148/radiol.230171.
    Radiology. 2023 May;307(3):e230312. doi: 10.1148/radiol.230312.",No,Sully,,,,,,,,,,
Drug information question responses by a drug information center and by ChatGPT: Correspondence,"In an effort to expedite the publication of articles, AJHP is posting manuscripts online as soon as possible after acceptance. Accepted manuscripts have been peer-reviewed and copyedited, but are posted online before technical formatting and author proofing. These manuscripts are not the final version of record and will be replaced with the final article (formatted per AJHP style and proofed by the authors) at a later time.",No,Sully,,,,,,,,,,
Prompt engineering in consistency and reliability with the evidence-based guideline for LLMs,"The use of large language models (LLMs) in clinical medicine is currently thriving. Effectively transferring LLMs’ pertinent theoretical knowledge from computer science to their application in clinical medicine is crucial. Prompt engineering has shown potential as an effective method in this regard. To explore the application of prompt engineering in LLMs and to examine the reliability of LLMs, different styles of prompts were designed and used to ask different LLMs about their agreement with the American Academy of Orthopedic Surgeons (AAOS) osteoarthritis (OA) evidence-based guidelines. Each question was asked 5 times. We compared the consistency of the findings with guidelines across different evidence levels for different prompts and assessed the reliability of different prompts by asking the same question 5 times. gpt-4-Web with ROT prompting had the highest overall consistency (62.9%) and a significant performance for strong recommendations, with a total consistency of 77.5%. The reliability of the different LLMs for different prompts was not stable (Fleiss kappa ranged from −0.002 to 0.984). This study revealed that different prompts had variable effects across various models, and the gpt-4-Web with ROT prompt was the most consistent. An appropriate prompt could improve the accuracy of responses to professional medical questions. © The Author(s) 2024.",Yes,Sully,,,,,,,,,,
Strategic behavior of large language models and the role of game structure versus contextual framing,"This paper investigates the strategic behavior of large language models (LLMs) across various game-theoretic settings, scrutinizing the interplay between game structure and contextual framing in decision-making. We focus our analysis on three advanced LLMs-GPT-3.5, GPT-4, and LLaMa-2-and how they navigate both the intrinsic aspects of different games and the nuances of their surrounding contexts. Our results highlight discernible patterns in each model's strategic approach. GPT-3.5 shows significant sensitivity to context but lags in its capacity for abstract strategic decision making. Conversely, both GPT-4 and LLaMa-2 demonstrate a more balanced sensitivity to game structures and contexts, albeit with crucial differences. Specifically, GPT-4 prioritizes the internal mechanics of the game over its contextual backdrop but does so with only a coarse differentiation among game types. In contrast, LLaMa-2 reflects a more granular understanding of individual game structures, while also giving due weight to contextual elements. This suggests that LLaMa-2 is better equipped to navigate the subtleties of different strategic scenarios while also incorporating context into its decision-making, whereas GPT-4 adopts a more generalized, structure-centric strategy.",No,Sully,,,,,,,,,,
Autodelineation of Treatment Target Volume for Radiation Therapy Using Large Language Model-Aided Multimodal Learning,"Purpose: Artificial intelligence-aided methods have made significant progress in the auto-delineation of normal tissues. However, these approaches struggle with the auto-contouring of radiation therapy target volume. Our goal was to model the delineation of target volume as a clinical decision-making problem, resolved by leveraging large language model-aided multimodal learning approaches. Methods and Materials: A vision-language model, termed Medformer, has been developed, employing the hierarchical vision transformer as its backbone and incorporating large language models to extract text-rich features. The contextually embedded linguistic features are seamlessly integrated into visual features for language-aware visual encoding through the visual language attention module. Metrics, including Dice similarity coefficient (DSC), intersection over union (IOU), and 95th percentile Hausdorff distance (HD95), were used to quantitatively evaluate the performance of our model. The evaluation was conducted on an in-house prostate cancer data set and a public oropharyngeal carcinoma data set, totaling 668 subjects. Results: Our Medformer achieved a DSC of 0.81 ± 0.10 versus 0.72 ± 0.10, IOU of 0.73 ± 0.12 versus 0.65 ± 0.09, and HD95 of 9.86 ± 9.77 mm versus 19.13 ± 12.96 mm for delineation of gross tumor volume on the prostate cancer dataset. Similarly, on the oropharyngeal carcinoma dataset, it achieved a DSC of 0.77 ± 0.11 versus 0.72 ± 0.09, IOU of 0.70 ± 0.09 versus 0.65 ± 0.07, and HD95 of 7.52 ± 4.8 mm versus 13.63 ± 7.13 mm, representing significant improvements (P < 0.05). For delineating the clinical target volume, Medformer achieved a DSC of 0.91 ± 0.04, IOU of 0.85 ± 0.05, and HD95 of 2.98 ± 1.60 mm, comparable with other state-of-the-art algorithms. Conclusions: Auto-delineation of the treatment target based on multimodal learning outperforms conventional approaches that rely purely on visual features. Our method could be adopted into routine practice to rapidly contour clinical target volume/gross tumor volume. © 2024 Elsevier Inc.",Yes,Sully,,,,,,,,,,
Geopolitical risks and climate change stocks,"This paper aims to examine the impact of geopolitical risk (GPR), threats (GPT) 
and acts (GPA) on returns and volatilities of regional climate change stocks 
under different market conditions, employing quantile regressions. Our main 
results suggest that climate change stock returns positively (negatively) 
respond to GPR in bullish (bearish) market states, however the effect is not 
uniform across the regions. The volatilities mainly show a positive response to 
geopolitical tensions; geopolitical acts appear to have a more pronounced impact 
on volatilities than geopolitical threats. We further find that GPR leads to 
higher volatility during the Russia-Ukraine war, creating heightened 
uncertainty. Overall, the results reveal that geopolitical risks have an 
asymmetric and heterogenous impact on climate change stocks. The results provide 
significant insights and implications for financial market participants and 
policy makers.

Copyright © 2024 The Authors. Published by Elsevier Ltd.. All rights reserved.",No,Sully,,,,,,,,,,
"Artificial Intelligence in Plastic Surgery: Insights from Plastic Surgeons, Education Integration, ChatGPT's Survey Predictions, and the Path Forward","Background: Artificial intelligence (AI) is emerging as a transformative technology with potential applications in various plastic surgery procedures and plastic surgery education. This article examines the views of plastic surgeons and residents on the role of AI in the field of plastic surgery. Methods: A 34-question survey on AI's role in plastic surgery was distributed to 564 plastic surgeons worldwide, and we received responses from 153 (26.77%) with the majority from Latin America. The survey explored various aspects such as current AI experience, attitudes toward AI, data sources, ethical considerations, and future prospects of AI in plastic surgery and education. Predictions from AI using ChatGPT for each question were compared with the actual survey responses. Results: The study found that most participants had little or no prior AI experience. Although some believed AI could enhance accuracy and visualization, opinions on its impact on surgical time, patient recovery, and satisfaction were mixed. Concerns included patient privacy, data security, costs, and informed consent. Valuable AI training data sources were identified, and there was agreement on the importance of standards and transparency. Respondents expected AI's increasing role in reconstructive and aesthetic surgery, suggesting its integration into residency programs, addressing administrative challenges, and patient complications. Confidence in the enduring importance of human professionals was expressed, with interest in further AI research. Conclusion: The survey's findings underscore the need to harness AI's potential while preserving human professionals' roles through informed consent, standardization, and AI education in plastic surgery. © Plastic and Reconstructive Surgery - Global Open.All rights reserved.",No,Sully,Survey,,,,,,,,,
ChatGPT failed Taiwan's Family Medicine Board Exam,"Background: Chat Generative Pre-trained Transformer (ChatGPT), OpenAI Limited Partnership, San Francisco, CA, USA is an artificial intelligence language model gaining popularity because of its large database and ability to interpret and respond to various queries. Although it has been tested by researchers in different fields, its performance varies depending on the domain. We aimed to further test its ability in the medical field. Methods: We used questions from Taiwan's 2022 Family Medicine Board Exam, which combined both Chinese and English and covered various question types, including reverse questions and multiple-choice questions, and mainly focused on general medical knowledge. We pasted each question into ChatGPT and recorded its response, comparing it to the correct answer provided by the exam board. We used SAS 9.4 (Cary, North Carolina, USA) and Excel to calculate the accuracy rates for each question type. Results: ChatGPT answered 52 questions out of 125 correctly, with an accuracy rate of 41.6%. The questions' length did not affect the accuracy rates. These were 45.5%, 33.3%, 58.3%, 50.0%, and 43.5% for negative-phrase questions, multiple-choice questions, mutually exclusive options, case scenario questions, and Taiwan's local policy-related questions, with no statistical difference observed. Conclusion: ChatGPT's accuracy rate was not good enough for Taiwan's Family Medicine Board Exam. Possible reasons include the difficulty level of the specialist exam and the relatively weak database of traditional Chinese language resources. However, ChatGPT performed acceptably in negative-phrase questions, mutually exclusive questions, and case scenario questions, and it can be a helpful tool for learning and exam preparation. Future research can explore ways to improve ChatGPT's accuracy rate for specialized exams and other domains. © 2023 Wolters Kluwer Health. All rights reserved.",Yes,Sully,,,,,,,,,,
Development of a Human Evaluation Framework and Correlation with Automated Metrics for Natural Language Generation of Medical Diagnoses,"In the evolving landscape of clinical Natural Language Generation (NLG), assessing abstractive text quality remains challenging, as existing methods often overlook generative task complexities. This work aimed to examine the current state of automated evaluation metrics in NLG in healthcare. To have a robust and well-validated baseline with which to examine the alignment of these metrics, we created a comprehensive human evaluation framework. Employing ChatGPT-3.5-turbo generative output, we correlated human judgments with each metric. None of the metrics demonstrated high alignment; however, the SapBERT score—a Unified Medical Language System (UMLS)- showed the best results. This underscores the importance of incorporating domain-specific knowledge into evaluation efforts. Our work reveals the deficiency in quality evaluations for generated text and introduces our comprehensive human evaluation framework as a baseline. Future efforts should prioritize integrating medical knowledge databases to enhance the alignment of automated metrics, particularly focusing on refining the SapBERT score for improved assessments.",Yes,Sully,,,,,,,,,,
Innovations in surgical training: exploring the role of artificial intelligence and large language models (LLM),"The landscape of surgical training is rapidly evolving with the advent of artificial intelligence (AI) and its integration into education and simulation. This manuscript aims to explore the potential applications and benefits of AI-assisted surgical training, particularly the use of large language models (LLMs), in enhancing communication, personalizing feedback, and promoting skill development. We discuss the advancements in simulation-based training, AI-driven assessment tools, video-based assessment systems, virtual reality (VR) and augmented reality (AR) platforms, and the potential role of LLMs in the transcription, translation, and summarization of feedback. Despite the promising opportunities presented by AI integration, several challenges must be addressed, including accuracy and reliability, ethical and privacy concerns, bias in AI models, integration with existing training systems, and training and adoption of AI-assisted tools. By proactively addressing these challenges and harnessing the potential of AI, the future of surgical training may be reshaped to provide a more comprehensive, safe, and effective learning experience for trainees, ultimately leading to better patient outcomes.",No,Sully,,,,,,,,,,
Technopessimism in the Spanish Print Media in the Public Debate on the Social Impact of Artificial Intelligence; [O tecnopesimismo na imprensa escrita espanhola no debate público sobre o impacto social da inteligência artificial]; [El tecnopesimismo en la prensa escrita española en el debate público sobre el impacto social de la Inteligencia Artificial],"The rapid evolution of Artificial Intelligence (AI) has intensified public debate about its social implications. In this context, journalistic coverage of technological advancements plays a key role in shaping public opinion. As a mediator of public debate, the press has the responsibility to provide critical and balanced coverage of these important issues. This study analyzes how the media represents ethical concerns regarding the social effects of AI. Based on a corpus of 912 articles from 12 Spanish newspapers, the topics and voices shaping the debate over a one-month period, five months after the launch of ChatGPT, were identified. The results reveal the main discourses organizing public debate, highlighting a predominant technopessimist perspective that emphasizes the potential risks AI poses to humanity and the urgent need to establish ethical standards. Additionally, it shows that large tech companies have played a prominent role in the debate, acting not only as key players in technological development but also as the main voices driving the discussion, in contrast to the limited participation of political, governmental, and civil society actors. While no systematic differences were observed between the newspapers analyzed, some differences in positioning emerged when comparing traditional media with digital-native outlets. © 2025, Austral University, Faculty of Communication. All rights reserved.",No,Sully,,,,,,,,,,
Artificial intelligence in neurology; [Künstliche Intelligenz in der Neurologie],"Ever since the publication of ChatGPT everyone is talking about Artificial intelligence (AI). Every AI-algorithm is based on the analysis of data. In neurology, digitalization has created sufficiently large amounts of data to be analyzed. This article aims to provide an overview of AI models, as well as current research and applications of AI in the field of neurology. It will also briefly highlight potential problems in the integration of AI into clinical practice and provide an outlook for the future. © 2023 Georg Thieme Verlag. All rights reserved.",No,Sully,,,,,,,,,,
Suicide Risk Assessments Through the Eyes of ChatGPT-3.5 Versus ChatGPT-4: Vignette Study,"Background: ChatGPT, a linguistic artificial intelligence (AI) model engineered by OpenAI, offers prospective contributions to mental health professionals. Although having significant theoretical implications, ChatGPT’s practical capabilities, particularly regarding suicide prevention, have not yet been substantiated. Objective: The study’s aim was to evaluate ChatGPT’s ability to assess suicide risk, taking into consideration 2 discernable factors—perceived burdensomeness and thwarted belongingness—over a 2-month period. In addition, we evaluated whether ChatGPT-4 more accurately evaluated suicide risk than did ChatGPT-3.5. Methods: ChatGPT was tasked with assessing a vignette that depicted a hypothetical patient exhibiting differing degrees of perceived burdensomeness and thwarted belongingness. The assessments generated by ChatGPT were subsequently contrasted with standard evaluations rendered by mental health professionals. Using both ChatGPT-3.5 and ChatGPT-4 (May 24, 2023), we executed 3 evaluative procedures in June and July 2023. Our intent was to scrutinize ChatGPT-4’s proficiency in assessing various facets of suicide risk in relation to the evaluative abilities of both mental health professionals and an earlier version of ChatGPT-3.5 (March 14 version). Results: During the period of June and July 2023, we found that the likelihood of suicide attempts as evaluated by ChatGPT-4 was similar to the norms of mental health professionals (n=379) under all conditions (average Z score of 0.01). Nonetheless, a pronounced discrepancy was observed regarding the assessments performed by ChatGPT-3.5 (May version), which markedly underestimated the potential for suicide attempts, in comparison to the assessments carried out by the mental health professionals (average Z score of –0.83). The empirical evidence suggests that ChatGPT-4’s evaluation of the incidence of suicidal ideation and psychache was higher than that of the mental health professionals (average Z score of 0.47 and 1.00, respectively). Conversely, the level of resilience as assessed by both ChatGPT-4 and ChatGPT-3.5 (both versions) was observed to be lower in comparison to the assessments offered by mental health professionals (average Z score of –0.89 and –0.90, respectively). Conclusions: The findings suggest that ChatGPT-4 estimates the likelihood of suicide attempts in a manner akin to evaluations provided by professionals. In terms of recognizing suicidal ideation, ChatGPT-4 appears to be more precise. However, regarding psychache, there was an observed overestimation by ChatGPT-4, indicating a need for further research. These results have implications regarding ChatGPT-4’s potential to support gatekeepers, patients, and even mental health professionals’ decision-making. Despite the clinical potential, intensive follow-up studies are necessary to establish the use of ChatGPT-4’s capabilities in clinical practice. The finding that ChatGPT-3.5 frequently underestimates suicide risk, especially in severe cases, is particularly troubling. It indicates that ChatGPT may downplay one’s actual suicide risk level. ©Inbar Levkovich, Zohar Elyoseph.",Yes,Sully,,,,,,,,,,
Extracting social support and social isolation information from clinical psychiatry notes: comparing a rule-based natural language processing system and a large language model,"Objectives: Social support (SS) and social isolation (SI) are social determinants of health (SDOH) associated with psychiatric outcomes. In electronic health records (EHRs), individual-level SS/SI is typically documented in narrative clinical notes rather than as structured coded data. Natural language processing (NLP) algorithms can automate the otherwise labor-intensive process of extraction of such information. Materials and Methods: Psychiatric encounter notes from Mount Sinai Health System (MSHS, n = 300) and Weill Cornell Medicine (WCM, n = 225) were annotated to create a gold-standard corpus. A rule-based system (RBS) involving lexicons and a large language model (LLM) using FLAN-T5-XL were developed to identify mentions of SS and SI and their subcategories (eg, social network, instrumental support, and loneliness). Results: For extracting SS/SI, the RBS obtained higher macroaveraged F1-scores than the LLM at both MSHS (0.89 versus 0.65) and WCM (0.85 versus 0.82). For extracting the subcategories, the RBS also outperformed the LLM at both MSHS (0.90 versus 0.62) and WCM (0.82 versus 0.81). Discussion and Conclusion: Unexpectedly, the RBS outperformed the LLMs across all metrics. An intensive review demonstrates that this finding is due to the divergent approach taken by the RBS and LLM. The RBS was designed and refined to follow the same specific rules as the gold-standard annotations. Conversely, the LLM was more inclusive with categorization and conformed to common English-language understanding. Both approaches offer advantages, although additional replication studies are warranted. © The Author(s) 2024. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.",Yes,Sully,,,,,,,,,,
Emergence angle: Comprehensive analysis and machine learning prediction for clinical application,"3417. J Prosthodont Res. 2023 Jul 31;67(3):468-474. doi: 10.2186/jpr.JPR_D_22_00194. 
Epub 2022 Dec 19.

Emergence angle: Comprehensive analysis and machine learning prediction for 
clinical application.

Saleh O(1), Nozaki K(2), Matsumura M(1), Yanaka W(1), Abdou A(3), Miura H(1), 
Fueki K(1).

Author information:
(1)Department of Masticatory Function and Health Science, Graduate School of 
Medical and Dental Sciences, Tokyo Medical and Dental University, Tokyo, Japan.
(2)Department of Advanced Prosthodontics, Graduate School of Medical and Dental 
Sciences, Tokyo Medical and Dental University, Tokyo, Japan.
(3)Department of Prosthodontics Dentistry, Faculty of Dentistry, King Salman 
International University, Cairo, Egypt.

PURPOSE: To analyze and compare the emergence angle (EA) using two measurement 
methods, conventional and modified (EA-GPT and EA-R), the EAs of all-natural 
teeth were evaluated and classified to derive a suitable and predictable 
clinically applicable measurement method.
METHODS: Natural human teeth (n=600) were classified, cleaned, and thoroughly 
inspected. Teeth were scanned using an intraoral scanner. The scanned data were 
analyzed using three-dimensional analysis software for both methods with several 
points per surface. A Bland-Altman analysis was used for statistical analysis 
and a heat map and a nonparametric density plot to assess the repetition and 
distribution. An XGBoost regression model was used for prediction.
RESULTS: The EA-R method showed significantly different values compared to the 
EA-GPT method, representing an increase of 17.5-20.7% for the proximal surfaces. 
An insignificant difference between the two methods was observed for other 
surfaces. Different teeth classes showed variation in the normal range, thereby 
resulting in a new classification of the EA for all-natural teeth based on the 
interquartile range. The machine learning gradient boosting model predicted 
conventional data with an average mean absolute error of 0.9.
CONCLUSIONS: Variations in the natural teeth EA and measurement methods, suggest 
a new classification for EA. The established artificial intelligence method 
demonstrated robust performance, which could aid in implementing EA measurement 
in prosthetic designs.",No,Sully,,,,,,,,,,
ChatGPT for Univariate Statistics: Validation of AI-Assisted Data Analysis in Healthcare Research,"Background: ChatGPT, a conversational artificial intelligence developed by OpenAI, has rapidly become an invaluable tool for researchers. With the recent integration of Python code interpretation into the ChatGPT environment, there has been a significant increase in the potential utility of ChatGPT as a research tool, particularly in terms of data analysis applications. Objective: This study aimed to assess ChatGPT as a data analysis tool and provide researchers with a framework for applying ChatGPT to data management tasks, descriptive statistics, and inferential statistics. Methods: A subset of the National Inpatient Sample was extracted. Data analysis trials were divided into data processing, categorization, and tabulation, as well as descriptive and inferential statistics. For data processing, categorization, and tabulation assessments, ChatGPT was prompted to reclassify variables, subset variables, and present data, respectively. Descriptive statistics assessments included mean, SD, median, and IQR calculations. Inferential statistics assessments were conducted at varying levels of prompt specificity (“Basic,” “Intermediate,” and “Advanced”). Specific tests included chi-square, Pearson correlation, independent 2-sample t test, 1-way ANOVA, Fisher exact, Spearman correlation, Mann-Whitney U test, and Kruskal-Wallis H test. Outcomes from consecutive prompt-based trials were assessed against expected statistical values calculated in Python (Python Software Foundation), SAS (SAS Institute), and RStudio (Posit PBC). Results: ChatGPT accurately performed data processing, categorization, and tabulation across all trials. For descriptive statistics, it provided accurate means, SDs, medians, and IQRs across all trials. Inferential statistics accuracy against expected statistical values varied with prompt specificity: 32.5% accuracy for “Basic” prompts, 81.3% for “Intermediate” prompts, and 92.5% for “Advanced” prompts. Conclusions: ChatGPT shows promise as a tool for exploratory data analysis, particularly for researchers with some statistical knowledge and limited programming expertise. However, its application requires careful prompt construction and human oversight to ensure accuracy. As a supplementary tool, ChatGPT can enhance data analysis efficiency and broaden research accessibility. ©Michael R Ruta, Tony Gaidici, Chase Irwin, Jonathan Lifshitz.",No,Sully,,,,,,,,,,
Artificial intelligence bot ChatGPT in medical research: the potential game changer as a double-edged sword,"1841. Knee Surg Sports Traumatol Arthrosc. 2023 Apr;31(4):1187-1189. doi: 
10.1007/s00167-023-07355-6. Epub 2023 Feb 21.

Artificial intelligence bot ChatGPT in medical research: the potential game 
changer as a double-edged sword.

Dahmen J(1)(2)(3), Kayaalp ME(4), Ollivier M(5), Pareek A(6), Hirschmann MT(7), 
Karlsson J(8), Winkler PW(9).

Author information:
(1)Department of Orthopaedic Surgery and Sports Medicine, Amsterdam Movement 
Sciences, Amsterdam UMC, Location AMC, University of Amsterdam, Meibergdreef 9, 
Amsterdam, The Netherlands. j.dahmen@amsterdamumc.nl.
(2)Academic Center for Evidence Based Sports Medicine (ACES), Amsterdam, The 
Netherlands. j.dahmen@amsterdamumc.nl.
(3)Amsterdam Collaboration for Health and Safety in Sports (ACHSS), 
International Olympic Committee (IOC) Research Center Amsterdam UMC, Amsterdam, 
The Netherlands. j.dahmen@amsterdamumc.nl.
(4)Department for Orthopaedics and Traumatology, Istanbul Kartal Dr. Lutfi 
Kirdar Training and Research Hospital, Istanbul, Turkey.
(5)Aix Marseille Univ, CNRS, ISM, Inst Movement Sci, Marseille, France.
(6)Sports Medicine and Shoulder Service, Department of Orthopedic Surgery, 
Hospital for Special Surgery, 535 East 70th Street, New York, NY, 10021, USA.
(7)Department of Orthopedic Surgery and Traumatology, Head Knee Surgery and DKF 
Head of Research, Kantonsspital Baselland, Bruderholz, 4101, Bottmingen, 
Switzerland.
(8)Department for Orthopaedics, Sahlgrenska University Hospital, Institute of 
Clinical Sciences, Sahlgrenska Academy, Gothenburg University, Gothenburg, 
Sweden.
(9)Department of Orthopaedics and Traumatology, Kepler University Hospital Linz, 
Linz, Austria.",No,Sully,,,,,,,,,,
Exploring the performance of large language models on hepatitis B infection-related questions: A comparative study,"BACKGROUND Patients with hepatitis B virus (HBV) infection require chronic and personalized care to improve outcomes. Large language models (LLMs) can potentially provide medical information for patients. AIM To examine the performance of three LLMs, ChatGPT-3.5, ChatGPT-4.0, and Google Gemini, in answering HBV-related questions. METHODS LLMs' responses to HBV-related questions were independently graded by two medical professionals using a four-point accuracy scale, and disagreements were resolved by a third reviewer. Each question was run three times using three LLMs. Readability was assessed via the Gunning Fog index and Flesch-Kincaid grade level. RESULTS Overall, all three LLM chatbots achieved high average accuracy scores for subjective questions (ChatGPT-3.5: 3.50; ChatGPT-4.0: 3.69; Google Gemini: 3.53, out of a maximum score of 4). With respect to objective questions, ChatGPT-4.0 achieved an 80.8% accuracy rate, compared with 62.9% for ChatGPT-3.5 and 73.1% for Google Gemini. Across the six domains, ChatGPT-4.0 performed better in terms of diagnosis, whereas Google Gemini demonstrated excellent clinical manifestations. Notably, in the readability analysis, the mean Gunning Fog index and Flesch-Kincaid grade level scores of the three LLM chatbots were significantly higher than the standard level eight, far exceeding the reading level of the normal population. CONCLUSION Our results highlight the potential of LLMs, especially ChatGPT-4.0, for delivering responses to HBV-related questions. LLMs may be an adjunctive informational tool for patients and physicians to improve outcomes. Nevertheless, current LLMs should not replace personalized treatment recommendations from physicians in the management of HBV infection. © The Author(s) 2025. Published by Baishideng Publishing Group Inc. All rights reserved.",Yes,Sully,,,,,,,,,,
"Danger, Danger, Gaston Labat! Does zero-shot artificial intelligence correlate with anticoagulation guidelines recommendations for neuraxial anesthesia?","Introduction Artificial intelligence and large language models (LLMs) have emerged as potentially disruptive technologies in healthcare. In this study GPT-3.5, an accessible LLM, was assessed for its accuracy and reliability in performing guideline-based evaluation of neuraxial bleeding risk in hypothetical patients on anticoagulation medication. The study also explored the impact of structured prompt guidance on the LLM's performance. Methods A dataset of 10 hypothetical patient stems and 26 anticoagulation profiles (260 unique combinations) was developed based on American Society of Regional Anesthesia and Pain Medicine guidelines. Five prompts were created for the LLM, ranging from minimal guidance to explicit instructions. The model's responses were compared with a ""truth table""based on the guidelines. Performance metrics, including accuracy and area under the receiver operating curve (AUC), were used. Results Baseline performance of GPT-3.5 was slightly above chance. With detailed prompts and explicit guidelines, performance improved significantly (AUC 0.70, 95% CI (0.64 to 0.77)). Performance varied among medication classes. Discussion LLMs show potential for assisting in clinical decision making but rely on accurate and relevant prompts. Integration of LLMs should consider safety and privacy concerns. Further research is needed to optimize LLM performance and address complex scenarios. The tested LLM demonstrates potential in assessing neuraxial bleeding risk but relies on precise prompts. LLM integration should be approached cautiously, considering limitations. Future research should focus on optimization and understanding LLM capabilities and limitations in healthcare.  © American Society of Regional Anesthesia & Pain Medicine 2024. No commercial re-use. See rights and permissions. Published by BMJ.",Yes,Sully,,,,,,,,,,
HEalthRecordBERT (HERBERT): Leveraging Transformers on Electronic Health Records for Chronic Kidney Disease Risk Stratification,"Risk stratification is an essential tool in the fight against many diseases, including chronic kidney disease. Recent work has focused on applying techniques from machine learning and leveraging the information contained in a patient's electronic health record (EHR). Irregular intervals between data entries and the large number of variables tracked in EHR datasets can make them challenging to work with. Many of the difficulties associated with these datasets can be overcome by using large language models, such as bidirectional encoder representations from transformers (BERT). Previous attempts to apply BERT to EHR for risk stratification have shown promise. In this work we propose HERBERT, a novel application of BERT to EHR data. We identify two key areas where BERT models must be modified to adapt them to EHR data, namely: the embedding layer and the pretraining task. We show how changes to these can lead to improved performance, relative to the previous state of the art. We evaluate our model by predicting the transition of chronic kidney disease patients to end stage renal disease. The strong performance of our model justifies our architectural changes and suggests that large language models could play an important role in future renal risk stratification.  Copyright © 2024 held by the owner/author(s).",Yes,Rochelle,,,,,,,,,,
Can Patients With Urogenital Cancer Rely on Artificial Intelligence Chatbots for Treatment Decisions?,"Objectives: In the era of artificial intelligence, almost half of the patients use the internet to get information about their diseases. Our study aims to demonstrate the reliability of the information provided by artificial intelligence chatbots (AICs) about urogenital cancer treatments. Methods: The most frequently searched keyword about prostate, bladder, kidney, and testicular cancer treatment via Google Trends was asked to 3 different AICs (ChatGPT, Gemini, Copilot). The answers were evaluated by 5 different examiners in terms of readability, understandability, actionability, reliability, and transparency. Results: The DISCERN score evaluation indicates that ChatGPT and Gemini provided moderate quality information, while Copilot's quality was low. (Total DISCERN scores; 41, 42, 35, respectively). PEMAT-P Understandability scores were low (40%) and PEMAT-P Actionability scores were moderate only for Gemini (60%) and low for the others (40%). Their readability according to the Coleman-Liau index was above the college level (16.9, 17.2, 16, respectively). Conclusions: In the era of artificial intelligence, patients will inevitably use AICs due to their easy and fast accessibility. However, patients need to recognize that AICs do not provide stage-specific treatment options, but only moderate-quality, low-reliability information about the disease, as well as information that is very difficult to read. © 2024 Elsevier Inc.",Yes,Rochelle,,,,,,,,,,
Middle East respiratory coronavirus (MERS-CoV) internalized by llama alveolar macrophages does not result in virus replication or induction of pro-inflammatory cytokines,"Severe Middle East respiratory syndrome (MERS) is characterized by massive infiltration of immune cells in lungs. MERS-coronavirus (MERS-CoV) replicates in vitro in human macrophages, inducing high pro-inflammatory responses. In contrast, camelids, the main reservoir for MERS-CoV, are asymptomatic carriers. Although limited infiltration of leukocytes has been observed in the lower respiratory tract of camelids, their role during infection remains unknown. Here we studied whether llama alveolar macrophages (LAMs) are susceptible to MERS-CoV infection and can elicit pro-inflammatory responses. MERS-CoV did not replicate in LAMs; however, they effectively capture and degrade viral particles. Moreover, transcriptomic analyses showed that LAMs do not induce pro-inflammatory cytokines upon MERS-CoV sensing. © 2023 The Authors",No,Rochelle,,,,,,,,,,
ChatGPT-4 Effectively Responds to Common Patient Questions on Total Ankle Arthroplasty: A Surgeon-Based Assessment of AI in Patient Education,"Background: Patient reliance on internet resources for clinical information has steadily increased. The recent widespread accessibility of artificial intelligence (AI) tools like ChatGPT has increased patient reliance on these resources while also raising concerns about the accuracy, reliability, and appropriateness of the information they provide. Previous studies have evaluated ChatGPT and found it could accurately respond to questions on common surgeries, such as total hip arthroplasty, but is untested for uncommon procedures like total ankle arthroplasty (TAA). This study evaluates ChatGPT-4’s performance in answering patient questions on TAA and further explores the opportunity for physician involvement in guiding the implementation of this technology. Methods: Twelve commonly asked patient questions regarding TAA were collated from established sources and posed to ChatGPT-4 without additional input. Four fellowship-trained surgeons independently rated the responses using a 1-4 scale, assessing accuracy and need for clarification. Interrater reliability, divergence, and trends in response content were analyzed to evaluate consistency across responses. Results: The mean score across all responses was 1.8, indicating an overall satisfactory performance by ChatGPT-4. Ratings were consistently good on factual questions, such as infection risk and success rates, whereas questions requiring nuanced information, such as postoperative protocols and prognosis, received poorer ratings. Significant variability was observed among surgeons’ ratings and between questions, reflecting differences in interpretation and expectations. Conclusion: ChatGPT-4 demonstrates its potential to reliably provide discrete information for uncommon procedures such as TAA, but it lacks the capability to effectively respond to questions requiring patient- or surgeon-specific insight. This limitation, paired with the growing reliance on AI, highlights the need for AI tools tailored to specific clinical practices to enhance accuracy and relevance in patient education. © The Author(s) 2025.",Yes,Rochelle,,,,,,,,,,
LMCG-Net: Integrating LLMs and ECG for LVEF-Based Classification for Pacing Patients,"Detecting left ventricular systolic dysfunction (LVSD) traditionally relies on expensive and specialized echocardiography, limiting accessibility for many patients. To address this, researchers explore the potential of electrocardiography (ECG), a more affordable and widely available alternative, despite its historically limited performance in cardiac dysfunction detection. In this study, we present a novel approach that integrates a 1D convolutional neural networks (CNNs) with a large-scale language model (LLM) to simultaneously analyze sequential ECG data and non-sequential clinical metadata. To validate our model's effectiveness, we conducted rigorous comparative experiments on both specially collected clinical data and public datasets, achieving an impressive AUROC of 0.97 across both. Our findings underscore the capability of ECG-based AI to accurately predict LVSD including pacemaker patients, offering a rapid and cost-effective alternative to traditional echocardiography. This innovative approach could significantly enhance early diagnosis and management of cardiac dysfunction. © 2024 IEEE.",No,Sully,,,,,,,,,,
Health literacy in ChatGPT: exploring the potential of the use of artificial intelligence to produce academic text; [A literacia em saúde no ChatGPT: explorando o potencial de uso de inteligência artificial para a elaboração de textos acadêmicos Artigo Temático],"The aim of this study was to identify and analyze the main constituent elements of text generated by ChatGPT in response to questions on an emerging topic in the academic literature in Portuguese – health literacy – and discuss how the evidence produced can contribute to improv-ing our understanding of the limits and challenges of using artificial intelligence (AI) in academic writing. We conducted an exploratory descriptive study based on responses to five consecutive questions in Portuguese and English with increasing levels of complexity put to ChatGPT. Our findings reveal the potential of the use of widely avail-able, unrestricted access AI-based technologies like ChatGPT for academic writing. Featuring a simple and intuitive interface, the tool generated structured and coherent text using natural-like language. Considering that academic productiv-ism is associated with a growing trend in profes-sional misconduct, especially plagiarism, there is a need too take a careful look at academic writing and scientific knowledge dissemination processes mediated by AI technologies. © 2024, Associacao Brasileira de Pos - Graduacao em Saude Coletiva. All rights reserved.",No,Rochelle,,,,,,,,,,
A comparative analysis between ChatGPT versus NASS clinical guidelines for adult isthmic spondylolisthesis,"Background: Isthmic spondylolisthesis is a prevalent condition often diagnosed in adults, especially those with low back pain. The main objective of this study was to evaluate the clinical viability of ChatGPT 3.5 and 4.0 by assessing its capacity to produce recommendations consistent with NASS's Evidence-based Clinical Guidelines for adult isthmic spondylolisthesis. Methods: To achieve the purpose of this study, we used the 2014 NASS Evidence-Based Clinical Guideline for Multidisciplinary Spine Care and presented its 31 questions to ChatGPT 3.5 and ChatGPT 4.0 separately, evaluating their responses for appropriateness and consistency with the guidelines. Results: ChatGPT 3.5 and ChatGPT 4.0 demonstrated concordance rates with the NASS guidelines of 45% and 42%, respectively, with ChatGPT 3.5 showing higher accuracy (91%) for questions with definitive recommendations and both versions showing lower concordance (20%) for questions with no direct recommendations. Conclusions: Future enhancements should focus on enabling ChatGPT to better reflect the latest evidence and clinical complexities, especially concerning issues that involve medical terms. © 2025 The Authors",Yes,Rochelle,,,,,,,,,,
Automated Pathologic TN Classification Prediction and Rationale Generation From Lung Cancer Surgical Pathology Reports Using a Large Language Model Fine-Tuned With Chain-of-Thought: Algorithm Development and Validation Study,"Background: Traditional rule-based natural language processing approaches in electronic health record systems are effective but are often time-consuming and prone to errors when handling unstructured data. This is primarily due to the substantial manual effort required to parse and extract information from diverse types of documentation. Recent advancements in large language model (LLM) technology have made it possible to automatically interpret medical context and support pathologic staging. However, existing LLMs encounter challenges in rapidly adapting to specialized guideline updates. In this study, we fine-tuned an LLM specifically for lung cancer pathologic staging, enabling it to incorporate the latest guidelines for pathologic TN classification. Objective: This study aims to evaluate the performance of fine-tuned generative language models in automatically inferring pathologic TN classifications and extracting their rationale from lung cancer surgical pathology reports. By addressing the inefficiencies and extensive parsing efforts associated with rule-based methods, this approach seeks to enable rapid and accurate reclassification aligned with the latest cancer staging guidelines. Methods: We conducted a comparative performance evaluation of 6 open-source LLMs for automated TN classification and rationale generation, using 3216 deidentified lung cancer surgical pathology reports based on the American Joint Committee on Cancer (AJCC) Cancer Staging Manual8th edition, collected from a tertiary hospital. The dataset was preprocessed by segmenting each report according to lesion location and morphological diagnosis. Performance was assessed using exact match ratio (EMR) and semantic match ratio (SMR) as evaluation metrics, which measure classification accuracy and the contextual alignment of the generated rationales, respectively. Results: Among the 6 models, the Orca2_13b model achieved the highest performance with an EMR of 0.934 and an SMR of 0.864. The Orca2_7b model also demonstrated strong performance, recording an EMR of 0.914 and an SMR of 0.854. In contrast, the Llama2_7b model achieved an EMR of 0.864 and an SMR of 0.771, while the Llama2_13b model showed an EMR of 0.762 and an SMR of 0.690. The Mistral_7b and Llama3_8b models, on the other hand, showed lower performance, with EMRs of 0.572 and 0.489, and SMRs of 0.377 and 0.456, respectively. Overall, the Orca2 models consistently outperformed the others in both TN stage classification and rationale generation. Conclusions: The generative language model approach presented in this study has the potential to enhance and automate TN classification in complex cancer staging, supporting both clinical practice and oncology data curation. With additional fine-tuning based on cancer-specific guidelines, this approach can be effectively adapted to other cancer types. © Sanghwan Kim, Sowon Jang, Borham Kim, Leonard Sunwoo, Seok Kim, Jin-Haeng Chung, Sejin Nam, Hyeongmin Cho, Donghyoung Lee, Keehyuck Lee, Sooyoung Yoo.",Yes,Rochelle,,,,,,,,,,
Human intelligence versus Chat-GPT: who performs better in correctly classifying patients in triage?,"Introduction: Chat-GPT is rapidly emerging as a promising and potentially revolutionary tool in medicine. One of its possible applications is the stratification of patients according to the severity of clinical conditions and prognosis during the triage evaluation in the emergency department (ED). Methods: Using a randomly selected sample of 30 vignettes recreated from real clinical cases, we compared the concordance in risk stratification of ED patients between healthcare personnel and Chat-GPT. The concordance was assessed with Cohen's kappa, and the performance was evaluated with the area under the receiver operating characteristic curve (AUROC) curves. Among the outcomes, we considered mortality within 72 h, the need for hospitalization, and the presence of a severe or time-dependent condition. Results: The concordance in triage code assignment between triage nurses and Chat-GPT was 0.278 (unweighted Cohen's kappa; 95% confidence intervals: 0.231–0.388). For all outcomes, the ROC values were higher for the triage nurses. The most relevant difference was found in 72-h mortality, where triage nurses showed an AUROC of 0.910 (0.757–1.000) compared to only 0.669 (0.153–1.000) for Chat-GPT. Conclusions: The current level of Chat-GPT reliability is insufficient to make it a valid substitute for the expertise of triage nurses in prioritizing ED patients. Further developments are required to enhance the safety and effectiveness of AI for risk stratification of ED patients. © 2024 Elsevier Inc.",Yes,Rochelle,,,,,,,,,,
Comparative outcomes of AI-assisted ChatGPT and face-to-face consultations in infertility patients: a cross-sectional study,"Background: With the advent of artificial intelligence (AI) in healthcare, digital platforms like ChatGPT offer innovative alternatives to traditional medical consultations. This study seeks to understand the comparative outcomes of AI-assisted ChatGPT consultations and conventional face-to-face interactions among infertility patients. Methods: A cross-sectional study was conducted involving 120 infertility patients, split evenly between those consulting via ChatGPT and traditional face-to-face methods. The primary outcomes assessed were patient satisfaction, understanding, and consultation duration. Secondary outcomes included demographic information, clinical history, and subsequent actions post-consultation. Results: While both consultation methods had a median age of 34 years, patients using ChatGPT reported significantly higher satisfaction levels (median 4 out of 5) compared to face-to-face consultations (median 3 out of 5; p < 0.001). The ChatGPT group also experienced shorter consultation durations, with a median difference of 12.5 minutes (p < 0.001). However, understanding, demographic distributions, and subsequent actions post-consultation were comparable between the two groups. Conclusions: AI-assisted ChatGPT consultations offer a promising alternative to traditional face-to-face consultations in assisted reproductive medicine. While patient satisfaction was higher and consultation durations were shorter with ChatGPT, further studies are required to understand the long-term implications and clinical outcomes associated with AI-driven medical consultations. © The Author(s) 2024. Published by Oxford University Press on behalf of Fellowship of Postgraduate Medicine. All rights reserved.",Yes,Rochelle,,,,,,,,,,
Application of ChatGPT in Medical Content Development: Challenges and Hope,,No,Rochelle,,,,,,,,,,
Assessing the appropriateness and completeness of ChatGPT-4's AI-generated responses for queries related to diabetic retinopathy,"2625. Indian J Ophthalmol. 2024 Jul 1;72(Suppl 4):S684-S687. doi: 
10.4103/IJO.IJO_2510_23. Epub 2024 Mar 8.

Assessing the appropriateness and completeness of ChatGPT-4's AI-generated 
responses for queries related to diabetic retinopathy.

Subramanian B(1), Rajalakshmi R(2), Sivaprasad S(3), Rao C(1), Raman R(1).

Author information:
(1)Department of Ophthalmology, Shri Bhagwan Mahavir Vitreoretinal Services, 
SankaraNethralaya, Chennai, Tamil Nadu, India.
(2)Department of Ophthalmology, Dr. Mohan's Diabetes Specialities Centre and 
Madras Diabetes Research Foundation, Chennai, Tamil Nadu, India.
(3)NIHR Biomedical Research Centre, Moorfields Eye Hospital NHS Foundation 
Trust, London, United Kingdom.

OBJECTIVE: To evaluate the appropriateness of responses generated by an online 
chat-based artificial intelligence (AI) model for diabetic retinopathy (DR) 
related questions.
DESIGN: Cross-sectional study.
METHODS: A set of 20 questions framed from the patient's perspective addressing 
DR-related queries, such as the definition of disease, symptoms, prevention 
methods, treatment options, diagnostic methods, visual impact, and 
complications, were formulated for input into ChatGPT-4. Peer-reviewed, 
literature-based answers were collected from popular search engines for the 
selected questions and three retinal experts reviewed the responses. An 
inter-human agreement was analyzed for consensus expert responses and also 
between experts. The answers generated by the AI model were compared with those 
provided by the experts. The experts rated the response generated by ChatGPT-4 
on a scale of 0-5 for appropriateness and completeness.
RESULTS: The answers provided by ChatGPT-4 were appropriate and complete for 
most of the DR-related questions. The response to questions on the adverse 
effects of laser photocoagulation therapy and compliance to treatment was not 
perfectly complete. The average rating given by the three retina expert 
evaluators was 4.84 for appropriateness and 4.38 for completeness of answers 
provided by the AI model. This corresponds to an overall 96.8% agreement among 
the experts for appropriateness and 87.6% for completeness regarding 
AI-generated answers.
CONCLUSION: ChatGPT-4 exhibits a high level of accuracy in generating 
appropriate responses for a range of questions in DR. However, there is a need 
to improvise the model to generate complete answers for certain DR-related 
topics.

Copyright © 2024 Copyright: © 2024 Indian Journal of Ophthalmology.",Yes,Rochelle,,,,,,,,,,
General-Purpose Large Language Models Versus a Domain-Specific Natural Language Processing Tool for Label Extraction From Chest Radiograph Reports,"Plain Language Summary: GPT-4 outperformed a radiology domain-specific natural 
language processing model in classifying imaging findings from chest radiograph 
reports, both with and without predefined labels. Prompt engineering for context 
further improved performance. The findings indicate a role for large language 
models to accelerate artificial intelligence model development in radiology by 
automating data annotation.",Yes,Rochelle,,,,,,,,,,
Understanding how and why users might use NHS repositories: A mixed methods study,"Background: There is little evidence on the use or potential use of NHS repositories within the UK. Methods: A mixed methods (quantitative/qualitative) study of two repositories: amber—the home of ambulance service research, and East Midlands Evidence Repository (EMER). A structured online questionnaire was distributed via the repository home page, and promoted via social media, email networks, and lists. Next, three research leaders were interviewed in person online (see Appendix S1, supporting information). Transcripts of the recorded interviews were summarised using ChatGPT 3.5. Results: From the 148 questionnaire responses, 38% of respondents had used an NHS repository. Librarian activities were key to encouraging repository use (that is, searching and depositing materials). ResearchGate was the most widely used alternative. Perceived benefits of using repositories included open access to materials, and knowledge sharing with colleagues. Users generally did not know the deposit process, and over 50% of respondents were unaware of Green Open Access. Discussion: Building greater awareness, and institutional support is key to increasing repository usage. Marketing activities and educating researchers about the benefits of engaging with the repository are fundamental. Conclusion: NHS librarians need to market NHS repositories using principles of knowledge management and ensure that the grey literature of research and evaluation reports in repositories is better used. © 2025 Health Libraries Group.",No,Rochelle,,,,,,,,,,
Can people with epilepsy trust AI chatbots for information on physical exercise?,"Purpose: This study aims to evaluate the similarity, readability, and alignment with current scientific knowledge of responses from AI-based chatbots to common questions about epilepsy and physical exercise. Methods: Four AI chatbots (ChatGPT-3.5,ChatGPT 4, Google Gemini, and Microsoft Copilot) were evaluated. Fourteen questions on epilepsy and physical exercise were designed to compare the platforms. Lexical similarity, response patterns, and thematic content were analyzed. Readability was measured using the Flesch Reading Ease and Flesch–Kincaid Grade Level scores. Seven experts rated the quality of responses on a Likert scale from “very poor” to “very good.” Results: The responses showed lexical similarity, with approaches to physical exercise ranging from conservative to holistic. Microsoft Copilot scored the highest on the Flesch Reading Ease scale (48.42 ± 13.71), while ChatGPT-3.5 scored the lowest (23.84 ± 8.19). All responses were generally rated as difficult to read. Quality ratings ranged from “Good” to “Acceptable,” with ChatGPT 4 being the preferred platform, chosen by 48.98 % of reviewers. Conclusion: The findings highlight the potential of AI chatbots as useful sources of information on epilepsy and physical exercise. However, simplifying language and tailoring content to user's needs is essential to enhance their effectiveness. © 2024 The Author(s)",Yes,Rochelle,,,,,,,,,,
From Revisions to Insights: Converting Radiology Report Revisions into Actionable Educational Feedback Using Generative AI Models,"2871. J Imaging Inform Med. 2025 Apr;38(2):1265-1279. doi: 10.1007/s10278-024-01233-4. 
Epub 2024 Aug 19.

From Revisions to Insights: Converting Radiology Report Revisions into 
Actionable Educational Feedback Using Generative AI Models.

Lyo S(1), Mohan S(2), Hassankhani A(2), Noor A(2), Dako F(2), Cook T(2).

Author information:
(1)Department of Radiology, Hospital of the University of Pennsylvania, 
Philadelphia, PA, USA. shawn.kt.lyo@gmail.com.
(2)Department of Radiology, Hospital of the University of Pennsylvania, 
Philadelphia, PA, USA.

Expert feedback on trainees' preliminary reports is crucial for radiologic 
training, but real-time feedback can be challenging due to non-contemporaneous, 
remote reading and increasing imaging volumes. Trainee report revisions contain 
valuable educational feedback, but synthesizing data from raw revisions is 
challenging. Generative AI models can potentially analyze these revisions and 
provide structured, actionable feedback. This study used the OpenAI GPT-4 Turbo 
API to analyze paired synthesized and open-source analogs of preliminary and 
finalized reports, identify discrepancies, categorize their severity and type, 
and suggest review topics. Expert radiologists reviewed the output by grading 
discrepancies, evaluating the severity and category accuracy, and suggested 
review topic relevance. The reproducibility of discrepancy detection and maximal 
discrepancy severity was also examined. The model exhibited high sensitivity, 
detecting significantly more discrepancies than radiologists (W = 19.0, 
p < 0.001) with a strong positive correlation (r = 0.778, p < 0.001). Interrater 
reliability for severity and type were fair (Fleiss' kappa = 0.346 and 0.340, 
respectively; weighted kappa = 0.622 for severity). The LLM achieved a weighted 
F1 score of 0.66 for severity and 0.64 for type. Generated teaching points were 
considered relevant in ~ 85% of cases, and relevance correlated with the maximal 
discrepancy severity (Spearman ρ = 0.76, p < 0.001). The reproducibility was 
moderate to good (ICC (2,1) = 0.690) for the number of discrepancies and 
substantial for maximal discrepancy severity (Fleiss' kappa = 0.718; weighted 
kappa = 0.94). Generative AI models can effectively identify discrepancies in 
report revisions and generate relevant educational feedback, offering promise 
for enhancing radiology training.

© 2024. The Author(s).",No,Rochelle,,,,,,,,,,
Rujifang inhibits triple-negative breast cancer growth via the PI3K/AKT pathway,"3865. J Ethnopharmacol. 2024 Jun 12;327:118011. doi: 10.1016/j.jep.2024.118011. Epub 
2024 Mar 10.

Rujifang inhibits triple-negative breast cancer growth via the PI3K/AKT pathway.

Jia W(1), Lin X(1), Chen X(1), Li H(1), Zhang X(2), Zhang Y(1), Chen Y(1), Wang 
B(1), Chen X(1), Chen J(3), Tian H(4).

Author information:
(1)The Eighth Clinical Medical College of Guangzhou University of Chinese 
Medicine, Foshan Hospital of Traditional Chinese Medicine, Foshan, 528000, 
Guangdong, China.
(2)Shenyang Pharmaceutical University, Shenyang, 110016, Liaoning, China.
(3)The Eighth Clinical Medical College of Guangzhou University of Chinese 
Medicine, Foshan Hospital of Traditional Chinese Medicine, Foshan, 528000, 
Guangdong, China. Electronic address: dsj06407@163.com.
(4)The Eighth Clinical Medical College of Guangzhou University of Chinese 
Medicine, Foshan Hospital of Traditional Chinese Medicine, Foshan, 528000, 
Guangdong, China. Electronic address: 13929969262@163.com.

ETHNOPHARMACOLOGICAL RELEVANCE: Rujifang (RJF) constitutes a traditional Chinese 
medicinal compound extensively employed in the management of triple-negative 
breast cancer (TNBC). However, information regarding its potential active 
ingredients, antitumor effects, safety, and mechanism of action remains 
unreported.
AIM OF THE STUDY: To investigate the efficacy and safety of RJF in the context 
of TNBC.
MATERIALS AND METHODS: We employed the ultra high-performance liquid 
chromatography-electrospray four-pole time-of-flight mass spectrometry technique 
(UPLC/Q-TOF-MS/MS) to scrutinize the chemical constituents of RJF. 
Subcutaneously transplanted tumor models were utilized to assess the impact of 
RJF on TNBC in vivo. Thirty female BLAB/c mice were randomly divided into five 
groups: the model group, cyclophosphamide group, and RJF high-dose, medium-dose, 
and low-dose groups. A total of 1 × 106 4T1 cells were subcutaneously injected 
into the right shoulder of mice, and they were administered treatments for a 
span of 28 days. We conducted evaluations on blood parameters, encompassing 
white blood cell count (WBC), red blood cell count (RBC), hemoglobin (HGB), 
platelet count (PLT), neutrophils, lymphocytes, and monocytes, as well as 
hepatorenal indicators including alkaline phosphatase (ALP), glutamate 
oxaloacetate transaminase (GOT), glutamate pyruvate transaminase (GPT), albumin, 
and creatinine (CRE) to gauge the safety of RJF. Ki67 and TUNEL were detected 
via immunohistochemistry and immunofluorescence, respectively. We prepared RJF 
drug-containing serum for TNBC cell lines and assessed the in vitro inhibitory 
effect of RJF on tumor cell growth through the CCK8 assay and cell cycle 
analysis. RT-PCR was employed to detect the mRNA expression of cyclin-dependent 
kinase and cyclin-dependent kinase inhibitors in tumor tissues, and Western blot 
was carried out to ascertain the expression of cyclin and pathway-related 
proteins.
RESULTS: 100 compounds were identified in RJF, which consisted of 3 flavonoids, 
24 glycosides, 18 alkaloids, 3 amino acids, 8 phenylpropanoids, 6 terpenes, 20 
organic acids, and 18 other compounds. In animal experiments, both CTX and RJF 
exhibited substantial antitumor effects. RJF led to an increase in the number of 
neutrophils in peripheral blood, with no significant impact on other 
hematological indices. In contrast, CTX reduced red blood cell count, hemoglobin 
levels, and white blood cell count, while increasing platelet count. RJF 
exhibited no discernible influence on hepatorenal function, whereas 
Cyclophosphamide (CTX) decreased ALP, GOT, and GPT levels. Both CTX and RJF 
reduced the expression of Ki67 and heightened the occurrence of apoptosis in 
tumor tissue. RJF drug-containing serum hindered the viability of 4T1 and 
MD-MBA-231 cells in a time and concentration-dependent manner. In cell cycle 
experiments, RJF diminished the proportion of G2 phase cells and arrested the 
cell cycle at the S phase. RT-PCR analysis indicated that RJF down-regulated the 
mRNA expression of CDK2 and CDK4, while up-regulating that of P21 and P27 in 
tumor tissue. The trends in CDKs and CDKIs protein expression mirrored those of 
mRNA expression. Moreover, the PI3K/AKT pathway displayed downregulation in the 
tumor tissue of mice treated with RJF.
CONCLUSION: RJF demonstrates effectiveness and safety in the context of TNBC. It 
exerts anti-tumor effects by arresting the cell cycle at the S phase through the 
PI3K-AKT pathway.

Copyright © 2024 The Authors. Published by Elsevier B.V. All rights reserved.",No,Rochelle,,,,,,,,,,
Reference without intentions in large language models,"During the 1960s and 1970s, Keith Donnellan ([Donnellan, K. S. 1966. “Reference and Definite Descriptions.” The Philosophical Review 75 (3): 281–304. https://doi.org/10.2307/2183143]; Donnellan, K. S. 1970. “Proper Names and Identifying Descriptions.” Synthese 21 (3–4): 335–358. https://doi.org/10.1007/BF00484804]; Donnellan, K. S. 1974. “Speaking of Nothing.” Philosophical Review 83 (1): 3–31. https://doi.org/10.2307/2183871] and Saul Kripke [Kripke, S. 1972. “Naming and Necessity.” In Semantics of Natural Language, edited by Donald Davidson and Gilbert Harman, 253–355. D. Reidel] promoted a ‘historical picture’ of reference as an alternative to previously prevailing description theories. The historical picture has since gained broad acceptance. Its most recent frontier is the apparent reference of names (and other words) produced by large language models (LLM). A number of authors have pointed out that the historical picture might support the view that this reference is not merely apparent, but is constitutively determined in the same way as human reference. A sticking point, however, is the role that linguistic intentions have been thought to play in the historical picture. This paper urges that in applying the historical picture of reference to LLMs we need not and should not focus on the plausibility of ascribing linguistic intentions to LLMs. Instead, the critical issue is whether LLMs can achieve a kind of basic reference that is prior to and independent of propositional attitudes such as intentions. © 2025 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",No,Rochelle,,,,,,,,,,
Can artificial intelligence diagnose seizures based on patients’ descriptions? A study of GPT-4,"Introduction Generalist large language models (LLMs) have shown diagnostic potential in various medical contexts. However, there has been little work on this topic in relation to epilepsy. This paper aims to test the performance of an LLM (OpenAI’s GPT-4) on the diAerential diagnosis of epileptic and functional/dissociative seizures (FDS) based on patients’ descriptions. Methods GPT-4 was asked to diagnose 41 cases of epilepsy (n=16) or FDS (n=25) based on transcripts of patients describing their symptoms. It was first asked to perform this task without being given any additional training examples (‘zero-shot’) before being asked to perform it having been given one, two, and three examples of each condition (one-, two, and three-shot). As a benchmark, three experienced neurologists were also asked to perform this task without access to any additional clinical information. Results In the zero-shot condition, GPT-4’s average balanced accuracy was 57% (κ: .15). Balanced accuracy improved in the one-shot condition (64%, κ: .27), though did not improve any further in the two-shot (62%, κ: .24) or three-shot (62%, κ: .23) conditions. Performance in all four conditions was worse than the average balanced accuracy of the experienced neurologists (71%, κ: .41). Significance Although its ‘raw’ performance was poor, GPT-4 showed noticeable improvement having been given just one example of a patient describing epilepsy and FDS. Giving two and three examples did not further improve performance, but more elaborate approaches (e.g. more refined prompt engineering, fine-tuning, or retrieval augmented generation) could unlock the full diagnostic potential of LLMs.",Yes,Rochelle,,,,,,,,,,
AI-driven translations for kidney transplant equity in Hispanic populations,"Health equity and accessing Spanish kidney transplant information continues being a substantial challenge facing the Hispanic community. This study evaluated ChatGPT's capabilities in translating 54 English kidney transplant frequently asked questions (FAQs) into Spanish using two versions of the AI model, GPT-3.5 and GPT-4.0. The FAQs included 19 from Organ Procurement and Transplantation Network (OPTN), 15 from National Health Service (NHS), and 20 from National Kidney Foundation (NKF). Two native Spanish-speaking nephrologists, both of whom are of Mexican heritage, scored the translations for linguistic accuracy and cultural sensitivity tailored to Hispanics using a 1-5 rubric. The inter-rater reliability of the evaluators, measured by Cohen's Kappa, was 0.85. Overall linguistic accuracy was 4.89 ± 0.31 for GPT-3.5 versus 4.94 ± 0.23 for GPT-4.0 (non-significant p = 0.23). Both versions scored 4.96 ± 0.19 in cultural sensitivity (p = 1.00). By source, GPT-3.5 linguistic accuracy was 4.84 ± 0.37 (OPTN), 4.93 ± 0.26 (NHS), 4.90 ± 0.31 (NKF). GPT-4.0 scored 4.95 ± 0.23 (OPTN), 4.93 ± 0.26 (NHS), 4.95 ± 0.22 (NKF). For cultural sensitivity, GPT-3.5 scored 4.95 ± 0.23 (OPTN), 4.93 ± 0.26 (NHS), 5.00 ± 0.00 (NKF), while GPT-4.0 scored 5.00 ± 0.00 (OPTN), 5.00 ± 0.00 (NHS), 4.90 ± 0.31 (NKF). These high linguistic and cultural sensitivity scores demonstrate Chat GPT effectively translated the English FAQs into Spanish across systems. The findings suggest Chat GPT's potential to promote health equity by improving Spanish access to essential kidney transplant information. Additional research should evaluate its medical translation capabilities across diverse contexts/languages. These English-to-Spanish translations may increase access to vital transplant information for underserved Spanish-speaking Hispanic patients.",No,Rochelle,,,,,,,,,,
Letter to the Editor: Can ChatGPT be used in oral and maxillofacial surgery?,"2948. J Stomatol Oral Maxillofac Surg. 2024 Apr;125(2):101653. doi: 
10.1016/j.jormas.2023.101653. Epub 2023 Oct 11.

Letter to the Editor: Can ChatGPT be used in oral and maxillofacial surgery?

Azadi A(1), Akbarzadeh Baghban A(2), Mohammad-Rahimi H(3).

Author information:
(1)Research Fellow, Dentofacial Deformities Research Center, Research Institute 
of Dental Sciences, Shahid Beheshti University of Medical Sciences, Tehran, 
Iran. Electronic address: a.azadi@sbmu.ac.ir.
(2)Proteomics Research Center, Department of Biostatistics, School of Allied 
Medical Sciences, Shahid Beheshti University of Medical Sciences, Tehran, Iran.
(3)Topic Group Dental Diagnostics and Digital Dentistry, ITU/WHO Focus Group AI 
on Health, Berlin, Germany.

Comment on
    J Stomatol Oral Maxillofac Surg. 2023 Oct;124(5):101471. doi: 
10.1016/j.jormas.2023.101471.",No,Rochelle,,,,,,,,,,
The Role of ChatGPT in osteoporosis management: a comparative analysis with clinical expertise,"2300. Arch Osteoporos. 2025 Apr 9;20(1):51. doi: 10.1007/s11657-025-01533-4.

The Role of ChatGPT in osteoporosis management: a comparative analysis with 
clinical expertise.

Bucak ÖF(1), Cinar C(2).

Author information:
(1)Başakşehir Çam and Sakura City Hospital, Physical Medicine and 
Rehabilitation, University of Health Sciences, İstanbul, Turkey. 
omerbucak46@gmail.com.
(2)Department of Interventional Physiatry, Biruni University, Istanbul, Turkey.

This study evaluates the role of ChatGPT in osteoporosis management, 
demonstrating 91% diagnostic accuracy and significantly faster response times 
compared to clinicians. The findings highlight the potential for artificial 
intelligence (AI) to revolutionize clinical decision-making while emphasizing 
the critical need for professional oversight to ensure patient safety and 
comprehensive care.
OBJECTIVE: Osteoporosis is a progressive skeletal disease that is characterized 
by increased bone fragility and an increased risk of fracture. Early diagnosis 
and effective treatment can significantly reduce healthcare costs; however, 
limited access to clinical expertise represents a significant challenge to 
patient care. This study evaluates the diagnostic and treatment recommendations 
provided by natural language processing (NLP)-based AI models for osteoporosis 
management and compares them with those of healthcare professionals.
METHODS: A multicenter, cross-sectional study was conducted with the creation of 
100 real scenarios from 206 patients with a diagnosis of osteoporosis. The data 
pertaining to bone mineral density (BMD) and the clinical parameters were 
subjected to analysis using ChatGPT-4.0. Thereafter, the recommendations 
proffered by this software were compared to those of five independent 
physiatrists. A statistical validation of the model's accuracy was conducted 
through the use of categorical distribution analysis.
RESULTS: ChatGPT exhibited a high degree of diagnostic accuracy, with 91% of 
responses being entirely accurate. It provided recommendations for both 
pharmacological and non-pharmacological interventions that were consistent with 
current clinical guidelines. Nevertheless, 8% of the responses were reported as 
incomplete. Furthermore, ChatGPT was able to produce diagnoses and treatment 
recommendations at a significantly faster rate than clinicians, while the mean 
answer time is 5.4 ± 2.45 min in clinicians and 2.3 ± 0.76 min in ChatGPT 
(p < 0.001).
CONCLUSION: These findings highlight the potential of AI tools like ChatGPT to 
improve efficiency in clinical decision-making while underscoring the necessity 
of collaboration with healthcare professionals to guarantee comprehensive 
patient care.

© 2025. International Osteoporosis Foundation and Bone Health and Osteoporosis 
Foundation.",Yes,Rochelle,,,,,,,,,,
Very rare tumour of the palatine tonsil: a molecular approach,"3566. BMJ Case Rep. 2024 Jan 12;17(1):e255864. doi: 10.1136/bcr-2023-255864.

Very rare tumour of the palatine tonsil: a molecular approach.

Ramael M(1), Van Steelandt H(2), Puls T(2)(3), Ramael M(4).

Author information:
(1)University of Antwerp Faculty of Medicine and Health Sciences, Wilrijk, 
Belgium.
(2)General Hospital AZ Herentals, Herentals, Belgium.
(3)Private Practice, Hikstraat 33, Herentals, Belgium.
(4)University of Antwerp Faculty of Medicine and Health Sciences, Wilrijk, 
Belgium marc.ramael@skynet.be.

Mucoepidermoid cancer (MEC) is extremely rare in the palatine tonsil with only 
three adequately described cases in the literature.We describe a woman in her 
late 70s with vague pharyngeal discomfort who underwent tonsillectomy, lymph 
node dissection of the neck and radiotherapy for MEC with loco-regional lymph 
node metastasis of the palatine tonsil. To confirm this extremely rare diagnosis 
and to gain deeper insight in the molecular oncogenesis, an extensive molecular 
study including next-generation sequencing and immunohistochemistry was 
performed. Immunoreactivity for p16 protein and real-time PCR showed high-risk 
oncogenic human papillomavirus 16 DNA and mutations in the BRAF, BARD and DNMT3A 
genes. Tumour mutational burden was low. After a follow-up of 7 years the 
patient is still alive and well without any residual or disseminated disease.

© BMJ Publishing Group Limited 2024. No commercial re-use. See rights and 
permissions. Published by BMJ.",No,Rochelle,,,,,,,,,,
Transcriptome Profiling of HCT-116 Colorectal Cancer Cells with RNA Sequencing Reveals Novel Targets for Polyphenol Nano Curcumin,"Colorectal cancer is one of the leading causes of cancer-related deaths worldwide. The gemini nanoparticle formulation of polyphenolic curcumin significantly inhibits the viability of cancer cells. However, the molecular mechanisms and pathways underlying its toxicity in colon cancer are unclear. Here, we aimed to uncover the possible novel targets of gemini curcumin (Gemini-Cur) on colorectal cancer and related cellular pathways. After confirming the cytotoxic effect of Gemini-Cur by MTT and apoptotic assays, RNA sequencing was employed to identify differentially expressed genes (DEGs) in HCT-116 cells. On a total of 3892 DEGs (padj &lt; 0.01), 442 genes showed a log2 FC &gt;|2| (including 244 upregulated and 198 downregulated). Gene ontology (GO) enrichment analysis was performed. Protein-protein interaction (PPI) and gene-pathway networks were constructed by using STRING and Cytoscape. The pathway analysis showed that Gemini-Cur predominantly modulates pathways related to the cell cycle. The gene network analysis revealed five central genes, namely GADD45G, ATF3, BUB1B, CCNA2 and CDK1. Real-time PCR and Western blotting analysis confirmed the significant modulation of these genes in Gemini-Cur-treated compared to non-treated cells. In conclusion, RNA sequencing revealed novel potential targets of curcumin on cancer cells. Further studies are required to elucidate the molecular mechanism of action of Gemini-Cur regarding the modulation of the expression of hub genes.",No,Rochelle,,,,,,,,,,
"Artificial intelligence, adversarial attacks, and ocular warfare","Purpose: We explore the potential misuse of artificial intelligence (AI), specifically large language models (LLMs), in generating harmful content related to ocular warfare. By examining the vulnerabilities of AI systems to adversarial attacks, we aim to highlight the urgent need for robust safety measures, enforceable regulation, and proactive ethics. Design: A viewpoint paper discussing the ethical challenges posed by AI, using ophthalmology as a case study. It examines the susceptibility of AI systems to adversarial attacks and the potential for their misuse in creating harmful content. Methods: The study involved crafting adversarial prompts to test the safeguards of a well-known LLM, OpenAI's ChatGPT-4.0. The focus was on evaluating the model's responses to hypothetical scenarios aimed at causing ocular damage through biological, chemical, and physical means. Results: The AI provided detailed responses on using Onchocerca volvulus for mass infection, methanol for optic nerve damage, mustard gas for severe eye injuries, and high-powered lasers for inducing blindness. Despite significant safeguards, the study revealed that with enough effort, it was possible to bypass these constraints and obtain harmful information, underscoring the vulnerabilities in AI systems. Conclusion: AI holds the potential for both positive transformative change and malevolent exploitation. The susceptibility of LLMs to adversarial attacks and the possibility of purposefully trained unethical AI systems present significant risks. This paper calls for improved robustness of AI systems, global legal and ethical frameworks, and proactive measures to ensure AI technologies benefit humanity and do not pose threats. © 2024 The Authors",No,Rochelle,,,,,,,,,,
Discovery and preclinical development of a therapeutically active nanobody-based chimeric antigen receptor targeting human CD22,"Chimeric antigen receptor (CAR) T cell therapies targeting B cell-restricted antigens CD19, CD20, or CD22 can produce potent clinical responses for some B cell malignancies, but relapse remains common. Camelid single-domain antibodies (sdAbs or nanobodies) are smaller, simpler, and easier to recombine than single-chain variable fragments (scFvs) used in most CARs, but fewer sdAb-CARs have been reported. Thus, we sought to identify a therapeutically active sdAb-CAR targeting human CD22. Immunization of an adult Llama glama with CD22 protein, sdAb-cDNA library construction, and phage panning yielded >20 sdAbs with diverse epitope and binding properties. Expressing CD22-sdAb-CAR in Jurkat cells drove varying CD22-specific reactivity not correlated with antibody affinity. Changing CD28- to CD8-transmembrane design increased CAR persistence and expression in vitro. CD22-sdAb-CAR candidates showed similar CD22-dependent CAR-T expansion in vitro, although only membrane-proximal epitope targeting CD22-sdAb-CARs activated direct cytolytic killing and extended survival in a lymphoma xenograft model. Based on enhanced survival in blinded xenograft studies, a lead CD22sdCAR-T was selected, achieving comparable complete responses to a benchmark short linker m971-scFv CAR-T in high-dose experiments. Finally, immunohistochemistry and flow cytometry confirm tissue and cellular-level specificity of the lead CD22-sdAb. This presents a complete report on preclinical development of a novel CD22sdCAR therapeutic. © 2024",No,Rochelle,,,,,,,,,,
Our journey with an AI assistant offering narrative therapy on WhatsApp,"This study examines the integration of AI chatbots into social work, with a focus on democratising AI for use in Narrative Therapy (NT). As AI becomes more accessible, social work encounters new opportunities to utilise these tools in practice, but also faces significant challenges. The study explores the feasibility of using customisable GPT platforms to develop an AI chatbot for NT sessions and assesses its performance. An autoethnographic case study was conducted using a chatbot configured with the OpenAI Assistant API to perform NT on WhatsApp. Findings suggest that while practitioners can configure the chatbot to guide users through NT stages and adapt to interactions, there are still limitations, such as the need for basic coding and technical knowledge for deployment and enhancement. The study highlights both the potential and the challenges of AI in social work, advocating for enhanced training, interdisciplinary collaboration, and the cautious development of AI-assisted practices. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",No,Rochelle,,,,,,,,,,
Patient-Representing Population's Perceptions of GPT-Generated Versus Standard Emergency Department Discharge Instructions: Randomized Blind Survey Assessment,"Background: Discharge instructions are a key form of documentation and patient communication in the time of transition from the emergency department (ED) to home. Discharge instructions are time-consuming and often underprioritized, especially in the ED, leading to discharge delays and possibly impersonal patient instructions. Generative artificial intelligence and large language models (LLMs) offer promising methods of creating high-quality and personalized discharge instructions; however, there exists a gap in understanding patient perspectives of LLM-generated discharge instructions. Objective: We aimed to assess the use of LLMs such as ChatGPT in synthesizing accurate and patient-accessible discharge instructions in the ED. Methods: We synthesized 5 unique, fictional ED encounters to emulate real ED encounters that included a diverse set of clinician history, physical notes, and nursing notes. These were passed to GPT-4 in Azure OpenAI Service (Microsoft) to generate LLM-generated discharge instructions. Standard discharge instructions were also generated for each of the 5 unique ED encounters. All GPT-generated and standard discharge instructions were then formatted into standardized after-visit summary documents. These after-visit summaries containing either GPT-generated or standard discharge instructions were randomly and blindly administered to Amazon MTurk respondents representing patient populations through Amazon MTurk Survey Distribution. Discharge instructions were assessed based on metrics of interpretability of significance, understandability, and satisfaction. Results: Our findings revealed that survey respondents’ perspectives regarding GPT-generated and standard discharge instructions were significantly (P=.01) more favorable toward GPT-generated return precautions, and all other sections were considered noninferior to standard discharge instructions. Of the 156 survey respondents, GPT-generated discharge instructions were assigned favorable ratings, “agree” and “strongly agree,” more frequently along the metric of interpretability of significance in discharge instruction subsections regarding diagnosis, procedures, treatment, post-ED medications or any changes to medications, and return precautions. Survey respondents found GPT-generated instructions to be more understandable when rating procedures, treatment, post-ED medications or medication changes, post-ED follow-up, and return precautions. Satisfaction with GPT-generated discharge instruction subsections was the most favorable in procedures, treatment, post-ED medications or medication changes, and return precautions. Wilcoxon rank-sum test of Likert responses revealed significant differences (P=.01) in the interpretability of significant return precautions in GPT-generated discharge instructions compared to standard discharge instructions but not for other evaluation metrics and discharge instruction subsections. Conclusions: This study demonstrates the potential for LLMs such as ChatGPT to act as a method of augmenting current documentation workflows in the ED to reduce the documentation burden of physicians. The ability of LLMs to provide tailored instructions for patients by improving readability and making instructions more applicable to patients could improve upon the methods of communication that currently exist. ©Thomas Huang, Conrad Safranek, Vimig Socrates, David Chartash, Donald Wright, Monisha Dilip, Rohit B Sangal, Richard Andrew Taylor.",Yes,Rochelle,,,,,,,,,,
Inflammatory Signals Across the Spectrum: A Detailed Exploration of Acute Appendicitis Stages According to EAES 2015 Guidelines,"Background: In this retrospective study, we evaluate the diagnostic utility of C-reactive protein (CRP) and leucocyte count within the EAES 2015 guidelines for acute appendicitis (AA) in differentiating uncomplicated (UAA) from complicated AA (CAA). Methods: Conducted at a tertiary care center in Germany, the study included 285 patients over 18 years who were diagnosed with AA from January 2019 to December 2021. Patient data included demographics, inflammatory markers, and postoperative outcomes. Results: CRP levels (Md: 60.2 mg/dL vs. 10.5 mg/dL; p < 0.001) and leucocyte count (Md: 14.4 Gpt/L vs. 13.1 Gpt/L; p = 0.016) were higher in CAA. CRP had a medium diagnostic value for detecting CAA (AUC = 0.79), with a cutoff at 44.3 mg/L, making it more likely to develop CAA. Leucocyte count showed low predictive value for CAA (AUC = 0.59). CRP ≥ 44.3 mg/L was associated with a higher risk of postoperative complications (OR: 2.9; p = 0.002) and prolonged hospitalization (OR: 3.5; p < 0.001). Conclusions: CRP, within the context of the EAES classification, presents as a valuable diagnostic marker to distinguish CAA from UAA, with a higher risk of postoperative complications and hospitalization. Leucocyte count showed low diagnostic value for the identification of CAA.",No,Rochelle,,,,,,,,,,
Modern Machiavelli? The illusion of ChatGPT-generated patient reviews in plastic and aesthetic surgery based on 9000 review classifications,"Background: Online patient reviews are crucial in guiding individuals who seek plastic surgery, but artificial chatbots pose a threat of disseminating fake reviews. This study aimed to compare real patient feedback with ChatGPT-generated reviews for the top five US plastic surgery procedures. Methods: Thirty real patient reviews on rhinoplasty, blepharoplasty, facelift, liposuction, and breast augmentation were collected from RealSelf and used as templates for ChatGPT to generate matching patient reviews. Prolific users (n = 30) assessed 150 pairs of reviews to identify human-written and artificial intelligence (AI)-generated reviews. Patient reviews were further assessed using AI content detector software (Copyleaks AI). Results: Among the 9000 classification tasks, 64.3% and 35.7% of reviews were classified as authentic and fake, respectively. On an average, the author (human versus machine) was correctly identified in 59.6% of cases, and this poor classification performance was consistent across all procedures. Patients with prior aesthetic treatment showed poorer classification performance than those without (p < 0.05). The mean character count in human-written reviews was significantly higher (p < 0.001) that that in AI-generated reviews, with a significant correlation between character count and participants' accuracy rate (p < 0.001). Emotional timbre of reviews differed significantly with “happiness” being more prevalent in human-written reviews (p < 0.001), and “disappointment” being more prevalent in AI reviews (p = 0.005). Copyleaks AI correctly classified 96.7% and 69.3% of human-written and ChatGPT-generated reviews, respectively. Conclusion: ChatGPT convincingly replicates authentic patient reviews, even deceiving commercial AI detection software. Analyzing emotional tone and review length can help differentiate real from fake reviews, underscoring the need to educate both patients and physicians to prevent misinformation and mistrust. © 2023 British Association of Plastic, Reconstructive and Aesthetic Surgeons",No,Rochelle,,,,,,,,,,
GPT-4 and histopathological image detection and classification of colorectal adenomas,"3213. J Clin Pathol. 2024 May 17;77(6):383. doi: 10.1136/jcp-2024-209405.

GPT-4 and histopathological image detection and classification of colorectal 
adenomas.

Daungsupawong H(1), Wiwanitkit V(2).

Author information:
(1)Private Academic Consultant, Vientiane, Lao People's Democratic Republic 
hinpetchdaung@gmail.com.
(2)DY Patil Vidhyapeeth, Pune, India.",Yes,Rochelle,,,,,,,,,,
ChatGPT's Responses to Dilemmas in Medical Ethics: The Devil is in the Details,"2614. Am J Bioeth. 2023 Oct;23(10):63-65. doi: 10.1080/15265161.2023.2250290. Epub 
2023 Oct 9.

ChatGPT's Responses to Dilemmas in Medical Ethics: The Devil is in the Details.

Meier LJ(1).

Author information:
(1)University of Cambridge.

Comment on
    Am J Bioeth. 2023 Oct;23(10):8-16. doi: 10.1080/15265161.2023.2233357.
    Am J Bioeth. 2023 Oct;23(10):17-27. doi: 10.1080/15265161.2023.2233358.",No,Sully,,,,,,,,,,
Bias of AI-generated content: an examination of news produced by large language models,"Large language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC). To harness this transformation, we need to understand the limitations of LLMs. Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA. We collect news articles from The New York Times and Reuters, both known for their dedication to provide unbiased news. We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles. We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines. Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases. Moreover, the AIGC generated by each LLM exhibits notable discrimination against females and individuals of the Black race. Among the LLMs, the AIGC generated by ChatGPT demonstrates the lowest level of bias, and ChatGPT is the sole model capable of declining content generation when provided with biased prompts.",No,Rochelle,,,,,,,,,,
Use of ChatGPT for Determining Clinical and Surgical Treatment of Lumbar Disc Herniation With Radiculopathy: A North American Spine Society Guideline Comparison,"Objective: Large language models like chat generative pre-trained transformer (ChatGPT) have found success in various sectors, but their application in the medical field remains limited. This study aimed to assess the feasibility of using ChatGPT to provide accurate medical information to patients, specifically evaluating how well ChatGPT versions 3.5 and 4 aligned with the 2012 North American Spine Society (NASS) guidelines for lumbar disk herniation with radiculopathy. Methods: ChatGPT's responses to questions based on the NASS guidelines were analyzed for accuracy. Three new categories—overconclusiveness, supplementary information, and incompleteness—were introduced to deepen the analysis. Overconclusiveness referred to recommendations not mentioned in the NASS guidelines, supplementary information de-noted additional relevant details, and incompleteness indicated omitted crucial information from the NASS guidelines. Results: Out of 29 clinical guidelines evaluated, ChatGPT-3.5 demonstrated accuracy in 15 responses (52%), while ChatGPT-4 achieved accuracy in 17 responses (59%). ChatGPT-3.5 was overconclusive in 14 responses (48%), while ChatGPT-4 exhibited overconclusiveness in 13 responses (45%). Additionally, ChatGPT-3.5 provided supplementary information in 24 responses (83%), and ChatGPT-4 provided supplemental information in 27 responses (93%). In terms of incompleteness, ChatGPT-3.5 displayed this in 11 responses (38%), while ChatGPT-4 showed incompleteness in 8 responses (23%). Conclusion: ChatGPT shows promise for clinical decision-making, but both patients and healthcare providers should exercise caution to ensure safety and quality of care. While these results are encouraging, further research is necessary to validate the use of large language models in clinical settings. © 2024 by the Korean Spinal Neurosurgery Society.",Yes,Rochelle,,,,,,,,,,
Still Using Only ChatGPT? The Comparison of Five Different Artificial Intelligence Chatbots’ Answers to the Most Common Questions About Kidney Stones,"Objective: To evaluate and compare the quality and comprehensibility of answers produced by five distinct artificial intelligence (AI) chatbots—GPT-4, Claude, Mistral, Google PaLM, and Grok—in response to the most frequently searched questions about kidney stones (KS). Materials and Methods: Google Trends facilitated the identification of pertinent terms related to KS. Each AI chatbot was provided with a unique sequence of 25 commonly searched phrases as input. The responses were assessed using DISCERN, the Patient Education Materials Assessment Tool for Printable Materials (PEMAT-P), the Flesch-Kincaid Grade Level (FKGL), and the Flesch-Kincaid Reading Ease (FKRE) criteria. Results: The three most frequently searched terms were “stone in kidney,” “kidney stone pain,” and “kidney pain.” Nepal, India, and Trinidad and Tobago were the countries that performed the most searches in KS. None of the AI chatbots attained the requisite level of comprehensibility. Grok demonstrated the highest FKRE (55.6 ± 7.1) and lowest FKGL (10.0 ± 1.1) ratings (p = 0.001), whereas Claude outperformed the other chatbots in its DISCERN scores (47.6 ± 1.2) (p = 0.001). PEMAT-P understandability was the lowest in GPT-4 (53.2 ± 2.0), and actionability was the highest in Claude (61.8 ± 3.5) (p = 0.001). Conclusion: GPT-4 had the most complex language structure of the five chatbots, making it the most difficult to read and comprehend, whereas Grok was the simplest. Claude had the best KS text quality. Chatbot technology can improve healthcare material and make it easier to grasp. Copyright 2024, Mary Ann Liebert, Inc., publishers.",Yes,Rochelle,,,,,,,,,,
Using AI to Translate and Simplify Spanish Orthopedic Medical Text: Instrument Validation Study,"Background: Language barriers contribute significantly to health care disparities in the United States, where a sizable proportion of patients are exclusively Spanish speakers. In orthopedic surgery, such barriers impact both patients’ comprehension of and patients’ engagement with available resources. Studies have explored the utility of large language models (LLMs) for medical translation but have yet to robustly evaluate artificial intelligence (AI)–driven translation and simplification of orthopedic materials for Spanish speakers. Objective: This study used the bilingual evaluation understudy (BLEU) method to assess translation quality and investigated the ability of AI to simplify patient education materials (PEMs) in Spanish. Methods: PEMs (n=78) from the American Academy of Orthopaedic Surgery were translated from English to Spanish, using 2 LLMs (GPT-4 and Google Translate). The BLEU methodology was applied to compare AI translations with professionally human-translated PEMs. The Friedman test and Dunn multiple comparisons test were used to statistically quantify differences in translation quality. A readability analysis and feature analysis were subsequently performed to evaluate text simplification success and the impact of English text features on BLEU scores. The capability of an LLM to simplify medical language written in Spanish was also assessed. Results: As measured by BLEU scores, GPT-4 showed moderate success in translating PEMs into Spanish but was less successful than Google Translate. Simplified PEMs demonstrated improved readability when compared to original versions (P<.001) but were unable to reach the targeted grade level for simplification. The feature analysis revealed that the total number of syllables and average number of syllables per sentence had the highest impact on BLEU scores. GPT-4 was able to significantly reduce the complexity of medical text written in Spanish (P<.001). Conclusions: Although Google Translate outperformed GPT-4 in translation accuracy, LLMs, such as GPT-4, may provide significant utility in translating medical texts into Spanish and simplifying such texts. We recommend considering a dual approach—using Google Translate for translation and GPT-4 for simplification—to improve medical information accessibility and orthopedic surgery education among Spanish-speaking patients. © Saman Andalib, Aidin Spina, Bryce Picton, Sean S Solomon, John A Scolaro, Ariana M Nelson.",No,Rochelle,,,,,,,,,,
Dermatology in the wake of an AI revolution: Who gets a say?,"2865. J Am Acad Dermatol. 2023 Oct;89(4):e159-e160. doi: 10.1016/j.jaad.2023.05.053. 
Epub 2023 Jun 1.

Dermatology in the wake of an AI revolution: Who gets a say?

Beltrami EJ(1), Grant-Kels JM(2).

Author information:
(1)University of Connecticut School of Medicine, Farmington, Connecticut.
(2)Department of Dermatology, University of Connecticut Health Center, 
Farmington, Connecticut; Department of Dermatology, University of Florida, 
Gainesville, Florida. Electronic address: grant@uchc.edu.

Comment on
    J Am Acad Dermatol. 2023 Oct;89(4):e157-e158. doi: 
10.1016/j.jaad.2023.05.054.",No,Rochelle,,,,,,,,,,
Human-AI Collaboration in Large Language Model-Assisted Brain MRI Differential Diagnosis: A Usability Study,"Background Prior studies have shown the potential of large language models (LLMs) to support in differential diagnosis in radiology. However, the interaction of human users with LLMs in this context has not been evaluated. Purpose To investigate the impact of human-LLM collaboration on accuracy and efficiency of brain MRI differential diagnosis. Methods In this retrospective study, twenty brain MRI cases with a challenging but definitive diagnosis were selected and randomized into two groups. Six inexperienced radiology residents were instructed to determine the three most likely differential diagnoses for each of these cases via conventional internet search or utilizing an LLM-based search engine (© Perplexity AI, powered by GPT-4). Accuracy of suggested differential diagnoses was analyzed using the chi-square test and Mann-Whitney U test. Interpretation times were analyzed using the student’s t-test. Benefits and challenges in human-LLM interaction were derived from observations and participant feedback. Results LLM-assisted brain MRI differential diagnosis yielded superior accuracy (38/59 [LLM-assisted] vs 25/59 [conventional] correct diagnoses, p = 0.03). No difference in interpretation time (8.12 +/- 3.22 min [LLM-assisted] vs 7.96 +/- 2.65 min [conventional], p = 0.76) or level of confidence (median of 2.5 [LLM-assisted] vs 3.0 [conventional], p = 0.96) was observed. Several challenges related to human errors and technical limitations were identified. Conclusion Human-LLM collaboration has the potential to improve brain MRI differential diagnosis. Yet, several challenges must be addressed to ensure effective adoption and user acceptance.",Yes,Rochelle,,,,,,,,,,
ChatGPT versus the neurosurgical written boards: a comparative analysis of artificial intelligence/machine learning performance on neurosurgical board-style questions,"2978. J Neurosurg. 2023 Mar 24;139(3):904-911. doi: 10.3171/2023.2.JNS23419.

ChatGPT versus the neurosurgical written boards: a comparative analysis of 
artificial intelligence/machine learning performance on neurosurgical 
board-style questions.

Hopkins BS(1), Nguyen VN(1), Dallas J(1), Texakalidis P(2), Yang M(1), Renn 
A(1), Guerra G(1), Kashif Z(1), Cheok S(1), Zada G(1), Mack WJ(1).

Author information:
(1)1Department of Neurological Surgery, University of Southern California, Los 
Angeles, California; and.
(2)2Department of Neurological Surgery, Northwestern University's Feinberg 
School of Medicine, Chicago, Illinois.",Yes,Rochelle,,,,,,,,,,
Table tennis coaching system based on a multimodal large language model with a table tennis knowledge base,"3297. PLoS One. 2025 Feb 13;20(2):e0317839. doi: 10.1371/journal.pone.0317839. 
eCollection 2025.

Table tennis coaching system based on a multimodal large language model with a 
table tennis knowledge base.

Ma W(1), Liu Y(2), Yi Q(3), Liu X(4), Xing W(5), Zhao R(6), Liu H(7), Li R(1).

Author information:
(1)School of Physical Education, Shanghai University of Sport, Shanghai, China.
(2)College of Physical Education and Sports, Beijing Normal University, Beijing, 
China.
(3)Faculty of Sports and Exercise Science, Universiti Malaya, Kuala Lumpur, 
Malaysia.
(4)School of Physical Education, Jiangsu University of Science and Technology, 
Zhenjiang, China.
(5)College of Physical Education and Health Engineering, Taiyuan University of 
Technology, Taiyuan, China.
(6)Department of Physical Education, Tongji University, Shanghai, China.
(7)College of Physical Education and Health, Hubei Business College, Hubei, 
China.

Table tennis is one of the most popular sports in the world, and it plays a 
positive role in the overall development of people's physical and mental health. 
This study develops an AI table tennis coaching system using a Multimodal Large 
Language Model with a table tennis knowledge base, aiming to provide precise 
training guidance and match strategies for table tennis beginners.
METHOD: By using visual recognition technology, motion capture technology, and 
advanced multimodal large language models with a comprehensive professional 
table tennis knowledge base, the system accurately identifies common errors made 
by beginners and provides targeted training guidance.
RESULT: The AI Table Tennis Coaching System demonstrates high accuracy in 
identifying mistakes made by beginner players, particularly in recognizing 
arm-related errors and racket-related errors, with accuracies reaching 73% and 
82% respectively.
CONCLUSION: The system operates at low costs, is easy to deploy, and offers a 
high cost-performance ratio, providing effective technological support for table 
tennis teaching and training. The AI table tennis coaching system is expected to 
play a significant role in enhancing training efficiency, promoting athlete 
skill improvement, and popularizing the sport. Future research will focus on 
improving the accuracy of footwork recognition in AI table tennis coaching 
systems and expanding their capability to provide training guidance for 
high-level athletes, thereby promoting the overall advancement of table tennis.

Copyright: © 2025 Ma et al. This is an open access article distributed under the 
terms of the Creative Commons Attribution License, which permits unrestricted 
use, distribution, and reproduction in any medium, provided the original author 
and source are credited.",No,Rochelle,,,,,,,,,,
Potential applications of ChatGPT in endoscopy: Opportunities and limitations,"ChatGPT is an artificial intelligence model that has the potential to revolutionize the field of endoscopy. It can rapidly summarize medical records, assist with diagnosis, provide patient communication support, and even understand endoscopic images. However, there are limitations, including the risk of inaccurate or inappropriate responses, privacy and security issues, and the potential to limit doctors' thinking. Further research and improvements are needed to ensure ChatGPT's safe use in the medical field. Overall, the potential benefits of ChatGPT in endoscopy are vast, and it has the ability to greatly improve the efficiency of diagnosis and treatment. © 2023 The Authors",No,Rochelle,,,,,,,,,,
A foundational large language model for edible plant genomes,"Significant progress has been made in the field of plant genomics, as demonstrated by the increased use of high-throughput methodologies that enable the characterization of multiple genome-wide molecular phenotypes. These findings have provided valuable insights into plant traits and their underlying genetic mechanisms, particularly in model plant species. Nonetheless, effectively leveraging them to make accurate predictions represents a critical step in crop genomic improvement. We present AgroNT, a foundational large language model trained on genomes from 48 plant species with a predominant focus on crop species. We show that AgroNT can obtain state-of-the-art predictions for regulatory annotations, promoter/terminator strength, tissue-specific gene expression, and prioritize functional variants. We conduct a large-scale in silico saturation mutagenesis analysis on cassava to evaluate the regulatory impact of over 10 million mutations and provide their predicted effects as a resource for variant characterization. Finally, we propose the use of the diverse datasets compiled here as the Plants Genomic Benchmark (PGB), providing a comprehensive benchmark for deep learning-based methods in plant genomic research. The pre-trained AgroNT model is publicly available on HuggingFace at https://huggingface.co/InstaDeepAI/agro-nucleotide-transformer-1b for future research purposes. © The Author(s) 2024.",No,Rochelle,,,,,,,,,,
Exploring the potential of artificial intelligence models for triage in the emergency department,"Objective: To perform a comparative analysis of the three-level triage protocol conducted by triage nurses and emergency medicine doctors with the use of ChatGPT, Gemini, and Pi, which are recognized artificial intelligence (AI) models widely used in the daily life Materials and methods: The study was prospectively conducted with patients presenting to the emergency department of a tertiary care hospital from 1 April 2024, to 7 April 2024. Among the patients who presented to the emergency department over this period, data pertaining to their primary complaints, arterial blood pressure values, heart rates, peripheral oxygen saturation values measured by pulse oximetry, body temperature values, age, and gender characteristics were analyzed. The triage categories determined by triage nurses, the abovementioned AI chatbots, and emergency medicine doctors were compared. Results: The study included 500 patients, of whom 23.8% were categorized identically by all triage evaluators. Compared to the triage conducted by emergency medicine doctors, triage nurses overtriaged 6.4% of the patients and undertriaged 3.1% of the yellow-coded patients and 3.4% of the red-coded patients. Of the AI chatbots, ChatGPT exhibited the closest triage approximation to that of emergency medicine doctors; however, its undertriage rates were 26.5% for yellow-coded patients and 42.6% for red-coded patients. Conclusion: The undertriage rates observed in AI models were considerably high. Hence, it does not yet seem appropriate to solely rely on the specified AI models for triage purposes in the emergency department. © 2024 Informa UK Limited, trading as Taylor & Francis Group.",Yes,Rochelle,,,,,,,,,,
Comment on published article “A chat about bipolar disorder”,"To the Editor, we follow the topic “A chat about bipolar disorder1”. According to the study's findings, ChatGPT proved its ability to deliver basic and informative information on bipolar disorders. © 2024 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd.",No,Rochelle,,,,,,,,,,
"Exploring the Value and Regulatory Perspectives of Artificial Intelligence ChatGPT in Pharmacoeconomic: A Qualitative Study on Benefits, Risks, and Stakeholder Beliefs","Background: Growth in artificial intelligence systems can allow the automation of a crucial section of the traditional manual work practiced in pharmacoeconomics and evidence synthesis. However, artificial intelligence has a low autonomous analytical skill capabilities. The objective is to conduct a thematic analysis of the benefits and risks of applying ChatGPT across various sub-disciplines within pharmacoeconomics analysis. A purposive sampling technique was used to select the participants, utilizing the convenience sampling approach. All interviews were recorded and transcribed verbatim, and thematic analysis was applied to identify themes within the data. The result shows that most of the respondents find AI ChatGPT helpful as it increases data analysis and processing efficiency, as well as improving real-time decision making. Additionally, the participants believe that information accessibility and dissemination are appealing features of AI ChatGPT. However, the respondents identified potential drawbacks in AI ChatGPT use, such as data quality and accuracy, contextual awareness limitations, privacy and security concerns, lack of responsibility and accountability, limitations in generalizability, social and ethical concerns, uncertainty understanding limitations, and amplification of bias. Employing ChatGPT in pharmacoeconomics presents significant potential for enhancing data processing efficiency, providing real-time decision support, and improving information accessibility for healthcare stakeholders. However, these benefits come with various risks and ethical challenges, including concerns about data accuracy, contextual awareness, security, accountability, generalizability, and potential bias amplification. By putting in place robust safeguards, adhering to ethical standards, and maintaining vigilant oversight, we can effectively leverage ChatGPT's potential while maintaining the principles of responsible, equitable, and ethical healthcare decision making. © 2024 IEEE.",No,Rochelle,,,,,,,,,,
Extracting symptoms from free-text responses using ChatGPT among COVID-19 cases in Hong Kong,"Objectives: To investigate the feasibility and performance of Chat Generative Pretrained Transformer (ChatGPT) in converting symptom narratives into structured symptom labels. Methods: We extracted symptoms from 300 deidentified symptom narratives of COVID-19 patients by a computer-based matching algorithm (the standard), and prompt engineering in ChatGPT. Common symptoms were those with a prevalence >10% according to the standard, and similarly less common symptoms were those with a prevalence of 2–10%. The precision of ChatGPT was compared with the standard using sensitivity and specificity with 95% exact binomial CIs (95% binCIs). In ChatGPT, we prompted without examples (zero-shot prompting) and with examples (few-shot prompting). Results: In zero-shot prompting, GPT-4 achieved high specificity (0.947 [95% binCI: 0.894–0.978]—1.000 [95% binCI: 0.965–0.988, 1.000]) for all symptoms, high sensitivity for common symptoms (0.853 [95% binCI: 0.689–0.950]—1.000 [95% binCI: 0.951–1.000]), and moderate sensitivity for less common symptoms (0.200 [95% binCI: 0.043–0.481]—1.000 [95% binCI: 0.590–0.815, 1.000]). Few-shot prompting increased the sensitivity and specificity. GPT-4 outperformed GPT-3.5 in response accuracy and consistent labelling. Discussion: This work substantiates ChatGPT's role as a research tool in medical fields. Its performance in converting symptom narratives to structured symptom labels was encouraging, saving time and effort in compiling the task-specific training data. It potentially accelerates free-text data compilation and synthesis in future disease outbreaks and improves the accuracy of symptom checkers. Focused prompt training addressing ambiguous descriptions impacts medical research positively. © 2023 European Society of Clinical Microbiology and Infectious Diseases",No,Rochelle,,,,,,,,,,
BARD: A Structured Technique for Group Elicitation of Bayesian Networks to Support Analytic Reasoning,"In many complex, real-world situations, problem solving and decision making require effective reasoning about causation and uncertainty. However, human reasoning in these cases is prone to confusion and error. Bayesian networks (BNs) are an artificial intelligence technology that models uncertain situations, supporting better probabilistic and causal reasoning and decision making. However, to date, BN methodologies and software require (but do not include) substantial upfront training, do not provide much guidance on either the model building process or on using the model for reasoning and reporting, and provide no support for building BNs collaboratively. Here, we contribute a detailed description and motivation for our new methodology and application, Bayesian ARgumentation via Delphi (BARD). BARD utilizes BNs and addresses these shortcomings by integrating (1) short, high-quality e-courses, tips, and help on demand; (2) a stepwise, iterative, and incremental BN construction process; (3) report templates and an automated explanation tool; and (4) a multiuser web-based software platform and Delphi-style social processes. The result is an end-to-end online platform, with associated online training, for groups without prior BN expertise to understand and analyze a problem, build a model of its underlying probabilistic causal structure, validate and reason with the causal model, and (optionally) use it to produce a written analytic report. Initial experiments demonstrate that, for suitable problems, BARD aids in reasoning and reporting. Comparing their effect sizes also suggests BARD's BN-building and collaboration combine beneficially and cumulatively. © 2021 The Authors. Risk Analysis published by Wiley Periodicals LLC on behalf of Society for Risk Analysis.",No,Rochelle,,,,,,,,,,
TTPMapper: Accurate Mapping of TTPs from Unstructured CTI Reports,"Cyber Threat Intelligence (CTI) is crucial for understanding and mitigating threats from Advanced Persistent Threat (APT) groups. APTs utilize various Tactics, Techniques, and Procedures (TTPs), as cataloged by MITRE ATT&CK, to execute their attacks. Identifying the specific techniques used by the APTs is vital for improving threat detection, enhancing situational awareness, streamlining incident response, and implementing proactive defense measures. The primary source for identification of these techniques is threat reports, as they contain detailed information about APT activities. However, extracting and mapping these TTPs from threat reports is challenging due to the unstructured nature of these reports, and variability in sentence structure and vocabulary. This paper presents TTPMapper, a novel approach to extract and map TTPs from threat reports accurately. Given the limitations in TTP descriptions and the need for extensive training data, TTPMapper incorporates data augmentation from sources like AlienVault, SNORT, and MITRE ATT&CK. TTPMapper comprises two machine learning models utilizing CyBERT: one trained on keyword-specific sentences and another on simplified and elaborated sentences. TTPMapper leverages multiple trained models to determine the most likely Technique for any given input. Additionally, we integrate GPT-4o to handle unseen sentences with low classification probabilities. This multi-model approach, combined with a heuristic confidence scoring system, enhances the accuracy of TTP mapping from unstructured text. We demonstrate TTPMapper's superior performance (94.08% accuracy) compared to existing models like TTPHunter in terms of accuracy, precision, recall, and F1-score. © 2024 IEEE.",No,Rochelle,,,,,,,,,,
AI-Supported Academic Advising: Exploring ChatGPT’s Current State and Future Potential toward Student Empowerment,"Artificial intelligence (AI), once a phenomenon primarily in the world of science fiction, has evolved rapidly in recent years, steadily infiltrating into our daily lives. ChatGPT, a freely accessible AI-powered large language model designed to generate human-like text responses to users, has been utilized in several areas, such as the healthcare industry, to facilitate interactive dissemination of information and decision-making. Academic advising has been essential in promoting success among university students, particularly those from disadvantaged backgrounds. Unfortunately, however, student advising has been marred with problems, with the availability and accessibility of adequate advising being among the hurdles. The current study explores how AI-powered tools like ChatGPT might serve to make academic advising more accessible, efficient, or effective. The authors compiled a list of questions frequently asked by current and prospective students in a teacher education bachelor’s degree program in the United States. Then, the questions were typed into the free version of ChatGPT, and the answers generated were explored and evaluated for their content and delivery. ChatGPT generated surprisingly high-quality answers, written in an authoritative yet supportive tone, and it was particularly adept at addressing general and open-ended career-related questions, such as career outlook, in a clear, comprehensive, and supportive manner using plain language. We argue that AI-powered tools, such as ChatGPT, may complement but not necessarily replace human academic advisers and that these tools may very well serve to promote educational equity by empowering individuals from a wide range of backgrounds with the means to initiate effective methods of seeking academic advice. © 2023 by the authors.",No,Rochelle,,,,,,,,,,
Allen Joseph Bard (1933-2024),Father of contemporary electrochemistry.,No,Rochelle,,,,,,,,,,
Is Artificial Intelligence a Useful Tool for Clinical Practice of Oral and Maxillofacial Surgery?,"This study aimed to assess the usefulness of ChatGPT Plus generated responses to clinical-specific questions in oral and maxillofacial surgery. This cross-sectional study was conducted with questions composed according to the Clinical Practise Guide of Ege University, School of Dentistry, and with different subjects of oral and maxillofacial surgery at the undergraduate level. These questions were classified according to their difficulty level (easy, medium, and hard) and inputted into ChatGPT Plus. Three researchers evaluated the responses using a 7-point Likert-Type accuracy scale and a modified global quality scale (range: 1-5). Also, error analysis was carried out for the questions scored ≤4 according to the accuracy assessment. A total of 66 questions were enrolled in this study. The questions included dental anesthesia, tooth extraction, preoperative and postoperative complications, suturing, writing prescriptions, and temporomandibular joint examination. The median accuracy score of ChatGPT Plus responses was 5, with 75% of the responses scoring 4 or above. The median quality score was 4, with 75% of the responses scoring 3 or above. There was a significant difference among the 3 difficulty levels, both in accuracy and quality scores (P<0.001 and 0.001, respectively). The median scores of hard-level questions were found to be lower than the easy-level and medium-level questions. The study outcomes emphasized high accuracy and quality in ChatGPT Plus's responses, except for the questions requiring a detailed response or a comment.  Copyright © 2024 Mutaz B. Habal, MD. All rights reserved.",Yes,Rochelle,,,,,,,,,,
Accuracy of Commercial Large Language Model (ChatGPT) to Predict the Diagnosis for Prehospital Patients Suitable for Ambulance Transport Decisions: Diagnostic Accuracy Study,"Objectives: While ambulance transport decisions guided by artificial intelligence (AI) could be useful, little is known of the accuracy of AI in making patient diagnoses based on the pre-hospital patient care report (PCR). The primary objective of this study was to assess the accuracy of ChatGPT (OpenAI, Inc., San Francisco, CA, USA) to predict a patient’s diagnosis using the PCR by comparing to a reference standard assigned by experienced paramedics. The secondary objective was to classify cases where the AI diagnosis did not agree with the reference standard as paramedic correct, ChatGPT correct, or equally correct. Methods: This diagnostic accuracy study used a zero-shot learning model and greedy decoding. A convenience sample of PCRs from paramedic students was analyzed by an untrained ChatGPT-4 model to determine the single most likely diagnosis. A reference standard was provided by an experienced paramedic reviewing each PCR and giving a differential diagnosis of three items. A trained prehospital professional assessed the ChatGPT diagnosis as concordant or non-concordant with one of the three paramedic diagnoses. If non-concordant, two board-certified emergency physicians independently decided if the ChatGPT or the paramedic diagnosis was more likely to be correct. Results: ChatGPT-4 diagnosed 78/104 (75.0%) of PCRs correctly (95% confidence interval: 65.3–82.7%). Among the 26 cases of disagreement, judgment by the emergency physicians was that in 6/26 (23.0%) the paramedic diagnosis was more likely to be correct. There was only one case of the 104 (0.96%) where transport decisions based on the AI guided diagnosis would have been potentially dangerous to the patient (under-triage). Conclusions: In this study, overall accuracy of ChatGPT to diagnose patients based on their emergency medical services PCR was 75.0%. In cases where the ChatGPT diagnosis was considered less likely than paramedic diagnosis, most commonly the AI diagnosis was more critical than the paramedic diagnosis—potentially leading to over-triage. The under-triage rate was <1%. © 2025 National Association of EMS Physicians.",Yes,Rochelle,,,,,,,,,,
[How studies on curare contributed to the development of neurophysiological research in Brazil],"[Article in French; Abstract available in French from the publisher]

Pereira Santos R(1), Nardi AE(2), da Mota Gomes M(2).

Author information:
(1)Service of Neurology, Clementino Fraga Filho University Hospital, Federal 
University of Rio de Janeiro, Rio de Janeiro, Brésil.
(2)Laboratory of History of Psychiatry, Neurology, and Mental Health, Institute 
of Psychiatry Faculty of Medicine, Federal University of Rio de Janeiro, Rio de 
Janeiro, Brésil.

Curare is a poison obtained from different species of plants in South America, 
which was used in arrows by the natives. Its lethal paralyzing potential and 
mechanism of action began to be explored in the 19th century. In this article, 
we highlight the research on this poison and the fruitful exchanges between the 
Brazilian Emperor Dom Pedro II and the researchers João Baptista de Lacerda, 
Louis Couty and Alfred Vulpian who contributed to the development of 
experimental neurophysiology in Brazil. Vulpian found that curare does not 
affect the nerve itself, but acts between the nerves and the muscle, through a 
""ligand substance"" - this Vulpian's pioneering concept is often wrongly 
attributed to Claude Bernard. These prestigious scientists contributed to the 
transnational circulation of knowledge that later yielded in the preparation of 
curare purified extract used for convulsive therapy and anesthesia.

Publisher: TITLE: Importance des études transnationales sur le curare dans le 
développement de la recherche en neurophysiologie au Brésil.
ABSTRACT: Le curare, un poison obtenu à partir de différentes espèces de plantes 
en Amérique du Sud, était utilisé sur les flèches par les autochtones. Son 
potentiel paralysant mortel et son mécanisme d’action ont commencé à être 
explorés par les chercheurs au XIXe siècle. Dans cet article, nous rappelons 
l’historique des recherches sur ce poison et les échanges entre l’empereur 
brésilien Dom Pedro II et les chercheurs João Baptista de Lacerda, Louis Couty 
et Alfred Vulpian qui ont beaucoup contribué au développement scientifique 
brésilien. Vulpian a découvert que le curare n’affecte pas le nerf lui-même, 
mais agit entre celui-ci et le muscle, par l’intermédiaire d’une « substance de 
liaison » – ce concept développé par Vulpian est souvent attribué à tort à 
Claude Bernard. Les travaux pionniers de ces savants prestigieux ont 
ultérieurement abouti à la préparation d’extrait purifié de curare, d’intérêt 
thérapeutique majeur pour le traitement de convulsions et pour l’anesthésie.

© Société de Biologie, 2023.",No,Rochelle,,,,,,,,,,
Chat-GPT: Opportunities and Challenges in Child Mental Healthcare,"Mental health in children and young people is a global public health concern. With the increasing prevalence of mental illnesses and a significant treatment gap, Mental Health in children and adolescents is now a global public health concern. The development and extensive research in the field of Artificial Intelligence(AI) for healthcare has been quite promising. The emergence of AI based alternatives could be a viable solution for reducing mental health treatment gap for people belonging to low and middle income countries. Development of Chatbots like ChatGPT which is trained, using large amount of textual data from the internet, can revolutionize child and adolescent mental healthcare by acting as an effective assisting tool but a lot of caution is required for its safe and responsible use in times to come. © 2023, Professional Medical Publications. All rights reserved.",No,Rochelle,,,,,,,,,,
Can ChatGPT Generate Acceptable Case-Based Multiple-Choice Questions for Medical School Anatomy Exams? A Pilot Study on Item Difficulty and Discrimination,"Developing high-quality multiple-choice questions (MCQs) for medical school exams is effortful and time-consuming. In this study, we investigated the ability of ChatGPT to generate case-based anatomy MCQs with acceptable levels of item difficulty and discrimination for medical school exams. We used ChatGPT to generate case-based anatomy MCQs for an endocrine and urogenital system exam based on a framework for artificial intelligence (AI)-assisted item generation. The questions were evaluated by experts, approved by the department, and administered to 502 second-year medical students (372 Turkish-language, 130 English-language). The items were analyzed to determine the discrimination and difficulty indices. The item discrimination indices ranged from 0.29 to 0.54, indicating acceptable differentiation between high- and low-performing students. All items in Turkish (six out of six) and five out of six in English met the higher discrimination threshold (≥ 0.30) required for large-scale standardized tests. The item difficulty indices ranged from 0.41 to 0.89, most items falling within the moderate difficulty range (0.20–0.80). Therefore, it was concluded that ChatGPT can generate case-based anatomy MCQs with acceptable psychometric properties, offering a promising tool for medical educators. However, human expertise remains crucial for reviewing and refining AI-generated assessment items. Future research should explore AI-generated MCQs across various anatomy topics and investigate different AI models for question generation. © 2025 American Association of Clinical Anatomists and British Association of Clinical Anatomists.",No,Rochelle,,,,,,,,,,
The role of artificial intelligence in gynecologic and obstetric emergencies,"Objective: To investigate the potential of artificial intelligence (AI) in emergency medicine, focusing on its utility in triaging and managing acute gynecologic and obstetric emergencies. Methods and Materials: This feasibility study assessed Chat-GPT's performance in triaging and recommending management interventions for gynecologic and obstetric emergencies, using ten fictive cases. Five common conditions were modeled for each specialty. Chat-GPT was tasked with proposing triage classifications and providing immediate management recommendations. Human experts independently reviewed each case, classified triage categories, and proposed management. Following this, experts evaluated Chat-GPT's recommendations, rating the AI's responses on accuracy and clinical applicability. Results: Chat-GPT's recommendations demonstrated high concordance with human evaluators. Chat-GPT's triage classifications matched those of human experts in most cases, though minor discrepancies in urgency ratings were observed. The AÍs suggestions were mostly rated as “very good” to “excellent.” While Chat-GPT consistently delivered appropriate responses, some human evaluators noted slight differences in perceived urgency. Conclusions: This study highlights Chat-GPT's potential as a clinical support tool in emergency medicine. Chat-GPT provided structured, evidence-based recommendations comparable to those of experienced clinicians, especially for high-stakes gynecologic and obstetric emergencies. Although encouraging, these results highlight the value of utilizing AI in addition to human knowledge, as variations in urgency ratings and management nuances highlight the necessity of human supervision in crucial decision-making. © 2025",Yes,Rochelle,,,,,,,,,,
Battle of the brains: A comparison of human and ChatGPT health editorials,"2636. Joint Bone Spine. 2023 Sep;90(5):105610. doi: 10.1016/j.jbspin.2023.105610. Epub 
2023 Jul 11.

Battle of the brains: A comparison of human and ChatGPT health editorials.

Boissier MC(1), Bessis N(2).

Author information:
(1)Inserm U 1125, Bobigny, France; Li2P, université Sorbonne Paris Nord, Paris, 
France; Department of Rheumatology, Avicenne Hospital, Bobigny, France. 
Electronic address: marie-christophe.boissier@aphp.fr.
(2)Inserm U 1125, Bobigny, France; Li2P, université Sorbonne Paris Nord, Paris, 
France.

Comment on
    Joint Bone Spine. 2023 Sep;90(5):105607. doi: 10.1016/j.jbspin.2023.105607.",No,Rochelle,,,,,,,,,,
Enhancing Awareness and Self-diagnosis of Obstructive Sleep Apnea Using AI-Powered Chatbots: The Role of ChatGPT in Revolutionizing Healthcare,"Since OpenAI (San Francisco, CA) released its generative AI chatbot, ChatGPT, we are on the cusp of technological transformation. The tool is capable of generating text according to the input that the user adds to it. Due to its ability to imitate human speech tone while extracting encyclopedic knowledge, ChatGPT can be a platform for personalized patient interaction. Thus, it has the potential to revolutionize the healthcare system. Our study aims to evaluate how ChatGPT can answer the queries of patients suffering from obstructive sleep apnea and aid in self-diagnosis. By analyzing symptoms and guiding patients' behavior toward prevention, ChatGPT can play a major role in avoiding serious health repercussions that develop in the later course of obstructive sleep apnea.",No,Sully,,,,,,,,,,
Instructional support on first aid in choking by an artificial intelligence-powered chatbot,"716. Am J Emerg Med. 2023 Aug;70:200-202. doi: 10.1016/j.ajem.2023.06.010. Epub 2023 
Jun 10.

Instructional support on first aid in choking by an artificial 
intelligence-powered chatbot.

Birkun AA(1), Gautam A(2).

Author information:
(1)Department of General Surgery, Anesthesiology, Resuscitation and Emergency 
Medicine, Medical Academy named after S.I. Georgievsky of V.I. Vernadsky Crimean 
Federal University, Lenin Blvd, 5/7, Simferopol 295051, Russian Federation. 
Electronic address: birkunalexei@gmail.com.
(2)Regional Government Hospital, Una (H.P.), 174303, India.",No,Sully,,,,,,,,,,
"Retraction Note: Diagnostic power of ChatGPT 4 in distal radius fracture detection through wrist radiographs (Archives of Orthopaedic and Trauma Surgery, (2024), 144, 5, (2461-2467), 10.1007/s00402-024-05298-2)","Authors have retracted this article because they lack proper permissions for X-rays and radiological reports employed in this study. Wolfram Demmer, Sinan Mert, Benedikt Fuchs, Elisabeth M. Hass-Lützenberger, Riccardo E. Giunta, Patrick Stoerzer, and Johannes Brauer agree to this retraction. Tim Nuernberger has not responded to correspondence from the publisher about this retraction.",No,Rochelle,,,,,,,,,,
Bridging the Literacy Gap for Surgical Consents: An AI-Human Expert Collaborative Approach,"Background: Despite the importance of informed consent in healthcare, the readability and specificity of consent forms often impedes patients’ comprehension. Health literacy is linked to patient outcomes, making it essential to address these issues. This study investigates the use of GPT-4 to simplify surgical consent forms and introduces an AI-human expert collaborative approach to validate content appropriateness. Methods: Consent forms from multiple institutions were assessed for readability and simplified using GPT-4, with pre- and post-simplification readability metrics compared using nonparametric tests. Independent reviews by medical authors and a malpractice defense attorney were conducted. Finally, GPT-4's potential for generating de novo procedure-specific consent forms was assessed, with forms evaluated using a validated 8-item rubric and expert subspecialty surgeon review. Results: Analysis of 15 academic medical centers' consent forms revealed significant reductions in average reading time, word rarity, and passive sentence frequency (all P<0.05) following GPT-4-faciliated simplification. Readability improved from an average college freshman to an 8th-grade level (P=0.004), matching the average American's reading level. Medical and legal sufficiency consistency was confirmed. GPT-4 generated procedure-specific consent forms for five varied surgical procedures at an average 6th-grade reading level. These forms received perfect scores on a standardized consent form rubric and withstood scrutiny upon expert subspeciality surgeon review. Conclusions: This study demonstrates the first AI-human expert collaboration to enhance surgical consent forms, significantly improving readability without sacrificing clinical detail. Our framework could be extended to other patient communication materials, emphasizing clear communication and mitigating disparities related to health literacy barriers. Ensuring AI technologies are safely incorporated into clinical practice is crucial to reach a wide range of patients, including the most vulnerable.",No,Rochelle,,,,,,,,,,
The application of chatbot in gastroenterology nursing,"Objective: The advent of large language models has triggered a wave of technological advancements in the global AI dialogue system, which has been widely adopted in various fields including medical care. This research aims to investigate the potential of chatbots in the field of gastroenterology nursing. Methods: Two nurses compiled and categorized 20 relevant questions related to gastroenterology nursing, grouping them into four modules. Two chatbot-based AI language models were selected to answer all the questions. The satisfaction levels and satisfaction rates for each module were analyzed to evaluate the performance of the two chatbots. Results: Chatbot A received an overall satisfaction rate of 85% (with 9 very satisfied, 8 satisfied, and 3 dissatisfied responses), while chatbot B had a lower satisfaction rate of 45% (with 0 very satisfied, 9 satisfied, and 11 dissatisfied responses). The satisfaction rates for module 1 (pre-hospital care) were 60% for chatbot A and 20% for chatbot B. In module 2 (health education during hospitalization), chatbot A's satisfaction rate was 100%, while chatbot B's satisfaction was only 60%. For module 3 (continuing care after discharge), chatbot A's satisfaction rate was 100%, while chatbot B's was 40%. Finally, in module 4 (nursing management), chatbot A received an 80% satisfaction rate, compared to chatbot B's 60% satisfaction rate. Conclusion: The performance of chatbot in terms of health education and nursing management for patients during hospitalization is acceptable; Further optimization is needed in terms of pre hospitalization nursing interventions and post discharge continuity care. The performance of different chatbots varies, and intelligent large models need to be tailored to the medical or nursing fields to better apply in the field of digestive disease care. © 2023 The Authors",Yes,Rochelle,,,,,,,,,,
Can ChatGPT generate surgical multiple-choice questions comparable to those written by a surgeon?,"Background: This study aimed to determine whether surgical multiple-choice questions generated by ChatGPT are comparable to those written by human experts (surgeons). Methods: The study was conducted at a medical school and involved 112 fourth-year medical students. Based on five learning objectives in general surgery (colorectal, gastric, trauma, breast, thyroid), ChatGPT and surgeons generated five multiple-choice questions. No change was made to the ChatGPT-generated questions. The statistical properties of these questions, including correlations between two group of questions and correlations with total scores (item discrimination) in a general surgery clerkship exam, were reported. Results: There was a significant positive correlation between the ChatGPT-generated and human-written questions for one learning objective (colorectal). More importantly, only one ChatGPT-generated question (colorectal) achieved an acceptable discrimination level, while other four failed to achieve it. In contrast, human-written questions showed acceptable discrimination levels. Conclusion: While ChatGPT has the potential to generate multiple-choice questions comparable to human-written ones in specific contexts, the variability across surgical topics points to the need for human oversight and review before their use in exams. It is important to integrate artificial intelligence tools like ChatGPT with human expertise to enhance efficiency and quality. © Copyright © 2024 Baylor University Medical Center.",No,Rochelle,,,,,,,,,,
Large Language Models to Help Appeal Denied Radiotherapy Services,"PURPOSELarge language model (LLM) artificial intelligences may help physicians appeal insurer denials of prescribed medical services, a task that delays patient care and contributes to burnout. We evaluated LLM performance at this task for denials of radiotherapy services.METHODSWe evaluated generative pretrained transformer 3.5 (GPT-3.5; OpenAI, San Francisco, CA), GPT-4, GPT-4 with internet search functionality (GPT-4web), and GPT-3.5ft. The latter was developed by fine-Tuning GPT-3.5 via an OpenAI application programming interface with 53 examples of appeal letters written by radiation oncologists. Twenty test prompts with simulated patient histories were programmatically presented to the LLMs, and output appeal letters were scored by three blinded radiation oncologists for language representation, clinical detail inclusion, clinical reasoning validity, literature citations, and overall readiness for insurer submission.RESULTSInterobserver agreement between radiation oncologists' scores was moderate or better for all domains (Cohen's kappa coefficients: 0.41-0.91). GPT-3.5, GPT-4, and GPT-4web wrote letters that were on average linguistically clear, summarized provided clinical histories without confabulation, reasoned appropriately, and were scored useful to expedite the insurance appeal process. GPT-4 and GPT-4web letters demonstrated superior clinical reasoning and were readier for submission than GPT-3.5 letters (P <.001). Fine-Tuning increased GPT-3.5ft confabulation and compromised performance compared with other LLMs across all domains (P <.001). All LLMs, including GPT-4web, were poor at supporting clinical assertions with existing, relevant, and appropriately cited primary literature.CONCLUSIONWhen prompted appropriately, three commercially available LLMs drafted letters that physicians deemed would expedite appealing insurer denials of radiotherapy services. LLMs may decrease this task's clerical workload on providers. However, LLM performance worsened when fine-Tuned with a task-specific, small training data set.  © 2024 by American Society of Clinical Oncology.",No,Rochelle,,,,,,,,,,
Evaluation of LLMs Accuracy and Application in Oncology Principles and Practice,"Background: In recent years, large language models (LLMs) have offered physicians and patients a new avenue for tumor diagnosis and treatment, showcasing distinctive potential. Our study assessed 16 large language models (LLMs), including ChatGPT, DeepSeek, Claude, Grok and Llama, with particular focus on their diagnostic precision and answer comprehensibility in oncology-related inquiries, while investigating performance variations among these models.<br><br>Methods: We developed 549 single‐choice/true‐false and 10 short‐answer questions to evaluate clinical oncology knowledge based on standard textbooks, guidelines, and literature. Our study enrolled five participant groups for diagnostic and treatment testing in oncology and thoracic oncology, including attending physicians,resident physicians, academic professionals, the general public, and LLMs. We applied sixteen generative LLMs adopting oncologist personas to answer the questions independently. Readability was measured with the Flesch Reading Ease Score (FRES). Three consultant‐level oncology specialists independently rated the LLMs' responses to the short‐answer questions on a 3‐point accuracy scale.<br><br>Findings: The study revealed GPT o1, DeepSeek-R1, and GPT o3-mini achieved top accuracy (90.16%-89.44%) in an overall accuracy evaluation, while Llama-3.2-1B performed lowest at 32.42%. GPT o1 demonstrated highest accuracy in management of tumor complications and emergencies and hematologic tumor (97.50%, 94.44%), while DeepSeek-R1 excelled in molecular biology of cancer (94.44%) and achieved perfect accuracy (100%)​in cancer pain management. LLMs group outperformed all other groups with an accuracy of 89.39% in comprehensive test and achieved comparable performance to attending physicians in thoracic oncology testing (91.6% vs. 89.4%, p-value = 0.5887). The Flesch Reading Ease Score (FRES) evaluation revealed that DeepSeek-R1 had the highest response readability. Additionally,Grok3 and DeepSeek R1 outperformed other models in quality of response, garnering 50% “excellent” ratings.<br><br>Interpretation: These results guide oncology-specific LLM selection through clinical evaluation of capabilities and limitations, with future refinements enhancing utility in optimizing cancer care efficiency and accuracy.FundingNone.",Yes,Rochelle,,,,,,,,,,
Improving medical reasoning through retrieval and self-reflection with retrieval-augmented large language models,"3900. Bioinformatics. 2024 Jun 28;40(Suppl 1):i119-i129. doi: 
10.1093/bioinformatics/btae238.

Improving medical reasoning through retrieval and self-reflection with 
retrieval-augmented large language models.

Jeong M(1), Sohn J(1), Sung M(2), Kang J(1)(3).

Author information:
(1)Department of Computer Science, Korea University, Seoul 02841, Republic of 
Korea.
(2)Department of Software Convergence, School of Computing, Kyung Hee 
University, Republic of Korea.
(3)AIGEN Sciences, Seoul 04778, Republic of Korea.

SUMMARY: Recent proprietary large language models (LLMs), such as GPT-4, have 
achieved a milestone in tackling diverse challenges in the biomedical domain, 
ranging from multiple-choice questions to long-form generations. To address 
challenges that still cannot be handled with the encoded knowledge of LLMs, 
various retrieval-augmented generation (RAG) methods have been developed by 
searching documents from the knowledge corpus and appending them unconditionally 
or selectively to the input of LLMs for generation. However, when applying 
existing methods to different domain-specific problems, poor generalization 
becomes apparent, leading to fetching incorrect documents or making inaccurate 
judgments. In this paper, we introduce Self-BioRAG, a framework reliable for 
biomedical text that specializes in generating explanations, retrieving 
domain-specific documents, and self-reflecting generated responses. We utilize 
84k filtered biomedical instruction sets to train Self-BioRAG that can assess 
its generated explanations with customized reflective tokens. Our work proves 
that domain-specific components, such as a retriever, domain-related document 
corpus, and instruction sets are necessary for adhering to domain-related 
instructions. Using three major medical question-answering benchmark datasets, 
experimental results of Self-BioRAG demonstrate significant performance gains by 
achieving a 7.2% absolute improvement on average over the state-of-the-art 
open-foundation model with a parameter size of 7B or less. Similarly, 
Self-BioRAG outperforms RAG by 8% Rouge-1 score in generating more proficient 
answers on two long-form question-answering benchmarks on average. Overall, we 
analyze that Self-BioRAG finds the clues in the question, retrieves relevant 
documents if needed, and understands how to answer with information from 
retrieved documents and encoded knowledge as a medical expert does. We release 
our data and code for training our framework components and model weights (7B 
and 13B) to enhance capabilities in biomedical and clinical domains.
AVAILABILITY AND IMPLEMENTATION: Self-BioRAG is available at 
https://github.com/dmis-lab/self-biorag.

© The Author(s) 2024. Published by Oxford University Press.",No,Rochelle,,,,,,,,,,
Patches in endoscopic surgical repairs of congenital diaphragmatic hernia: systematic review,"Background: Endoscopic patch repairs (ePR) are routinely performed using thoracoscopic and laparoscopic approaches in large-size CDH. This systematic review characterises the epidemiology of endoscopic congenital diaphragmatic hernia (CDH) repair, patch repairs (PR), techniques of insertion, patch types used, and correlation with recurrences and morbidities. Methods: Systematic search was conducted across MEDLINE, EMBASE, Scopus, and Web of Science. Search terms were: congenital diaphragmatic hernia, endoscopic, prosthetic patch repair and recurrence. Results: Twenty articles were included, reporting data on 608 patients of whom 381 underwent endoscopic repair (thoracoscopic n = 336, laparoscopic n = 45), 282 underwent PR, and 151 underwent ePR (thoracoscopic PR n = 121, laparoscopic PR n = 30). Eleven patch materials were identified: Goretex n = 80, Permacol n = 18, Bard Sauvage Filamentous Fabric n = 11, Goretex/Marlex n = 10, Surgisis n = 10, Dacron n = 8, Dualmesh n = 8, Dualmesh plus n = 2, Parietex n = 2, Alloderm n = 1, and Goretex/Epiflex n = 1. There were no recurrences following laparoscopic PR and 19 (15.7%) following thoracoscopic PR. Overall ePR recurrence rate was 12.6%. Synthetic non-resorbable (SNOR) was the most common biomaterial subtype (n = 109), followed by natural resorbable (NR) (n = 29), natural and synthetic non-resorbable (NSNOR) (n = 11), and natural and synthetic resorbable (NSR) (n = 2). NSR had no recurrences, recurrence rate for NSNOR was 9.1% (n = 1), SNOR 12.8% (n = 14) and NR 13.8% (n = 4). Conclusion: This study identified 151 ePR in CDH, highlighting the 11 biomaterials utilised and significant variations in recurrence rates between patch types and endoscopic techniques. With Goretex accounting for over half of repairs and six patch types used infrequently, it remains difficult to determine the optimal biomaterial with regard to recurrence rate.",No,Rochelle,,,,,,,,,,
Assessing the role of GPT-4 in thyroid ultrasound diagnosis and treatment recommendations: enhancing interpretability with a chain of thought approach,"Background: As artificial intelligence (AI) becomes increasingly prevalent in the medical field, the effectiveness of AI-generated medical reports in disease diagnosis remains to be evaluated. ChatGPT is a large language model developed by open AI with a notable capacity for text abstraction and comprehension. This study aimed to explore the capabilities, limitations, and potential of Generative Pre-trained Transformer (GPT)-4 in analyzing thyroid cancer ultrasound reports, providing diagnoses, and recommending treatment plans. Methods: Using 109 diverse thyroid cancer cases, we evaluated GPT-4's performance by comparing its generated reports to those from doctors with various levels of experience. We also conducted a Turing Test and a consistency analysis. To enhance the interpretability of the model, we applied the Chain of Thought (CoT) method to deconstruct the decision-making chain of the GPT model. Results: GPT-4 demonstrated proficiency in report structuring, professional terminology, and clarity of expression, but showed limitations in diagnostic accuracy. In addition, our consistency analysis highlighted certain discrepancies in the AI's performance. The CoT method effectively enhanced the interpretability of the AI's decision-making process. Conclusions: GPT-4 exhibits potential as a supplementary tool in healthcare, especially for generating thyroid gland diagnostic reports. Our proposed online platform, ""ThyroAIGuide"", alongside the CoT method, underscores the potential of AI to augment diagnostic processes, elevate healthcare accessibility, and advance patient education. However, the journey towards fully integrating AI into healthcare is ongoing, requiring continuous research, development, and careful monitoring by medical professionals to ensure patient safety and quality of care. © 2024 AME Publishing Company. All rights reserved.",Yes,Rochelle,,,,,,,,,,
ChatGPT Assisting Diagnosis of Neuro-ophthalmology Diseases Based on Case Reports,"Purpose: To evaluate the efficiency of large language models (LLMs) including ChatGPT to assist in diagnosing neuro-ophthalmic diseases based on case reports. Design: Prospective study Subjects or Participants: We selected 22 different case reports of neuro-ophthalmic diseases from a publicly available online database. These cases included a wide range of chronic and acute diseases that are commonly seen by neuro-ophthalmic sub-specialists. Methods: We inserted the text from each case as a new prompt into both ChatGPT v3.5 and ChatGPT Plus v4.0 and asked for the most probable diagnosis. We then presented the exact information to two neuro-ophthalmologists and recorded their diagnoses followed by comparison to responses from both versions of ChatGPT. Main Outcome Measures: Diagnostic accuracy in terms of number of correctly diagnosed cases among diagnoses. Results: ChatGPT v3.5, ChatGPT Plus v4.0, and the two neuro-ophthalmologists were correct in 13 (59%), 18 (82%), 19 (86%), and 19 (86%) out of 22 cases, respectively. The agreement between the various diagnostic sources were as follows: ChatGPT v3.5 and ChatGPT Plus v4.0, 13 (59%); ChatGPT v3.5 and the first neuro-ophthalmologist, 12 (55%); ChatGPT v3.5 and the second neuro-ophthalmologist, 12 (55%); ChatGPT Plus v4.0 and the first neuro-ophthalmologist, 17 (77%); ChatGPT Plus v4.0 and the second neuro-ophthalmologist, 16 (73%); and first and second neuro-ophthalmologists 17 (17%). Conclusions: The accuracy of ChatGPT v3.5 and ChatGPT Plus v4.0 in diagnosing patients with neuro-ophthalmic diseases was 59% and 82%, respectively. With further development, ChatGPT Plus v4.0 may have potential to be used in clinical care settings to assist clinicians in providing quick, accurate diagnoses of patients in neuro-ophthalmology. The applicability of using LLMs like ChatGPT in clinical settings that lack access to subspeciality trained neuro-ophthalmologists deserves further research.",Yes,Rochelle,,,,,,,,,,
Feats: A database of semantic features for early produced noun concepts,"3279. Behav Res Methods. 2024 Apr;56(4):3259-3279. doi: 10.3758/s13428-023-02242-x. 
Epub 2023 Dec 26.

Feats: A database of semantic features for early produced noun concepts.

Borovsky A(#)(1), Peters RE(#)(2), Cox JI(3), McRae K(4).

Author information:
(1)Department of Speech, Language, and Hearing Sciences, Purdue University, West 
Lafayette, IN, 47906, USA. aborovsky@purdue.edu.
(2)Duolingo, Pittsburgh, PA, USA.
(3)J. Crayton Pruitt Family Department of Biomedical Engineering, University of 
Florida, Gainesville, FL, USA.
(4)Department of Psychology and Brain & Mind Institute, University of Western 
Ontario, London, Canada.
(#)Contributed equally

Semantic feature production norms have several desirable characteristics that 
have supported models of representation and processing in adults. However, 
several key challenges have limited the use of semantic feature norms in studies 
of early language acquisition. First, existing norms provide uneven and 
inconsistent coverage of early-acquired concepts that are typically produced and 
assessed in children under the age of three, which is a time of tremendous 
growth of early vocabulary skills. Second, it is difficult to assess the degree 
to which young children may be familiar with normed features derived from these 
adult-generated datasets. Third, it has been difficult to adopt standard methods 
to generate semantic network models of early noun learning. Here, we introduce 
Feats-a tool that was designed to make headway on these challenges by providing 
a database, the Language Learning and Meaning Acquisition (LLaMA) lab Noun Norms 
that extends a widely used set of feature norms McRae et al. Behavior Research 
Methods 37, 547-559, (2005) to include full coverage of noun concepts on a 
commonly used early vocabulary assessment. Feats includes several tools to 
facilitate exploration of features comprising early-acquired nouns, assess the 
developmental appropriateness of individual features using toddler-accessibility 
norms, and extract semantic network statistics for individual vocabulary 
profiles. We provide a tutorial overview of Feats. We additionally validate our 
approach by presenting an analysis of an overlapping set of concepts collected 
across prior and new data collection methods. Furthermore, using network graph 
analyses, we show that the extended set of norms provides novel, reliable 
results given their enhanced coverage.

© 2023. The Psychonomic Society, Inc.",No,Rochelle,,,,,,,,,,
“Application and accuracy of artificial intelligence-derived large language models in patients with age related macular degeneration”,"Introduction: Age-related macular degeneration (AMD) affects millions of people globally, leading to a surge in online research of putative diagnoses, causing potential misinformation and anxiety in patients and their parents. This study explores the efficacy of artificial intelligence-derived large language models (LLMs) like in addressing AMD patients' questions. Methods: ChatGPT 3.5 (2023), Bing AI (2023), and Google Bard (2023) were adopted as LLMs. Patients’ questions were subdivided in two question categories, (a) general medical advice and (b) pre- and post-intravitreal injection advice and classified as (1) accurate and sufficient (2) partially accurate but sufficient and (3) inaccurate and not sufficient. Non-parametric test has been done to compare the means between the 3 LLMs scores and also an analysis of variance and reliability tests were performed among the 3 groups. Results: In category a) of questions, the average score was 1.20 (± 0.41) with ChatGPT 3.5, 1.60 (± 0.63) with Bing AI and 1.60 (± 0.73) with Google Bard, showing no significant differences among the 3 groups (p = 0.129). The average score in category b was 1.07 (± 0.27) with ChatGPT 3.5, 1.69 (± 0.63) with Bing AI and 1.38 (± 0.63) with Google Bard, showing a significant difference among the 3 groups (p = 0.0042). Reliability statistics showed Chronbach’s α of 0.237 (range 0.448, 0.096–0.544). Conclusion: ChatGPT 3.5 consistently offered the most accurate and satisfactory responses, particularly with technical queries. While LLMs displayed promise in providing precise information about AMD; however, further improvements are needed especially in more technical questions. © 2023, The Author(s).",Yes,Rochelle,,,,,,,,,,
Generative AI for Drug Discovery: A GPT-2 and LSTM Based Models for Designing EGFR Inhibitors,"The design of novel EGFR inhibitors is a critical focus in cancer drug discovery. This study leverages generative AI models, specifically fine-tuned GPT-2 and LSTM architectures, to generate new chemical structures targeting the Epidermal Growth Factor Receptor (EGFR). The models were trained on a curated dataset of approximately 500,000 bioactive ligands from the ChEMBL database, with SMILES strings as input. After generating a batch of 1,000 molecules, post-generation filtering was applied based on Lipinski's rule of five, Quantitative Estimate of Drug-likeness (QED), and Synthetic Accessibility Scores (SAS) to ensure drug-like properties. Molecular docking studies were performed using PyRx with AutoDock Vina, focusing on the crystal structure of EGFR (PDB ID: 1M17). The LSTM model outperformed GPT-2, achieving a higher validity rate (90.98% vs. 52.27%) and similar uniqueness rates, while also producing molecules with stronger binding affinities, ranging from -9.4 to -10.4 kcal/mol. The results indicate that the LSTM model is more effective for generating chemically valid EGFR inhibitors, offering promising candidates for further experimental validation. This study demonstrates the potential of generative AI to accelerate the identification of effective cancer therapeutics.",No,Rochelle,,,,,,,,,,
"Breaking Bones, Breaking Barriers: ChatGPT, DeepSeek, and Gemini in Hand Fracture Management","Background: Hand fracture management requires precise diagnostic accuracy and complex decision-making. Advances in artificial intelligence (AI) suggest that large language models (LLMs) may assist or even rival traditional clinical approaches. This study evaluates the effectiveness of ChatGPT-4o, DeepSeek-V3, and Gemini 1.5 in diagnosing and recommending treatment strategies for hand fractures compared to experienced surgeons. Methods: A retrospective analysis of 58 anonymized hand fracture cases was conducted. Clinical details, including fracture site, displacement, and soft-tissue involvement, were provided to the AI models, which generated management plans. Their recommendations were compared to actual surgeon decisions, assessing accuracy, precision, recall, and F1 score. Results: ChatGPT-4o demonstrated the highest accuracy (98.28%) and recall (91.74%), effectively identifying most correct interventions but occasionally proposing extraneous options (precision 58.48%). DeepSeek-V3 showed moderate accuracy (63.79%), with balanced precision (61.17%) and recall (57.89%), sometimes omitting correct treatments. Gemini 1.5 performed poorly (accuracy 18.97%), with low precision and recall, indicating substantial limitations in clinical decision support. Conclusions: AI models can enhance clinical workflows, particularly in radiographic interpretation and triage, but their limitations highlight the irreplaceable role of human expertise in complex hand trauma management. ChatGPT-4o demonstrated promising accuracy but requires refinement. Ethical concerns regarding AI-driven medical decisions, including bias and transparency, must be addressed before widespread clinical implementation. © 2025 by the authors.",Yes,Rochelle,,,,,,,,,,
ChatGPT and oncological applications: comment,"This letter to editor discusses on the publication on large language models for oncological applications. Pros and Cons for ChatGPT are discussed. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",No,Rochelle,,,,,,,,,,
Symptom-BERT: Enhancing Cancer Symptom Detection in EHR Clinical Notes,"Context: Extracting cancer symptom documentation allows clinicians to develop highly individualized symptom prediction algorithms to deliver symptom management care. Leveraging advanced language models to detect symptom data in clinical narratives can significantly enhance this process. Objective: This study uses a pretrained large language model to detect and extract cancer symptoms in clinical notes. Methods: We developed a pretrained language model to identify cancer symptoms in clinical notes based on a clinical corpus from the Enterprise Data Warehouse for Research at a healthcare system in the Midwestern United States. This study was conducted in 4 phases:1 pretraining a Bio-Clinical BERT model on one million unlabeled clinical documents,2 fine-tuning Symptom-BERT for detecting 13 cancer symptom groups within 1112 annotated clinical notes,3 generating 180 synthetic clinical notes using ChatGPT-4 for external validation, and4 comparing the internal and external performance of Symptom-BERT against a non-pretrained version and six other BERT implementations. Results: The Symptom-BERT model effectively detected cancer symptoms in clinical notes. It achieved results with a micro-averaged F1-score of 0.933, an AUC of 0.929 internally, and 0.831 and 0.834 externally. Our analysis shows that physical symptoms, like Pruritus, are typically identified with higher performance than psychological symptoms, such as anxiety. Conclusion: This study underscores the transformative potential of specialized pretraining on domain-specific data in boosting the performance of language models for medical applications. The Symptom-BERT model's exceptional efficacy in detecting cancer symptoms heralds a groundbreaking stride in patient-centered AI technologies, offering a promising path to elevate symptom management and cultivate superior patient self-care outcomes. © 2024 American Academy of Hospice and Palliative Medicine",Yes,Rochelle,,,,,,,,,,
ChatGPT for assessing risk of bias of randomized trials using the RoB 2.0 tool: A methods study,"Background: Internationally accepted standards for systematic reviews necessitate assessment of the risk of bias of primary studies. Assessing risk of bias, however, can be time- and resource-intensive. AI-based solutions may increase efficiency and reduce burden. Objective: To evaluate the reliability of ChatGPT for performing risk of bias assessments of randomized trials using the revised risk of bias tool for randomized trials (RoB 2.0). Methods: We sampled recently published Cochrane systematic reviews of medical interventions (up to October 2023) that included randomized controlled trials and assessed risk of bias using the Cochrane-endorsed revised risk of bias tool for randomized trials (RoB 2.0). From each eligible review, we collected data on the risk of bias assessments for the first three reported outcomes. Using ChatGPT-4, we assessed the risk of bias for the same outcomes using three different prompts: a minimal prompt including limited instructions, a maximal prompt with extensive instructions, and an optimized prompt that was designed to yield the best risk of bias judgements. The agreement between ChatGPT's assessments and those of Cochrane systematic reviewers was quantified using weighted kappa statistics. Results: We included 34 systematic reviews with 157 unique trials. We found the agreement between ChatGPT and systematic review authors for assessment of overall risk of bias to be 0.16 (95% CI: 0.01 to 0.3) for the maximal ChatGPT prompt, 0.17 (95% CI: 0.02 to 0.32) for the optimized prompt, and 0.11 (95% CI: -0.04 to 0.27) for the minimal prompt. For the optimized prompt, agreement ranged between 0.11 (95% CI: -0.11 to 0.33) to 0.29 (95% CI: 0.14 to 0.44) across risk of bias domains, with the lowest agreement for the deviations from the intended intervention domain and the highest agreement for the missing outcome data domain. Conclusion: Our results suggest that ChatGPT and systematic reviewers only have “slight” to “fair” agreement in risk of bias judgements for randomized trials. ChatGPT is currently unable to reliably assess risk of bias of randomized trials. We advise against using ChatGPT to perform risk of bias assessments. There may be opportunities to use ChatGPT to streamline other aspects of systematic reviews, such as screening of search records or collection of data.",No,Rochelle,,,,,,,,,,
"Perceptions of ChatGPT in healthcare: usefulness, trust, and risk","Introduction: This study explores the perceptions of ChatGPT in healthcare settings in Taiwan, focusing on its usefulness, trust, and associated risks. As AI technologies like ChatGPT increasingly influence various sectors, their potential in public health education, promotion, medical education, and clinical practice is significant but not without challenges. The study aims to assess how individuals with and without healthcare-related education perceive and adopt ChatGPT, contributing to a deeper understanding of AI’s role in enhancing public health outcomes. Methods: An online survey was conducted among 659 university and graduate students, all of whom had prior experience using ChatGPT. The survey measured perceptions of ChatGPT’s ease of use, novelty, usefulness, trust, and risk, particularly within clinical practice, medical education, and research settings. Multiple linear regression models were used to analyze how these factors influence perception in healthcare applications, comparing responses between healthcare majors and non-healthcare majors. Results: The study revealed that both healthcare and non-healthcare majors find ChatGPT more useful in medical education and research than in clinical practice. Regression analysis revealed that for healthcare majors, general trust is crucial for ChatGPT’s adoption in clinical practice and influences its use in medical education and research. For non-healthcare majors, novelty, perceived general usefulness, and trust are key predictors. Interestingly, while healthcare majors were cautious about ease of use, fearing it might increase risk, non-healthcare majors associated increased complexity with greater trust. Conclusion: This study highlights the varying expectations between healthcare and non-healthcare majors regarding ChatGPT’s role in healthcare. The findings suggest the need for AI applications to be tailored to address specific user needs, particularly in clinical practice, where trust and reliability are paramount. Additionally, the potential of AI tools like ChatGPT to contribute to public health education and promotion is significant, as these technologies can enhance health literacy and encourage behavior change. These insights can inform future healthcare practices and policies by guiding the thoughtful and effective integration of AI tools like ChatGPT, ensuring they complement clinical judgment, enhance educational outcomes, support research integrity, and ultimately contribute to improved public health outcomes. Copyright © 2024 Chen, Kuo and Chang.",No,Rochelle,,,,,,,,,,
A deep hierarchy of predictions enables assignment of semantic roles in online speech comprehension,"Understanding speech requires mapping fleeting and often ambiguous soundwaves to meaning. While humans are known to exploit their capacity to contextualize to facilitate this process, how internal knowledge is deployed on-line remains an open question. Here, we present a model that extracts multiple levels of information from continuous speech online. The model applies linguistic and nonlinguistic knowledge to speech processing, by periodically generating top-down predictions and incorporating bottom-up incoming evidence in a nested temporal hierarchy. We show that a nonlinguistic context level provides semantic predictions informed by sensory inputs, which are crucial for disambiguating among multiple meanings of the same word. The explicit knowledge hierarchy of the model enables a more holistic account of the neurophysiological responses to speech compared to using lexical predictions generated by a neural-network language model (GPT-2). We also show that hierarchical predictions reduce peripheral processing via minimizing uncertainty and prediction error. With this proof-of-concept model we demonstrate that the deployment of hierarchical predictions is a possible strategy for the brain to dynamically utilize structured knowledge and make sense of the speech input.",No,Rochelle,,,,,,,,,,
Accuracy of the Information on Sudden Sensorineural Hearing Loss From Chat Generated Pre-Trained Transformer; [Chat Generated Pre-Trained Transformer를 통해 얻은 돌발성 감각신경성 난청 정보의 정확성],"Background and Objectives Chat generated pre-trained transformer (ChatGPT) is a conversational artificial intelligence model, which has recently attracted worldwide attention by enabling natural conversations based on huge information from deep learing in various fields. Several studies have reported usefullness and reliability of medical information obtained by ChatGPT, but there are no studies explaining reliability and accuracy in the field of otorhinolarynoglogy. On this regard, we investigated the accuracy of information on sudden sensorineural hearing loss obtained by ChatGPT. Materials and Method Twenty-five questions and answeres related to sudden sensorineural hearing loss were recorded from ChatGPT based on textbook from Korean Society of Otorhinolaryngology-Head and Neck Surgery and Clinical Guidelines of American Academy of Otolaryngology-Head and Neck Surgery. Answers were shown to one specialist in otorhinolaryngoly in a blind test and asked to assess their accuracy. Each question was rated as ‘accurate’ or ‘inaccurate.’ If the contents were not found in the textbook or the guidelines, it was rated as ‘unreliable.’ Results Of the 25 questions, 19 (76%) were identified as ‘accurate,’ 6 (24%) were ‘inaccurate,’ and 0 (0%) were ‘unreliable.’ Questions about definition, prevalence, hearing rehabilitation, diagnosis and treatment were found to be more accurate than the average, while causes and prognosis were less accurate than the average. Conclusion The information on sudden sensorineurla hearing loss obatined from ChatGPT was quite accurate. It is expected to provide substantial help to patients and doctors. As medicine and medical artificial intelligence develop together, further research is needed on reliability and accuracy in vaious diseases and fields of otorhinolaryngology-head and neck surgery. Copyright© 2024.",Yes,Rochelle,,,,,,,,,,
"ChatGPT in research and health professions education: challenges, opportunities, and future directions","ChatGPT was launched by OpenAI in November 2022 and within 2 months it became popular across a wide range of industrial, social, and intellectual contexts including healthcare education. This article reviews the impact of ChatGPT on research and health professions education by identifying the challenges and opportunities in these fields. Additionally, it aims to provide future directions to mitigate the challenges and maximize the benefits of this technology in health professions education. ChatGPT has the potential to revolutionize the field of research and health professions education. However, there is a need to address ethical concerns and limitations such as lack of real-time data, data inaccuracies, biases, plagiarism, and copyright infringement before its implementation. Future research can highlight the ways to mitigate these challenges; establish guidelines and policies; and explore how effectively ChatGPT and other AI tools can be used in the field of research and healthcare professions education. © The Author(s) 2023.",No,Rochelle,,,,,,,,,,
Enhancing semantical text understanding with fine-tuned large language models: A case study on Quora Question Pair duplicate identification,"Semantical text understanding holds significant importance in natural language processing (NLP). Numerous datasets, such as Quora Question Pairs (QQP), have been devised for this purpose. In our previous study, we developed a Siamese Convolutional Neural Network (S-CNN) that achieved an F1 score of 82.02% (95% C.I.: 81.83%-82.20%). Given the growing attention toward large language models (LLMs) like ChatGPT, we aimed to explore their effectiveness in text similarity tasks. In this research, we leveraged 5 pretrained LLMs, conducted various fine-tuning approaches (prompt engineering, n-shot learning, and supervised learning using the low-rank adaptation [LoRA]), and compared their performance using F1 score. To ensure a fair comparison, we followed our previous study’s design and dataset by employing a 10-fold cross-validation for supervised model training and evaluation. Additionally, we conducted a secondary study by introducing a recent larger LLM with 70B parameters and comparing it with the 7B model using the GLUE benchmark, and both models were finetuned with the corpus. The fine-tuned LLaMA model with 7B parameters (qLLaMA_LoRA-7B) using 100,000 QQP corpus yielded the best results, achieving an F1 score of 84.9% (95% C.I.: 84.13%-85.67%), which outperformed the Alpaca_LoRA-65B (finetuned based on LLaMA-65B) (F1: 64.98% [64.72%-65.25%]; P<0.01) and had a 3% improvement compared to our previously published best model, S-CNN. The finetuned LLaMA3.1-70B (qLLaMA3.1_LoRA-70B) with 70B parameters (F1: 74.4%) outperformed the qLLaMA_LoRA-7B (F1: 71.9%) using the GLUE benchmark. The study demonstrated an effective LLM finetuning framework, which highlights the importance of finetuning LLMs for improved performance. Our task-specific supervised finetuning demonstrated improved LLM performance compared to larger pretrained models with or without n-shot learning; moreover, finetuning a larger LLM further improved performance compared to finetuning a smaller LLM. Our LLM-based finetuning framework may potentially improve various document similarity tasks, such as matching resumes with job descriptions, recommending subject-matter experts, or identifying potential reviewers for grant proposals or manuscript submissions.",No,Rochelle,,,,,,,,,,
Proceedings of the 2024 annual meeting of European Association for the Study of Diabetes: Advances in management of diabetes and metabolic diseases; [2024年欧洲糖尿病研究协会年会会议纪要：糖尿病及代谢相关疾病管理的学术进展],"The 60th annual meeting of the European Association for the Study of Diabetes(EASD), held in Madrid, Spain, in September 2024, convened leading physicians and researchers from more than 130 countries. This premier event shared and discussed advances in diagnosis and treatment, as well as future trends in diabetes and metabolic disease research. Key topics included the presentation of the Claude Bernard Prize, advancements in diabetes management strategies, the interplay between obesity and diabetes, novel therapeutic developments, and emerging diagnostic and treatment approaches for metabolic dysfunction-associated steatotic liver disease. © 2025 Chinese Medical Association.",No,Rochelle,,,,,,,,,,
Leveraging ChatGPT-4 for Enhanced Education: Personalized Problem-Solving and Consistent Learning,"Generative AI has revolutionized education by providing personalized learning experiences, enabling interactive content creation, and offering innovative approaches to problem-solving, significantly enhancing student engagement and understanding of complex subjects. This research demonstrates that ChatGPT-4, a cutting-edge generative AI, can significantly enhance the educational process, particularly in complex subjects like Machine Learning. By customizing ChatGPT-4 into a robot to replicate specific teaching methodologies, it supports students in mastering problem-solving techniques that align with their instructors' preferences. This adaptation not only aids in problem-solving but also in generating quizzes and handling diverse learning challenges in a manner consistent with classroom teachings. The key advantage of this robot lies in its ability to offer tailored learning experiences, bridging the gap between theoretical knowledge and practical application, thereby ensuring students are better prepared for examinations. The positive impact of such AI integration into education points toward a future where learning is more interactive, personalized, and effective, highlighting the transformative potential of AI in enhancing both student engagement and comprehension.  © 2024 IEEE.",No,Rochelle,,,,,,,,,,
The potential role of ChatGPT and artificial intelligence in anatomy education: a conversation with ChatGPT,"Purpose: A recent study published in the JMIR Med Educ Journal explored the potential impact of the Generative Pre-Train (ChatGPT), a generative language model, on medical education, research, and practice. In the present study, an interview with ChatGPT was conducted to determine its capabilities and potential for use in anatomy education (AE) and anatomy research (AR). Methods: The study involved 18 questions asked of ChatGPT after obtaining an online subscription to the 4th edition. The questions were randomly selected and evaluated based on accuracy, relevance, and comprehensiveness. Results: The ChatGPT provided accurate and well-structured anatomical descriptions, including clinical relevance and relationships between structures. The chatbot also offered concise summaries of chapters and helpful advice on anatomical terminology, even with complex terms. However, when it came to anatomical variants and their clinical significance, the chatbot’s replies were inadequate unless variants were systematically classified into types. ChatGPT-4 generated multiple-choice quizzes and matching questions of varying difficulty levels, as well as summaries of articles when presented with text. However, the chatbot recognized its limitations in terms of accuracy, as did the authors of the current study. Conclusion: ChatGPT-4 can be a valuable interactive educational tool for students in the field of anatomy, encouraging engagement and further questions. However, it cannot replace the critical role of educators and should be used as a complementary tool. Future research should establish guidelines for ChatGPT’s optimal use and application in medical education. © 2023, The Author(s).",No,Rochelle,,,,,,,,,,
Cell2Sentence: Teaching Large Language Models the Language of Biology,"We introduce Cell2Sentence (C2S), a novel method to directly adapt large language models to a biological context, specifically single-cell transcriptomics. By transforming gene expression data into”cell sentences,” C2S bridges the gap between natural language processing and biology. We demonstrate cell sentences enable the finetuning of language models for diverse tasks in biology, including cell generation, complex cell-type annotation, and direct data-driven text generation. Our experiments reveal that GPT-2, when fine-tuned with C2S, can generate biologically valid cells based on cell type inputs, and accurately predict cell types from cell sentences. This illustrates that language models, through C2S finetuning, can acquire a significant understanding of single-cell biology while maintaining robust text generation capabilities. C2S offers a flexible, accessible framework to integrate natural language processing with transcriptomics, utilizing existing models and libraries for a wide range of biological",No,Rochelle,,,,,,,,,,
Delving into PubMed Records: Some Terms in Medical Writing Have Drastically Changed after the Arrival of ChatGPT,"Objective: This study aims to investigate whether the usage of specific terminologies has increased, focusing on words and phrases frequently reported as overused by ChatGPT. Materials and Methods: The list of 117 potentially AI-influenced terms was curated based on posts and comments from anonymous ChatGPT users, and 75 common academic phrases were used as controls. PubMed records from 2000 to 2024 (until April) were analyzed to track the frequency of these terms. Usage trends were normalized using a modified Z-score transformation. A linear mixed-effects model was used to compare the usage of potentially AI-influenced terms to common academic phrases over time. Results: A total of 26,403,493 PubMed records were investigated. Among the potentially AI-influenced terms, 74 displayed a meaningful increase (modified Z-score ≥ 3.5) in usage in 2024. The linear mixed-effects model showed a significant effect of potentially AI-influenced terms on usage frequency compared to common academic phrases (p < 0.001). The usage of potentially AI-influenced terms showed a noticeable increase starting in 2020. Discussion: This study revealed that certain words and phrases, such as ""delve,"" ""underscore,"" ""meticulous,"" and ""commendable,"" have been used more frequently in medical and biological fields since the introduction of ChatGPT. The usage rate of these words/phrases has been increasing for several years before the release of ChatGPT, suggesting that ChatGPT might have accelerated the popularity of scientific expressions that were already gaining traction. Conclusions: The identified terms in this study can provide valuable insights for both LLM users, educators, and supervisors in these fields.",No,Rochelle,,,,,,,,,,
Inter-Rater Disagreements in Applying the Montreal Classification for Crohn's Disease: The Five-Nations Survey Study,"Background: The Montreal classification has been widely used in Crohn's disease since 2005 to categorize patients by the age of onset (A), disease location (L), behavior (B), and upper gastrointestinal tract and perianal involvement. With evolving management paradigms in Crohn's disease, we aimed to assess the performance of gastroenterologists in applying the Montreal classification. Methods: An online survey was conducted among participants at an international educational conference on inflammatory bowel diseases. Participants classified 20 theoretical Crohn's disease cases using the Montreal classification. Agreement rates with the inflammatory bowel diseases board (three expert gastroenterologists whose consensus rating was considered the gold standard) were calculated for gastroenterologist specialists and fellows/specialists with ≤ 2 years of clinical experience. A majority vote < 75% among participants was considered a notable disagreement. The same cases were classified using three large language models (LLMs), ChatGPT-4, Claude-3, and Gemini-1.5, and assessed for agreement with the board and gastroenterologists. Fleiss Kappa was used to assess within-group agreement. Results: Thirty-eight participants from five countries completed the survey. In defining the Montreal classification as a whole, specialists (21/38 [55%]) had a higher agreement rate with the board compared to fellows/young specialists (17/38 [45%]) (58% vs. 49%, p = 0.012) and to LLMs (58% vs. 18%, p < 0.001). Disease behavior classification was the most challenging, with 76% agreement among specialists and fellows/young specialists and 48% among LLMs compared to the inflammatory bowel diseases board. Regarding disease behavior, within-group agreement was moderate (specialists: k = 0.522, fellows/young specialists: k = 0.532, LLMs: k = 0.577; p < 0.001 for all). Notable points of disagreement included: defining disease behavior concerning obstructive symptoms, assessing disease extent via video capsule endoscopy, and evaluating treatment-related reversibility of the disease phenotype. Conclusions: There is significant inter-rater disagreement in applying the Montreal classification, particularly for disease behavior in Crohn's disease. Improved education or revisions to phenotype criteria may be needed to enhance consensus on the Montreal classification. © 2025 The Author(s). United European Gastroenterology Journal published by Wiley Periodicals LLC on behalf of United European Gastroenterology.",Yes,Rochelle,,,,,,,,,,
"Tiny Language Models for Automation and Control: Overview, Potential Applications, and Future Research Directions","Large Language Models (LLMs), like GPT and BERT, have significantly advanced Natural Language Processing (NLP), enabling high performance on complex tasks. However, their size and computational needs make LLMs unsuitable for deployment on resource-constrained devices, where efficiency, speed, and low power consumption are critical. Tiny Language Models (TLMs), also known as BabyLMs, offer compact alternatives by using advanced compression and optimization techniques to function effectively on devices such as smartphones, Internet of Things (IoT) systems, and embedded platforms. This paper provides a comprehensive survey of TLM architectures and methodologies, including key techniques such as knowledge distillation, quantization, and pruning. Additionally, it explores potential and emerging applications of TLMs in automation and control, covering areas such as edge computing, IoT, industrial automation, and healthcare. The survey discusses challenges unique to TLMs, such as trade-offs between model size and accuracy, limited generalization, and ethical considerations in deployment. Future research directions are also proposed, focusing on hybrid compression techniques, application-specific adaptations, and context-aware TLMs optimized for hardware-specific constraints. This paper aims to serve as a foundational resource for advancing TLMs capabilities across diverse real-world applications.",No,Rochelle,,,,,,,,,,
Navigating challenges and opportunities: Nursing student's views on generative AI in higher education,"BACKGROUND: With the increasing prevalence of generative AI tools in academic 
settings, there is a growing interest in their use among students for learning 
and assessments.
DESIGN: Employing a qualitative descriptive design, this study used 
semi-structured interviews with nursing students to capture the nuanced insights 
of the participants.
METHODS: Semi-structured interviews were digitally recorded and then transcribed 
verbatim. The research team reviewed all the data independently and then 
convened to discuss and reach a consensus on the identified themes.
RESULTS: This study was conducted within the discipline of nursing at a regional 
Australian university. Thirteen nursing students, from both first and second 
year of the programme, were interviewed as part of this study. Six distinct 
themes emerged from the data analysis, including the educational impact of AI 
tools, equitable learning environment, ethical considerations of AI use, 
technology integration, safe and practical utility and generational differences.
CONCLUSIONS: This initial exploration sheds light on the diverse perspectives of 
nursing students concerning the incorporation of generative AI tools in their 
education. It underscores the potential for both positive contributions and 
challenges associated with the integration of generative AI in nursing education 
and practice.

Copyright © 2024. Published by Elsevier Ltd.",No,Rochelle,,,,,,,,,,
Diminished diversity-of-thought in a standard large language model,"We test whether large language models (LLMs) can be used to simulate human participants in social-science studies. To do this, we ran replications of 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, colloquially known as GPT-3.5. Based on our pre-registered analyses, we find that among the eight studies we could analyse, our GPT sample replicated 37.5% of the original results and 37.5% of the Many Labs 2 results. However, we were unable to analyse the remaining six studies due to an unexpected phenomenon we call the ""correct answer"" effect. Different runs of GPT-3.5 answered nuanced questions probing political orientation, economic preference, judgement, and moral philosophy with zero or near-zero variation in responses: with the supposedly ""correct answer."" In one exploratory follow-up study, we found that a ""correct answer"" was robust to changing the demographic details that precede the prompt. In another, we found that most but not all ""correct answers"" were robust to changing the order of answer choices. One of our most striking findings occurred in our replication of the Moral Foundations Theory survey results, where we found GPT-3.5 identifying as a political conservative in 99.6% of the cases, and as a liberal in 99.3% of the cases in the reverse-order condition. However, both self-reported 'GPT conservatives' and 'GPT liberals' showed right-leaning moral foundations. Our results cast doubts on the validity of using LLMs as a general replacement for human participants in the social sciences. Our results also raise concerns that a hypothetical AI-led future may be subject to a diminished diversity of thought.",No,Rochelle,,,,,,,,,,
MediScan: A Framework of U-Health and Prognostic AI Assessment on Medical Imaging,"With technological advancements, remarkable progress has been made with the convergence of health sciences and Artificial Intelligence (AI). Modern health systems are proposed to ease patient diagnostics. However, the challenge is to provide AI-based precautions to patients and doctors for more accurate risk assessment. The proposed healthcare system aims to integrate patients, doctors, laboratories, pharmacies, and administrative personnel use cases and their primary functions onto a single platform. The proposed framework can also process microscopic images, CT scans, X-rays, and MRI to classify malignancy and give doctors a set of AI precautions for patient risk assessment. The proposed framework incorporates various DCNN models for identifying different forms of tumors and fractures in the human body i.e., brain, bones, lungs, kidneys, and skin, and generating precautions with the help of the Fined-Tuned Large Language Model (LLM) i.e., Generative Pretrained Transformer 4 (GPT-4). With enough training data, DCNN can learn highly representative, data-driven, hierarchical image features. The GPT-4 model is selected for generating precautions due to its explanation, reasoning, memory, and accuracy on prior medical assessments and research studies. Classification models are evaluated by classification report (i.e., Recall, Precision, F1 Score, Support, Accuracy, and Macro and Weighted Average) and confusion matrix and have shown robust performance compared to the conventional schemes. © 2024 by the authors.",No,Rochelle,,,,,,,,,,
Assessing the Performance of Chat Generative Pretrained Transformer (ChatGPT) in Answering Andrology-Related Questions,"Objective: The internet and social media have become primary sources of health information, with men frequently turning to these platforms before seeking professional help. Chat generative pretrained transformer (ChatGPT), an artificial intelligence model developed by OpenAI, has gained popularity as a natural language processing program. The present study evaluated the accuracy and reproducibility of ChatGPT's responses to andrology-related questions. Methods: The study analyzed frequently asked andrology questions from health forums, hospital websites, and social media platforms like YouTube and Instagram. Questions were categorized into topics like male hypogonadism, erectile dysfunction, etc. The European Association of Urology (EAU) guideline recommendations were also included. These questions were input into ChatGPT, and responses were evaluated by 3 experienced urologists who scored them on a scale of 1 to 4. Results: Out of 136 evaluated questions, 108 met the criteria. Of these, 87.9% received correct and adequate answers, 9.3% were correct but insufficient, and 3 responses contained both correct and incorrect information. No question was answered completely wrong. The highest correct answer rates were for disorders of ejaculation, penile curvature, and male hypogonadism. The EAU guideline-based questions achieved a correctness rate of 86.3%. The reproducibility of the answers was over 90%. Conclusion: The study found that ChatGPT provided accurate and reliable answers to over 80% of andrology-related questions. While limitations exist, such as potential out-dated data and inability to understand emotional aspects, ChatGPT's potential in the health-care sector is promising. Collaborating with health-care professionals during artificial intelligence model development could enhance its reliability. © Author(s).",Yes,Rochelle,,,,,,,,,,
"Large language models for conducting systematic reviews: on the rise, but not yet ready for use—a scoping review","Background and Objectives: Machine learning promises versatile help in the creation of systematic reviews (SRs). Recently, further developments in the form of large language models (LLMs) and their application in SR conduct attracted attention. We aimed at providing an overview of LLM applications in SR conduct in health research. Methods: We systematically searched MEDLINE, Web of Science, IEEEXplore, ACM Digital Library, Europe PMC (preprints), Google Scholar, and conducted an additional hand search (last search: February 26, 2024). We included scientific articles in English or German, published from April 2021 onwards, building upon the results of a mapping review that has not yet identified LLM applications to support SRs. Two reviewers independently screened studies for eligibility; after piloting, 1 reviewer extracted data, checked by another. Results: Our database search yielded 8054 hits, and we identified 33 articles from our hand search. We finally included 37 articles on LLM support. LLM approaches covered 10 of 13 defined SR steps, most frequently literature search (n = 15, 41%), study selection (n = 14, 38%), and data extraction (n = 11, 30%). The mostly recurring LLM was Generative Pretrained Transformer (GPT) (n = 33, 89%). Validation studies were predominant (n = 21, 57%). In half of the studies, authors evaluated LLM use as promising (n = 20, 54%), one-quarter as neutral (n = 9, 24%) and one-fifth as nonpromising (n = 8, 22%). Conclusion: Although LLMs show promise in supporting SR creation, fully established or validated applications are often lacking. The rapid increase in research on LLMs for evidence synthesis production highlights their growing relevance. Plain Language Summary: Systematic reviews are a crucial tool in health research where experts carefully collect and analyze all available evidence on a specific research question. Creating these reviews is typically time- and resource-intensive, often taking months or even years to complete, as researchers must thoroughly search, evaluate, and synthesize an immense number of scientific studies. For the present article, we conducted a review to understand how new artificial intelligence (AI) tools, specifically large language models (LLMs) like Generative Pretrained Transformer (GPT), can be used to help create systematic reviews in health research. We searched multiple scientific databases and finally found 37 relevant articles. We found that LLMs have been tested to help with various parts of the systematic review process, particularly in 3 main areas: searching scientific literature (41% of studies), selecting relevant studies (38%), and extracting important information from these studies (30%). GPT was the most commonly used LLM, appearing in 89% of the studies. Most of the research (57%) focused on testing whether these AI tools actually work as intended in this context of systematic review production. The results were mixed: about half of the studies found LLMs promising, a quarter were neutral, and one-fifth found them not promising. While LLMs show potential for making the systematic review process more efficient, there is still a lack of fully tested and validated applications. However, the increasing number of studies in this field suggests that these AI tools are becoming increasingly important in creating systematic reviews. © 2025 The Author(s)",No,Rochelle,,,,,,,,,,
Deriving Insights From Open-Ended Learner Feedback: An Exploration of Natural Language Processing Approaches,"INTRODUCTION: Open-ended feedback from learners offers valuable insights for adapting continuing health education to their needs; however, this feedback is burdensome to analyze with qualitative methods. Natural language processing offers a potential solution, but it is unclear which methods provide useful insights. We evaluated natural language processing methods for analyzing open-ended feedback from continuing professional development training at a psychiatric hospital. METHODS: The data set consisted of survey responses from staff participants, which included two text responses on how participants intended to use the training (""intent to use""; n = 480) and other information they wished to share (""open-ended feedback""; n = 291). We analyzed ""intent-to-use"" responses with topic modeling, ""open-ended feedback"" with sentiment analysis, and both responses with large language model (LLM)-based clustering. We examined outputs of each approach to determine their value for deriving insights about the training. RESULTS: Our results indicated that because the ""intent-to-use"" responses were short and lacked diversity, topic modeling was not useful in differentiating content between the topics. For ""open-ended feedback,"" sentiment scores did not accurately reflect the valence of responses. The LLM-based clustering approach generated meaningful clusters characterized by semantically similar words for both responses. DISCUSSION: LLMs may be a useful approach for deriving insights from learner feedback because they capture context, making them capable of distinguishing between responses that use similar words to convey different topics. Future directions involve exploring other methods involving LLMs, or examining how these methods fare on other data sets or types of learner feedback.",No,Rochelle,,,,,,,,,,
Optimizing Resume Parsing Processes by Leveraging Large Language Models,"In the present era of internet revolution, organizations have to go through numerous resumes in order to identify the most suitable candidates for their Job Description (JD), while ensuring that no acquisition of talent is overlooked through human mistakes. Thus, tools like Applicant Tracking Systems (ATS) have taken over the human process of resume screening, enabling assessment of thousands of resumes in a matter of seconds. Although these technologies are incredibly effective, they are not flawless. Consequently, highly qualified individuals may miss out on said opportunities if their resumes are not formatted correctly. Therefore, individuals must ensure that their resume is appropriately structured prior to submitting it to any organization. The study centers on the present literature and suggests an enhanced approach for parsing resumes by leveraging Large Language Models (LLMs).  © 2024 IEEE.",No,Rochelle,,,,,,,,,,
Large language models predict human sensory judgments across six modalities,"3047. Sci Rep. 2024 Sep 13;14(1):21445. doi: 10.1038/s41598-024-72071-1.

Large language models predict human sensory judgments across six modalities.

Marjieh R(1), Sucholutsky I(2), van Rijn P(3), Jacoby N(#)(3)(4), Griffiths 
TL(#)(5)(2).

Author information:
(1)Department of Psychology, Princeton University, Princeton, USA. 
raja.marjieh@princeton.edu.
(2)Department of Computer Science, Princeton University, Princeton, USA.
(3)Max Planck Institute for Empirical Aesthetics, Frankfurt am Main, Germany.
(4)Department of Psychology, Cornell University, Ithaca, USA.
(5)Department of Psychology, Princeton University, Princeton, USA.
(#)Contributed equally

Determining the extent to which the perceptual world can be recovered from 
language is a longstanding problem in philosophy and cognitive science. We show 
that state-of-the-art large language models can unlock new insights into this 
problem by providing a lower bound on the amount of perceptual information that 
can be extracted from language. Specifically, we elicit pairwise similarity 
judgments from GPT models across six psychophysical datasets. We show that the 
judgments are significantly correlated with human data across all domains, 
recovering well-known representations like the color wheel and pitch spiral. 
Surprisingly, we find that a model (GPT-4) co-trained on vision and language 
does not necessarily lead to improvements specific to the visual modality, and 
provides highly correlated predictions with human data irrespective of whether 
direct visual input is provided or purely textual descriptors. To study the 
impact of specific languages, we also apply the models to a multilingual 
color-naming task. We find that GPT-4 replicates cross-linguistic variation in 
English and Russian illuminating the interaction of language and perception.

© 2024. The Author(s).",No,Rochelle,,,,,,,,,,
ChatGPT and Generating a Differential Diagnosis Early in an Emergency Department Presentation,"2725. Ann Emerg Med. 2024 Jan;83(1):83-86. doi: 10.1016/j.annemergmed.2023.08.003. 
Epub 2023 Sep 9.

ChatGPT and Generating a Differential Diagnosis Early in an Emergency Department 
Presentation.

Berg HT, van Bakel B, van de Wouw L, Jie KE, Schipper A, Jansen H, O'Connor RD, 
van Ginneken B, Kurstjens S.",Yes,Rochelle,,,,,,,,,,
Effectiveness of ChatGPT in remote learning environments: An empirical study with medical students in Saudi Arabia,"Purpose: This study aims to assess the effectiveness of ChatGPT in remote learning among medical students. Methods: This cross-sectional survey study recruited 386 medical students from three public universities in Saudi Arabia. Participants completed an online questionnaire designed to assess perceptions of ChatGPT's effectiveness in remote learning. The questionnaire included Likert scale questions to evaluate various aspects of ChatGPT's support in remote learning, such as personalized learning, language and communication skills, and interactive quizzing. Data were analyzed using SPSS, employing descriptive statistics, independent samples t-tests, one-way ANOVA, and Cronbach's alpha to evaluate reliability. Results: Participants mostly used ChatGPT on a weekly (43.2%) or daily (48.7%) basis, primarily on personal computers (62.5%). Mean scores for ChatGPT's support in remote learning were high for personalized learning (4.35), language and communication skills (4.23), and interactive quizzing and assessments (4.01). Statistically significant differences were found based on gender for interactive quizzing (p =.0177) and continuity of education (p =.0122). Conclusion: Despite certain challenges and variations in perceptions based on gender and education level, the overwhelmingly positive attitudes toward ChatGPT highlight its potential as a valuable tool in medical education. © The Author(s) 2024.",No,Rochelle,,,,,,,,,,
GenePT: A Simple But Effective Foundation Model for Genes and Cells Built From ChatGPT,"There has been significant recent progress in leveraging large-scale gene expression data to develop foundation models for single-cell biology. Models such as Geneformer and scGPT implicitly learn gene and cellular functions from the gene expression profiles of millions of cells, which requires extensive data curation and resource-intensive training. Here we explore a much simpler alternative by leveraging ChatGPT embeddings of genes based on literature. Our proposal, GenePT, uses NCBI text descriptions of individual genes with GPT-3.5 to generate gene embeddings. From there, GenePT generates single-cell embeddings in two ways: (i) by averaging the gene embeddings, weighted by each gene’s expression level; or (ii) by creating a sentence embedding for each cell, using gene names ordered by the expression level. Without the need for dataset curation and additional pretraining, GenePT is efficient and easy to use. On many downstream tasks used to evaluate recent single-cell foundation models — e.g., classifying gene properties and cell types — GenePT achieves comparable, and often better, performance than Geneformer and other models. GenePT demonstrates that large language model embedding of literature is a simple and effective path for biological foundation models.",No,Rochelle,,,,,,,,,,
Zeolitic Imidazole Framework/Silica Nanocomposite for Targeted Cancer Therapeutics: Comparative Study of Chemo-Drug Cisplatin (CPt) and Green Platinum (GPt) Efficacy,"2317. Int J Mol Sci. 2024 Mar 9;25(6):3157. doi: 10.3390/ijms25063157.

Zeolitic Imidazole Framework/Silica Nanocomposite for Targeted Cancer 
Therapeutics: Comparative Study of Chemo-Drug Cisplatin (CPt) and Green Platinum 
(GPt) Efficacy.

Alotaibi HG(1)(2)(3), Al-Abbad E(1)(4), Almohazey D(5), Ravinayagam V(6), Akhtar 
S(7), Dafalla H(8), Jermy BR(3).

Author information:
(1)Renewable Energy Unit, Basic & Applied Scientific Research Center (BASRC), 
Imam Abdulrahman Bin Faisal University, Dammam 31441, Saudi Arabia.
(2)Department of Chemistry, Collage of Science, Imam Muhammad Bin Saud Islamic 
University, Riyadh 31441, Saudi Arabia.
(3)Department of Nanomedicine Research, Institute for Research and Medical 
Consultations, Imam Abdulrahman Bin Faisal University, Dammam 31441, Saudi 
Arabia.
(4)Department of Chemistry, College of Science, Imam Abdulrahman Bin Faisal 
University, Dammam 31441, Saudi Arabia.
(5)Department of Stem Cell Research, Institute for Research and Medical 
Consultations, Imam Abdulrahman Bin Faisal University, Dammam 31441, Saudi 
Arabia.
(6)Deanship of Scientific Research & Department of Nanomedicine Research, 
Institute for Research and Medical Consultations, Imam Abdulrahman Bin Faisal 
University, Dammam 31441, Saudi Arabia.
(7)Department of Biophysics Research, Institute for Research and Medical 
Consultations, Imam Abdulrahman Bin Faisal University, Dammam 31441, Saudi 
Arabia.
(8)College of Engineering Research (CER), King Fahd University of Petroleum and 
Minerals, Dhahran 31261, Saudi Arabia.

A chemo-drug such as cisplatin is effective for cancer treatment but remains 
non-specific, is susceptible to drug resistance, and induces several side 
effects on organ systems. Zeolitic imidazolate framework-8, a type of MOF, has 
gained attention, including as a drug delivery method for targeted cancer 
therapeutics. In this study, ZIF-8/Silica nanocomposite was synthesized using a 
one-pot hydrothermal technique using the Stober technique. We studied the effect 
of phyto-synthesized GPt and chemo-drug cisplatin CPt on ZIF-8/Silica for 
targeted efficacy of cancer therapy. The texture, morphology, and chemical 
environment of Pt on ZIF-8/Silica were analyzed using different characterization 
techniques such as XRD, FT-IR, BET, diffuse reflectance spectroscopy, SEM-EDX, 
TEM, zeta potential, and TGA analysis. The isothermal behavior of CPt and GPt 
adsorption was investigated using isotherm models like Langmuir, Freundlich, and 
Temkin isotherm. The adsorption kinetics indicating the adsorption efficiency of 
GPt and CPt are influenced by the concentration of Pt complex and the adsorption 
sites of ZIF-8/Silica. A high entrapment efficiency and loading capacity of GPt 
(86% and 4.3%) and CPt (91% and 4.5%) were evident on ZIF-8/Silica. The 
nanocomposite showed a pH-sensitive Pt release using a dialysis membrane 
technique. For instance, a high release of GPt (93%) was observed under pH = 6.6 
in 72 h, while the release reduced to 50% at pH 7.4 in 72 h. The anti-cancer 
activity of nanoformulations was studied in vitro using MCF7 (breast cancer 
cells) and HFF-1 (human foreskin fibroblast) cells. The findings demonstrated 
that GPt is as effective as CPt; the EC50 value for MCF7 cells treated with 
ZIF-8/Silica/Cp/PEG was 94.86 µg/mL, whereas for ZIF-8/Silica/GPt/PEG it was 
60.19 µg/mL.",No,Rochelle,,,,,,,,,,
"Performance of Advanced Large Language Models (GPT-4o, GPT-4, Gemini 1.5 Pro, Claude 3 Opus) on Japanese Medical Licensing Examination: A Comparative Study","Purpose This study aims to evaluate the accuracy of medical knowledge in the most advanced LLMs (GPT-4o, GPT-4, Gemini 1.5 Pro, and Claude 3 Opus) as of 2024. It is the first to evaluate these LLMs using a non-English medical licensing exam. The insights from this study will guide educators, policymakers, and technical experts in the effective use of AI in medical education and clinical diagnosis. Method Authors inputted 790 questions from Japanese National Medical Examination into the chat windows of the LLMs to obtain responses. Two authors independently assessed the correctness. Authors analyzed the overall accuracy rates of the LLMs and compared their performance on image and non-image questions, questions of varying difficulty levels, general and clinical questions, and questions from different medical specialties. Additionally, authors examined the correlation between the number of publications and LLMs' performance in different medical specialties. Results GPT-4o achieved highest accuracy rate of 89.2% and outperformed the other LLMs in overall performance and each specific category. All four LLMs performed better on non-image questions than image questions, with a 10% accuracy gap. They also performed better on easy questions compared to normal and difficult ones. GPT-4o achieved a 95.0% accuracy rate on easy questions, marking it as an effective knowledge source for medical education. Four LLMs performed worst on ""Gastroenterology and Hepatology"" specialty. There was a positive correlation between the number of publications and LLM performance in different specialties. Conclusions GPT-4o achieved an overall accuracy rate close to 90%, with 95.0% on easy questions, significantly outperforming the other LLMs. This indicates GPT-4o's potential as a knowledge source for easy questions. Image-based questions and question difficulty significantly impact LLM accuracy. ""Gastroenterology and Hepatology"" is the specialty with the lowest performance. The LLMs' performance across medical specialties correlates positively with the number of related publications.",Yes,Rochelle,,,,,,,,,,
Visualizing Mental Health Insights: A Pipeline from Social Media to Chernoff Faces,"This study proposes an approach for analyzing mental health through publicly available social media data, employing Large Language Models (LLMs) and visualization techniques to transform textual data into Chernoff Faces. The analysis began with a dataset comprising 15,744 posts sourced from major social media platforms, which was refined down to 2,621 posts through meticulous data cleaning, feature extraction, and visualization processes. Our methodology includes stages of Data Preparation, Feature Extraction, Chernoff Face Visualization, and Clinical Validation. Dimensionality reduction techniques such as PCA, t-SNE, and UMAP were employed to transform complex mental health data into comprehensible visual representations. Validation involved a survey among 60 volunteer psychiatrists, underscoring the visualizations' potential for enhancing clinical assessments. This work sets the stage for future evaluations, specifically focusing on a combined features method to further refine the visual representation of mental health conditions and to augment the diagnostic tools available to mental health professionals. © 2024 The Authors.",No,Rochelle,,,,,,,,,,
Assessing question characteristic influences on ChatGPT's performance and response-explanation consistency: Insights from Taiwan's Nursing Licensing Exam,"Background: Investigates the integration of an artificial intelligence tool, specifically ChatGPT, in nursing education, addressing its effectiveness in exam preparation and self-assessment. Objective: This study aims to evaluate the performance of ChatGPT, one of the most promising artificial intelligence-driven linguistic understanding tools in answering question banks for nursing licensing examination preparation. It further analyzes question characteristics that might impact the accuracy of ChatGPT-generated answers and examines its reliability through human expert reviews. Design: Cross-sectional survey comparing ChatGPT-generated answers and their explanations. Setting: 400 questions from Taiwan's 2022 Nursing Licensing Exam. Methods: The study analyzed 400 questions from five distinct subjects of Taiwan's 2022 Nursing Licensing Exam using the ChatGPT model which provided answers and in-depth explanations for each question. The impact of various question characteristics, such as type and cognitive level, on the accuracy of the ChatGPT-generated responses was assessed using logistic regression analysis. Additionally, human experts evaluated the explanations for each question, comparing them with the ChatGPT-generated answers to determine consistency. Results: ChatGPT exhibited overall accuracy at 80.75 % for Taiwan's National Nursing Exam, which passes the exam. The accuracy of ChatGPT-generated answers diverged significantly across test subjects, demonstrating a hierarchy ranging from General Medicine at 88.75 %, Medical–Surgical Nursing at 80.0 %, Psychology and Community Nursing at 70.0 %, Obstetrics and Gynecology Nursing at 67.5 %, down to Basic Nursing at 63.0 %. ChatGPT had a higher probability of eliciting incorrect responses for questions with certain characteristics, notably those with clinical vignettes [odds ratio 2.19, 95 % confidence interval 1.24–3.87, P = 0.007] and complex multiple-choice questions [odds ratio 2.37, 95 % confidence interval 1.00–5.60, P = 0.049]. Furthermore, 14.25 % of ChatGPT-generated answers were inconsistent with their explanations, leading to a reduction in the overall accuracy to 74 %. Conclusions: This study reveals the ChatGPT's capabilities and limitations in nursing exam preparation, underscoring its potential as an auxiliary educational tool. It highlights the model's varied performance across different question types and notable inconsistencies between its answers and explanations. The study contributes significantly to the understanding of artificial intelligence in learning environments, guiding the future development of more effective and reliable artificial intelligence-based educational technologies. Tweetable abstract: New study reveals ChatGPT's potential and challenges in nursing education: Achieves 80.75 % accuracy in exam prep but faces hurdles with complex questions and logical consistency. #AIinNursing #AIinEducation #NursingExams #ChatGPT © 2024 Elsevier Ltd",Yes,Rochelle,,,,,,,,,,
GDPR Compliant ChatGPT Playground,"ChatGPT is an AI based conversational tool developed by OpenAPI on the design principles of Large Language Model (LLM) and a publicly accessible tool. ChatGPT has increasingly becoming popular tool for enabling applications involving interactive and contextual search across corporate companies, profit/non-profit organizations, educational/medical institutions, and researcher's community to name a few.The corporate companies are abided by GDPR (General Data Protection Regulation) compliance checks and restricted to share confidential, personal or sensitive information's (hereinafter referred as critical data) into public domains. As ChatGPT server is hosted outside corporate boundaries, to fulfil GDPR compliance check, the corporate companies must have necessary systems in place of any data leaving outside of corporate boundaries.We are proposing a novel solution in identifying GDPR noncompliant DPP (Data Privacy and Protection) entities from the prompt query given to ChatGPT. To achieve this, from the corporate documents we first manually tag critical entities from 'named entity tagging tool' in building the corporate specific DPP entities knowledgebase, build custom NER (Named Entity Recognition) model on top of prebuilt corporate specific DPP entities knowledgebase, an ChatGPT playground interface to accept any user's prompt query, before firing the query to ChatGPT we validate the user's prompt query against custom NER model to detect if any corporate specific DPP entities are present, warn the user by highlighting the corporate specific DPP entities if present to facilitate user in negating the same, we enabled feedback loop from the user for the highlighted corporate specific DPP entities to improvise the custom NER model and logging all the input prompt queries fired to ChatGPT to enable corporate auditing process by using techniques from Natural Language Processing (NLP), Information Extraction, Information Retrieval (IR) and Custom NER model. © 2024 IEEE.",No,Rochelle,,,,,,,,,,
Importance of Patient History in Artificial Intelligence-Assisted Medical Diagnosis: Comparison Study,"BACKGROUND: Medical history contributes approximately 80% to a diagnosis, 
although physical examinations and laboratory investigations increase a 
physician's confidence in the medical diagnosis. The concept of artificial 
intelligence (AI) was first proposed more than 70 years ago. Recently, its role 
in various fields of medicine has grown remarkably. However, no studies have 
evaluated the importance of patient history in AI-assisted medical diagnosis.
OBJECTIVE: This study explored the contribution of patient history to 
AI-assisted medical diagnoses and assessed the accuracy of ChatGPT in reaching a 
clinical diagnosis based on the medical history provided.
METHODS: Using clinical vignettes of 30 cases identified in The BMJ, we 
evaluated the accuracy of diagnoses generated by ChatGPT. We compared the 
diagnoses made by ChatGPT based solely on medical history with the correct 
diagnoses. We also compared the diagnoses made by ChatGPT after incorporating 
additional physical examination findings and laboratory data alongside history 
with the correct diagnoses.
RESULTS: ChatGPT accurately diagnosed 76.6% (23/30) of the cases with only the 
medical history, consistent with previous research targeting physicians. We also 
found that this rate was 93.3% (28/30) when additional information was included.
CONCLUSIONS: Although adding additional information improves diagnostic 
accuracy, patient history remains a significant factor in AI-assisted medical 
diagnosis. Thus, when using AI in medical diagnosis, it is crucial to include 
pertinent and correct patient histories for an accurate diagnosis. Our findings 
emphasize the continued significance of patient history in clinical diagnoses in 
this age and highlight the need for its integration into AI-assisted medical 
diagnosis systems.

© Fumitoshi Fukuzawa, Yasutaka Yanagita, Daiki Yokokawa, Shun Uchida, Shiho 
Yamashita, Yu Li, Kiyoshi Shikino, Tomoko Tsukamoto, Kazutaka Noda, Takanori 
Uehara, Masatomi Ikusaka. Originally published in JMIR Medical Education 
(https://mededu.jmir.org).",Yes,Rochelle,,,,,,,,,,
Playbook workflow builder: Interactive construction of bioinformatics workflows,"The Playbook Workflow Builder (PWB) is a web-based platform to dynamically construct and execute bioinformatics workflows by utilizing a growing network of input datasets, semantically annotated API endpoints, and data visualization tools contributed by an ecosystem of collaborators. Via a user-friendly user interface, workflows can be constructed from contributed building-blocks without technical expertise. The output of each step of the workflow is added into reports containing textual descriptions, figures, tables, and references. To construct workflows, users can click on cards that represent each step in a workflow, or construct workflows via a chat interface that is assisted by a large language model (LLM). Completed workflows are compatible with Common Workflow Language (CWL) and can be published as research publications, slideshows, and posters. To demonstrate how the PWB generates meaningful hypotheses that draw knowledge from across multiple resources, we present several use cases. For example, one of these use cases prioritizes drug targets for individual cancer patients using data from the NIH Common Fund programs GTEx, LINCS, Metabolomics, GlyGen, and ExRNA. The workflows created with PWB can be repurposed to tackle similar use cases using different inputs. The PWB platform is available from: https://playbook-workflow-builder.cloud/.",No,Sully,,,,,,,,,,
"Chat GPT, Gemini or Meta AI: A comparison of AI platforms as a tool for answering higher-order questions in microbiology","Introduction: Artificial intelligence (AI) platforms have achieved a noteworthy role in various fields of medical sciences, ranging from medical education to clinical diagnostics and treatment. ChatGPT, Gemini, and Meta AI are some large language models (LLMs) that have gained immense popularity among students for solving questions from different branches of education. Materials and Methods: A cross-sectional study was conducted in the Department of Microbiology to assess the performance of ChatGPT, Gemini, and Meta AI in answering higher-order questions from various competencies of the microbiology curriculum (MI 1 to 8), according to CBME guidelines. Sixty higher-order questions were compiled from university question papers of two universities. Their responses were assessed by three faculty members from the department. Results: The mean rank scores of ChatGPT, Gemini, and Meta AI were found to be 102.76, 108.5, and 60.23 by Evaluator 1; 106.03, 88.5, and 76.95 by Evaluator 2; and 104.85, 85.6, and 81.04, respectively, indicating lowest overall mean rank score for Meta AI. ChatGPT had the highest mean score in MI 2,3,5,6,7, and 8 competencies, while Gemini had a higher score for MI 1 and 4 competencies. A qualitative assessment of the three platforms was also performed. ChatGPT provided elaborative responses, some responses from Gemini lacked certain significant points, and Meta AI gave answers in bullet points. Conclusions: Both ChatGPT and Gemini have created vast databases to correctly respond to higher-order queries in medical microbiology in comparison to Meta AI. Our study is the first of its kind to compare these three popular LLM platforms for microbiology.  © 2025 Journal of Postgraduate Medicine.",No,Sully,,,,,,,,,,
"Expression of Concern: Evaluating the Factors Influencing Residency Match for Surgical Specialty Applicants and Programs: Challenges and Future Directions (The American Surgeon™, (2024), (00031348241262427), 10.1177/00031348241262427)","Nasef H, Chin B, Breeding T, et al. Impact of Trauma Center Type on Outcomes in Pediatric Population Following Severe Isolated Blunt Traumatic Brain Injuries: A National Analysis. The American Surgeon(TM). 2024;0(0). doi:10.1177/00031348241262432 PMID: 38900905 Zagales R, Watts E, Awan MU, et al. Optimizing Nutritional Needs of Burn Patients: An Evaluation of Nutritional Assessment Tools, Feeding Strategies, and Their Impact on Patient Outcomes. The American Surgeon(TM). 2024;0(0). doi:10.1177/00031348241259042 PMID: 38830580 Nasef H, Tweedie C, Bundschu N, et al. Predictors of Clinical Outcomes and the Need for Massive Transfusion Protocols in Geriatric Trauma Patients With Hemorrhagic Shock: A Systematic Review. The American Surgeon(TM). 2024;0(0). doi:10.1177/00031348241256069 PMID: 38821531 Nasef H, Patel H, Amin Q, et al. Evaluating the Accuracy, Comprehensiveness, and Validity of ChatGPT Compared to Evidence-Based Sources Regarding Common Surgical Conditions: Surgeons’ Perspectives. The American Surgeon(TM). 2024;0(0). doi:10.1177/00031348241256075 PMID: 38794965 Elkbuli A, Bundschu N, Nasef H, Chin B, McClure DL, Rhodes-Lyons HX. National Analysis of Clinical Outcomes Associated With Cirrhotic Blunt Trauma Patients Undergoing Emergency Laparotomy Versus Non-operative Management: A Propensity Case-Matched Analysis. The American Surgeon(TM). 2024;0(0). doi:10.1177/00031348241256078 PMID: 38770924 Published in Issues: Elkbuli A, Breeding T, Martinez B, et al. Evaluating Mortality Outcomes, Transfusion Characteristics, and Risk Factors Associated With Cirrhotic Trauma Patients Undergoing Emergency Laparotomy Versus Non-Operative Management: A National Analysis. The American Surgeon(TM).",No,Sully,,,,,,,,,,
Large language models encode clinical knowledge,"Large language models (LLMs) have demonstrated impressive capabilities, but the bar for clinical applications is high. Attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA. We propose a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. In addition, we evaluate Pathways Language Model(1) (PaLM, a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM(2) on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA(3), MedMCQA(4), PubMedQA(5) and Measuring Massive Multitask Language Understanding (MMLU) clinical topics(6)), including 67.6% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17%. However, human evaluation reveals key gaps. To resolve this, we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians. We show that comprehension, knowledge recall and reasoning improve with model scale and instruction prompt tuning, suggesting the potential utility of LLMs in medicine. Our human evaluations reveal limitations of today’s models, reinforcing the importance of both evaluation frameworks and method development in creating safe, helpful LLMs for clinical applications.",Yes,Sully,Absolute classic paper,,,,,,,,,
A Multiagent-Driven Robotic AI Chemist Enabling Autonomous Chemical Research On Demand,"The successful integration of large language models (LLMs) into laboratory workflows has demonstrated robust capabilities in natural language processing, autonomous task execution, and collaborative problem-solving. This offers an exciting opportunity to realize the dream of autonomous chemical research on demand. Here, we report a robotic AI chemist powered by a hierarchical multiagent system, ChemAgents, based on an on-board Llama-3.1-70B LLM, capable of executing complex, multistep experiments with minimal human intervention. It operates through a Task Manager agent that interacts with human researchers and coordinates four role-specific agents─Literature Reader, Experiment Designer, Computation Performer, and Robot Operator─each leveraging one of four foundational resources: a comprehensive Literature Database, an extensive Protocol Library, a versatile Model Library, and a state-of-the-art Automated Lab. We demonstrate its versatility and efficacy through six experimental tasks of varying complexity, ranging from straightforward synthesis and characterization to more complex exploration and screening of experimental parameters, culminating in the discovery and optimization of functional materials. Additionally, we introduce a seventh task, where ChemAgents is deployed in a new robotic chemistry lab environment to autonomously perform photocatalytic organic reactions, highlighting ChemAgents’s scalability and adaptability. Our multiagent-driven robotic AI chemist showcases the potential of on-demand autonomous chemical research to accelerate discovery and democratize access to advanced experimental capabilities across academic disciplines and industries.",No,Sully,,,,,,,,,,
Age Estimation from Blood Test Results Using a Random Forest Model,"Background and Objectives: From the perspective of preventive medicine, in situations where screening tests are widely used, this study aims to clarify the role of screening data on ageing and health problems by estimating age from screening data with verifying the number of data items required. Materials and Methods: A Python random forest model was generated using Chat GPT and tested. Results: When using all 71 items, including gender, for the test results, a high accuracy of R(2) = 0.7010 was obtained when there were 9243 training data sets (80% of the total number of data sets). The R2 decreased slightly to 0.6937 when the number of data items was reduced to 15 by discarding lesser importance items. When the number of data sets were less than 800 or when the number of data items were less than 7, the R(2) value fell below 0.6. Interestingly, a higher age was tended to be estimated for postmenopausal women compared to pre-menopausal women. Conclusions: The age estimated from blood data by the random forest model (blood age, so to speak) is so precise that it can be useful for assessing physical ageing state. However, the specific relationship between blood age and health status is still unclear, waiting for future research in order to deepen our understanding of this area.",No,Sully,,,,,,,,,,